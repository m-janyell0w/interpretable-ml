{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0e103d-168f-450e-8256-73b08f6de291",
   "metadata": {
    "id": "5e0e103d-168f-450e-8256-73b08f6de291"
   },
   "source": [
    "# LassoNet (Lemhadri et al, 2021)\n",
    "\n",
    "Docs: https://lassonet.ml/\n",
    "\n",
    "LassoNet is basically a residual feedfoward NN-architecture that enables structured feature selection using Lasso penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da347da-2928-4c7a-b7af-3fa938d5f393",
   "metadata": {
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1656662363454,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "3da347da-2928-4c7a-b7af-3fa938d5f393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm-janyellow\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import basic libraries\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import lassonet\n",
    "from lassonet import LassoNetRegressor\n",
    "from lassonet import plot_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import wandb \n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kP-zR_jdxyuG",
   "metadata": {
    "id": "kP-zR_jdxyuG",
    "tags": []
   },
   "source": [
    "## Define some basic helper and preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1c947a-2e8f-47eb-9527-71ca753c5702",
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1656662369949,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "8a1c947a-2e8f-47eb-9527-71ca753c5702"
   },
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "def data_loader(data_path, pickle=True, parse_dates=False):\n",
    "    # To-Do: include date parsing and set index to date/permno\n",
    "    if not pickle:\n",
    "      if parse_dates:\n",
    "        dateparse = lambda x: pd.to_datetime(x, format='%Y-%m-%d', errors='coerce')\n",
    "        data = pd.read_csv(root_path + data_path, index_col=[\"date\",\"permno\"],\n",
    "                           parse_dates=['date'], date_parser=dateparse, skipinitialspace=True)\n",
    "      else:\n",
    "        data = pd.read_csv(root_path + data_path)\n",
    "    else:\n",
    "      data = pd.read_pickle(root_path + data_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a6471f-12d0-4d95-bf74-d71eb9ddcfcc",
   "metadata": {
    "executionInfo": {
     "elapsed": 1785,
     "status": "ok",
     "timestamp": 1656662373441,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "b7a6471f-12d0-4d95-bf74-d71eb9ddcfcc"
   },
   "outputs": [],
   "source": [
    "root_path = \"./data/\"\n",
    "subsample_path = 'subsample_processed_scaled.csv'\n",
    "#subsample = data_loader(subsample_path, pickle=False, parse_dates=True)\n",
    "#subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df28228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'permno', 'cum_return_1_0', 'cum_return_6_2', 'cum_return_12_2',\n",
       "       'cum_return_12_7', 'cum_return_36_13', 'investment', 'd_ceq', 'dpi2a',\n",
       "       'd_shrout', 'ivc', 'noa', 'ato', 'cto', 'd_dgm_dsales', 'eps', 'ipm',\n",
       "       'pcm', 'pm', 'pm_adj', 'prof', 'rna', 'roa', 'roc', 'roe', 'roic',\n",
       "       's2c', 'sat', 'at_adj', 'aoa', 'ol', 'tan', 'oa', 'a2me', 'beme',\n",
       "       'beme_adj', 'c', 'c2d', 'd_so', 'debt2p', 'e2p', 'free_cf', 'ldp',\n",
       "       'nop', 'o2p', 'q', 's2p', 'sales_g', 'at', 'beta', 'beta_daily', 'dto',\n",
       "       'idio_vol', 'lme', 'lme_adj', 'lturnover', 'rel_to_high_price',\n",
       "       'ret_max', 'spread_mean', 'std_turn', 'std_volume', 'suv', 'total_vol',\n",
       "       'ret', 'yy', 'mm_cos', 'mm_sin', 'stock', 'TARGET'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_loader(subsample_path, pickle=False)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed5a929-21fd-4f3f-8fb8-0264352e835c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656662374213,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "0ed5a929-21fd-4f3f-8fb8-0264352e835c"
   },
   "outputs": [],
   "source": [
    "# Load full dataset with multiindex enabled\n",
    "fullsample_path = 'data_processed_scaled.csv'\n",
    "#data = data_loader(fullsample_path, pickle=False, parse_dates=True)\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642d2b89-6388-49b9-bf96-b8f9b5f24f8b",
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1656662376442,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "642d2b89-6388-49b9-bf96-b8f9b5f24f8b"
   },
   "outputs": [],
   "source": [
    "def normalize_target(data):\n",
    "    scaler = StandardScaler()\n",
    "    target = data.TARGET.values.reshape(-1, 1)\n",
    "    #print(target.shape)\n",
    "    data['TARGET'] = scaler.fit_transform(target)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1666e9e-5331-42b5-bd17-208f647f50db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1656662508224,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "e1666e9e-5331-42b5-bd17-208f647f50db",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bfc77547-c142-481d-a94a-d0200ae896c6",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#subsample.TARGET.describe()\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m permnos_total \u001b[38;5;241m=\u001b[39m \u001b[43msubsample\u001b[49m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mdroplevel([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m sample_permno \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(permnos_total) \u001b[38;5;66;03m# ramdom stock selected\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# get and inspect distribution of target of that one\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subsample' is not defined"
     ]
    }
   ],
   "source": [
    "## Inspect target vbl\n",
    "import random\n",
    "#subsample.TARGET.describe()\n",
    "permnos_total = subsample.index.droplevel(['date'])\n",
    "sample_permno = random.choice(permnos_total) # ramdom stock selected\n",
    "\n",
    "# get and inspect distribution of target of that one\n",
    "single_stock = subsample.xs(sample_permno, level='permno')\n",
    "single_stock.TARGET.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7263371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selector\n",
    "features_wo_months = ['cum_return_1_0', 'cum_return_6_2', 'cum_return_12_2',\n",
    "       'cum_return_12_7', 'cum_return_36_13', 'investment', 'd_ceq', 'dpi2a',\n",
    "       'd_shrout', 'ivc', 'noa', 'ato', 'cto', 'd_dgm_dsales', 'eps', 'ipm',\n",
    "       'pcm', 'pm', 'pm_adj', 'prof', 'rna', 'roa', 'roc', 'roe', 'roic',\n",
    "       's2c', 'sat', 'at_adj', 'aoa', 'ol', 'tan', 'oa', 'a2me', 'beme',\n",
    "       'beme_adj', 'c', 'c2d', 'd_so', 'debt2p', 'e2p', 'free_cf', 'ldp',\n",
    "       'nop', 'o2p', 'q', 's2p', 'sales_g', 'at', 'beta', 'beta_daily', 'dto',\n",
    "       'idio_vol', 'lme', 'lme_adj', 'lturnover', 'rel_to_high_price',\n",
    "       'ret_max', 'spread_mean', 'std_turn', 'std_volume', 'suv', 'total_vol',\n",
    "       'ret', 'yy', 'stock', 'TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2f1ca-13f1-45f7-9835-2e660c82a460",
   "metadata": {
    "id": "0cc2f1ca-13f1-45f7-9835-2e660c82a460",
    "tags": []
   },
   "source": [
    "## Simple Train / test split\n",
    "\n",
    "Split data only once into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cfec3bf-7c14-43f7-b1cc-3877acd98457",
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1656662420540,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "4cfec3bf-7c14-43f7-b1cc-3877acd98457"
   },
   "outputs": [],
   "source": [
    "def data_splitter(data, end_of_training=\"1985-12-31\", end_of_validation=\"1990-12-31\"):\n",
    "    # define start of training\n",
    "    start_of_training = data.index.get_level_values(0).min()\n",
    "    \n",
    "    # isolate y from data set\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.TARGET\n",
    "    \n",
    "    # define initial training and test window\n",
    "    train_window = pd.date_range(start=start_of_training, end=end_of_training, freq=\"M\")\n",
    "    train_window = len(train_window)\n",
    "\n",
    "    # slice to required size\n",
    "    X_train = X.loc[pd.IndexSlice[start_of_training:end_of_training,], :]\n",
    "    y_train = y.loc[pd.IndexSlice[start_of_training:end_of_training,]]\n",
    "    X_valid = X.loc[pd.IndexSlice[end_of_training:end_of_validation,], :]\n",
    "    y_valid = y.loc[pd.IndexSlice[end_of_training:end_of_validation,]]\n",
    "    X_test = X.loc[pd.IndexSlice[end_of_validation:,], :]\n",
    "    y_test = y.loc[pd.IndexSlice[end_of_validation:,]]\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2t0Gj0S2ikqC",
   "metadata": {
    "id": "2t0Gj0S2ikqC",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning\n",
    "(https://towardsdatascience.com/bayesian-optimization-for-hyperparameter-tuning-how-and-why-655b0ee0b399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vu2N5hwhPSg8",
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1656662542004,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "vu2N5hwhPSg8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\Documents\\ml-seminar\\2-LassoNet.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39m# Lets try Bayesian search first\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000013?line=1'>2</a>\u001b[0m X_train, X_test, _, y_train, y_test, _ \u001b[39m=\u001b[39m data_splitter(subsample)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000013?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m \u001b[39mimport\u001b[39;00m BayesSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000013?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subsample' is not defined"
     ]
    }
   ],
   "source": [
    "# Lets try Bayesian search first\n",
    "X_train, X_test, _, y_train, y_test, _ = data_splitter(subsample)\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "DzUvtlGROjnW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1656662582172,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "DzUvtlGROjnW",
    "outputId": "fd78d94a-9152-49c0-c0f6-1c648d088dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization took (0.0, 2) minutes.\n"
     ]
    }
   ],
   "source": [
    "# TO-DO: adjust!\n",
    "# Bayesian Search for hyperparm tuning\n",
    "n_iter = 10\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": (0.0001, 0.1, \"log-uniform\"),\n",
    "    \"hidden_dims\" : [d/3, 2*d/3, d, 4*d/3]\n",
    "}\n",
    "\n",
    "reg_bay = BayesSearchCV(estimator=ExplainableBoostingRegressor(random_state=0, n_jobs=-1),\n",
    "                    search_spaces=param_grid,\n",
    "                    n_iter=n_iter,\n",
    "                    cv=5,\n",
    "                    n_jobs=8,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    random_state=0)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Run Bayes Search (this takes a while)\n",
    "#model_bay = reg_bay.fit(X_train, y_train)\n",
    "\n",
    "execution_time = (datetime.now() - start_time).total_seconds()\n",
    "print(f\"Optimization took {np.round(execution_time/60),2} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXJsO112Z_vL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1656618993520,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "yXJsO112Z_vL",
    "outputId": "b0456bdc-3075-4036-8768-f3014b495635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: OrderedDict([('early_stopping_rounds', 37), ('early_stopping_tolerance', 0.00020919480782183626), ('learning_rate', 0.000609840586504895), ('max_bins', 230), ('max_rounds', 3000)]) \n",
      " with best score of -0.012216270250622302 \n"
     ]
    }
   ],
   "source": [
    "# model_bay\n",
    "#X_train, X_test, _, y_train, y_test, _ = data_splitter(subsample)\n",
    "\n",
    "# model can be saved, used for predictions or scoring\n",
    "best_parms = model_bay.best_params_\n",
    "best_score = model_bay.best_score_\n",
    "best_estimator = model_bay.best_estimator_\n",
    "cv_results = model_bay.cv_results_\n",
    "print(f\"Best params are: {best_parms} \\n with best score of {best_score} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83f6e7-6831-421b-950c-af403a3a69c2",
   "metadata": {
    "id": "9f83f6e7-6831-421b-950c-af403a3a69c2",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train and Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea9f202-64f3-42fc-9ff9-b33823b2d070",
   "metadata": {
    "id": "9ea9f202-64f3-42fc-9ff9-b33823b2d070"
   },
   "outputs": [],
   "source": [
    "# helper to isolate y from data set\n",
    "def isolate_target(data):\n",
    "    X = data.iloc[:,:-1]\n",
    "    #print(X)\n",
    "    y = data.TARGET\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32deb6e8-0328-42f7-ab7b-b4bf1d29ba3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1656662379339,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "32deb6e8-0328-42f7-ab7b-b4bf1d29ba3f"
   },
   "outputs": [],
   "source": [
    "def feature_selector(data, selectors):\n",
    "    return data.loc[:,selectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb9bb16-67e4-4f8c-a509-a3d86407cbfe",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1656662679407,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "2fb9bb16-67e4-4f8c-a509-a3d86407cbfe"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, tune=False, param_dict={}):\n",
    "    if tune:\n",
    "        print(\"model is being tuned\")\n",
    "        model.set_params(**param_dict)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, X_valid, y_valid):\n",
    "    return model.score(X_valid, y_valid) # validation set RÂ²\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    rmse_ = np.sqrt(((y_test - y_pred)**2).mean())  # np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    return rmse_\n",
    "\n",
    "def visualize_feature_selection(model, X_test, y_test):\n",
    "    plot_path(model, path, X_test, y_test)\n",
    "    plt.savefig(f'{results_dir}Lassonet_path_{run_id}')\n",
    "    \n",
    "def df_to_array(X_train, X_test, y_train, y_test):\n",
    "    X_train, X_test, y_train, y_test = X_train.values, X_test.values, y_train.values, y_test.values\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4000c1-0771-4ba0-922f-b9af8868b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(X, model, feature_names, run_id=1):\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    importances = model.feature_importances_.numpy()\n",
    "    order = np.argsort(importances)[::-1]\n",
    "    importances = importances[order]\n",
    "    ordered_feature_names = [feature_names[i] for i in order[:30]] # show the first 30\n",
    "\n",
    "    w = round(n_features*0.6)\n",
    "    h = round(n_features*0.4)\n",
    "    plt.figure(figsize=(w,h))\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.bar(\n",
    "        np.arange(n_features),\n",
    "        importances,\n",
    "        #color=color,\n",
    "    )\n",
    "    plt.xticks(np.arange(n_features), ordered_feature_names, rotation=90)\n",
    "    #colors = {\"real features\": \"g\", \"fake features\": \"r\"}\n",
    "    #labels = list(colors.keys())\n",
    "    #handles = [plt.Rectangle((0, 0), 1, 1, color=colors[label]) for label in labels]\n",
    "    #plt.legend(handles, labels)\n",
    "    plt.ylabel(\"Feature importance\")\n",
    "\n",
    "    plt.savefig(f\"feature_importance_plot_{run_id}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03ae83-b334-4a4d-b933-a2e9ffd50798",
   "metadata": {
    "id": "dd03ae83-b334-4a4d-b933-a2e9ffd50798",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pipeline - bring it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e38b0d7-2017-4b56-a1e2-8affd7bbdbae",
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1656667748384,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "5e38b0d7-2017-4b56-a1e2-8affd7bbdbae"
   },
   "outputs": [],
   "source": [
    "def pipeline(data_name, pickle, date_parse, model=LassoNetRegressor(random_state=0, verbose=True), \n",
    "             tune=False, feature_selection=[], param_dict={}):\n",
    "    # init training run\n",
    "    wandb.init(project=\"interpretable-ml\", group=\"lassonet-studies\")\n",
    "    # start timer for total run time\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # load an split data sets\n",
    "    data = data_loader(data_name, pickle, date_parse)\n",
    "    if len(feature_selection)>=1:\n",
    "          data = feature_selector(data, feature_selection) \n",
    "    data = normalize_target(data)\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = data_splitter(data)\n",
    "    # bring data to array\n",
    "    X_train, X_test, y_train, y_test = df_to_array(X_train, X_valid, y_train, y_valid)\n",
    "    \n",
    "    # train the model\n",
    "    fitted_model = train_model(model, X_train, y_train, tune, param_dict)\n",
    "    \n",
    "    # plot feat selection path\n",
    "    visualize_feature_selection(fitted_model, X_test, y_test)\n",
    "    \n",
    "    # evaluate model perdormance\n",
    "    params = fitted_model.get_params()\n",
    "    is_score = validate_model(model, X_train, y_train)\n",
    "    oos_score = validate_model(model, X_test, y_test)\n",
    "    y_pred = fitted_model.predict(X_test)\n",
    "    rmse_test = rmse(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # finish training\n",
    "    execution_time = (datetime.now() - start_time).total_seconds()\n",
    "    wandb.log({\"mse\" : mse, \"rmse\" : rmse_test, \"mae\" : mae, \"n_features\": n_features, \n",
    "               \"time_spent\" : execution_time, \"Model Params\" : params})\n",
    "    wandb.finish()\n",
    "    return execution_time, is_score, oos_score, mae, mse, rmse_test, params, X_valid, y_valid, y_pred, fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f8c8a-f583-4cc0-b9d2-1a09d6767294",
   "metadata": {},
   "source": [
    "## First experiment: all features, but sampled permnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95c1bac-0ac4-449c-b7e3-bfe32a967e62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dense model in 159 epochs, val loss 7.60e-01, regularization 2.93e+00\n",
      "Lambda = 7.60e-01, selected 67 features in 5 epochs\n",
      "val_objective 3.01e+00, val_loss 7.66e-01, regularization 2.95e+00\n",
      "Lambda = 7.75e-01, selected 67 features in 100 epochs\n",
      "val_objective 1.86e+00, val_loss 7.81e-01, regularization 1.39e+00\n",
      "Lambda = 7.91e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.87e+00, val_loss 7.81e-01, regularization 1.37e+00\n",
      "Lambda = 8.07e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.87e+00, val_loss 7.80e-01, regularization 1.36e+00\n",
      "Lambda = 8.23e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.88e+00, val_loss 7.80e-01, regularization 1.34e+00\n",
      "Lambda = 8.39e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.89e+00, val_loss 7.80e-01, regularization 1.32e+00\n",
      "Lambda = 8.56e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.90e+00, val_loss 7.79e-01, regularization 1.31e+00\n",
      "Lambda = 8.73e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.91e+00, val_loss 7.79e-01, regularization 1.30e+00\n",
      "Lambda = 8.91e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.93e+00, val_loss 7.78e-01, regularization 1.29e+00\n",
      "Lambda = 9.08e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.94e+00, val_loss 7.78e-01, regularization 1.28e+00\n",
      "Lambda = 9.26e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.95e+00, val_loss 7.78e-01, regularization 1.27e+00\n",
      "Lambda = 9.45e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 7.77e-01, regularization 1.25e+00\n",
      "Lambda = 9.64e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 7.77e-01, regularization 1.24e+00\n",
      "Lambda = 9.83e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.99e+00, val_loss 7.76e-01, regularization 1.24e+00\n",
      "Lambda = 1.00e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.01e+00, val_loss 7.76e-01, regularization 1.23e+00\n",
      "Lambda = 1.02e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.03e+00, val_loss 7.75e-01, regularization 1.22e+00\n",
      "Lambda = 1.04e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.05e+00, val_loss 7.75e-01, regularization 1.22e+00\n",
      "Lambda = 1.06e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.07e+00, val_loss 7.74e-01, regularization 1.21e+00\n",
      "Lambda = 1.09e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.09e+00, val_loss 7.74e-01, regularization 1.21e+00\n",
      "Lambda = 1.11e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.11e+00, val_loss 7.73e-01, regularization 1.20e+00\n",
      "Lambda = 1.13e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.13e+00, val_loss 7.72e-01, regularization 1.20e+00\n",
      "Lambda = 1.15e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.15e+00, val_loss 7.72e-01, regularization 1.20e+00\n",
      "Lambda = 1.18e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.18e+00, val_loss 7.71e-01, regularization 1.20e+00\n",
      "Lambda = 1.20e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.20e+00, val_loss 7.71e-01, regularization 1.19e+00\n",
      "Lambda = 1.22e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.23e+00, val_loss 7.70e-01, regularization 1.19e+00\n",
      "Lambda = 1.25e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.25e+00, val_loss 7.70e-01, regularization 1.19e+00\n",
      "Lambda = 1.27e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.28e+00, val_loss 7.69e-01, regularization 1.19e+00\n",
      "Lambda = 1.30e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.30e+00, val_loss 7.69e-01, regularization 1.18e+00\n",
      "Lambda = 1.32e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.33e+00, val_loss 7.69e-01, regularization 1.18e+00\n",
      "Lambda = 1.35e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.36e+00, val_loss 7.68e-01, regularization 1.18e+00\n",
      "Lambda = 1.38e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.38e+00, val_loss 7.68e-01, regularization 1.17e+00\n",
      "Lambda = 1.40e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.41e+00, val_loss 7.68e-01, regularization 1.17e+00\n",
      "Lambda = 1.43e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.44e+00, val_loss 7.67e-01, regularization 1.17e+00\n",
      "Lambda = 1.46e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.47e+00, val_loss 7.67e-01, regularization 1.16e+00\n",
      "Lambda = 1.49e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.50e+00, val_loss 7.67e-01, regularization 1.16e+00\n",
      "Lambda = 1.52e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.53e+00, val_loss 7.67e-01, regularization 1.16e+00\n",
      "Lambda = 1.55e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.56e+00, val_loss 7.66e-01, regularization 1.15e+00\n",
      "Lambda = 1.58e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.59e+00, val_loss 7.66e-01, regularization 1.15e+00\n",
      "Lambda = 1.61e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.62e+00, val_loss 7.66e-01, regularization 1.15e+00\n",
      "Lambda = 1.65e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.65e+00, val_loss 7.66e-01, regularization 1.14e+00\n",
      "Lambda = 1.68e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.68e+00, val_loss 7.66e-01, regularization 1.14e+00\n",
      "Lambda = 1.71e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.71e+00, val_loss 7.65e-01, regularization 1.14e+00\n",
      "Lambda = 1.75e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.75e+00, val_loss 7.65e-01, regularization 1.13e+00\n",
      "Lambda = 1.78e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.78e+00, val_loss 7.65e-01, regularization 1.13e+00\n",
      "Lambda = 1.82e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.81e+00, val_loss 7.65e-01, regularization 1.13e+00\n",
      "Lambda = 1.85e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.85e+00, val_loss 7.65e-01, regularization 1.12e+00\n",
      "Lambda = 1.89e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.88e+00, val_loss 7.65e-01, regularization 1.12e+00\n",
      "Lambda = 1.93e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.92e+00, val_loss 7.64e-01, regularization 1.12e+00\n",
      "Lambda = 1.97e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.95e+00, val_loss 7.64e-01, regularization 1.11e+00\n",
      "Lambda = 2.01e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.99e+00, val_loss 7.64e-01, regularization 1.11e+00\n",
      "Lambda = 2.05e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.03e+00, val_loss 7.64e-01, regularization 1.11e+00\n",
      "Lambda = 2.09e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.06e+00, val_loss 7.64e-01, regularization 1.10e+00\n",
      "Lambda = 2.13e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.10e+00, val_loss 7.64e-01, regularization 1.10e+00\n",
      "Lambda = 2.17e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.14e+00, val_loss 7.64e-01, regularization 1.09e+00\n",
      "Lambda = 2.21e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.18e+00, val_loss 7.64e-01, regularization 1.09e+00\n",
      "Lambda = 2.26e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.22e+00, val_loss 7.64e-01, regularization 1.09e+00\n",
      "Lambda = 2.30e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.26e+00, val_loss 7.63e-01, regularization 1.08e+00\n",
      "Lambda = 2.35e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.30e+00, val_loss 7.63e-01, regularization 1.08e+00\n",
      "Lambda = 2.40e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.34e+00, val_loss 7.63e-01, regularization 1.08e+00\n",
      "Lambda = 2.44e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.38e+00, val_loss 7.63e-01, regularization 1.07e+00\n",
      "Lambda = 2.49e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.42e+00, val_loss 7.63e-01, regularization 1.07e+00\n",
      "Lambda = 2.54e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.47e+00, val_loss 7.63e-01, regularization 1.06e+00\n",
      "Lambda = 2.59e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.51e+00, val_loss 7.63e-01, regularization 1.06e+00\n",
      "Lambda = 2.65e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.55e+00, val_loss 7.63e-01, regularization 1.05e+00\n",
      "Lambda = 2.70e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.60e+00, val_loss 7.63e-01, regularization 1.05e+00\n",
      "Lambda = 2.75e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.64e+00, val_loss 7.63e-01, regularization 1.05e+00\n",
      "Lambda = 2.81e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.69e+00, val_loss 7.63e-01, regularization 1.04e+00\n",
      "Lambda = 2.86e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.74e+00, val_loss 7.63e-01, regularization 1.04e+00\n",
      "Lambda = 2.92e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.78e+00, val_loss 7.62e-01, regularization 1.03e+00\n",
      "Lambda = 2.98e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.83e+00, val_loss 7.62e-01, regularization 1.03e+00\n",
      "Lambda = 3.04e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.88e+00, val_loss 7.62e-01, regularization 1.03e+00\n",
      "Lambda = 3.10e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.93e+00, val_loss 7.62e-01, regularization 1.02e+00\n",
      "Lambda = 3.16e+00, selected 67 features in 5 epochs\n",
      "val_objective 3.98e+00, val_loss 7.62e-01, regularization 1.02e+00\n",
      "Lambda = 3.23e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.03e+00, val_loss 7.62e-01, regularization 1.01e+00\n",
      "Lambda = 3.29e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.08e+00, val_loss 7.62e-01, regularization 1.01e+00\n",
      "Lambda = 3.36e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.13e+00, val_loss 7.62e-01, regularization 1.00e+00\n",
      "Lambda = 3.42e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.19e+00, val_loss 7.62e-01, regularization 1.00e+00\n",
      "Lambda = 3.49e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.24e+00, val_loss 7.62e-01, regularization 9.97e-01\n",
      "Lambda = 3.56e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.30e+00, val_loss 7.62e-01, regularization 9.93e-01\n",
      "Lambda = 3.63e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.36e+00, val_loss 7.62e-01, regularization 9.89e-01\n",
      "Lambda = 3.71e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.41e+00, val_loss 7.62e-01, regularization 9.85e-01\n",
      "Lambda = 3.78e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.47e+00, val_loss 7.62e-01, regularization 9.81e-01\n",
      "Lambda = 3.86e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.53e+00, val_loss 7.62e-01, regularization 9.77e-01\n",
      "Lambda = 3.93e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.59e+00, val_loss 7.62e-01, regularization 9.73e-01\n",
      "Lambda = 4.01e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.65e+00, val_loss 7.62e-01, regularization 9.69e-01\n",
      "Lambda = 4.09e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.71e+00, val_loss 7.62e-01, regularization 9.65e-01\n",
      "Lambda = 4.17e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.77e+00, val_loss 7.62e-01, regularization 9.62e-01\n",
      "Lambda = 4.26e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.84e+00, val_loss 7.62e-01, regularization 9.58e-01\n",
      "Lambda = 4.34e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.90e+00, val_loss 7.61e-01, regularization 9.54e-01\n",
      "Lambda = 4.43e+00, selected 67 features in 5 epochs\n",
      "val_objective 4.97e+00, val_loss 7.61e-01, regularization 9.50e-01\n",
      "Lambda = 4.52e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.04e+00, val_loss 7.61e-01, regularization 9.46e-01\n",
      "Lambda = 4.61e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.10e+00, val_loss 7.61e-01, regularization 9.43e-01\n",
      "Lambda = 4.70e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.17e+00, val_loss 7.61e-01, regularization 9.39e-01\n",
      "Lambda = 4.79e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.24e+00, val_loss 7.61e-01, regularization 9.35e-01\n",
      "Lambda = 4.89e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.31e+00, val_loss 7.61e-01, regularization 9.31e-01\n",
      "Lambda = 4.99e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.38e+00, val_loss 7.61e-01, regularization 9.27e-01\n",
      "Lambda = 5.09e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.46e+00, val_loss 7.61e-01, regularization 9.23e-01\n",
      "Lambda = 5.19e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.53e+00, val_loss 7.61e-01, regularization 9.19e-01\n",
      "Lambda = 5.29e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.61e+00, val_loss 7.61e-01, regularization 9.15e-01\n",
      "Lambda = 5.40e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.68e+00, val_loss 7.61e-01, regularization 9.11e-01\n",
      "Lambda = 5.51e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.76e+00, val_loss 7.61e-01, regularization 9.07e-01\n",
      "Lambda = 5.62e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.83e+00, val_loss 7.61e-01, regularization 9.03e-01\n",
      "Lambda = 5.73e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.91e+00, val_loss 7.61e-01, regularization 8.99e-01\n",
      "Lambda = 5.84e+00, selected 67 features in 5 epochs\n",
      "val_objective 5.99e+00, val_loss 7.61e-01, regularization 8.95e-01\n",
      "Lambda = 5.96e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.07e+00, val_loss 7.61e-01, regularization 8.91e-01\n",
      "Lambda = 6.08e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.15e+00, val_loss 7.61e-01, regularization 8.87e-01\n",
      "Lambda = 6.20e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.24e+00, val_loss 7.61e-01, regularization 8.83e-01\n",
      "Lambda = 6.32e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.32e+00, val_loss 7.61e-01, regularization 8.79e-01\n",
      "Lambda = 6.45e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.40e+00, val_loss 7.61e-01, regularization 8.75e-01\n",
      "Lambda = 6.58e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.49e+00, val_loss 7.61e-01, regularization 8.70e-01\n",
      "Lambda = 6.71e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.58e+00, val_loss 7.60e-01, regularization 8.66e-01\n",
      "Lambda = 6.85e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.66e+00, val_loss 7.60e-01, regularization 8.62e-01\n",
      "Lambda = 6.98e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.75e+00, val_loss 7.60e-01, regularization 8.58e-01\n",
      "Lambda = 7.12e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.84e+00, val_loss 7.60e-01, regularization 8.54e-01\n",
      "Lambda = 7.27e+00, selected 67 features in 5 epochs\n",
      "val_objective 6.93e+00, val_loss 7.60e-01, regularization 8.50e-01\n",
      "Lambda = 7.41e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.03e+00, val_loss 7.60e-01, regularization 8.46e-01\n",
      "Lambda = 7.56e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.12e+00, val_loss 7.60e-01, regularization 8.42e-01\n",
      "Lambda = 7.71e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.22e+00, val_loss 7.60e-01, regularization 8.38e-01\n",
      "Lambda = 7.86e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.31e+00, val_loss 7.60e-01, regularization 8.33e-01\n",
      "Lambda = 8.02e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.41e+00, val_loss 7.60e-01, regularization 8.29e-01\n",
      "Lambda = 8.18e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.51e+00, val_loss 7.60e-01, regularization 8.25e-01\n",
      "Lambda = 8.35e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.61e+00, val_loss 7.60e-01, regularization 8.21e-01\n",
      "Lambda = 8.51e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.72e+00, val_loss 7.60e-01, regularization 8.17e-01\n",
      "Lambda = 8.68e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.82e+00, val_loss 7.60e-01, regularization 8.13e-01\n",
      "Lambda = 8.86e+00, selected 67 features in 5 epochs\n",
      "val_objective 7.93e+00, val_loss 7.60e-01, regularization 8.09e-01\n",
      "Lambda = 9.03e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.03e+00, val_loss 7.60e-01, regularization 8.05e-01\n",
      "Lambda = 9.21e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.14e+00, val_loss 7.60e-01, regularization 8.01e-01\n",
      "Lambda = 9.40e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.25e+00, val_loss 7.60e-01, regularization 7.97e-01\n",
      "Lambda = 9.59e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.36e+00, val_loss 7.59e-01, regularization 7.93e-01\n",
      "Lambda = 9.78e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.47e+00, val_loss 7.59e-01, regularization 7.89e-01\n",
      "Lambda = 9.97e+00, selected 67 features in 5 epochs\n",
      "val_objective 8.58e+00, val_loss 7.59e-01, regularization 7.84e-01\n",
      "Lambda = 1.02e+01, selected 67 features in 5 epochs\n",
      "val_objective 8.70e+00, val_loss 7.59e-01, regularization 7.80e-01\n",
      "Lambda = 1.04e+01, selected 67 features in 5 epochs\n",
      "val_objective 8.81e+00, val_loss 7.59e-01, regularization 7.76e-01\n",
      "Lambda = 1.06e+01, selected 67 features in 5 epochs\n",
      "val_objective 8.93e+00, val_loss 7.59e-01, regularization 7.72e-01\n",
      "Lambda = 1.08e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.05e+00, val_loss 7.59e-01, regularization 7.68e-01\n",
      "Lambda = 1.10e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.17e+00, val_loss 7.59e-01, regularization 7.64e-01\n",
      "Lambda = 1.12e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.29e+00, val_loss 7.59e-01, regularization 7.60e-01\n",
      "Lambda = 1.15e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.41e+00, val_loss 7.59e-01, regularization 7.56e-01\n",
      "Lambda = 1.17e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.54e+00, val_loss 7.59e-01, regularization 7.51e-01\n",
      "Lambda = 1.19e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.67e+00, val_loss 7.59e-01, regularization 7.47e-01\n",
      "Lambda = 1.22e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.79e+00, val_loss 7.59e-01, regularization 7.43e-01\n",
      "Lambda = 1.24e+01, selected 67 features in 5 epochs\n",
      "val_objective 9.92e+00, val_loss 7.58e-01, regularization 7.39e-01\n",
      "Lambda = 1.26e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.00e+01, val_loss 7.58e-01, regularization 7.35e-01\n",
      "Lambda = 1.29e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.02e+01, val_loss 7.58e-01, regularization 7.30e-01\n",
      "Lambda = 1.32e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.03e+01, val_loss 7.58e-01, regularization 7.26e-01\n",
      "Lambda = 1.34e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.04e+01, val_loss 7.58e-01, regularization 7.22e-01\n",
      "Lambda = 1.37e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.06e+01, val_loss 7.58e-01, regularization 7.17e-01\n",
      "Lambda = 1.40e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.07e+01, val_loss 7.58e-01, regularization 7.13e-01\n",
      "Lambda = 1.42e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.08e+01, val_loss 7.58e-01, regularization 7.08e-01\n",
      "Lambda = 1.45e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.10e+01, val_loss 7.58e-01, regularization 7.04e-01\n",
      "Lambda = 1.48e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.11e+01, val_loss 7.58e-01, regularization 6.99e-01\n",
      "Lambda = 1.51e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.13e+01, val_loss 7.58e-01, regularization 6.95e-01\n",
      "Lambda = 1.54e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.14e+01, val_loss 7.58e-01, regularization 6.90e-01\n",
      "Lambda = 1.57e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.15e+01, val_loss 7.57e-01, regularization 6.86e-01\n",
      "Lambda = 1.60e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.17e+01, val_loss 7.57e-01, regularization 6.81e-01\n",
      "Lambda = 1.64e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.18e+01, val_loss 7.57e-01, regularization 6.76e-01\n",
      "Lambda = 1.67e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.20e+01, val_loss 7.57e-01, regularization 6.72e-01\n",
      "Lambda = 1.70e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.21e+01, val_loss 7.57e-01, regularization 6.67e-01\n",
      "Lambda = 1.74e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.23e+01, val_loss 7.57e-01, regularization 6.63e-01\n",
      "Lambda = 1.77e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.24e+01, val_loss 7.57e-01, regularization 6.58e-01\n",
      "Lambda = 1.81e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.26e+01, val_loss 7.57e-01, regularization 6.53e-01\n",
      "Lambda = 1.84e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.27e+01, val_loss 7.57e-01, regularization 6.49e-01\n",
      "Lambda = 1.88e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.29e+01, val_loss 7.57e-01, regularization 6.44e-01\n",
      "Lambda = 1.92e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.30e+01, val_loss 7.57e-01, regularization 6.39e-01\n",
      "Lambda = 1.96e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.32e+01, val_loss 7.57e-01, regularization 6.34e-01\n",
      "Lambda = 1.99e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.33e+01, val_loss 7.56e-01, regularization 6.29e-01\n",
      "Lambda = 2.03e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.35e+01, val_loss 7.56e-01, regularization 6.25e-01\n",
      "Lambda = 2.08e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.36e+01, val_loss 7.56e-01, regularization 6.20e-01\n",
      "Lambda = 2.12e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.38e+01, val_loss 7.56e-01, regularization 6.15e-01\n",
      "Lambda = 2.16e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.39e+01, val_loss 7.56e-01, regularization 6.10e-01\n",
      "Lambda = 2.20e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.41e+01, val_loss 7.56e-01, regularization 6.05e-01\n",
      "Lambda = 2.25e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.42e+01, val_loss 7.56e-01, regularization 6.00e-01\n",
      "Lambda = 2.29e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.44e+01, val_loss 7.56e-01, regularization 5.95e-01\n",
      "Lambda = 2.34e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.45e+01, val_loss 7.56e-01, regularization 5.90e-01\n",
      "Lambda = 2.38e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.47e+01, val_loss 7.56e-01, regularization 5.85e-01\n",
      "Lambda = 2.43e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.49e+01, val_loss 7.55e-01, regularization 5.80e-01\n",
      "Lambda = 2.48e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.50e+01, val_loss 7.55e-01, regularization 5.75e-01\n",
      "Lambda = 2.53e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.52e+01, val_loss 7.55e-01, regularization 5.70e-01\n",
      "Lambda = 2.58e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.53e+01, val_loss 7.55e-01, regularization 5.64e-01\n",
      "Lambda = 2.63e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.55e+01, val_loss 7.55e-01, regularization 5.59e-01\n",
      "Lambda = 2.68e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.56e+01, val_loss 7.55e-01, regularization 5.54e-01\n",
      "Lambda = 2.74e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.58e+01, val_loss 7.55e-01, regularization 5.49e-01\n",
      "Lambda = 2.79e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.59e+01, val_loss 7.55e-01, regularization 5.44e-01\n",
      "Lambda = 2.85e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.61e+01, val_loss 7.55e-01, regularization 5.39e-01\n",
      "Lambda = 2.91e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.63e+01, val_loss 7.55e-01, regularization 5.33e-01\n",
      "Lambda = 2.96e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.64e+01, val_loss 7.55e-01, regularization 5.28e-01\n",
      "Lambda = 3.02e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.66e+01, val_loss 7.55e-01, regularization 5.23e-01\n",
      "Lambda = 3.08e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.67e+01, val_loss 7.54e-01, regularization 5.17e-01\n",
      "Lambda = 3.15e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.69e+01, val_loss 7.54e-01, regularization 5.12e-01\n",
      "Lambda = 3.21e+01, selected 67 features in 25 epochs\n",
      "val_objective 1.63e+01, val_loss 7.54e-01, regularization 4.85e-01\n",
      "Lambda = 3.27e+01, selected 67 features in 45 epochs\n",
      "val_objective 1.52e+01, val_loss 7.53e-01, regularization 4.41e-01\n",
      "Lambda = 3.34e+01, selected 67 features in 100 epochs\n",
      "val_objective 1.26e+01, val_loss 7.53e-01, regularization 3.56e-01\n",
      "Lambda = 3.40e+01, selected 67 features in 100 epochs\n",
      "val_objective 1.04e+01, val_loss 7.52e-01, regularization 2.82e-01\n",
      "Lambda = 3.47e+01, selected 67 features in 100 epochs\n",
      "val_objective 8.26e+00, val_loss 7.52e-01, regularization 2.16e-01\n",
      "Lambda = 3.54e+01, selected 67 features in 100 epochs\n",
      "val_objective 6.29e+00, val_loss 7.52e-01, regularization 1.56e-01\n",
      "Lambda = 3.61e+01, selected 65 features in 100 epochs\n",
      "val_objective 4.40e+00, val_loss 7.54e-01, regularization 1.01e-01\n",
      "Lambda = 3.69e+01, selected 50 features in 100 epochs\n",
      "val_objective 2.71e+00, val_loss 7.55e-01, regularization 5.30e-02\n",
      "Lambda = 3.76e+01, selected 24 features in 100 epochs\n",
      "val_objective 1.68e+00, val_loss 7.57e-01, regularization 2.46e-02\n",
      "Lambda = 3.83e+01, selected 9 features in 100 epochs\n",
      "val_objective 1.27e+00, val_loss 7.59e-01, regularization 1.32e-02\n",
      "Lambda = 3.91e+01, selected 7 features in 20 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.18e-02\n",
      "Lambda = 3.99e+01, selected 7 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.16e-02\n",
      "Lambda = 4.07e+01, selected 6 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.13e-02\n",
      "Lambda = 4.15e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.10e-02\n",
      "Lambda = 4.23e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.08e-02\n",
      "Lambda = 4.32e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.06e-02\n",
      "Lambda = 4.40e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.04e-02\n",
      "Lambda = 4.49e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.59e-01, regularization 1.01e-02\n",
      "Lambda = 4.58e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.59e-01, regularization 9.91e-03\n",
      "Lambda = 4.67e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.59e-01, regularization 9.67e-03\n",
      "Lambda = 4.77e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.60e-01, regularization 9.47e-03\n",
      "Lambda = 4.86e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.60e-01, regularization 9.27e-03\n",
      "Lambda = 4.96e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.60e-01, regularization 9.07e-03\n",
      "Lambda = 5.06e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.60e-01, regularization 8.87e-03\n",
      "Lambda = 5.16e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 7.60e-01, regularization 8.66e-03\n",
      "Lambda = 5.26e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 8.45e-03\n",
      "Lambda = 5.37e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 8.24e-03\n",
      "Lambda = 5.48e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 8.03e-03\n",
      "Lambda = 5.59e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.84e-03\n",
      "Lambda = 5.70e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.65e-03\n",
      "Lambda = 5.81e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.49e-03\n",
      "Lambda = 5.93e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.36e-03\n",
      "Lambda = 6.05e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.23e-03\n",
      "Lambda = 6.17e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 7.09e-03\n",
      "Lambda = 6.29e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 6.95e-03\n",
      "Lambda = 6.42e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 6.81e-03\n",
      "Lambda = 6.54e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 6.67e-03\n",
      "Lambda = 6.68e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.60e-01, regularization 6.53e-03\n",
      "Lambda = 6.81e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.19e+00, val_loss 7.60e-01, regularization 6.38e-03\n",
      "Lambda = 6.95e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.19e+00, val_loss 7.60e-01, regularization 6.23e-03\n",
      "Lambda = 7.08e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.19e+00, val_loss 7.60e-01, regularization 6.08e-03\n",
      "Lambda = 7.23e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.19e+00, val_loss 7.61e-01, regularization 5.92e-03\n",
      "Lambda = 7.37e+01, selected 2 features in 5 epochs\n",
      "val_objective 1.19e+00, val_loss 7.61e-01, regularization 5.77e-03\n",
      "Lambda = 7.52e+01, selected 1 features in 100 epochs\n",
      "val_objective 9.65e-01, val_loss 7.62e-01, regularization 2.70e-03\n",
      "Lambda = 7.67e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.63e-01, val_loss 7.62e-01, regularization 2.62e-03\n",
      "Lambda = 7.82e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.61e-01, val_loss 7.62e-01, regularization 2.54e-03\n",
      "Lambda = 7.98e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.59e-01, val_loss 7.62e-01, regularization 2.46e-03\n",
      "Lambda = 8.14e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.56e-01, val_loss 7.62e-01, regularization 2.38e-03\n",
      "Lambda = 8.30e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.53e-01, val_loss 7.62e-01, regularization 2.30e-03\n",
      "Lambda = 8.47e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.50e-01, val_loss 7.62e-01, regularization 2.22e-03\n",
      "Lambda = 8.64e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.46e-01, val_loss 7.62e-01, regularization 2.13e-03\n",
      "Lambda = 8.81e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.43e-01, val_loss 7.62e-01, regularization 2.05e-03\n",
      "Lambda = 8.98e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.38e-01, val_loss 7.62e-01, regularization 1.96e-03\n",
      "Lambda = 9.16e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.34e-01, val_loss 7.62e-01, regularization 1.87e-03\n",
      "Lambda = 9.35e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.28e-01, val_loss 7.63e-01, regularization 1.77e-03\n",
      "Lambda = 9.53e+01, selected 1 features in 5 epochs\n",
      "val_objective 9.23e-01, val_loss 7.63e-01, regularization 1.68e-03\n",
      "Lambda = 9.72e+01, selected 0 features in 95 epochs\n",
      "val_objective 7.64e-01, val_loss 7.64e-01, regularization 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "# load an split data sets\n",
    "data = data_loader(subsample_path, pickle=False, parse_dates=True)\n",
    "data = normalize_target(data)\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = data_splitter(data)\n",
    "# bring data to array\n",
    "X_train, X_test, y_train, y_test = df_to_array(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "## trial run#\n",
    "model = LassoNetRegressor(hidden_dims=(50,), verbose=True, patience=(100, 5))\n",
    "path = model.path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf25b3f0-01b6-4c3c-820e-07545ffe1e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot \n",
    "plot_path(model, path, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30505882-0b83-46b8-b791-1c56def9aab9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HistoryItem(lambda_=0, state_dict={'layers.0.weight': tensor([[-0.0728,  0.0218,  0.0802,  ..., -0.0106,  0.0624,  0.0331],\n",
       "         [-0.1229,  0.0141, -0.0225,  ...,  0.0259, -0.0921, -0.0838],\n",
       "         [-0.0352, -0.0505, -0.0140,  ..., -0.2520, -0.1382, -0.0144],\n",
       "         ...,\n",
       "         [-0.0022, -0.1438, -0.0255,  ..., -0.1619, -0.0614,  0.0429],\n",
       "         [ 0.1322, -0.0204, -0.0890,  ..., -0.0207, -0.0066,  0.1308],\n",
       "         [-0.0298, -0.0179,  0.1393,  ...,  0.0537, -0.0945,  0.1781]]), 'layers.0.bias': tensor([-0.0646,  0.1441,  0.0466,  0.0642,  0.0966,  0.0955,  0.0078, -0.1458,\n",
       "          0.0113, -0.0807,  0.0732,  0.0922,  0.1298,  0.0382, -0.1475, -0.1179,\n",
       "         -0.0679, -0.0981,  0.1510,  0.0153,  0.0599,  0.1561, -0.0896,  0.0583,\n",
       "         -0.0775,  0.1811, -0.0716, -0.0420, -0.0628,  0.1096, -0.0166,  0.0213,\n",
       "         -0.0288, -0.0456, -0.0269, -0.1453,  0.0152,  0.0621,  0.1058,  0.0600,\n",
       "         -0.0357,  0.0350,  0.1163, -0.0450,  0.1305, -0.0134, -0.0685, -0.0025,\n",
       "          0.0335,  0.1200]), 'layers.1.weight': tensor([[ 0.0252,  0.1165, -0.1110, -0.1264,  0.0772, -0.0976, -0.0550, -0.0775,\n",
       "           0.1331, -0.0567,  0.0861, -0.0891,  0.0988, -0.0472, -0.0711,  0.0404,\n",
       "          -0.0889, -0.0866,  0.0745,  0.1284, -0.1119,  0.1052, -0.1181, -0.1144,\n",
       "          -0.0811,  0.1460,  0.1280,  0.1281,  0.0995, -0.0262, -0.1501,  0.1129,\n",
       "           0.0512,  0.0567, -0.1340,  0.0900,  0.1678, -0.0712,  0.1533, -0.0694,\n",
       "          -0.1555,  0.0809,  0.1167, -0.0695,  0.0740,  0.1622, -0.0931, -0.0358,\n",
       "          -0.0893, -0.0908]]), 'layers.1.bias': tensor([-0.0761]), 'skip.weight': tensor([[ 8.4082e-02, -5.7038e-03,  3.6189e-02,  4.8167e-02,  4.7868e-02,\n",
       "           4.1030e-02, -5.7320e-02, -5.8121e-02,  3.2686e-02,  4.5154e-02,\n",
       "          -6.1024e-03, -8.1667e-02, -5.5338e-02,  3.6502e-02,  6.3624e-02,\n",
       "          -9.6686e-02,  1.9928e-02,  8.1749e-02,  9.0081e-02,  1.2071e-02,\n",
       "           1.6460e-02,  4.4111e-02,  2.7966e-02,  6.3466e-03, -3.6741e-02,\n",
       "           6.5143e-02, -5.9963e-03,  4.1601e-03, -5.4695e-02,  1.6872e-02,\n",
       "           3.8252e-02, -8.5890e-02,  5.9540e-02, -2.4136e-02,  2.1173e-02,\n",
       "          -1.0092e-02, -6.5095e-02, -3.0887e-02, -3.2225e-02, -6.2035e-02,\n",
       "          -6.7645e-02, -8.1208e-02,  4.6124e-02, -7.5741e-02,  4.0586e-03,\n",
       "           5.2930e-02, -4.6590e-02, -9.1538e-05, -7.9444e-02, -3.7385e-02,\n",
       "           6.9655e-02, -1.4135e-03, -5.2559e-02,  1.6122e-02,  4.5468e-03,\n",
       "           8.7704e-03, -1.0105e-01, -7.3004e-03, -1.4736e-02,  5.3776e-02,\n",
       "           5.1199e-02,  7.6726e-02, -8.9212e-03,  1.8319e-02,  8.9464e-02,\n",
       "          -8.1690e-02,  7.1182e-02]])}, objective=0.7241682410240173, loss=0.7241682410240173, val_objective=0.7600476741790771, val_loss=0.7600476741790771, regularization=2.92653751373291, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=159),\n",
       " HistoryItem(lambda_=0.7600476741790771, state_dict={'layers.0.weight': tensor([[-0.0728,  0.0218,  0.0802,  ..., -0.0106,  0.0624,  0.0331],\n",
       "         [-0.1229,  0.0142, -0.0225,  ...,  0.0259, -0.0921, -0.0838],\n",
       "         [-0.0352, -0.0505, -0.0140,  ..., -0.2521, -0.1382, -0.0144],\n",
       "         ...,\n",
       "         [-0.0022, -0.1438, -0.0255,  ..., -0.1619, -0.0614,  0.0429],\n",
       "         [ 0.1322, -0.0204, -0.0890,  ..., -0.0207, -0.0066,  0.1308],\n",
       "         [-0.0298, -0.0179,  0.1393,  ...,  0.0537, -0.0945,  0.1781]]), 'layers.0.bias': tensor([-0.0646,  0.1441,  0.0466,  0.0642,  0.0966,  0.0955,  0.0078, -0.1458,\n",
       "          0.0113, -0.0807,  0.0732,  0.0922,  0.1299,  0.0382, -0.1475, -0.1180,\n",
       "         -0.0680, -0.0981,  0.1510,  0.0153,  0.0599,  0.1561, -0.0896,  0.0583,\n",
       "         -0.0775,  0.1811, -0.0716, -0.0420, -0.0628,  0.1096, -0.0166,  0.0213,\n",
       "         -0.0288, -0.0456, -0.0268, -0.1454,  0.0152,  0.0621,  0.1058,  0.0600,\n",
       "         -0.0357,  0.0350,  0.1163, -0.0450,  0.1305, -0.0134, -0.0685, -0.0025,\n",
       "          0.0335,  0.1200]), 'layers.1.weight': tensor([[ 0.0252,  0.1166, -0.1110, -0.1264,  0.0772, -0.0976, -0.0551, -0.0775,\n",
       "           0.1331, -0.0567,  0.0862, -0.0891,  0.0991, -0.0472, -0.0709,  0.0405,\n",
       "          -0.0888, -0.0865,  0.0746,  0.1286, -0.1117,  0.1053, -0.1181, -0.1143,\n",
       "          -0.0810,  0.1461,  0.1280,  0.1281,  0.0996, -0.0262, -0.1501,  0.1130,\n",
       "           0.0513,  0.0568, -0.1340,  0.0901,  0.1679, -0.0711,  0.1535, -0.0692,\n",
       "          -0.1556,  0.0809,  0.1169, -0.0693,  0.0742,  0.1622, -0.0932, -0.0356,\n",
       "          -0.0892, -0.0909]]), 'layers.1.bias': tensor([-0.0761]), 'skip.weight': tensor([[ 0.0803, -0.0163,  0.0324,  0.0443,  0.0440,  0.0373, -0.0536, -0.0543,\n",
       "           0.0289,  0.0414, -0.0200, -0.0780, -0.0518,  0.0327,  0.0597, -0.0930,\n",
       "           0.0161,  0.0779,  0.0863,  0.0213,  0.0129,  0.0400,  0.0241,  0.0169,\n",
       "          -0.0333,  0.0613, -0.0186,  0.0246, -0.0509,  0.0151,  0.0344, -0.0822,\n",
       "           0.0560, -0.0234,  0.0261, -0.0185, -0.0614, -0.0271, -0.0283, -0.0584,\n",
       "          -0.0640, -0.0774,  0.0423, -0.0720,  0.0176,  0.0491, -0.0428, -0.0174,\n",
       "          -0.0755, -0.0336,  0.0659, -0.0142, -0.0480,  0.0148,  0.0165,  0.0196,\n",
       "          -0.0970, -0.0240, -0.0184,  0.0502,  0.0475,  0.0732, -0.0258,  0.0292,\n",
       "           0.0857, -0.0779,  0.0674]])}, objective=2.969397679172289, loss=0.7270998954772949, val_objective=3.007857814632189, val_loss=0.7655600309371948, regularization=2.950206756591797, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.7752486276626587, state_dict={'layers.0.weight': tensor([[-0.0724,  0.0224,  0.0812,  ..., -0.0101,  0.0620,  0.0335],\n",
       "         [-0.1213,  0.0159, -0.0198,  ...,  0.0275, -0.0937, -0.0813],\n",
       "         [-0.0360, -0.0515, -0.0161,  ..., -0.2540, -0.1370, -0.0161],\n",
       "         ...,\n",
       "         [-0.0029, -0.1442, -0.0262,  ..., -0.1624, -0.0610,  0.0422],\n",
       "         [ 0.1303, -0.0212, -0.0907,  ..., -0.0220, -0.0056,  0.1293],\n",
       "         [-0.0315, -0.0198,  0.1359,  ...,  0.0522, -0.0931,  0.1767]]), 'layers.0.bias': tensor([-0.0644,  0.1424,  0.0467,  0.0636,  0.0954,  0.0953,  0.0077, -0.1473,\n",
       "          0.0090, -0.0813,  0.0714,  0.0926,  0.1289,  0.0376, -0.1478, -0.1183,\n",
       "         -0.0686, -0.0992,  0.1499,  0.0118,  0.0593,  0.1544, -0.0909,  0.0575,\n",
       "         -0.0781,  0.1799, -0.0763, -0.0443, -0.0633,  0.1096, -0.0181,  0.0209,\n",
       "         -0.0302, -0.0459, -0.0281, -0.1459,  0.0109,  0.0618,  0.1048,  0.0595,\n",
       "         -0.0369,  0.0345,  0.1162, -0.0451,  0.1295, -0.0156, -0.0688, -0.0022,\n",
       "          0.0336,  0.1200]), 'layers.1.weight': tensor([[ 0.0349,  0.1082, -0.1163, -0.1150,  0.0647, -0.0967, -0.0572, -0.0581,\n",
       "           0.1298, -0.0433,  0.0711, -0.0795,  0.0923, -0.0321, -0.0648,  0.0438,\n",
       "          -0.0831, -0.0630,  0.0591,  0.1169, -0.1045,  0.0876, -0.1067, -0.1033,\n",
       "          -0.0717,  0.1365,  0.1129,  0.1156,  0.0916, -0.0284, -0.1393,  0.1114,\n",
       "           0.0345,  0.0530, -0.1198,  0.0944,  0.1500, -0.0574,  0.1547, -0.0554,\n",
       "          -0.1501,  0.0721,  0.1217, -0.0674,  0.0731,  0.1523, -0.0902, -0.0396,\n",
       "          -0.0840, -0.0916]]), 'layers.1.bias': tensor([-0.0821]), 'skip.weight': tensor([[ 0.0359, -0.0154,  0.0171,  0.0164,  0.0170,  0.0203, -0.0193, -0.0169,\n",
       "           0.0123,  0.0164, -0.0194, -0.0465, -0.0206,  0.0160,  0.0172, -0.0178,\n",
       "           0.0149,  0.0162,  0.0294,  0.0205,  0.0121,  0.0159,  0.0211,  0.0161,\n",
       "          -0.0179,  0.0204, -0.0183,  0.0236, -0.0195,  0.0145,  0.0178, -0.0440,\n",
       "           0.0260, -0.0224,  0.0256, -0.0177, -0.0236, -0.0171, -0.0144, -0.0219,\n",
       "          -0.0130, -0.0286,  0.0201, -0.0236,  0.0171,  0.0246, -0.0220, -0.0164,\n",
       "          -0.0226, -0.0144,  0.0357, -0.0132, -0.0179,  0.0137,  0.0163,  0.0189,\n",
       "          -0.0170, -0.0230, -0.0175,  0.0189,  0.0186,  0.0154, -0.0247,  0.0284,\n",
       "           0.0349, -0.0281,  0.0296]])}, objective=1.820633903994692, loss=0.743226945400238, val_objective=1.8585437097693807, val_loss=0.7811367511749268, regularization=1.389756679534912, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=100),\n",
       " HistoryItem(lambda_=0.7907536002159119, state_dict={'layers.0.weight': tensor([[-0.0724,  0.0224,  0.0812,  ..., -0.0101,  0.0619,  0.0336],\n",
       "         [-0.1212,  0.0159, -0.0197,  ...,  0.0276, -0.0939, -0.0812],\n",
       "         [-0.0361, -0.0516, -0.0162,  ..., -0.2541, -0.1369, -0.0162],\n",
       "         ...,\n",
       "         [-0.0029, -0.1442, -0.0262,  ..., -0.1624, -0.0609,  0.0421],\n",
       "         [ 0.1302, -0.0213, -0.0908,  ..., -0.0221, -0.0055,  0.1292],\n",
       "         [-0.0316, -0.0199,  0.1357,  ...,  0.0521, -0.0930,  0.1766]]), 'layers.0.bias': tensor([-0.0644,  0.1424,  0.0467,  0.0635,  0.0953,  0.0952,  0.0076, -0.1473,\n",
       "          0.0089, -0.0814,  0.0713,  0.0926,  0.1288,  0.0376, -0.1479, -0.1183,\n",
       "         -0.0686, -0.0993,  0.1498,  0.0116,  0.0593,  0.1543, -0.0909,  0.0574,\n",
       "         -0.0781,  0.1799, -0.0765, -0.0444, -0.0633,  0.1095, -0.0182,  0.0209,\n",
       "         -0.0302, -0.0459, -0.0282, -0.1459,  0.0107,  0.0618,  0.1048,  0.0594,\n",
       "         -0.0371,  0.0345,  0.1162, -0.0451,  0.1295, -0.0157, -0.0688, -0.0022,\n",
       "          0.0336,  0.1200]), 'layers.1.weight': tensor([[ 0.0354,  0.1079, -0.1165, -0.1142,  0.0641, -0.0964, -0.0572, -0.0569,\n",
       "           0.1297, -0.0425,  0.0702, -0.0789,  0.0917, -0.0311, -0.0645,  0.0438,\n",
       "          -0.0829, -0.0618,  0.0582,  0.1160, -0.1043,  0.0865, -0.1059, -0.1023,\n",
       "          -0.0712,  0.1361,  0.1119,  0.1148,  0.0914, -0.0282, -0.1387,  0.1114,\n",
       "           0.0335,  0.0527, -0.1190,  0.0946,  0.1489, -0.0570,  0.1547, -0.0548,\n",
       "          -0.1497,  0.0717,  0.1218, -0.0674,  0.0727,  0.1515, -0.0900, -0.0400,\n",
       "          -0.0837, -0.0912]]), 'layers.1.bias': tensor([-0.0822]), 'skip.weight': tensor([[ 0.0343, -0.0154,  0.0171,  0.0164,  0.0170,  0.0202, -0.0193, -0.0169,\n",
       "           0.0122,  0.0164, -0.0193, -0.0449, -0.0205,  0.0159,  0.0172, -0.0161,\n",
       "           0.0149,  0.0162,  0.0274,  0.0205,  0.0121,  0.0158,  0.0210,  0.0161,\n",
       "          -0.0179,  0.0204, -0.0183,  0.0236, -0.0195,  0.0145,  0.0177, -0.0425,\n",
       "           0.0260, -0.0224,  0.0256, -0.0177, -0.0236, -0.0171, -0.0144, -0.0219,\n",
       "          -0.0130, -0.0272,  0.0200, -0.0225,  0.0171,  0.0246, -0.0220, -0.0164,\n",
       "          -0.0226, -0.0144,  0.0348, -0.0132, -0.0179,  0.0136,  0.0163,  0.0189,\n",
       "          -0.0169, -0.0230, -0.0174,  0.0189,  0.0175,  0.0154, -0.0246,  0.0283,\n",
       "           0.0332, -0.0281,  0.0285]])}, objective=1.8282399831509288, loss=0.7431602478027344, val_objective=1.865747099945515, val_loss=0.7806673645973206, regularization=1.3722096681594849, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.8065686722202301, state_dict={'layers.0.weight': tensor([[-0.0723,  0.0224,  0.0813,  ..., -0.0100,  0.0619,  0.0336],\n",
       "         [-0.1211,  0.0160, -0.0196,  ...,  0.0277, -0.0940, -0.0810],\n",
       "         [-0.0362, -0.0516, -0.0163,  ..., -0.2543, -0.1368, -0.0163],\n",
       "         ...,\n",
       "         [-0.0029, -0.1443, -0.0263,  ..., -0.1625, -0.0609,  0.0421],\n",
       "         [ 0.1301, -0.0213, -0.0908,  ..., -0.0223, -0.0054,  0.1291],\n",
       "         [-0.0318, -0.0200,  0.1355,  ...,  0.0520, -0.0928,  0.1765]]), 'layers.0.bias': tensor([-0.0644,  0.1423,  0.0466,  0.0634,  0.0953,  0.0952,  0.0076, -0.1474,\n",
       "          0.0089, -0.0814,  0.0712,  0.0926,  0.1287,  0.0375, -0.1479, -0.1183,\n",
       "         -0.0686, -0.0994,  0.1498,  0.0113,  0.0593,  0.1542, -0.0911,  0.0573,\n",
       "         -0.0781,  0.1799, -0.0768, -0.0445, -0.0632,  0.1095, -0.0183,  0.0210,\n",
       "         -0.0303, -0.0459, -0.0283, -0.1459,  0.0104,  0.0618,  0.1047,  0.0594,\n",
       "         -0.0372,  0.0345,  0.1162, -0.0451,  0.1294, -0.0159, -0.0688, -0.0022,\n",
       "          0.0335,  0.1199]), 'layers.1.weight': tensor([[ 0.0358,  0.1077, -0.1168, -0.1134,  0.0636, -0.0961, -0.0571, -0.0558,\n",
       "           0.1297, -0.0417,  0.0693, -0.0784,  0.0910, -0.0300, -0.0643,  0.0438,\n",
       "          -0.0828, -0.0605,  0.0573,  0.1150, -0.1042,  0.0854, -0.1051, -0.1013,\n",
       "          -0.0707,  0.1358,  0.1109,  0.1140,  0.0913, -0.0279, -0.1381,  0.1116,\n",
       "           0.0326,  0.0525, -0.1182,  0.0948,  0.1477, -0.0567,  0.1546, -0.0543,\n",
       "          -0.1492,  0.0714,  0.1219, -0.0674,  0.0724,  0.1508, -0.0897, -0.0404,\n",
       "          -0.0834, -0.0908]]), 'layers.1.bias': tensor([-0.0822]), 'skip.weight': tensor([[ 0.0327, -0.0154,  0.0171,  0.0163,  0.0170,  0.0202, -0.0193, -0.0169,\n",
       "           0.0122,  0.0163, -0.0193, -0.0432, -0.0205,  0.0159,  0.0171, -0.0160,\n",
       "           0.0149,  0.0161,  0.0252,  0.0204,  0.0120,  0.0158,  0.0210,  0.0161,\n",
       "          -0.0179,  0.0203, -0.0182,  0.0236, -0.0195,  0.0145,  0.0177, -0.0409,\n",
       "           0.0260, -0.0224,  0.0255, -0.0176, -0.0236, -0.0171, -0.0144, -0.0219,\n",
       "          -0.0130, -0.0258,  0.0200, -0.0213,  0.0170,  0.0245, -0.0219, -0.0163,\n",
       "          -0.0226, -0.0144,  0.0339, -0.0132, -0.0178,  0.0136,  0.0163,  0.0188,\n",
       "          -0.0168, -0.0229, -0.0174,  0.0188,  0.0164,  0.0153, -0.0246,  0.0283,\n",
       "           0.0314, -0.0281,  0.0274]])}, objective=1.836766940962689, loss=0.7431356310844421, val_objective=1.8739043301457334, val_loss=0.7802730202674866, regularization=1.3559060096740723, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.8227000456646347, state_dict={'layers.0.weight': tensor([[-0.0723,  0.0224,  0.0813,  ..., -0.0100,  0.0618,  0.0337],\n",
       "         [-0.1209,  0.0161, -0.0195,  ...,  0.0279, -0.0941, -0.0808],\n",
       "         [-0.0362, -0.0516, -0.0164,  ..., -0.2544, -0.1367, -0.0165],\n",
       "         ...,\n",
       "         [-0.0030, -0.1443, -0.0263,  ..., -0.1625, -0.0609,  0.0420],\n",
       "         [ 0.1300, -0.0213, -0.0909,  ..., -0.0224, -0.0053,  0.1290],\n",
       "         [-0.0319, -0.0201,  0.1354,  ...,  0.0519, -0.0927,  0.1764]]), 'layers.0.bias': tensor([-0.0644,  0.1423,  0.0466,  0.0634,  0.0953,  0.0951,  0.0076, -0.1475,\n",
       "          0.0088, -0.0814,  0.0712,  0.0926,  0.1287,  0.0375, -0.1479, -0.1183,\n",
       "         -0.0687, -0.0994,  0.1497,  0.0111,  0.0592,  0.1541, -0.0912,  0.0572,\n",
       "         -0.0782,  0.1798, -0.0771, -0.0447, -0.0632,  0.1095, -0.0184,  0.0210,\n",
       "         -0.0303, -0.0459, -0.0284, -0.1459,  0.0101,  0.0618,  0.1047,  0.0594,\n",
       "         -0.0374,  0.0345,  0.1163, -0.0451,  0.1294, -0.0160, -0.0689, -0.0022,\n",
       "          0.0335,  0.1199]), 'layers.1.weight': tensor([[ 0.0362,  0.1074, -0.1170, -0.1126,  0.0631, -0.0958, -0.0570, -0.0548,\n",
       "           0.1296, -0.0410,  0.0683, -0.0779,  0.0903, -0.0290, -0.0640,  0.0438,\n",
       "          -0.0826, -0.0593,  0.0565,  0.1141, -0.1042,  0.0844, -0.1043, -0.1004,\n",
       "          -0.0702,  0.1356,  0.1099,  0.1132,  0.0912, -0.0277, -0.1375,  0.1117,\n",
       "           0.0317,  0.0522, -0.1173,  0.0951,  0.1466, -0.0565,  0.1545, -0.0538,\n",
       "          -0.1487,  0.0711,  0.1221, -0.0674,  0.0721,  0.1500, -0.0895, -0.0408,\n",
       "          -0.0831, -0.0904]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0310, -0.0153,  0.0171,  0.0163,  0.0170,  0.0201, -0.0193, -0.0168,\n",
       "           0.0122,  0.0163, -0.0193, -0.0415, -0.0205,  0.0159,  0.0171, -0.0160,\n",
       "           0.0149,  0.0161,  0.0231,  0.0204,  0.0120,  0.0158,  0.0210,  0.0160,\n",
       "          -0.0179,  0.0203, -0.0182,  0.0235, -0.0195,  0.0145,  0.0177, -0.0393,\n",
       "           0.0260, -0.0223,  0.0255, -0.0176, -0.0235, -0.0171, -0.0143, -0.0218,\n",
       "          -0.0129, -0.0244,  0.0200, -0.0202,  0.0170,  0.0245, -0.0219, -0.0163,\n",
       "          -0.0225, -0.0143,  0.0328, -0.0131, -0.0178,  0.0135,  0.0162,  0.0188,\n",
       "          -0.0168, -0.0229, -0.0173,  0.0188,  0.0153,  0.0153, -0.0245,  0.0283,\n",
       "           0.0302, -0.0281,  0.0263]])}, objective=1.8454288682142719, loss=0.743162989616394, val_objective=1.8821981391111835, val_loss=0.7799322605133057, regularization=1.3398150205612183, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.8391540465779275, state_dict={'layers.0.weight': tensor([[-0.0723,  0.0225,  0.0814,  ..., -0.0100,  0.0618,  0.0337],\n",
       "         [-0.1208,  0.0161, -0.0194,  ...,  0.0280, -0.0943, -0.0806],\n",
       "         [-0.0363, -0.0517, -0.0165,  ..., -0.2546, -0.1366, -0.0166],\n",
       "         ...,\n",
       "         [-0.0030, -0.1443, -0.0263,  ..., -0.1626, -0.0608,  0.0419],\n",
       "         [ 0.1298, -0.0214, -0.0910,  ..., -0.0225, -0.0052,  0.1289],\n",
       "         [-0.0320, -0.0201,  0.1353,  ...,  0.0517, -0.0926,  0.1763]]), 'layers.0.bias': tensor([-0.0643,  0.1422,  0.0466,  0.0633,  0.0952,  0.0950,  0.0075, -0.1476,\n",
       "          0.0087, -0.0815,  0.0711,  0.0927,  0.1286,  0.0375, -0.1480, -0.1184,\n",
       "         -0.0687, -0.0995,  0.1497,  0.0109,  0.0592,  0.1540, -0.0913,  0.0571,\n",
       "         -0.0782,  0.1798, -0.0773, -0.0448, -0.0631,  0.1095, -0.0185,  0.0211,\n",
       "         -0.0304, -0.0459, -0.0284, -0.1459,  0.0099,  0.0618,  0.1046,  0.0594,\n",
       "         -0.0376,  0.0345,  0.1163, -0.0451,  0.1293, -0.0162, -0.0689, -0.0021,\n",
       "          0.0335,  0.1198]), 'layers.1.weight': tensor([[ 0.0365,  0.1072, -0.1172, -0.1117,  0.0626, -0.0955, -0.0568, -0.0537,\n",
       "           0.1296, -0.0404,  0.0675, -0.0774,  0.0897, -0.0279, -0.0637,  0.0438,\n",
       "          -0.0824, -0.0581,  0.0557,  0.1131, -0.1041,  0.0833, -0.1035, -0.0994,\n",
       "          -0.0698,  0.1353,  0.1089,  0.1124,  0.0912, -0.0274, -0.1369,  0.1119,\n",
       "           0.0308,  0.0520, -0.1165,  0.0953,  0.1456, -0.0563,  0.1544, -0.0534,\n",
       "          -0.1483,  0.0709,  0.1222, -0.0675,  0.0718,  0.1492, -0.0892, -0.0411,\n",
       "          -0.0828, -0.0899]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0293, -0.0153,  0.0170,  0.0163,  0.0170,  0.0201, -0.0192, -0.0168,\n",
       "           0.0122,  0.0163, -0.0192, -0.0397, -0.0205,  0.0158,  0.0171, -0.0160,\n",
       "           0.0149,  0.0160,  0.0210,  0.0204,  0.0120,  0.0157,  0.0209,  0.0160,\n",
       "          -0.0178,  0.0203, -0.0182,  0.0235, -0.0195,  0.0145,  0.0176, -0.0376,\n",
       "           0.0260, -0.0223,  0.0254, -0.0175, -0.0235, -0.0170, -0.0143, -0.0218,\n",
       "          -0.0129, -0.0230,  0.0199, -0.0189,  0.0170,  0.0245, -0.0219, -0.0162,\n",
       "          -0.0225, -0.0143,  0.0318, -0.0131, -0.0178,  0.0135,  0.0162,  0.0188,\n",
       "          -0.0168, -0.0228, -0.0173,  0.0188,  0.0140,  0.0152, -0.0245,  0.0282,\n",
       "           0.0301, -0.0280,  0.0251]])}, objective=1.8547610481572239, loss=0.7431679964065552, val_objective=1.8911925991368381, val_loss=0.7795995473861694, regularization=1.3246591091156006, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.855937127509486, state_dict={'layers.0.weight': tensor([[-0.0722,  0.0225,  0.0814,  ..., -0.0099,  0.0618,  0.0337],\n",
       "         [-0.1207,  0.0161, -0.0193,  ...,  0.0282, -0.0944, -0.0804],\n",
       "         [-0.0364, -0.0517, -0.0166,  ..., -0.2547, -0.1365, -0.0167],\n",
       "         ...,\n",
       "         [-0.0031, -0.1443, -0.0263,  ..., -0.1626, -0.0608,  0.0419],\n",
       "         [ 0.1297, -0.0214, -0.0910,  ..., -0.0226, -0.0052,  0.1287],\n",
       "         [-0.0322, -0.0202,  0.1351,  ...,  0.0516, -0.0925,  0.1761]]), 'layers.0.bias': tensor([-0.0643,  0.1422,  0.0466,  0.0632,  0.0952,  0.0950,  0.0075, -0.1476,\n",
       "          0.0086, -0.0815,  0.0710,  0.0927,  0.1286,  0.0374, -0.1480, -0.1184,\n",
       "         -0.0687, -0.0995,  0.1496,  0.0107,  0.0592,  0.1539, -0.0914,  0.0570,\n",
       "         -0.0782,  0.1798, -0.0776, -0.0449, -0.0631,  0.1095, -0.0186,  0.0211,\n",
       "         -0.0304, -0.0459, -0.0285, -0.1459,  0.0097,  0.0618,  0.1046,  0.0593,\n",
       "         -0.0377,  0.0345,  0.1163, -0.0451,  0.1293, -0.0163, -0.0689, -0.0021,\n",
       "          0.0335,  0.1198]), 'layers.1.weight': tensor([[ 0.0369,  0.1071, -0.1175, -0.1110,  0.0621, -0.0952, -0.0565, -0.0526,\n",
       "           0.1296, -0.0397,  0.0666, -0.0769,  0.0890, -0.0269, -0.0634,  0.0438,\n",
       "          -0.0822, -0.0568,  0.0549,  0.1121, -0.1041,  0.0823, -0.1027, -0.0984,\n",
       "          -0.0693,  0.1351,  0.1079,  0.1117,  0.0912, -0.0271, -0.1362,  0.1121,\n",
       "           0.0300,  0.0519, -0.1158,  0.0956,  0.1445, -0.0561,  0.1543, -0.0530,\n",
       "          -0.1477,  0.0706,  0.1224, -0.0675,  0.0715,  0.1484, -0.0890, -0.0414,\n",
       "          -0.0824, -0.0894]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0276, -0.0152,  0.0170,  0.0163,  0.0170,  0.0201, -0.0192, -0.0168,\n",
       "           0.0122,  0.0162, -0.0192, -0.0379, -0.0204,  0.0158,  0.0171, -0.0159,\n",
       "           0.0149,  0.0160,  0.0203,  0.0203,  0.0120,  0.0157,  0.0209,  0.0160,\n",
       "          -0.0178,  0.0202, -0.0182,  0.0234, -0.0194,  0.0144,  0.0176, -0.0359,\n",
       "           0.0259, -0.0222,  0.0254, -0.0175, -0.0235, -0.0170, -0.0143, -0.0218,\n",
       "          -0.0129, -0.0216,  0.0199, -0.0177,  0.0170,  0.0244, -0.0218, -0.0162,\n",
       "          -0.0225, -0.0143,  0.0306, -0.0131, -0.0177,  0.0134,  0.0162,  0.0187,\n",
       "          -0.0167, -0.0228, -0.0172,  0.0188,  0.0128,  0.0152, -0.0244,  0.0282,\n",
       "           0.0301, -0.0280,  0.0239]])}, objective=1.8650318702144473, loss=0.7431721687316895, val_objective=1.9011264761371462, val_loss=0.7792667746543884, regularization=1.3106800317764282, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.8730558700596758, state_dict={'layers.0.weight': tensor([[-0.0722,  0.0225,  0.0815,  ..., -0.0099,  0.0617,  0.0338],\n",
       "         [-0.1206,  0.0162, -0.0192,  ...,  0.0283, -0.0945, -0.0803],\n",
       "         [-0.0365, -0.0518, -0.0167,  ..., -0.2549, -0.1364, -0.0169],\n",
       "         ...,\n",
       "         [-0.0032, -0.1443, -0.0264,  ..., -0.1627, -0.0608,  0.0418],\n",
       "         [ 0.1295, -0.0214, -0.0911,  ..., -0.0227, -0.0051,  0.1286],\n",
       "         [-0.0323, -0.0203,  0.1350,  ...,  0.0515, -0.0924,  0.1760]]), 'layers.0.bias': tensor([-0.0643,  0.1421,  0.0465,  0.0632,  0.0951,  0.0949,  0.0074, -0.1477,\n",
       "          0.0085, -0.0815,  0.0709,  0.0927,  0.1285,  0.0374, -0.1480, -0.1184,\n",
       "         -0.0688, -0.0996,  0.1496,  0.0105,  0.0592,  0.1538, -0.0915,  0.0568,\n",
       "         -0.0782,  0.1798, -0.0778, -0.0450, -0.0630,  0.1094, -0.0187,  0.0212,\n",
       "         -0.0305, -0.0459, -0.0286, -0.1460,  0.0094,  0.0618,  0.1045,  0.0593,\n",
       "         -0.0379,  0.0345,  0.1163, -0.0451,  0.1292, -0.0165, -0.0689, -0.0021,\n",
       "          0.0334,  0.1197]), 'layers.1.weight': tensor([[ 0.0373,  0.1069, -0.1178, -0.1102,  0.0617, -0.0948, -0.0562, -0.0516,\n",
       "           0.1296, -0.0392,  0.0657, -0.0764,  0.0884, -0.0259, -0.0630,  0.0438,\n",
       "          -0.0820, -0.0556,  0.0542,  0.1111, -0.1042,  0.0814, -0.1019, -0.0974,\n",
       "          -0.0688,  0.1349,  0.1069,  0.1110,  0.0912, -0.0268, -0.1356,  0.1124,\n",
       "           0.0292,  0.0517, -0.1150,  0.0958,  0.1435, -0.0559,  0.1542, -0.0526,\n",
       "          -0.1472,  0.0704,  0.1226, -0.0676,  0.0712,  0.1476, -0.0888, -0.0417,\n",
       "          -0.0821, -0.0889]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0259, -0.0152,  0.0170,  0.0163,  0.0169,  0.0200, -0.0192, -0.0167,\n",
       "           0.0121,  0.0162, -0.0191, -0.0361, -0.0204,  0.0157,  0.0170, -0.0159,\n",
       "           0.0149,  0.0160,  0.0203,  0.0203,  0.0120,  0.0156,  0.0208,  0.0159,\n",
       "          -0.0178,  0.0202, -0.0182,  0.0234, -0.0194,  0.0144,  0.0176, -0.0342,\n",
       "           0.0259, -0.0222,  0.0253, -0.0175, -0.0234, -0.0170, -0.0143, -0.0218,\n",
       "          -0.0129, -0.0203,  0.0198, -0.0173,  0.0170,  0.0244, -0.0218, -0.0161,\n",
       "          -0.0225, -0.0142,  0.0295, -0.0131, -0.0177,  0.0133,  0.0162,  0.0187,\n",
       "          -0.0167, -0.0227, -0.0172,  0.0187,  0.0126,  0.0152, -0.0244,  0.0281,\n",
       "           0.0301, -0.0280,  0.0227]])}, objective=1.8773975922353625, loss=0.7430643439292908, val_objective=1.9131066753156543, val_loss=0.7787734270095825, regularization=1.2992676496505737, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.8905169874608693, state_dict={'layers.0.weight': tensor([[-0.0722,  0.0225,  0.0815,  ..., -0.0098,  0.0617,  0.0338],\n",
       "         [-0.1204,  0.0162, -0.0191,  ...,  0.0284, -0.0946, -0.0801],\n",
       "         [-0.0366, -0.0518, -0.0167,  ..., -0.2550, -0.1363, -0.0170],\n",
       "         ...,\n",
       "         [-0.0032, -0.1443, -0.0264,  ..., -0.1627, -0.0607,  0.0418],\n",
       "         [ 0.1294, -0.0214, -0.0912,  ..., -0.0228, -0.0050,  0.1285],\n",
       "         [-0.0324, -0.0203,  0.1349,  ...,  0.0514, -0.0923,  0.1759]]), 'layers.0.bias': tensor([-0.0643,  0.1421,  0.0465,  0.0631,  0.0951,  0.0948,  0.0074, -0.1478,\n",
       "          0.0085, -0.0815,  0.0708,  0.0927,  0.1285,  0.0374, -0.1481, -0.1184,\n",
       "         -0.0688, -0.0996,  0.1495,  0.0103,  0.0592,  0.1538, -0.0916,  0.0567,\n",
       "         -0.0783,  0.1798, -0.0781, -0.0451, -0.0630,  0.1094, -0.0188,  0.0212,\n",
       "         -0.0305, -0.0460, -0.0286, -0.1460,  0.0092,  0.0618,  0.1045,  0.0593,\n",
       "         -0.0381,  0.0345,  0.1163, -0.0451,  0.1291, -0.0166, -0.0690, -0.0021,\n",
       "          0.0334,  0.1197]), 'layers.1.weight': tensor([[ 0.0376,  0.1068, -0.1180, -0.1095,  0.0612, -0.0944, -0.0559, -0.0505,\n",
       "           0.1296, -0.0386,  0.0649, -0.0760,  0.0878, -0.0249, -0.0627,  0.0438,\n",
       "          -0.0818, -0.0544,  0.0535,  0.1101, -0.1042,  0.0804, -0.1010, -0.0965,\n",
       "          -0.0683,  0.1347,  0.1059,  0.1103,  0.0913, -0.0264, -0.1349,  0.1127,\n",
       "           0.0284,  0.0516, -0.1143,  0.0961,  0.1425, -0.0558,  0.1541, -0.0523,\n",
       "          -0.1467,  0.0702,  0.1228, -0.0676,  0.0709,  0.1468, -0.0886, -0.0419,\n",
       "          -0.0818, -0.0883]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0243, -0.0151,  0.0170,  0.0163,  0.0169,  0.0200, -0.0191, -0.0167,\n",
       "           0.0121,  0.0162, -0.0191, -0.0343, -0.0204,  0.0157,  0.0170, -0.0158,\n",
       "           0.0149,  0.0159,  0.0202,  0.0202,  0.0119,  0.0156,  0.0208,  0.0159,\n",
       "          -0.0178,  0.0202, -0.0181,  0.0233, -0.0194,  0.0144,  0.0176, -0.0325,\n",
       "           0.0259, -0.0222,  0.0253, -0.0174, -0.0234, -0.0169, -0.0142, -0.0217,\n",
       "          -0.0128, -0.0190,  0.0198, -0.0173,  0.0169,  0.0244, -0.0218, -0.0161,\n",
       "          -0.0225, -0.0142,  0.0283, -0.0130, -0.0177,  0.0133,  0.0162,  0.0186,\n",
       "          -0.0167, -0.0227, -0.0172,  0.0187,  0.0126,  0.0151, -0.0243,  0.0281,\n",
       "           0.0301, -0.0280,  0.0214]])}, objective=1.8900756054019603, loss=0.7429297566413879, val_objective=1.925448220262495, val_loss=0.7783023715019226, regularization=1.288179636001587, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.9083273272100867, state_dict={'layers.0.weight': tensor([[-0.0721,  0.0225,  0.0816,  ..., -0.0098,  0.0616,  0.0339],\n",
       "         [-0.1203,  0.0163, -0.0191,  ...,  0.0286, -0.0948, -0.0799],\n",
       "         [-0.0367, -0.0518, -0.0168,  ..., -0.2552, -0.1362, -0.0172],\n",
       "         ...,\n",
       "         [-0.0033, -0.1443, -0.0264,  ..., -0.1628, -0.0607,  0.0417],\n",
       "         [ 0.1292, -0.0215, -0.0912,  ..., -0.0229, -0.0049,  0.1284],\n",
       "         [-0.0326, -0.0204,  0.1348,  ...,  0.0513, -0.0922,  0.1758]]), 'layers.0.bias': tensor([-0.0643,  0.1420,  0.0465,  0.0630,  0.0951,  0.0947,  0.0074, -0.1478,\n",
       "          0.0084, -0.0815,  0.0708,  0.0927,  0.1284,  0.0373, -0.1481, -0.1184,\n",
       "         -0.0688, -0.0997,  0.1495,  0.0100,  0.0592,  0.1537, -0.0917,  0.0566,\n",
       "         -0.0783,  0.1798, -0.0783, -0.0452, -0.0629,  0.1094, -0.0189,  0.0213,\n",
       "         -0.0306, -0.0460, -0.0287, -0.1460,  0.0090,  0.0618,  0.1044,  0.0593,\n",
       "         -0.0382,  0.0346,  0.1164, -0.0451,  0.1291, -0.0168, -0.0690, -0.0020,\n",
       "          0.0334,  0.1196]), 'layers.1.weight': tensor([[ 0.0380,  0.1067, -0.1183, -0.1088,  0.0607, -0.0941, -0.0555, -0.0495,\n",
       "           0.1296, -0.0381,  0.0640, -0.0756,  0.0871, -0.0239, -0.0623,  0.0438,\n",
       "          -0.0816, -0.0532,  0.0529,  0.1090, -0.1043,  0.0795, -0.1002, -0.0956,\n",
       "          -0.0679,  0.1344,  0.1049,  0.1096,  0.0914, -0.0261, -0.1342,  0.1130,\n",
       "           0.0277,  0.0515, -0.1137,  0.0964,  0.1416, -0.0557,  0.1539, -0.0520,\n",
       "          -0.1461,  0.0700,  0.1231, -0.0677,  0.0706,  0.1459, -0.0884, -0.0422,\n",
       "          -0.0815, -0.0877]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0226, -0.0151,  0.0170,  0.0162,  0.0169,  0.0199, -0.0191, -0.0166,\n",
       "           0.0121,  0.0162, -0.0190, -0.0324, -0.0203,  0.0157,  0.0170, -0.0158,\n",
       "           0.0148,  0.0159,  0.0202,  0.0202,  0.0119,  0.0155,  0.0207,  0.0159,\n",
       "          -0.0178,  0.0201, -0.0181,  0.0233, -0.0193,  0.0144,  0.0175, -0.0307,\n",
       "           0.0259, -0.0221,  0.0253, -0.0174, -0.0233, -0.0169, -0.0142, -0.0217,\n",
       "          -0.0128, -0.0176,  0.0197, -0.0173,  0.0169,  0.0243, -0.0217, -0.0160,\n",
       "          -0.0224, -0.0142,  0.0270, -0.0130, -0.0177,  0.0132,  0.0162,  0.0186,\n",
       "          -0.0166, -0.0226, -0.0171,  0.0187,  0.0126,  0.0151, -0.0242,  0.0280,\n",
       "           0.0300, -0.0279,  0.0201]])}, objective=1.90267352255322, loss=0.742831826210022, val_objective=1.9377328554008153, val_loss=0.7778911590576172, regularization=1.2768983840942383, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.9264938737542885, state_dict={'layers.0.weight': tensor([[-0.0721,  0.0226,  0.0816,  ..., -0.0097,  0.0616,  0.0339],\n",
       "         [-0.1201,  0.0163, -0.0190,  ...,  0.0287, -0.0949, -0.0797],\n",
       "         [-0.0368, -0.0518, -0.0169,  ..., -0.2553, -0.1361, -0.0173],\n",
       "         ...,\n",
       "         [-0.0033, -0.1444, -0.0264,  ..., -0.1628, -0.0607,  0.0416],\n",
       "         [ 0.1291, -0.0215, -0.0913,  ..., -0.0230, -0.0048,  0.1283],\n",
       "         [-0.0327, -0.0205,  0.1347,  ...,  0.0511, -0.0921,  0.1757]]), 'layers.0.bias': tensor([-0.0643,  0.1420,  0.0465,  0.0630,  0.0950,  0.0947,  0.0073, -0.1479,\n",
       "          0.0083, -0.0816,  0.0707,  0.0927,  0.1284,  0.0373, -0.1482, -0.1185,\n",
       "         -0.0689, -0.0997,  0.1495,  0.0098,  0.0592,  0.1536, -0.0918,  0.0565,\n",
       "         -0.0783,  0.1798, -0.0786, -0.0453, -0.0629,  0.1094, -0.0190,  0.0213,\n",
       "         -0.0306, -0.0460, -0.0288, -0.1460,  0.0088,  0.0619,  0.1043,  0.0593,\n",
       "         -0.0384,  0.0346,  0.1164, -0.0451,  0.1290, -0.0169, -0.0690, -0.0020,\n",
       "          0.0333,  0.1196]), 'layers.1.weight': tensor([[ 0.0383,  0.1066, -0.1186, -0.1081,  0.0602, -0.0938, -0.0551, -0.0485,\n",
       "           0.1296, -0.0377,  0.0632, -0.0753,  0.0865, -0.0229, -0.0620,  0.0438,\n",
       "          -0.0814, -0.0520,  0.0522,  0.1080, -0.1044,  0.0785, -0.0994, -0.0947,\n",
       "          -0.0675,  0.1342,  0.1040,  0.1089,  0.0916, -0.0258, -0.1336,  0.1133,\n",
       "           0.0269,  0.0514, -0.1131,  0.0966,  0.1406, -0.0556,  0.1538, -0.0517,\n",
       "          -0.1456,  0.0698,  0.1234, -0.0678,  0.0703,  0.1451, -0.0883, -0.0424,\n",
       "          -0.0811, -0.0872]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0210, -0.0150,  0.0169,  0.0162,  0.0169,  0.0199, -0.0191, -0.0166,\n",
       "           0.0121,  0.0161, -0.0190, -0.0305, -0.0203,  0.0156,  0.0170, -0.0158,\n",
       "           0.0148,  0.0158,  0.0202,  0.0202,  0.0119,  0.0155,  0.0207,  0.0158,\n",
       "          -0.0177,  0.0201, -0.0181,  0.0232, -0.0193,  0.0143,  0.0175, -0.0290,\n",
       "           0.0258, -0.0221,  0.0252, -0.0173, -0.0233, -0.0169, -0.0142, -0.0217,\n",
       "          -0.0128, -0.0163,  0.0197, -0.0172,  0.0169,  0.0243, -0.0217, -0.0160,\n",
       "          -0.0224, -0.0141,  0.0257, -0.0130, -0.0176,  0.0132,  0.0162,  0.0185,\n",
       "          -0.0166, -0.0226, -0.0171,  0.0186,  0.0126,  0.0150, -0.0242,  0.0280,\n",
       "           0.0300, -0.0279,  0.0187]])}, objective=1.9151715637877778, loss=0.7427703738212585, val_objective=1.9499401451781586, val_loss=0.7775389552116394, regularization=1.2654170989990234, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.9450237512293743, state_dict={'layers.0.weight': tensor([[-0.0720,  0.0226,  0.0817,  ..., -0.0097,  0.0616,  0.0340],\n",
       "         [-0.1200,  0.0163, -0.0189,  ...,  0.0288, -0.0950, -0.0795],\n",
       "         [-0.0369, -0.0519, -0.0170,  ..., -0.2554, -0.1360, -0.0175],\n",
       "         ...,\n",
       "         [-0.0034, -0.1444, -0.0265,  ..., -0.1629, -0.0606,  0.0416],\n",
       "         [ 0.1289, -0.0215, -0.0913,  ..., -0.0231, -0.0048,  0.1281],\n",
       "         [-0.0329, -0.0205,  0.1346,  ...,  0.0510, -0.0920,  0.1755]]), 'layers.0.bias': tensor([-0.0643,  0.1419,  0.0464,  0.0629,  0.0950,  0.0946,  0.0073, -0.1479,\n",
       "          0.0082, -0.0816,  0.0706,  0.0928,  0.1283,  0.0373, -0.1482, -0.1185,\n",
       "         -0.0689, -0.0998,  0.1494,  0.0096,  0.0593,  0.1535, -0.0919,  0.0564,\n",
       "         -0.0783,  0.1798, -0.0788, -0.0454, -0.0628,  0.1093, -0.0192,  0.0214,\n",
       "         -0.0307, -0.0460, -0.0288, -0.1460,  0.0086,  0.0619,  0.1043,  0.0592,\n",
       "         -0.0386,  0.0346,  0.1164, -0.0451,  0.1290, -0.0171, -0.0690, -0.0020,\n",
       "          0.0333,  0.1195]), 'layers.1.weight': tensor([[ 0.0386,  0.1065, -0.1189, -0.1075,  0.0597, -0.0935, -0.0547, -0.0475,\n",
       "           0.1297, -0.0372,  0.0624, -0.0749,  0.0859, -0.0219, -0.0616,  0.0438,\n",
       "          -0.0812, -0.0509,  0.0516,  0.1070, -0.1046,  0.0776, -0.0986, -0.0938,\n",
       "          -0.0670,  0.1340,  0.1030,  0.1083,  0.0918, -0.0255, -0.1329,  0.1136,\n",
       "           0.0262,  0.0513, -0.1125,  0.0969,  0.1397, -0.0555,  0.1536, -0.0515,\n",
       "          -0.1450,  0.0696,  0.1237, -0.0679,  0.0699,  0.1442, -0.0881, -0.0425,\n",
       "          -0.0808, -0.0867]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0193, -0.0150,  0.0169,  0.0162,  0.0169,  0.0199, -0.0190, -0.0166,\n",
       "           0.0120,  0.0161, -0.0189, -0.0286, -0.0203,  0.0156,  0.0170, -0.0157,\n",
       "           0.0148,  0.0158,  0.0202,  0.0201,  0.0119,  0.0155,  0.0207,  0.0158,\n",
       "          -0.0177,  0.0200, -0.0181,  0.0231, -0.0193,  0.0143,  0.0175, -0.0272,\n",
       "           0.0258, -0.0221,  0.0252, -0.0173, -0.0233, -0.0168, -0.0141, -0.0216,\n",
       "          -0.0127, -0.0149,  0.0196, -0.0172,  0.0169,  0.0242, -0.0216, -0.0159,\n",
       "          -0.0224, -0.0141,  0.0243, -0.0130, -0.0176,  0.0131,  0.0161,  0.0185,\n",
       "          -0.0165, -0.0225, -0.0170,  0.0186,  0.0125,  0.0150, -0.0241,  0.0279,\n",
       "           0.0300, -0.0279,  0.0176]])}, objective=1.9278171228414545, loss=0.7427452206611633, val_objective=1.9622963236814508, val_loss=0.7772244215011597, regularization=1.2540128231048584, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.9639242262539618, state_dict={'layers.0.weight': tensor([[-0.0720,  0.0226,  0.0817,  ..., -0.0096,  0.0615,  0.0340],\n",
       "         [-0.1198,  0.0164, -0.0189,  ...,  0.0290, -0.0951, -0.0793],\n",
       "         [-0.0370, -0.0519, -0.0171,  ..., -0.2556, -0.1359, -0.0176],\n",
       "         ...,\n",
       "         [-0.0035, -0.1444, -0.0265,  ..., -0.1629, -0.0606,  0.0415],\n",
       "         [ 0.1287, -0.0215, -0.0914,  ..., -0.0232, -0.0047,  0.1280],\n",
       "         [-0.0331, -0.0206,  0.1345,  ...,  0.0509, -0.0919,  0.1752]]), 'layers.0.bias': tensor([-0.0643,  0.1419,  0.0464,  0.0629,  0.0950,  0.0945,  0.0072, -0.1480,\n",
       "          0.0082, -0.0816,  0.0706,  0.0928,  0.1283,  0.0373, -0.1482, -0.1185,\n",
       "         -0.0689, -0.0998,  0.1494,  0.0094,  0.0593,  0.1534, -0.0920,  0.0563,\n",
       "         -0.0784,  0.1797, -0.0790, -0.0455, -0.0627,  0.1093, -0.0193,  0.0214,\n",
       "         -0.0307, -0.0460, -0.0289, -0.1460,  0.0084,  0.0619,  0.1042,  0.0592,\n",
       "         -0.0388,  0.0346,  0.1165, -0.0451,  0.1289, -0.0172, -0.0690, -0.0020,\n",
       "          0.0333,  0.1195]), 'layers.1.weight': tensor([[ 0.0388,  0.1064, -0.1193, -0.1069,  0.0592, -0.0932, -0.0542, -0.0465,\n",
       "           0.1298, -0.0368,  0.0616, -0.0746,  0.0853, -0.0210, -0.0613,  0.0439,\n",
       "          -0.0810, -0.0498,  0.0510,  0.1060, -0.1047,  0.0767, -0.0978, -0.0929,\n",
       "          -0.0666,  0.1338,  0.1020,  0.1077,  0.0919, -0.0251, -0.1322,  0.1139,\n",
       "           0.0255,  0.0512, -0.1119,  0.0971,  0.1388, -0.0555,  0.1535, -0.0512,\n",
       "          -0.1445,  0.0693,  0.1240, -0.0680,  0.0696,  0.1434, -0.0880, -0.0427,\n",
       "          -0.0805, -0.0862]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0176, -0.0149,  0.0169,  0.0162,  0.0169,  0.0198, -0.0190, -0.0165,\n",
       "           0.0120,  0.0161, -0.0189, -0.0267, -0.0202,  0.0155,  0.0169, -0.0157,\n",
       "           0.0148,  0.0157,  0.0202,  0.0201,  0.0119,  0.0154,  0.0206,  0.0158,\n",
       "          -0.0177,  0.0200, -0.0181,  0.0231, -0.0193,  0.0143,  0.0175, -0.0254,\n",
       "           0.0258, -0.0220,  0.0251, -0.0172, -0.0232, -0.0168, -0.0141, -0.0216,\n",
       "          -0.0127, -0.0147,  0.0196, -0.0172,  0.0168,  0.0242, -0.0216, -0.0159,\n",
       "          -0.0224, -0.0140,  0.0229, -0.0130, -0.0176,  0.0131,  0.0161,  0.0184,\n",
       "          -0.0165, -0.0225, -0.0170,  0.0185,  0.0125,  0.0150, -0.0241,  0.0279,\n",
       "           0.0299, -0.0278,  0.0175]])}, objective=1.9424728594600589, loss=0.7425931096076965, val_objective=1.9766528449832828, val_loss=0.7767730951309204, regularization=1.2447863817214966, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=0.9832027107790411, state_dict={'layers.0.weight': tensor([[-0.0719,  0.0226,  0.0817,  ..., -0.0096,  0.0615,  0.0341],\n",
       "         [-0.1197,  0.0164, -0.0188,  ...,  0.0291, -0.0952, -0.0790],\n",
       "         [-0.0371, -0.0519, -0.0172,  ..., -0.2557, -0.1358, -0.0178],\n",
       "         ...,\n",
       "         [-0.0035, -0.1444, -0.0265,  ..., -0.1629, -0.0606,  0.0414],\n",
       "         [ 0.1286, -0.0215, -0.0914,  ..., -0.0233, -0.0046,  0.1279],\n",
       "         [-0.0332, -0.0206,  0.1344,  ...,  0.0508, -0.0918,  0.1749]]), 'layers.0.bias': tensor([-0.0642,  0.1419,  0.0464,  0.0629,  0.0949,  0.0945,  0.0072, -0.1481,\n",
       "          0.0081, -0.0816,  0.0705,  0.0928,  0.1282,  0.0372, -0.1483, -0.1185,\n",
       "         -0.0689, -0.0999,  0.1494,  0.0092,  0.0593,  0.1534, -0.0921,  0.0562,\n",
       "         -0.0784,  0.1797, -0.0793, -0.0456, -0.0627,  0.1093, -0.0194,  0.0215,\n",
       "         -0.0307, -0.0459, -0.0289, -0.1460,  0.0082,  0.0619,  0.1041,  0.0592,\n",
       "         -0.0389,  0.0346,  0.1165, -0.0451,  0.1288, -0.0173, -0.0690, -0.0020,\n",
       "          0.0332,  0.1194]), 'layers.1.weight': tensor([[ 0.0391,  0.1063, -0.1196, -0.1063,  0.0587, -0.0929, -0.0538, -0.0455,\n",
       "           0.1298, -0.0364,  0.0608, -0.0743,  0.0847, -0.0200, -0.0609,  0.0439,\n",
       "          -0.0808, -0.0486,  0.0504,  0.1050, -0.1049,  0.0757, -0.0969, -0.0921,\n",
       "          -0.0662,  0.1335,  0.1010,  0.1071,  0.0922, -0.0248, -0.1316,  0.1142,\n",
       "           0.0249,  0.0512, -0.1114,  0.0973,  0.1379, -0.0554,  0.1533, -0.0510,\n",
       "          -0.1439,  0.0691,  0.1243, -0.0681,  0.0693,  0.1425, -0.0879, -0.0428,\n",
       "          -0.0801, -0.0857]]), 'layers.1.bias': tensor([-0.0824]), 'skip.weight': tensor([[ 0.0164, -0.0149,  0.0169,  0.0161,  0.0169,  0.0198, -0.0190, -0.0165,\n",
       "           0.0120,  0.0161, -0.0188, -0.0248, -0.0202,  0.0155,  0.0169, -0.0156,\n",
       "           0.0148,  0.0157,  0.0201,  0.0200,  0.0118,  0.0154,  0.0206,  0.0157,\n",
       "          -0.0177,  0.0200, -0.0180,  0.0230, -0.0192,  0.0142,  0.0175, -0.0236,\n",
       "           0.0257, -0.0220,  0.0251, -0.0172, -0.0232, -0.0168, -0.0141, -0.0216,\n",
       "          -0.0127, -0.0146,  0.0195, -0.0171,  0.0168,  0.0242, -0.0215, -0.0158,\n",
       "          -0.0224, -0.0140,  0.0214, -0.0130, -0.0175,  0.0131,  0.0161,  0.0184,\n",
       "          -0.0165, -0.0224, -0.0169,  0.0185,  0.0125,  0.0149, -0.0240,  0.0278,\n",
       "           0.0299, -0.0278,  0.0175]])}, objective=1.957728074205726, loss=0.742434024810791, val_objective=1.9916435939200814, val_loss=0.7763495445251465, regularization=1.2360564470291138, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.002866764994622, state_dict={'layers.0.weight': tensor([[-0.0719,  0.0226,  0.0818,  ..., -0.0096,  0.0615,  0.0341],\n",
       "         [-0.1195,  0.0164, -0.0187,  ...,  0.0292, -0.0954, -0.0788],\n",
       "         [-0.0372, -0.0520, -0.0172,  ..., -0.2559, -0.1358, -0.0179],\n",
       "         ...,\n",
       "         [-0.0036, -0.1444, -0.0265,  ..., -0.1630, -0.0605,  0.0414],\n",
       "         [ 0.1284, -0.0216, -0.0915,  ..., -0.0234, -0.0046,  0.1278],\n",
       "         [-0.0334, -0.0207,  0.1343,  ...,  0.0507, -0.0917,  0.1746]]), 'layers.0.bias': tensor([-0.0642,  0.1418,  0.0464,  0.0628,  0.0949,  0.0944,  0.0071, -0.1481,\n",
       "          0.0080, -0.0816,  0.0705,  0.0928,  0.1282,  0.0372, -0.1483, -0.1186,\n",
       "         -0.0690, -0.0999,  0.1493,  0.0090,  0.0593,  0.1533, -0.0922,  0.0561,\n",
       "         -0.0784,  0.1797, -0.0795, -0.0457, -0.0626,  0.1093, -0.0195,  0.0215,\n",
       "         -0.0308, -0.0459, -0.0289, -0.1460,  0.0080,  0.0619,  0.1040,  0.0592,\n",
       "         -0.0391,  0.0346,  0.1165, -0.0450,  0.1288, -0.0175, -0.0691, -0.0019,\n",
       "          0.0332,  0.1194]), 'layers.1.weight': tensor([[ 0.0393,  0.1062, -0.1200, -0.1057,  0.0582, -0.0927, -0.0534, -0.0446,\n",
       "           0.1299, -0.0360,  0.0601, -0.0741,  0.0840, -0.0191, -0.0606,  0.0439,\n",
       "          -0.0805, -0.0475,  0.0498,  0.1040, -0.1050,  0.0748, -0.0962, -0.0913,\n",
       "          -0.0658,  0.1333,  0.1001,  0.1065,  0.0924, -0.0245, -0.1309,  0.1145,\n",
       "           0.0242,  0.0511, -0.1109,  0.0976,  0.1371, -0.0554,  0.1531, -0.0508,\n",
       "          -0.1433,  0.0688,  0.1246, -0.0682,  0.0690,  0.1417, -0.0878, -0.0429,\n",
       "          -0.0798, -0.0853]]), 'layers.1.bias': tensor([-0.0824]), 'skip.weight': tensor([[ 0.0164, -0.0148,  0.0168,  0.0161,  0.0168,  0.0197, -0.0189, -0.0164,\n",
       "           0.0120,  0.0161, -0.0188, -0.0229, -0.0202,  0.0154,  0.0169, -0.0156,\n",
       "           0.0148,  0.0156,  0.0201,  0.0200,  0.0118,  0.0153,  0.0205,  0.0157,\n",
       "          -0.0176,  0.0199, -0.0180,  0.0230, -0.0192,  0.0142,  0.0174, -0.0227,\n",
       "           0.0257, -0.0219,  0.0250, -0.0171, -0.0231, -0.0167, -0.0140, -0.0215,\n",
       "          -0.0126, -0.0146,  0.0194, -0.0171,  0.0168,  0.0241, -0.0215, -0.0158,\n",
       "          -0.0224, -0.0140,  0.0198, -0.0129, -0.0175,  0.0130,  0.0161,  0.0184,\n",
       "          -0.0164, -0.0224, -0.0169,  0.0185,  0.0125,  0.0149, -0.0240,  0.0278,\n",
       "           0.0299, -0.0278,  0.0175]])}, objective=1.974936008435981, loss=0.7421708106994629, val_objective=2.00865560768296, val_loss=0.7758904099464419, regularization=1.2292412519454956, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.0229241002945144, state_dict={'layers.0.weight': tensor([[-0.0718,  0.0227,  0.0818,  ..., -0.0095,  0.0614,  0.0342],\n",
       "         [-0.1193,  0.0165, -0.0187,  ...,  0.0293, -0.0955, -0.0787],\n",
       "         [-0.0373, -0.0520, -0.0173,  ..., -0.2560, -0.1357, -0.0180],\n",
       "         ...,\n",
       "         [-0.0037, -0.1444, -0.0265,  ..., -0.1630, -0.0605,  0.0413],\n",
       "         [ 0.1282, -0.0216, -0.0915,  ..., -0.0235, -0.0045,  0.1276],\n",
       "         [-0.0335, -0.0207,  0.1342,  ...,  0.0506, -0.0916,  0.1743]]), 'layers.0.bias': tensor([-0.0642,  0.1418,  0.0464,  0.0628,  0.0949,  0.0944,  0.0071, -0.1482,\n",
       "          0.0080, -0.0816,  0.0704,  0.0929,  0.1281,  0.0372, -0.1484, -0.1186,\n",
       "         -0.0690, -0.0999,  0.1493,  0.0089,  0.0593,  0.1532, -0.0923,  0.0560,\n",
       "         -0.0784,  0.1797, -0.0797, -0.0458, -0.0625,  0.1093, -0.0196,  0.0216,\n",
       "         -0.0308, -0.0459, -0.0290, -0.1460,  0.0078,  0.0619,  0.1040,  0.0592,\n",
       "         -0.0393,  0.0346,  0.1166, -0.0450,  0.1287, -0.0176, -0.0691, -0.0019,\n",
       "          0.0332,  0.1193]), 'layers.1.weight': tensor([[ 0.0395,  0.1061, -0.1204, -0.1052,  0.0577, -0.0925, -0.0530, -0.0437,\n",
       "           0.1301, -0.0356,  0.0594, -0.0738,  0.0834, -0.0182, -0.0602,  0.0439,\n",
       "          -0.0803, -0.0465,  0.0492,  0.1030, -0.1052,  0.0738, -0.0954, -0.0904,\n",
       "          -0.0654,  0.1331,  0.0992,  0.1059,  0.0926, -0.0242, -0.1303,  0.1148,\n",
       "           0.0235,  0.0510, -0.1104,  0.0978,  0.1363, -0.0554,  0.1530, -0.0507,\n",
       "          -0.1428,  0.0685,  0.1250, -0.0683,  0.0687,  0.1408, -0.0877, -0.0429,\n",
       "          -0.0795, -0.0850]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0164, -0.0148,  0.0168,  0.0161,  0.0168,  0.0197, -0.0189, -0.0164,\n",
       "           0.0119,  0.0160, -0.0187, -0.0209, -0.0201,  0.0154,  0.0169, -0.0156,\n",
       "           0.0147,  0.0156,  0.0201,  0.0199,  0.0118,  0.0153,  0.0205,  0.0157,\n",
       "          -0.0176,  0.0199, -0.0180,  0.0229, -0.0191,  0.0142,  0.0174, -0.0227,\n",
       "           0.0257, -0.0219,  0.0250, -0.0171, -0.0231, -0.0167, -0.0140, -0.0215,\n",
       "          -0.0126, -0.0146,  0.0194, -0.0171,  0.0168,  0.0241, -0.0215, -0.0157,\n",
       "          -0.0223, -0.0139,  0.0182, -0.0129, -0.0174,  0.0130,  0.0161,  0.0183,\n",
       "          -0.0164, -0.0223, -0.0168,  0.0184,  0.0125,  0.0148, -0.0239,  0.0277,\n",
       "           0.0298, -0.0277,  0.0174]])}, objective=1.993171181481026, loss=0.741851806640625, val_objective=2.0267236493040546, val_loss=0.7754042744636536, regularization=1.2232768535614014, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.0433825823004048, state_dict={'layers.0.weight': tensor([[-0.0717,  0.0227,  0.0818,  ..., -0.0095,  0.0614,  0.0342],\n",
       "         [-0.1192,  0.0165, -0.0186,  ...,  0.0294, -0.0956, -0.0785],\n",
       "         [-0.0375, -0.0520, -0.0174,  ..., -0.2561, -0.1356, -0.0182],\n",
       "         ...,\n",
       "         [-0.0037, -0.1444, -0.0266,  ..., -0.1631, -0.0605,  0.0412],\n",
       "         [ 0.1281, -0.0216, -0.0916,  ..., -0.0236, -0.0044,  0.1275],\n",
       "         [-0.0337, -0.0208,  0.1341,  ...,  0.0506, -0.0915,  0.1740]]), 'layers.0.bias': tensor([-0.0642,  0.1417,  0.0463,  0.0627,  0.0948,  0.0943,  0.0070, -0.1482,\n",
       "          0.0079, -0.0817,  0.0703,  0.0929,  0.1281,  0.0372, -0.1484, -0.1186,\n",
       "         -0.0690, -0.1000,  0.1493,  0.0087,  0.0593,  0.1531, -0.0924,  0.0560,\n",
       "         -0.0784,  0.1797, -0.0799, -0.0459, -0.0625,  0.1092, -0.0197,  0.0216,\n",
       "         -0.0308, -0.0459, -0.0290, -0.1461,  0.0076,  0.0619,  0.1039,  0.0591,\n",
       "         -0.0395,  0.0346,  0.1166, -0.0450,  0.1287, -0.0178, -0.0691, -0.0019,\n",
       "          0.0331,  0.1193]), 'layers.1.weight': tensor([[ 0.0397,  0.1061, -0.1208, -0.1047,  0.0572, -0.0923, -0.0527, -0.0427,\n",
       "           0.1302, -0.0352,  0.0587, -0.0736,  0.0827, -0.0174, -0.0599,  0.0439,\n",
       "          -0.0800, -0.0454,  0.0486,  0.1021, -0.1053,  0.0729, -0.0946, -0.0896,\n",
       "          -0.0650,  0.1328,  0.0983,  0.1053,  0.0929, -0.0239, -0.1297,  0.1152,\n",
       "           0.0229,  0.0509, -0.1100,  0.0980,  0.1355, -0.0554,  0.1529, -0.0505,\n",
       "          -0.1422,  0.0682,  0.1253, -0.0684,  0.0685,  0.1400, -0.0876, -0.0430,\n",
       "          -0.0792, -0.0846]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0164, -0.0147,  0.0168,  0.0160,  0.0168,  0.0196, -0.0189, -0.0164,\n",
       "           0.0119,  0.0160, -0.0187, -0.0190, -0.0201,  0.0153,  0.0169, -0.0155,\n",
       "           0.0147,  0.0155,  0.0200,  0.0199,  0.0118,  0.0152,  0.0204,  0.0156,\n",
       "          -0.0176,  0.0198, -0.0180,  0.0229, -0.0191,  0.0142,  0.0174, -0.0226,\n",
       "           0.0256, -0.0218,  0.0249, -0.0171, -0.0231, -0.0166, -0.0140, -0.0214,\n",
       "          -0.0126, -0.0145,  0.0193, -0.0170,  0.0167,  0.0240, -0.0214, -0.0156,\n",
       "          -0.0223, -0.0139,  0.0174, -0.0129, -0.0174,  0.0130,  0.0160,  0.0183,\n",
       "          -0.0163, -0.0223, -0.0168,  0.0184,  0.0124,  0.0148, -0.0239,  0.0277,\n",
       "           0.0298, -0.0277,  0.0174]])}, objective=2.012358506991676, loss=0.7415321469306946, val_objective=2.04566677458506, val_loss=0.7748404145240784, regularization=1.2179869413375854, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.0642502339464128, state_dict={'layers.0.weight': tensor([[-0.0717,  0.0227,  0.0819,  ..., -0.0095,  0.0613,  0.0343],\n",
       "         [-0.1190,  0.0165, -0.0186,  ...,  0.0295, -0.0957, -0.0783],\n",
       "         [-0.0376, -0.0521, -0.0174,  ..., -0.2563, -0.1355, -0.0183],\n",
       "         ...,\n",
       "         [-0.0038, -0.1444, -0.0266,  ..., -0.1631, -0.0605,  0.0412],\n",
       "         [ 0.1279, -0.0216, -0.0916,  ..., -0.0236, -0.0044,  0.1274],\n",
       "         [-0.0339, -0.0208,  0.1341,  ...,  0.0505, -0.0914,  0.1737]]), 'layers.0.bias': tensor([-0.0642,  0.1417,  0.0463,  0.0627,  0.0948,  0.0942,  0.0070, -0.1483,\n",
       "          0.0079, -0.0817,  0.0703,  0.0929,  0.1280,  0.0372, -0.1485, -0.1186,\n",
       "         -0.0691, -0.1000,  0.1492,  0.0085,  0.0593,  0.1531, -0.0925,  0.0559,\n",
       "         -0.0784,  0.1797, -0.0801, -0.0460, -0.0624,  0.1092, -0.0198,  0.0217,\n",
       "         -0.0309, -0.0459, -0.0290, -0.1461,  0.0074,  0.0620,  0.1039,  0.0591,\n",
       "         -0.0396,  0.0346,  0.1166, -0.0450,  0.1286, -0.0179, -0.0691, -0.0019,\n",
       "          0.0331,  0.1193]), 'layers.1.weight': tensor([[ 0.0399,  0.1061, -0.1211, -0.1042,  0.0567, -0.0922, -0.0523, -0.0419,\n",
       "           0.1303, -0.0348,  0.0581, -0.0733,  0.0821, -0.0166, -0.0596,  0.0440,\n",
       "          -0.0797, -0.0444,  0.0481,  0.1013, -0.1054,  0.0719, -0.0939, -0.0888,\n",
       "          -0.0647,  0.1325,  0.0974,  0.1048,  0.0931, -0.0235, -0.1291,  0.1155,\n",
       "           0.0223,  0.0509, -0.1095,  0.0982,  0.1347, -0.0554,  0.1528, -0.0504,\n",
       "          -0.1417,  0.0679,  0.1256, -0.0685,  0.0682,  0.1392, -0.0875, -0.0430,\n",
       "          -0.0789, -0.0843]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0163, -0.0147,  0.0167,  0.0160,  0.0168,  0.0196, -0.0188, -0.0164,\n",
       "           0.0119,  0.0160, -0.0186, -0.0170, -0.0200,  0.0153,  0.0168, -0.0155,\n",
       "           0.0147,  0.0155,  0.0200,  0.0198,  0.0117,  0.0152,  0.0204,  0.0156,\n",
       "          -0.0176,  0.0198, -0.0180,  0.0228, -0.0191,  0.0141,  0.0174, -0.0226,\n",
       "           0.0256, -0.0218,  0.0249, -0.0170, -0.0230, -0.0166, -0.0139, -0.0214,\n",
       "          -0.0125, -0.0145,  0.0193, -0.0170,  0.0167,  0.0240, -0.0214, -0.0156,\n",
       "          -0.0223, -0.0138,  0.0173, -0.0129, -0.0173,  0.0129,  0.0160,  0.0182,\n",
       "          -0.0163, -0.0222, -0.0167,  0.0183,  0.0124,  0.0147, -0.0238,  0.0276,\n",
       "           0.0298, -0.0277,  0.0174]])}, objective=2.0326457480509554, loss=0.7411558628082275, val_objective=2.065666721256522, val_loss=0.774176836013794, regularization=1.213520884513855, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.0855352386253412, state_dict={'layers.0.weight': tensor([[-0.0716,  0.0227,  0.0819,  ..., -0.0094,  0.0613,  0.0343],\n",
       "         [-0.1188,  0.0166, -0.0185,  ...,  0.0296, -0.0958, -0.0781],\n",
       "         [-0.0377, -0.0521, -0.0175,  ..., -0.2564, -0.1354, -0.0184],\n",
       "         ...,\n",
       "         [-0.0039, -0.1445, -0.0266,  ..., -0.1632, -0.0604,  0.0411],\n",
       "         [ 0.1277, -0.0216, -0.0916,  ..., -0.0237, -0.0043,  0.1273],\n",
       "         [-0.0340, -0.0209,  0.1340,  ...,  0.0504, -0.0914,  0.1733]]), 'layers.0.bias': tensor([-0.0642,  0.1416,  0.0463,  0.0627,  0.0948,  0.0942,  0.0070, -0.1483,\n",
       "          0.0078, -0.0817,  0.0702,  0.0929,  0.1280,  0.0371, -0.1485, -0.1186,\n",
       "         -0.0691, -0.1000,  0.1492,  0.0083,  0.0593,  0.1530, -0.0926,  0.0558,\n",
       "         -0.0784,  0.1796, -0.0803, -0.0461, -0.0623,  0.1092, -0.0198,  0.0217,\n",
       "         -0.0309, -0.0459, -0.0291, -0.1461,  0.0073,  0.0620,  0.1038,  0.0591,\n",
       "         -0.0398,  0.0347,  0.1167, -0.0450,  0.1286, -0.0180, -0.0691, -0.0019,\n",
       "          0.0331,  0.1192]), 'layers.1.weight': tensor([[ 0.0401,  0.1061, -0.1215, -0.1037,  0.0562, -0.0921, -0.0521, -0.0410,\n",
       "           0.1304, -0.0344,  0.0575, -0.0731,  0.0815, -0.0159, -0.0594,  0.0440,\n",
       "          -0.0795, -0.0434,  0.0475,  0.1004, -0.1055,  0.0710, -0.0932, -0.0880,\n",
       "          -0.0643,  0.1323,  0.0966,  0.1043,  0.0934, -0.0232, -0.1285,  0.1158,\n",
       "           0.0216,  0.0508, -0.1091,  0.0985,  0.1340, -0.0554,  0.1527, -0.0503,\n",
       "          -0.1411,  0.0676,  0.1258, -0.0685,  0.0680,  0.1384, -0.0875, -0.0430,\n",
       "          -0.0786, -0.0840]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0163, -0.0146,  0.0167,  0.0160,  0.0168,  0.0195, -0.0188, -0.0163,\n",
       "           0.0119,  0.0160, -0.0186, -0.0151, -0.0200,  0.0152,  0.0168, -0.0155,\n",
       "           0.0147,  0.0154,  0.0200,  0.0198,  0.0117,  0.0151,  0.0203,  0.0155,\n",
       "          -0.0175,  0.0197, -0.0179,  0.0227, -0.0190,  0.0141,  0.0173, -0.0226,\n",
       "           0.0256, -0.0217,  0.0248, -0.0170, -0.0230, -0.0166, -0.0139, -0.0214,\n",
       "          -0.0125, -0.0145,  0.0192, -0.0170,  0.0167,  0.0239, -0.0213, -0.0155,\n",
       "          -0.0223, -0.0138,  0.0173, -0.0129, -0.0173,  0.0129,  0.0160,  0.0182,\n",
       "          -0.0163, -0.0221, -0.0167,  0.0183,  0.0124,  0.0147, -0.0237,  0.0276,\n",
       "           0.0297, -0.0277,  0.0173]])}, objective=2.053197155504331, loss=0.7408100366592407, val_objective=2.085944960622892, val_loss=0.7735578417778017, regularization=1.2089769840240479, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.107245943397848, state_dict={'layers.0.weight': tensor([[-0.0716,  0.0227,  0.0819,  ..., -0.0094,  0.0613,  0.0343],\n",
       "         [-0.1187,  0.0166, -0.0185,  ...,  0.0297, -0.0959, -0.0779],\n",
       "         [-0.0378, -0.0521, -0.0176,  ..., -0.2565, -0.1353, -0.0186],\n",
       "         ...,\n",
       "         [-0.0039, -0.1445, -0.0266,  ..., -0.1632, -0.0604,  0.0410],\n",
       "         [ 0.1276, -0.0216, -0.0917,  ..., -0.0238, -0.0043,  0.1272],\n",
       "         [-0.0342, -0.0209,  0.1339,  ...,  0.0503, -0.0913,  0.1730]]), 'layers.0.bias': tensor([-0.0642,  0.1416,  0.0463,  0.0626,  0.0947,  0.0941,  0.0069, -0.1483,\n",
       "          0.0078, -0.0817,  0.0702,  0.0930,  0.1279,  0.0371, -0.1485, -0.1186,\n",
       "         -0.0691, -0.1001,  0.1492,  0.0082,  0.0593,  0.1530, -0.0927,  0.0557,\n",
       "         -0.0785,  0.1796, -0.0805, -0.0462, -0.0623,  0.1092, -0.0199,  0.0218,\n",
       "         -0.0309, -0.0459, -0.0291, -0.1461,  0.0071,  0.0620,  0.1038,  0.0591,\n",
       "         -0.0400,  0.0347,  0.1167, -0.0450,  0.1285, -0.0181, -0.0691, -0.0019,\n",
       "          0.0330,  0.1192]), 'layers.1.weight': tensor([[ 0.0403,  0.1061, -0.1218, -0.1032,  0.0557, -0.0920, -0.0518, -0.0402,\n",
       "           0.1305, -0.0341,  0.0569, -0.0729,  0.0808, -0.0152, -0.0591,  0.0441,\n",
       "          -0.0792, -0.0424,  0.0469,  0.0996, -0.1056,  0.0702, -0.0925, -0.0872,\n",
       "          -0.0640,  0.1320,  0.0958,  0.1038,  0.0937, -0.0229, -0.1280,  0.1162,\n",
       "           0.0210,  0.0507, -0.1086,  0.0987,  0.1333, -0.0555,  0.1527, -0.0502,\n",
       "          -0.1406,  0.0673,  0.1261, -0.0686,  0.0678,  0.1376, -0.0874, -0.0431,\n",
       "          -0.0784, -0.0836]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0163, -0.0146,  0.0167,  0.0159,  0.0167,  0.0195, -0.0187, -0.0163,\n",
       "           0.0118,  0.0159, -0.0185, -0.0135, -0.0200,  0.0152,  0.0168, -0.0155,\n",
       "           0.0147,  0.0154,  0.0199,  0.0197,  0.0117,  0.0150,  0.0203,  0.0155,\n",
       "          -0.0175,  0.0197, -0.0179,  0.0227, -0.0190,  0.0141,  0.0173, -0.0226,\n",
       "           0.0255, -0.0217,  0.0248, -0.0169, -0.0229, -0.0165, -0.0139, -0.0213,\n",
       "          -0.0125, -0.0144,  0.0192, -0.0169,  0.0166,  0.0239, -0.0213, -0.0155,\n",
       "          -0.0223, -0.0137,  0.0173, -0.0128, -0.0173,  0.0129,  0.0160,  0.0181,\n",
       "          -0.0162, -0.0221, -0.0166,  0.0182,  0.0123,  0.0146, -0.0237,  0.0275,\n",
       "           0.0297, -0.0277,  0.0173]])}, objective=2.0744715169954158, loss=0.7404916882514954, val_objective=2.106940014748559, val_loss=0.7729601860046387, regularization=1.2047728300094604, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.129390862265805, state_dict={'layers.0.weight': tensor([[-0.0715,  0.0227,  0.0819,  ..., -0.0093,  0.0612,  0.0344],\n",
       "         [-0.1185,  0.0166, -0.0185,  ...,  0.0298, -0.0960, -0.0778],\n",
       "         [-0.0379, -0.0522, -0.0176,  ..., -0.2566, -0.1353, -0.0187],\n",
       "         ...,\n",
       "         [-0.0040, -0.1445, -0.0266,  ..., -0.1632, -0.0604,  0.0410],\n",
       "         [ 0.1274, -0.0217, -0.0917,  ..., -0.0239, -0.0042,  0.1271],\n",
       "         [-0.0343, -0.0209,  0.1339,  ...,  0.0502, -0.0912,  0.1726]]), 'layers.0.bias': tensor([-0.0642,  0.1416,  0.0463,  0.0626,  0.0947,  0.0941,  0.0069, -0.1484,\n",
       "          0.0077, -0.0817,  0.0702,  0.0930,  0.1279,  0.0371, -0.1486, -0.1186,\n",
       "         -0.0692, -0.1001,  0.1492,  0.0080,  0.0594,  0.1529, -0.0928,  0.0556,\n",
       "         -0.0785,  0.1796, -0.0807, -0.0463, -0.0622,  0.1092, -0.0200,  0.0218,\n",
       "         -0.0309, -0.0459, -0.0291, -0.1461,  0.0069,  0.0620,  0.1037,  0.0591,\n",
       "         -0.0401,  0.0347,  0.1167, -0.0450,  0.1285, -0.0182, -0.0691, -0.0018,\n",
       "          0.0330,  0.1191]), 'layers.1.weight': tensor([[ 0.0405,  0.1061, -0.1222, -0.1028,  0.0553, -0.0919, -0.0516, -0.0395,\n",
       "           0.1306, -0.0337,  0.0563, -0.0727,  0.0802, -0.0145, -0.0589,  0.0442,\n",
       "          -0.0789, -0.0415,  0.0463,  0.0988, -0.1057,  0.0693, -0.0918, -0.0865,\n",
       "          -0.0636,  0.1318,  0.0950,  0.1033,  0.0940, -0.0226, -0.1275,  0.1165,\n",
       "           0.0205,  0.0507, -0.1082,  0.0989,  0.1326, -0.0556,  0.1527, -0.0501,\n",
       "          -0.1401,  0.0669,  0.1264, -0.0687,  0.0676,  0.1368, -0.0874, -0.0431,\n",
       "          -0.0781, -0.0833]]), 'layers.1.bias': tensor([-0.0825]), 'skip.weight': tensor([[ 0.0163, -0.0145,  0.0167,  0.0159,  0.0167,  0.0194, -0.0187, -0.0163,\n",
       "           0.0118,  0.0159, -0.0185, -0.0134, -0.0199,  0.0151,  0.0168, -0.0154,\n",
       "           0.0147,  0.0153,  0.0199,  0.0197,  0.0117,  0.0150,  0.0202,  0.0155,\n",
       "          -0.0175,  0.0196, -0.0179,  0.0226, -0.0189,  0.0140,  0.0173, -0.0225,\n",
       "           0.0255, -0.0216,  0.0247, -0.0169, -0.0229, -0.0165, -0.0139, -0.0213,\n",
       "          -0.0125, -0.0144,  0.0191, -0.0169,  0.0166,  0.0238, -0.0212, -0.0154,\n",
       "          -0.0222, -0.0137,  0.0173, -0.0128, -0.0172,  0.0128,  0.0159,  0.0180,\n",
       "          -0.0162, -0.0220, -0.0166,  0.0182,  0.0123,  0.0146, -0.0236,  0.0275,\n",
       "           0.0296, -0.0276,  0.0173]])}, objective=2.0976795933406596, loss=0.7400587201118469, val_objective=2.129944839255119, val_loss=0.7723239660263064, regularization=1.2020823955535889, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.1519786795111213, state_dict={'layers.0.weight': tensor([[-0.0715,  0.0227,  0.0820,  ..., -0.0093,  0.0612,  0.0344],\n",
       "         [-0.1184,  0.0166, -0.0184,  ...,  0.0299, -0.0961, -0.0776],\n",
       "         [-0.0380, -0.0522, -0.0177,  ..., -0.2567, -0.1352, -0.0188],\n",
       "         ...,\n",
       "         [-0.0040, -0.1444, -0.0266,  ..., -0.1633, -0.0603,  0.0409],\n",
       "         [ 0.1273, -0.0217, -0.0918,  ..., -0.0240, -0.0041,  0.1270],\n",
       "         [-0.0344, -0.0210,  0.1338,  ...,  0.0501, -0.0911,  0.1722]]), 'layers.0.bias': tensor([-0.0642,  0.1415,  0.0462,  0.0625,  0.0947,  0.0940,  0.0068, -0.1484,\n",
       "          0.0077, -0.0817,  0.0701,  0.0930,  0.1279,  0.0371, -0.1486, -0.1187,\n",
       "         -0.0692, -0.1001,  0.1491,  0.0079,  0.0594,  0.1528, -0.0929,  0.0555,\n",
       "         -0.0785,  0.1796, -0.0808, -0.0463, -0.0621,  0.1091, -0.0201,  0.0219,\n",
       "         -0.0310, -0.0459, -0.0292, -0.1461,  0.0068,  0.0620,  0.1037,  0.0591,\n",
       "         -0.0403,  0.0347,  0.1168, -0.0450,  0.1284, -0.0183, -0.0691, -0.0018,\n",
       "          0.0330,  0.1191]), 'layers.1.weight': tensor([[ 0.0407,  0.1062, -0.1225, -0.1024,  0.0549, -0.0919, -0.0514, -0.0387,\n",
       "           0.1307, -0.0334,  0.0558, -0.0725,  0.0796, -0.0138, -0.0588,  0.0443,\n",
       "          -0.0786, -0.0406,  0.0458,  0.0980, -0.1058,  0.0685, -0.0912, -0.0858,\n",
       "          -0.0633,  0.1315,  0.0943,  0.1029,  0.0943, -0.0223, -0.1270,  0.1169,\n",
       "           0.0199,  0.0507, -0.1078,  0.0992,  0.1319, -0.0557,  0.1526, -0.0501,\n",
       "          -0.1396,  0.0666,  0.1266, -0.0688,  0.0674,  0.1361, -0.0873, -0.0431,\n",
       "          -0.0779, -0.0830]]), 'layers.1.bias': tensor([-0.0824]), 'skip.weight': tensor([[ 0.0162, -0.0144,  0.0167,  0.0158,  0.0167,  0.0193, -0.0186, -0.0163,\n",
       "           0.0118,  0.0159, -0.0184, -0.0134, -0.0199,  0.0150,  0.0167, -0.0154,\n",
       "           0.0146,  0.0153,  0.0199,  0.0196,  0.0116,  0.0150,  0.0202,  0.0154,\n",
       "          -0.0174,  0.0196, -0.0179,  0.0225, -0.0189,  0.0140,  0.0173, -0.0225,\n",
       "           0.0254, -0.0216,  0.0246, -0.0168, -0.0228, -0.0164, -0.0138, -0.0212,\n",
       "          -0.0124, -0.0143,  0.0190, -0.0168,  0.0166,  0.0238, -0.0212, -0.0153,\n",
       "          -0.0222, -0.0136,  0.0172, -0.0128, -0.0172,  0.0128,  0.0159,  0.0180,\n",
       "          -0.0162, -0.0220, -0.0165,  0.0181,  0.0123,  0.0145, -0.0236,  0.0274,\n",
       "           0.0296, -0.0276,  0.0172]])}, objective=2.121291760481557, loss=0.7396605014801025, val_objective=2.1533666887652485, val_loss=0.7717354297637942, regularization=1.199354887008667, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.1750182531013438, state_dict={'layers.0.weight': tensor([[-0.0714,  0.0228,  0.0820,  ..., -0.0093,  0.0612,  0.0345],\n",
       "         [-0.1182,  0.0167, -0.0184,  ...,  0.0300, -0.0962, -0.0774],\n",
       "         [-0.0381, -0.0522, -0.0178,  ..., -0.2569, -0.1351, -0.0189],\n",
       "         ...,\n",
       "         [-0.0041, -0.1442, -0.0266,  ..., -0.1633, -0.0603,  0.0409],\n",
       "         [ 0.1271, -0.0217, -0.0918,  ..., -0.0240, -0.0041,  0.1269],\n",
       "         [-0.0346, -0.0210,  0.1338,  ...,  0.0501, -0.0910,  0.1718]]), 'layers.0.bias': tensor([-0.0642,  0.1415,  0.0462,  0.0625,  0.0946,  0.0940,  0.0068, -0.1485,\n",
       "          0.0076, -0.0818,  0.0701,  0.0930,  0.1278,  0.0371, -0.1486, -0.1187,\n",
       "         -0.0692, -0.1001,  0.1491,  0.0077,  0.0594,  0.1528, -0.0930,  0.0555,\n",
       "         -0.0785,  0.1796, -0.0810, -0.0464, -0.0621,  0.1091, -0.0202,  0.0219,\n",
       "         -0.0310, -0.0459, -0.0292, -0.1461,  0.0067,  0.0620,  0.1036,  0.0590,\n",
       "         -0.0405,  0.0347,  0.1168, -0.0450,  0.1284, -0.0184, -0.0691, -0.0018,\n",
       "          0.0329,  0.1191]), 'layers.1.weight': tensor([[ 0.0409,  0.1062, -0.1228, -0.1020,  0.0545, -0.0919, -0.0512, -0.0381,\n",
       "           0.1308, -0.0331,  0.0552, -0.0724,  0.0790, -0.0132, -0.0586,  0.0443,\n",
       "          -0.0783, -0.0398,  0.0452,  0.0972, -0.1059,  0.0677, -0.0906, -0.0851,\n",
       "          -0.0631,  0.1312,  0.0935,  0.1025,  0.0946, -0.0220, -0.1266,  0.1172,\n",
       "           0.0194,  0.0506, -0.1074,  0.0994,  0.1313, -0.0558,  0.1526, -0.0500,\n",
       "          -0.1391,  0.0663,  0.1269, -0.0689,  0.0672,  0.1354, -0.0873, -0.0432,\n",
       "          -0.0776, -0.0828]]), 'layers.1.bias': tensor([-0.0824]), 'skip.weight': tensor([[ 0.0162, -0.0144,  0.0167,  0.0158,  0.0167,  0.0193, -0.0186, -0.0162,\n",
       "           0.0117,  0.0159, -0.0183, -0.0133, -0.0198,  0.0150,  0.0167, -0.0154,\n",
       "           0.0146,  0.0152,  0.0198,  0.0196,  0.0116,  0.0150,  0.0201,  0.0154,\n",
       "          -0.0174,  0.0195, -0.0178,  0.0225, -0.0189,  0.0140,  0.0172, -0.0224,\n",
       "           0.0254, -0.0215,  0.0246, -0.0167, -0.0228, -0.0164, -0.0138, -0.0212,\n",
       "          -0.0124, -0.0143,  0.0190, -0.0168,  0.0165,  0.0237, -0.0211, -0.0153,\n",
       "          -0.0222, -0.0136,  0.0172, -0.0128, -0.0171,  0.0128,  0.0159,  0.0179,\n",
       "          -0.0162, -0.0219, -0.0164,  0.0181,  0.0122,  0.0145, -0.0235,  0.0273,\n",
       "           0.0295, -0.0276,  0.0172]])}, objective=2.1453303542184052, loss=0.739296555519104, val_objective=2.177228197102469, val_loss=0.7711943984031677, regularization=1.196605920791626, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.1985186181633707, state_dict={'layers.0.weight': tensor([[-0.0714,  0.0228,  0.0820,  ..., -0.0092,  0.0611,  0.0345],\n",
       "         [-0.1181,  0.0167, -0.0183,  ...,  0.0301, -0.0963, -0.0773],\n",
       "         [-0.0383, -0.0523, -0.0178,  ..., -0.2570, -0.1350, -0.0190],\n",
       "         ...,\n",
       "         [-0.0042, -0.1439, -0.0266,  ..., -0.1634, -0.0603,  0.0408],\n",
       "         [ 0.1270, -0.0217, -0.0918,  ..., -0.0241, -0.0040,  0.1268],\n",
       "         [-0.0347, -0.0210,  0.1337,  ...,  0.0500, -0.0909,  0.1713]]), 'layers.0.bias': tensor([-0.0642,  0.1415,  0.0462,  0.0625,  0.0946,  0.0939,  0.0068, -0.1485,\n",
       "          0.0076, -0.0818,  0.0700,  0.0931,  0.1278,  0.0371, -0.1487, -0.1187,\n",
       "         -0.0693, -0.1001,  0.1491,  0.0076,  0.0594,  0.1527, -0.0931,  0.0554,\n",
       "         -0.0785,  0.1796, -0.0812, -0.0465, -0.0620,  0.1091, -0.0203,  0.0220,\n",
       "         -0.0310, -0.0459, -0.0292, -0.1462,  0.0065,  0.0620,  0.1036,  0.0590,\n",
       "         -0.0406,  0.0347,  0.1169, -0.0450,  0.1283, -0.0185, -0.0692, -0.0018,\n",
       "          0.0329,  0.1190]), 'layers.1.weight': tensor([[ 0.0410,  0.1062, -0.1231, -0.1016,  0.0542, -0.0919, -0.0511, -0.0375,\n",
       "           0.1309, -0.0328,  0.0547, -0.0722,  0.0784, -0.0126, -0.0585,  0.0444,\n",
       "          -0.0781, -0.0390,  0.0447,  0.0965, -0.1060,  0.0669, -0.0900, -0.0844,\n",
       "          -0.0628,  0.1310,  0.0928,  0.1021,  0.0948, -0.0217, -0.1261,  0.1175,\n",
       "           0.0188,  0.0506, -0.1070,  0.0996,  0.1306, -0.0559,  0.1526, -0.0500,\n",
       "          -0.1387,  0.0660,  0.1271, -0.0689,  0.0670,  0.1347, -0.0873, -0.0432,\n",
       "          -0.0774, -0.0825]]), 'layers.1.bias': tensor([-0.0823]), 'skip.weight': tensor([[ 0.0162, -0.0144,  0.0166,  0.0157,  0.0167,  0.0192, -0.0186, -0.0162,\n",
       "           0.0117,  0.0158, -0.0183, -0.0133, -0.0198,  0.0149,  0.0167, -0.0153,\n",
       "           0.0146,  0.0152,  0.0198,  0.0195,  0.0116,  0.0149,  0.0200,  0.0154,\n",
       "          -0.0174,  0.0195, -0.0178,  0.0224, -0.0188,  0.0140,  0.0172, -0.0224,\n",
       "           0.0253, -0.0215,  0.0245, -0.0167, -0.0227, -0.0163, -0.0138, -0.0211,\n",
       "          -0.0124, -0.0142,  0.0189, -0.0167,  0.0165,  0.0237, -0.0211, -0.0152,\n",
       "          -0.0222, -0.0135,  0.0172, -0.0128, -0.0171,  0.0127,  0.0159,  0.0179,\n",
       "          -0.0161, -0.0218, -0.0164,  0.0180,  0.0122,  0.0144, -0.0234,  0.0273,\n",
       "           0.0295, -0.0276,  0.0171]])}, objective=2.1697449296599984, loss=0.7389637231826782, val_objective=2.201477012026942, val_loss=0.7706958055496218, regularization=1.193791389465332, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.222488990526638, state_dict={'layers.0.weight': tensor([[-0.0713,  0.0228,  0.0820,  ..., -0.0092,  0.0611,  0.0345],\n",
       "         [-0.1180,  0.0167, -0.0183,  ...,  0.0302, -0.0964, -0.0771],\n",
       "         [-0.0384, -0.0523, -0.0179,  ..., -0.2571, -0.1350, -0.0191],\n",
       "         ...,\n",
       "         [-0.0042, -0.1435, -0.0267,  ..., -0.1634, -0.0603,  0.0408],\n",
       "         [ 0.1269, -0.0217, -0.0919,  ..., -0.0242, -0.0040,  0.1268],\n",
       "         [-0.0348, -0.0211,  0.1337,  ...,  0.0499, -0.0909,  0.1709]]), 'layers.0.bias': tensor([-0.0642,  0.1415,  0.0462,  0.0624,  0.0946,  0.0939,  0.0068, -0.1485,\n",
       "          0.0075, -0.0818,  0.0700,  0.0931,  0.1278,  0.0371, -0.1487, -0.1187,\n",
       "         -0.0693, -0.1002,  0.1491,  0.0074,  0.0594,  0.1527, -0.0931,  0.0553,\n",
       "         -0.0785,  0.1796, -0.0813, -0.0465, -0.0619,  0.1091, -0.0204,  0.0220,\n",
       "         -0.0310, -0.0459, -0.0292, -0.1462,  0.0064,  0.0620,  0.1036,  0.0590,\n",
       "         -0.0408,  0.0347,  0.1169, -0.0450,  0.1283, -0.0186, -0.0692, -0.0018,\n",
       "          0.0329,  0.1190]), 'layers.1.weight': tensor([[ 0.0412,  0.1063, -0.1234, -0.1012,  0.0538, -0.0919, -0.0509, -0.0369,\n",
       "           0.1311, -0.0326,  0.0542, -0.0720,  0.0779, -0.0120, -0.0584,  0.0444,\n",
       "          -0.0779, -0.0383,  0.0442,  0.0958, -0.1061,  0.0661, -0.0895, -0.0838,\n",
       "          -0.0625,  0.1308,  0.0922,  0.1017,  0.0951, -0.0214, -0.1257,  0.1178,\n",
       "           0.0183,  0.0505, -0.1067,  0.0998,  0.1300, -0.0561,  0.1527, -0.0500,\n",
       "          -0.1382,  0.0658,  0.1272, -0.0690,  0.0669,  0.1341, -0.0873, -0.0433,\n",
       "          -0.0772, -0.0823]]), 'layers.1.bias': tensor([-0.0822]), 'skip.weight': tensor([[ 0.0161, -0.0144,  0.0166,  0.0157,  0.0166,  0.0192, -0.0185, -0.0162,\n",
       "           0.0117,  0.0158, -0.0182, -0.0133, -0.0197,  0.0149,  0.0167, -0.0153,\n",
       "           0.0146,  0.0151,  0.0198,  0.0195,  0.0116,  0.0149,  0.0200,  0.0153,\n",
       "          -0.0174,  0.0194, -0.0178,  0.0223, -0.0188,  0.0139,  0.0172, -0.0224,\n",
       "           0.0253, -0.0214,  0.0245, -0.0166, -0.0227, -0.0163, -0.0138, -0.0211,\n",
       "          -0.0124, -0.0142,  0.0189, -0.0167,  0.0165,  0.0236, -0.0210, -0.0151,\n",
       "          -0.0222, -0.0135,  0.0172, -0.0128, -0.0171,  0.0127,  0.0158,  0.0178,\n",
       "          -0.0161, -0.0218, -0.0163,  0.0180,  0.0122,  0.0144, -0.0234,  0.0272,\n",
       "           0.0295, -0.0276,  0.0171]])}, objective=2.194558683343495, loss=0.7386585474014282, val_objective=2.2261328730064283, val_loss=0.7702327370643616, regularization=1.1909310817718506, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.2469387703371708, state_dict={'layers.0.weight': tensor([[-0.0713,  0.0228,  0.0821,  ..., -0.0092,  0.0611,  0.0346],\n",
       "         [-0.1179,  0.0168, -0.0183,  ...,  0.0303, -0.0965, -0.0770],\n",
       "         [-0.0385, -0.0523, -0.0179,  ..., -0.2572, -0.1349, -0.0192],\n",
       "         ...,\n",
       "         [-0.0043, -0.1432, -0.0267,  ..., -0.1634, -0.0602,  0.0407],\n",
       "         [ 0.1267, -0.0218, -0.0919,  ..., -0.0242, -0.0039,  0.1267],\n",
       "         [-0.0350, -0.0211,  0.1336,  ...,  0.0498, -0.0908,  0.1704]]), 'layers.0.bias': tensor([-0.0641,  0.1414,  0.0461,  0.0624,  0.0946,  0.0939,  0.0067, -0.1486,\n",
       "          0.0075, -0.0818,  0.0700,  0.0931,  0.1277,  0.0370, -0.1487, -0.1187,\n",
       "         -0.0693, -0.1002,  0.1490,  0.0073,  0.0594,  0.1526, -0.0932,  0.0552,\n",
       "         -0.0785,  0.1796, -0.0815, -0.0466, -0.0619,  0.1091, -0.0204,  0.0221,\n",
       "         -0.0310, -0.0459, -0.0293, -0.1462,  0.0063,  0.0620,  0.1035,  0.0590,\n",
       "         -0.0409,  0.0347,  0.1169, -0.0450,  0.1283, -0.0187, -0.0692, -0.0018,\n",
       "          0.0328,  0.1190]), 'layers.1.weight': tensor([[ 0.0413,  0.1063, -0.1236, -0.1008,  0.0536, -0.0919, -0.0508, -0.0363,\n",
       "           0.1312, -0.0323,  0.0537, -0.0719,  0.0774, -0.0114, -0.0583,  0.0445,\n",
       "          -0.0778, -0.0376,  0.0437,  0.0950, -0.1061,  0.0654, -0.0890, -0.0832,\n",
       "          -0.0623,  0.1305,  0.0915,  0.1014,  0.0953, -0.0212, -0.1253,  0.1181,\n",
       "           0.0178,  0.0505, -0.1063,  0.1000,  0.1294, -0.0562,  0.1527, -0.0499,\n",
       "          -0.1378,  0.0655,  0.1274, -0.0691,  0.0667,  0.1334, -0.0873, -0.0434,\n",
       "          -0.0770, -0.0821]]), 'layers.1.bias': tensor([-0.0821]), 'skip.weight': tensor([[ 0.0161, -0.0143,  0.0166,  0.0157,  0.0166,  0.0191, -0.0185, -0.0161,\n",
       "           0.0116,  0.0158, -0.0182, -0.0132, -0.0197,  0.0148,  0.0166, -0.0153,\n",
       "           0.0146,  0.0150,  0.0197,  0.0194,  0.0115,  0.0149,  0.0199,  0.0153,\n",
       "          -0.0173,  0.0194, -0.0177,  0.0223, -0.0187,  0.0139,  0.0172, -0.0223,\n",
       "           0.0252, -0.0213,  0.0244, -0.0166, -0.0226, -0.0162, -0.0137, -0.0210,\n",
       "          -0.0123, -0.0142,  0.0188, -0.0166,  0.0165,  0.0236, -0.0209, -0.0151,\n",
       "          -0.0221, -0.0134,  0.0171, -0.0127, -0.0171,  0.0127,  0.0158,  0.0178,\n",
       "          -0.0161, -0.0217, -0.0163,  0.0179,  0.0121,  0.0143, -0.0233,  0.0272,\n",
       "           0.0294, -0.0275,  0.0170]])}, objective=2.219792395644842, loss=0.7383777499198914, val_objective=2.2512161431843625, val_loss=0.7698014974594116, regularization=1.1880412101745605, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.2718775457439142, state_dict={'layers.0.weight': tensor([[-0.0712,  0.0228,  0.0821,  ..., -0.0091,  0.0610,  0.0346],\n",
       "         [-0.1177,  0.0168, -0.0182,  ...,  0.0303, -0.0966, -0.0768],\n",
       "         [-0.0386, -0.0524, -0.0180,  ..., -0.2573, -0.1348, -0.0193],\n",
       "         ...,\n",
       "         [-0.0043, -0.1429, -0.0267,  ..., -0.1635, -0.0602,  0.0407],\n",
       "         [ 0.1266, -0.0218, -0.0919,  ..., -0.0243, -0.0039,  0.1266],\n",
       "         [-0.0351, -0.0212,  0.1336,  ...,  0.0498, -0.0907,  0.1700]]), 'layers.0.bias': tensor([-0.0641,  0.1414,  0.0461,  0.0623,  0.0946,  0.0938,  0.0067, -0.1486,\n",
       "          0.0075, -0.0818,  0.0699,  0.0931,  0.1277,  0.0370, -0.1488, -0.1187,\n",
       "         -0.0694, -0.1002,  0.1490,  0.0072,  0.0594,  0.1526, -0.0933,  0.0551,\n",
       "         -0.0786,  0.1796, -0.0816, -0.0467, -0.0618,  0.1090, -0.0205,  0.0221,\n",
       "         -0.0311, -0.0459, -0.0293, -0.1462,  0.0062,  0.0620,  0.1035,  0.0590,\n",
       "         -0.0411,  0.0347,  0.1170, -0.0450,  0.1282, -0.0188, -0.0692, -0.0018,\n",
       "          0.0328,  0.1189]), 'layers.1.weight': tensor([[ 0.0415,  0.1063, -0.1239, -0.1004,  0.0533, -0.0919, -0.0508, -0.0358,\n",
       "           0.1313, -0.0322,  0.0532, -0.0718,  0.0768, -0.0109, -0.0583,  0.0445,\n",
       "          -0.0777, -0.0370,  0.0432,  0.0944, -0.1062,  0.0647, -0.0885, -0.0826,\n",
       "          -0.0620,  0.1303,  0.0909,  0.1011,  0.0956, -0.0209, -0.1249,  0.1184,\n",
       "           0.0174,  0.0504, -0.1060,  0.1001,  0.1289, -0.0564,  0.1528, -0.0499,\n",
       "          -0.1374,  0.0652,  0.1275, -0.0692,  0.0666,  0.1329, -0.0873, -0.0435,\n",
       "          -0.0768, -0.0820]]), 'layers.1.bias': tensor([-0.0820]), 'skip.weight': tensor([[ 0.0161, -0.0143,  0.0166,  0.0157,  0.0166,  0.0191, -0.0184, -0.0161,\n",
       "           0.0116,  0.0157, -0.0181, -0.0132, -0.0196,  0.0147,  0.0166, -0.0152,\n",
       "           0.0146,  0.0150,  0.0197,  0.0194,  0.0115,  0.0148,  0.0199,  0.0152,\n",
       "          -0.0173,  0.0193, -0.0177,  0.0222, -0.0186,  0.0139,  0.0171, -0.0223,\n",
       "           0.0252, -0.0213,  0.0244, -0.0165, -0.0226, -0.0162, -0.0137, -0.0209,\n",
       "          -0.0123, -0.0141,  0.0187, -0.0166,  0.0164,  0.0235, -0.0209, -0.0150,\n",
       "          -0.0221, -0.0134,  0.0171, -0.0127, -0.0170,  0.0126,  0.0158,  0.0177,\n",
       "          -0.0161, -0.0216, -0.0163,  0.0179,  0.0121,  0.0143, -0.0232,  0.0271,\n",
       "           0.0294, -0.0275,  0.0170]])}, objective=2.2454201242283562, loss=0.7381190061569214, val_objective=2.2766997477368096, val_loss=0.7693986296653748, regularization=1.1850992441177368, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.2973150966587925, state_dict={'layers.0.weight': tensor([[-0.0712,  0.0228,  0.0821,  ..., -0.0091,  0.0610,  0.0347],\n",
       "         [-0.1176,  0.0168, -0.0182,  ...,  0.0304, -0.0967, -0.0767],\n",
       "         [-0.0387, -0.0524, -0.0181,  ..., -0.2574, -0.1347, -0.0194],\n",
       "         ...,\n",
       "         [-0.0044, -0.1426, -0.0267,  ..., -0.1635, -0.0602,  0.0406],\n",
       "         [ 0.1265, -0.0218, -0.0920,  ..., -0.0244, -0.0038,  0.1265],\n",
       "         [-0.0352, -0.0212,  0.1335,  ...,  0.0497, -0.0907,  0.1695]]), 'layers.0.bias': tensor([-0.0641,  0.1414,  0.0461,  0.0623,  0.0945,  0.0938,  0.0067, -0.1486,\n",
       "          0.0074, -0.0818,  0.0699,  0.0931,  0.1277,  0.0370, -0.1488, -0.1187,\n",
       "         -0.0694, -0.1002,  0.1490,  0.0070,  0.0594,  0.1526, -0.0934,  0.0551,\n",
       "         -0.0786,  0.1796, -0.0818, -0.0467, -0.0617,  0.1090, -0.0206,  0.0221,\n",
       "         -0.0311, -0.0459, -0.0293, -0.1462,  0.0060,  0.0621,  0.1035,  0.0590,\n",
       "         -0.0412,  0.0347,  0.1170, -0.0450,  0.1282, -0.0189, -0.0692, -0.0018,\n",
       "          0.0328,  0.1189]), 'layers.1.weight': tensor([[ 0.0416,  0.1064, -0.1241, -0.1001,  0.0531, -0.0920, -0.0507, -0.0354,\n",
       "           0.1314, -0.0320,  0.0528, -0.0716,  0.0764, -0.0103, -0.0582,  0.0445,\n",
       "          -0.0776, -0.0364,  0.0427,  0.0937, -0.1062,  0.0640, -0.0880, -0.0820,\n",
       "          -0.0618,  0.1301,  0.0903,  0.1008,  0.0958, -0.0207, -0.1245,  0.1187,\n",
       "           0.0170,  0.0504, -0.1056,  0.1003,  0.1284, -0.0566,  0.1528, -0.0499,\n",
       "          -0.1371,  0.0650,  0.1277, -0.0693,  0.0665,  0.1323, -0.0873, -0.0437,\n",
       "          -0.0766, -0.0818]]), 'layers.1.bias': tensor([-0.0818]), 'skip.weight': tensor([[ 0.0160, -0.0143,  0.0165,  0.0156,  0.0166,  0.0190, -0.0183, -0.0161,\n",
       "           0.0116,  0.0157, -0.0180, -0.0131, -0.0196,  0.0147,  0.0166, -0.0152,\n",
       "           0.0145,  0.0149,  0.0196,  0.0193,  0.0115,  0.0148,  0.0198,  0.0152,\n",
       "          -0.0173,  0.0193, -0.0177,  0.0221, -0.0186,  0.0139,  0.0171, -0.0222,\n",
       "           0.0251, -0.0212,  0.0243, -0.0165, -0.0225, -0.0161, -0.0137, -0.0209,\n",
       "          -0.0123, -0.0141,  0.0187, -0.0165,  0.0164,  0.0234, -0.0208, -0.0149,\n",
       "          -0.0221, -0.0133,  0.0170, -0.0127, -0.0170,  0.0126,  0.0158,  0.0176,\n",
       "          -0.0160, -0.0216, -0.0163,  0.0178,  0.0120,  0.0142, -0.0232,  0.0270,\n",
       "           0.0293, -0.0275,  0.0169]])}, objective=2.2714666246991806, loss=0.737879753112793, val_objective=2.3026070117574386, val_loss=0.769020140171051, regularization=1.1821236610412598, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.3232613985919683, state_dict={'layers.0.weight': tensor([[-0.0712,  0.0228,  0.0821,  ..., -0.0091,  0.0610,  0.0347],\n",
       "         [-0.1175,  0.0169, -0.0182,  ...,  0.0305, -0.0968, -0.0766],\n",
       "         [-0.0388, -0.0524, -0.0181,  ..., -0.2575, -0.1347, -0.0195],\n",
       "         ...,\n",
       "         [-0.0044, -0.1423, -0.0267,  ..., -0.1635, -0.0602,  0.0406],\n",
       "         [ 0.1264, -0.0218, -0.0920,  ..., -0.0244, -0.0038,  0.1264],\n",
       "         [-0.0353, -0.0212,  0.1335,  ...,  0.0496, -0.0906,  0.1690]]), 'layers.0.bias': tensor([-0.0641,  0.1414,  0.0460,  0.0623,  0.0945,  0.0937,  0.0066, -0.1487,\n",
       "          0.0074, -0.0818,  0.0699,  0.0931,  0.1277,  0.0370, -0.1488, -0.1188,\n",
       "         -0.0694, -0.1002,  0.1490,  0.0069,  0.0594,  0.1525, -0.0934,  0.0550,\n",
       "         -0.0786,  0.1796, -0.0819, -0.0468, -0.0616,  0.1090, -0.0207,  0.0222,\n",
       "         -0.0311, -0.0459, -0.0294, -0.1462,  0.0059,  0.0621,  0.1035,  0.0589,\n",
       "         -0.0414,  0.0347,  0.1171, -0.0450,  0.1282, -0.0190, -0.0692, -0.0018,\n",
       "          0.0327,  0.1189]), 'layers.1.weight': tensor([[ 0.0417,  0.1064, -0.1243, -0.0997,  0.0529, -0.0920, -0.0506, -0.0349,\n",
       "           0.1315, -0.0319,  0.0524, -0.0715,  0.0759, -0.0098, -0.0582,  0.0445,\n",
       "          -0.0775, -0.0359,  0.0423,  0.0931, -0.1063,  0.0634, -0.0876, -0.0815,\n",
       "          -0.0615,  0.1299,  0.0897,  0.1006,  0.0960, -0.0204, -0.1242,  0.1189,\n",
       "           0.0166,  0.0503, -0.1053,  0.1004,  0.1278, -0.0567,  0.1529, -0.0498,\n",
       "          -0.1367,  0.0648,  0.1278, -0.0694,  0.0663,  0.1318, -0.0873, -0.0438,\n",
       "          -0.0764, -0.0817]]), 'layers.1.bias': tensor([-0.0816]), 'skip.weight': tensor([[ 0.0160, -0.0142,  0.0165,  0.0156,  0.0165,  0.0189, -0.0183, -0.0161,\n",
       "           0.0115,  0.0157, -0.0180, -0.0130, -0.0195,  0.0146,  0.0165, -0.0152,\n",
       "           0.0145,  0.0148,  0.0196,  0.0192,  0.0114,  0.0148,  0.0197,  0.0152,\n",
       "          -0.0172,  0.0192, -0.0177,  0.0220, -0.0185,  0.0139,  0.0171, -0.0222,\n",
       "           0.0251, -0.0211,  0.0242, -0.0164, -0.0224, -0.0161, -0.0137, -0.0208,\n",
       "          -0.0122, -0.0140,  0.0187, -0.0165,  0.0163,  0.0234, -0.0208, -0.0149,\n",
       "          -0.0221, -0.0132,  0.0170, -0.0127, -0.0170,  0.0126,  0.0157,  0.0176,\n",
       "          -0.0160, -0.0215, -0.0163,  0.0178,  0.0120,  0.0142, -0.0231,  0.0270,\n",
       "           0.0292, -0.0274,  0.0169]])}, objective=2.297916039539569, loss=0.7376578450202942, val_objective=2.32892291219353, val_loss=0.7686647176742556, regularization=1.179100513458252, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.3497266265638077, state_dict={'layers.0.weight': tensor([[-0.0711,  0.0229,  0.0821,  ..., -0.0090,  0.0609,  0.0347],\n",
       "         [-0.1174,  0.0169, -0.0181,  ...,  0.0306, -0.0969, -0.0764],\n",
       "         [-0.0389, -0.0525, -0.0182,  ..., -0.2576, -0.1346, -0.0196],\n",
       "         ...,\n",
       "         [-0.0045, -0.1419, -0.0267,  ..., -0.1636, -0.0601,  0.0405],\n",
       "         [ 0.1262, -0.0218, -0.0920,  ..., -0.0245, -0.0037,  0.1264],\n",
       "         [-0.0354, -0.0213,  0.1334,  ...,  0.0496, -0.0905,  0.1684]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0460,  0.0622,  0.0945,  0.0937,  0.0066, -0.1487,\n",
       "          0.0074, -0.0819,  0.0699,  0.0932,  0.1277,  0.0370, -0.1488, -0.1188,\n",
       "         -0.0695, -0.1002,  0.1490,  0.0068,  0.0594,  0.1525, -0.0935,  0.0549,\n",
       "         -0.0786,  0.1796, -0.0821, -0.0468, -0.0616,  0.1090, -0.0208,  0.0222,\n",
       "         -0.0311, -0.0459, -0.0294, -0.1462,  0.0058,  0.0621,  0.1034,  0.0589,\n",
       "         -0.0415,  0.0348,  0.1171, -0.0450,  0.1281, -0.0190, -0.0692, -0.0018,\n",
       "          0.0327,  0.1188]), 'layers.1.weight': tensor([[ 0.0419,  0.1064, -0.1245, -0.0993,  0.0527, -0.0921, -0.0505, -0.0345,\n",
       "           0.1316, -0.0318,  0.0520, -0.0714,  0.0755, -0.0092, -0.0582,  0.0446,\n",
       "          -0.0774, -0.0354,  0.0419,  0.0924, -0.1063,  0.0628, -0.0872, -0.0810,\n",
       "          -0.0613,  0.1297,  0.0892,  0.1003,  0.0963, -0.0202, -0.1239,  0.1191,\n",
       "           0.0162,  0.0503, -0.1050,  0.1006,  0.1274, -0.0569,  0.1530, -0.0498,\n",
       "          -0.1364,  0.0646,  0.1279, -0.0695,  0.0662,  0.1313, -0.0874, -0.0440,\n",
       "          -0.0763, -0.0816]]), 'layers.1.bias': tensor([-0.0814]), 'skip.weight': tensor([[ 0.0159, -0.0142,  0.0165,  0.0156,  0.0165,  0.0189, -0.0182, -0.0160,\n",
       "           0.0115,  0.0156, -0.0179, -0.0130, -0.0195,  0.0145,  0.0165, -0.0151,\n",
       "           0.0145,  0.0148,  0.0195,  0.0192,  0.0114,  0.0147,  0.0197,  0.0151,\n",
       "          -0.0172,  0.0191, -0.0176,  0.0220, -0.0185,  0.0139,  0.0170, -0.0221,\n",
       "           0.0250, -0.0211,  0.0242, -0.0163, -0.0224, -0.0160, -0.0136, -0.0208,\n",
       "          -0.0122, -0.0140,  0.0186, -0.0164,  0.0163,  0.0233, -0.0207, -0.0148,\n",
       "          -0.0220, -0.0132,  0.0170, -0.0127, -0.0170,  0.0125,  0.0157,  0.0175,\n",
       "          -0.0160, -0.0214, -0.0162,  0.0177,  0.0119,  0.0142, -0.0230,  0.0269,\n",
       "           0.0292, -0.0274,  0.0168]])}, objective=2.3247837279619863, loss=0.7374513149261475, val_objective=2.355661794978588, val_loss=0.768329381942749, regularization=1.1760399341583252, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.3767211590950839, state_dict={'layers.0.weight': tensor([[-0.0711,  0.0229,  0.0822,  ..., -0.0090,  0.0609,  0.0348],\n",
       "         [-0.1173,  0.0169, -0.0181,  ...,  0.0307, -0.0970, -0.0763],\n",
       "         [-0.0390, -0.0525, -0.0182,  ..., -0.2577, -0.1345, -0.0197],\n",
       "         ...,\n",
       "         [-0.0045, -0.1416, -0.0267,  ..., -0.1636, -0.0601,  0.0405],\n",
       "         [ 0.1261, -0.0218, -0.0921,  ..., -0.0246, -0.0037,  0.1263],\n",
       "         [-0.0355, -0.0213,  0.1334,  ...,  0.0495, -0.0904,  0.1679]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0460,  0.0622,  0.0945,  0.0936,  0.0066, -0.1487,\n",
       "          0.0073, -0.0819,  0.0699,  0.0932,  0.1277,  0.0370, -0.1489, -0.1188,\n",
       "         -0.0695, -0.1003,  0.1489,  0.0067,  0.0594,  0.1524, -0.0936,  0.0549,\n",
       "         -0.0786,  0.1796, -0.0822, -0.0469, -0.0615,  0.1090, -0.0208,  0.0223,\n",
       "         -0.0311, -0.0459, -0.0294, -0.1462,  0.0057,  0.0621,  0.1034,  0.0589,\n",
       "         -0.0417,  0.0348,  0.1172, -0.0450,  0.1281, -0.0191, -0.0692, -0.0017,\n",
       "          0.0327,  0.1188]), 'layers.1.weight': tensor([[ 0.0420,  0.1065, -0.1247, -0.0990,  0.0525, -0.0921, -0.0505, -0.0341,\n",
       "           0.1317, -0.0317,  0.0516, -0.0713,  0.0751, -0.0087, -0.0582,  0.0446,\n",
       "          -0.0774, -0.0349,  0.0414,  0.0918, -0.1063,  0.0622, -0.0868, -0.0805,\n",
       "          -0.0611,  0.1296,  0.0886,  0.1001,  0.0965, -0.0200, -0.1235,  0.1194,\n",
       "           0.0158,  0.0502, -0.1047,  0.1007,  0.1269, -0.0571,  0.1531, -0.0498,\n",
       "          -0.1361,  0.0644,  0.1279, -0.0695,  0.0662,  0.1308, -0.0874, -0.0441,\n",
       "          -0.0761, -0.0815]]), 'layers.1.bias': tensor([-0.0812]), 'skip.weight': tensor([[ 0.0159, -0.0142,  0.0165,  0.0156,  0.0165,  0.0188, -0.0182, -0.0160,\n",
       "           0.0115,  0.0156, -0.0178, -0.0129, -0.0194,  0.0145,  0.0165, -0.0151,\n",
       "           0.0145,  0.0147,  0.0195,  0.0191,  0.0114,  0.0147,  0.0196,  0.0151,\n",
       "          -0.0172,  0.0191, -0.0176,  0.0219, -0.0184,  0.0138,  0.0170, -0.0221,\n",
       "           0.0250, -0.0210,  0.0241, -0.0163, -0.0223, -0.0159, -0.0136, -0.0207,\n",
       "          -0.0122, -0.0139,  0.0186, -0.0164,  0.0163,  0.0233, -0.0206, -0.0148,\n",
       "          -0.0220, -0.0131,  0.0169, -0.0127, -0.0169,  0.0125,  0.0157,  0.0174,\n",
       "          -0.0159, -0.0214, -0.0162,  0.0177,  0.0119,  0.0142, -0.0230,  0.0268,\n",
       "           0.0291, -0.0274,  0.0168]])}, objective=2.3520830806370254, loss=0.7372586131095886, val_objective=2.3828375872250076, val_loss=0.768013119697571, regularization=1.1729495525360107, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.4042555822769855, state_dict={'layers.0.weight': tensor([[-0.0710,  0.0229,  0.0822,  ..., -0.0090,  0.0609,  0.0348],\n",
       "         [-0.1172,  0.0170, -0.0181,  ...,  0.0307, -0.0971, -0.0762],\n",
       "         [-0.0391, -0.0526, -0.0183,  ..., -0.2578, -0.1345, -0.0198],\n",
       "         ...,\n",
       "         [-0.0046, -0.1412, -0.0267,  ..., -0.1636, -0.0601,  0.0404],\n",
       "         [ 0.1260, -0.0218, -0.0921,  ..., -0.0246, -0.0036,  0.1262],\n",
       "         [-0.0356, -0.0213,  0.1333,  ...,  0.0495, -0.0904,  0.1673]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0459,  0.0622,  0.0945,  0.0936,  0.0066, -0.1488,\n",
       "          0.0073, -0.0819,  0.0698,  0.0932,  0.1276,  0.0370, -0.1489, -0.1188,\n",
       "         -0.0695, -0.1003,  0.1489,  0.0066,  0.0594,  0.1524, -0.0936,  0.0548,\n",
       "         -0.0786,  0.1796, -0.0823, -0.0469, -0.0614,  0.1090, -0.0209,  0.0223,\n",
       "         -0.0311, -0.0458, -0.0294, -0.1463,  0.0056,  0.0621,  0.1034,  0.0589,\n",
       "         -0.0418,  0.0348,  0.1172, -0.0450,  0.1281, -0.0192, -0.0693, -0.0017,\n",
       "          0.0327,  0.1188]), 'layers.1.weight': tensor([[ 0.0421,  0.1065, -0.1248, -0.0986,  0.0524, -0.0922, -0.0505, -0.0337,\n",
       "           0.1319, -0.0316,  0.0512, -0.0712,  0.0747, -0.0082, -0.0582,  0.0446,\n",
       "          -0.0774, -0.0344,  0.0411,  0.0913, -0.1064,  0.0616, -0.0864, -0.0800,\n",
       "          -0.0609,  0.1294,  0.0881,  0.0999,  0.0967, -0.0197, -0.1232,  0.1196,\n",
       "           0.0155,  0.0502, -0.1044,  0.1009,  0.1264, -0.0573,  0.1532, -0.0497,\n",
       "          -0.1357,  0.0642,  0.1280, -0.0696,  0.0661,  0.1303, -0.0874, -0.0443,\n",
       "          -0.0759, -0.0814]]), 'layers.1.bias': tensor([-0.0810]), 'skip.weight': tensor([[ 0.0158, -0.0141,  0.0164,  0.0156,  0.0165,  0.0187, -0.0181, -0.0160,\n",
       "           0.0115,  0.0156, -0.0177, -0.0129, -0.0193,  0.0144,  0.0164, -0.0151,\n",
       "           0.0145,  0.0146,  0.0194,  0.0190,  0.0113,  0.0147,  0.0195,  0.0150,\n",
       "          -0.0171,  0.0190, -0.0176,  0.0218, -0.0184,  0.0138,  0.0170, -0.0220,\n",
       "           0.0249, -0.0209,  0.0240, -0.0162, -0.0223, -0.0159, -0.0136, -0.0206,\n",
       "          -0.0122, -0.0138,  0.0186, -0.0163,  0.0162,  0.0232, -0.0206, -0.0147,\n",
       "          -0.0220, -0.0131,  0.0169, -0.0126, -0.0169,  0.0125,  0.0156,  0.0174,\n",
       "          -0.0159, -0.0213, -0.0162,  0.0176,  0.0118,  0.0141, -0.0229,  0.0268,\n",
       "           0.0291, -0.0274,  0.0167]])}, objective=2.379833587590033, loss=0.7370775938034058, val_objective=2.410469063702399, val_loss=0.7677130699157717, regularization=1.1698411703109741, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.4323406939225254, state_dict={'layers.0.weight': tensor([[-0.0710,  0.0229,  0.0822,  ..., -0.0089,  0.0608,  0.0348],\n",
       "         [-0.1171,  0.0170, -0.0180,  ...,  0.0308, -0.0972, -0.0760],\n",
       "         [-0.0392, -0.0526, -0.0183,  ..., -0.2579, -0.1344, -0.0199],\n",
       "         ...,\n",
       "         [-0.0046, -0.1409, -0.0268,  ..., -0.1637, -0.0601,  0.0404],\n",
       "         [ 0.1259, -0.0218, -0.0921,  ..., -0.0247, -0.0036,  0.1261],\n",
       "         [-0.0357, -0.0214,  0.1333,  ...,  0.0494, -0.0903,  0.1668]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0459,  0.0621,  0.0945,  0.0935,  0.0065, -0.1488,\n",
       "          0.0073, -0.0819,  0.0698,  0.0932,  0.1276,  0.0370, -0.1489, -0.1188,\n",
       "         -0.0696, -0.1003,  0.1489,  0.0065,  0.0594,  0.1524, -0.0937,  0.0547,\n",
       "         -0.0786,  0.1796, -0.0824, -0.0470, -0.0613,  0.1089, -0.0210,  0.0224,\n",
       "         -0.0312, -0.0458, -0.0295, -0.1463,  0.0055,  0.0621,  0.1034,  0.0588,\n",
       "         -0.0420,  0.0348,  0.1172, -0.0451,  0.1281, -0.0192, -0.0693, -0.0017,\n",
       "          0.0326,  0.1187]), 'layers.1.weight': tensor([[ 0.0422,  0.1066, -0.1250, -0.0983,  0.0523, -0.0923, -0.0504, -0.0334,\n",
       "           0.1320, -0.0315,  0.0509, -0.0710,  0.0743, -0.0077, -0.0583,  0.0446,\n",
       "          -0.0774, -0.0340,  0.0407,  0.0907, -0.1064,  0.0610, -0.0860, -0.0795,\n",
       "          -0.0607,  0.1292,  0.0876,  0.0997,  0.0969, -0.0195, -0.1229,  0.1198,\n",
       "           0.0152,  0.0501, -0.1041,  0.1010,  0.1260, -0.0574,  0.1533, -0.0497,\n",
       "          -0.1354,  0.0640,  0.1281, -0.0697,  0.0660,  0.1299, -0.0874, -0.0445,\n",
       "          -0.0757, -0.0813]]), 'layers.1.bias': tensor([-0.0807]), 'skip.weight': tensor([[ 0.0158, -0.0141,  0.0164,  0.0155,  0.0164,  0.0187, -0.0180, -0.0159,\n",
       "           0.0114,  0.0155, -0.0177, -0.0128, -0.0193,  0.0143,  0.0164, -0.0150,\n",
       "           0.0144,  0.0146,  0.0194,  0.0190,  0.0113,  0.0146,  0.0195,  0.0150,\n",
       "          -0.0171,  0.0189, -0.0175,  0.0217, -0.0183,  0.0138,  0.0169, -0.0220,\n",
       "           0.0249, -0.0209,  0.0240, -0.0162, -0.0222, -0.0158, -0.0136, -0.0206,\n",
       "          -0.0121, -0.0138,  0.0185, -0.0163,  0.0162,  0.0231, -0.0205, -0.0147,\n",
       "          -0.0220, -0.0130,  0.0169, -0.0126, -0.0169,  0.0124,  0.0156,  0.0173,\n",
       "          -0.0159, -0.0212, -0.0162,  0.0175,  0.0118,  0.0141, -0.0228,  0.0267,\n",
       "           0.0290, -0.0273,  0.0167]])}, objective=2.408048992863987, loss=0.7369078993797302, val_objective=2.438569968453739, val_loss=0.7674288749694824, regularization=1.1667203903198242, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.460987507800976, state_dict={'layers.0.weight': tensor([[-0.0709,  0.0229,  0.0822,  ..., -0.0089,  0.0608,  0.0349],\n",
       "         [-0.1170,  0.0171, -0.0180,  ...,  0.0309, -0.0972, -0.0759],\n",
       "         [-0.0393, -0.0526, -0.0184,  ..., -0.2580, -0.1343, -0.0200],\n",
       "         ...,\n",
       "         [-0.0047, -0.1405, -0.0268,  ..., -0.1637, -0.0600,  0.0404],\n",
       "         [ 0.1258, -0.0218, -0.0921,  ..., -0.0247, -0.0036,  0.1261],\n",
       "         [-0.0359, -0.0214,  0.1332,  ...,  0.0493, -0.0902,  0.1662]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0459,  0.0621,  0.0945,  0.0935,  0.0065, -0.1488,\n",
       "          0.0073, -0.0819,  0.0698,  0.0932,  0.1276,  0.0370, -0.1490, -0.1188,\n",
       "         -0.0696, -0.1003,  0.1489,  0.0064,  0.0594,  0.1524, -0.0938,  0.0547,\n",
       "         -0.0787,  0.1796, -0.0826, -0.0470, -0.0613,  0.1089, -0.0211,  0.0224,\n",
       "         -0.0312, -0.0458, -0.0295, -0.1463,  0.0054,  0.0621,  0.1034,  0.0588,\n",
       "         -0.0421,  0.0348,  0.1173, -0.0451,  0.1280, -0.0193, -0.0693, -0.0017,\n",
       "          0.0326,  0.1187]), 'layers.1.weight': tensor([[ 0.0423,  0.1066, -0.1251, -0.0979,  0.0522, -0.0924, -0.0504, -0.0331,\n",
       "           0.1321, -0.0314,  0.0505, -0.0709,  0.0739, -0.0072, -0.0583,  0.0446,\n",
       "          -0.0774, -0.0336,  0.0403,  0.0901, -0.1064,  0.0605, -0.0857, -0.0791,\n",
       "          -0.0605,  0.1291,  0.0871,  0.0996,  0.0971, -0.0193, -0.1226,  0.1200,\n",
       "           0.0149,  0.0501, -0.1039,  0.1011,  0.1256, -0.0576,  0.1534, -0.0497,\n",
       "          -0.1352,  0.0638,  0.1281, -0.0698,  0.0660,  0.1294, -0.0875, -0.0447,\n",
       "          -0.0755, -0.0813]]), 'layers.1.bias': tensor([-0.0805]), 'skip.weight': tensor([[ 0.0157, -0.0141,  0.0164,  0.0155,  0.0164,  0.0186, -0.0180, -0.0159,\n",
       "           0.0114,  0.0155, -0.0177, -0.0127, -0.0192,  0.0143,  0.0164, -0.0150,\n",
       "           0.0144,  0.0145,  0.0193,  0.0189,  0.0112,  0.0146,  0.0194,  0.0150,\n",
       "          -0.0171,  0.0189, -0.0175,  0.0217, -0.0182,  0.0138,  0.0169, -0.0219,\n",
       "           0.0248, -0.0208,  0.0239, -0.0161, -0.0221, -0.0158, -0.0136, -0.0205,\n",
       "          -0.0121, -0.0137,  0.0185, -0.0162,  0.0162,  0.0231, -0.0204, -0.0147,\n",
       "          -0.0219, -0.0130,  0.0169, -0.0126, -0.0168,  0.0124,  0.0156,  0.0172,\n",
       "          -0.0158, -0.0211, -0.0162,  0.0175,  0.0117,  0.0141, -0.0227,  0.0266,\n",
       "           0.0290, -0.0273,  0.0166]])}, objective=2.4367431799807875, loss=0.7367477416992188, val_objective=2.4671559731402724, val_loss=0.7671605348587038, regularization=1.1635934114456177, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.4902072579569956, state_dict={'layers.0.weight': tensor([[-0.0709,  0.0229,  0.0822,  ..., -0.0089,  0.0608,  0.0349],\n",
       "         [-0.1169,  0.0171, -0.0180,  ...,  0.0310, -0.0973, -0.0758],\n",
       "         [-0.0394, -0.0527, -0.0185,  ..., -0.2581, -0.1342, -0.0201],\n",
       "         ...,\n",
       "         [-0.0047, -0.1401, -0.0268,  ..., -0.1637, -0.0600,  0.0403],\n",
       "         [ 0.1257, -0.0218, -0.0922,  ..., -0.0248, -0.0035,  0.1260],\n",
       "         [-0.0360, -0.0215,  0.1332,  ...,  0.0493, -0.0902,  0.1656]]), 'layers.0.bias': tensor([-0.0641,  0.1413,  0.0458,  0.0621,  0.0945,  0.0934,  0.0065, -0.1488,\n",
       "          0.0072, -0.0819,  0.0698,  0.0932,  0.1276,  0.0370, -0.1490, -0.1188,\n",
       "         -0.0696, -0.1003,  0.1489,  0.0063,  0.0594,  0.1523, -0.0938,  0.0546,\n",
       "         -0.0787,  0.1796, -0.0827, -0.0471, -0.0612,  0.1089, -0.0211,  0.0225,\n",
       "         -0.0312, -0.0458, -0.0295, -0.1463,  0.0053,  0.0621,  0.1033,  0.0588,\n",
       "         -0.0422,  0.0348,  0.1173, -0.0451,  0.1280, -0.0193, -0.0693, -0.0017,\n",
       "          0.0326,  0.1186]), 'layers.1.weight': tensor([[ 0.0424,  0.1067, -0.1253, -0.0976,  0.0521, -0.0924, -0.0504, -0.0328,\n",
       "           0.1322, -0.0314,  0.0502, -0.0709,  0.0736, -0.0067, -0.0583,  0.0446,\n",
       "          -0.0774, -0.0332,  0.0400,  0.0896, -0.1064,  0.0599, -0.0853, -0.0786,\n",
       "          -0.0603,  0.1289,  0.0867,  0.0994,  0.0973, -0.0191, -0.1223,  0.1202,\n",
       "           0.0146,  0.0501, -0.1036,  0.1013,  0.1252, -0.0578,  0.1535, -0.0496,\n",
       "          -0.1349,  0.0637,  0.1282, -0.0699,  0.0659,  0.1290, -0.0875, -0.0449,\n",
       "          -0.0754, -0.0812]]), 'layers.1.bias': tensor([-0.0802]), 'skip.weight': tensor([[ 0.0157, -0.0140,  0.0164,  0.0155,  0.0164,  0.0185, -0.0179, -0.0158,\n",
       "           0.0114,  0.0155, -0.0176, -0.0127, -0.0191,  0.0142,  0.0163, -0.0150,\n",
       "           0.0144,  0.0145,  0.0193,  0.0188,  0.0112,  0.0146,  0.0193,  0.0149,\n",
       "          -0.0170,  0.0188, -0.0175,  0.0216, -0.0182,  0.0138,  0.0169, -0.0219,\n",
       "           0.0247, -0.0207,  0.0238, -0.0161, -0.0221, -0.0157, -0.0136, -0.0204,\n",
       "          -0.0121, -0.0137,  0.0185, -0.0161,  0.0161,  0.0230, -0.0204, -0.0147,\n",
       "          -0.0219, -0.0130,  0.0169, -0.0126, -0.0168,  0.0123,  0.0156,  0.0171,\n",
       "          -0.0158, -0.0211, -0.0161,  0.0174,  0.0117,  0.0141, -0.0227,  0.0266,\n",
       "           0.0289, -0.0273,  0.0166]])}, objective=2.4658453359679045, loss=0.7365968823432922, val_objective=2.4961546554640592, val_loss=0.766906201839447, regularization=1.1604080200195312, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.5200114031161356, state_dict={'layers.0.weight': tensor([[-0.0709,  0.0229,  0.0823,  ..., -0.0089,  0.0607,  0.0349],\n",
       "         [-0.1168,  0.0171, -0.0179,  ...,  0.0310, -0.0974, -0.0757],\n",
       "         [-0.0394, -0.0527, -0.0185,  ..., -0.2582, -0.1342, -0.0202],\n",
       "         ...,\n",
       "         [-0.0048, -0.1398, -0.0268,  ..., -0.1637, -0.0600,  0.0403],\n",
       "         [ 0.1255, -0.0219, -0.0922,  ..., -0.0248, -0.0035,  0.1260],\n",
       "         [-0.0361, -0.0215,  0.1332,  ...,  0.0492, -0.0901,  0.1649]]), 'layers.0.bias': tensor([-0.0641,  0.1412,  0.0458,  0.0620,  0.0945,  0.0934,  0.0065, -0.1489,\n",
       "          0.0072, -0.0819,  0.0698,  0.0933,  0.1276,  0.0370, -0.1490, -0.1189,\n",
       "         -0.0696, -0.1003,  0.1489,  0.0062,  0.0594,  0.1523, -0.0939,  0.0546,\n",
       "         -0.0787,  0.1797, -0.0828, -0.0471, -0.0611,  0.1089, -0.0212,  0.0225,\n",
       "         -0.0312, -0.0458, -0.0295, -0.1463,  0.0052,  0.0621,  0.1033,  0.0588,\n",
       "         -0.0424,  0.0348,  0.1174, -0.0451,  0.1280, -0.0194, -0.0693, -0.0017,\n",
       "          0.0326,  0.1186]), 'layers.1.weight': tensor([[ 0.0425,  0.1067, -0.1254, -0.0973,  0.0520, -0.0925, -0.0504, -0.0325,\n",
       "           0.1323, -0.0314,  0.0499, -0.0708,  0.0733, -0.0063, -0.0584,  0.0447,\n",
       "          -0.0775, -0.0329,  0.0396,  0.0891, -0.1064,  0.0594, -0.0850, -0.0782,\n",
       "          -0.0601,  0.1288,  0.0862,  0.0993,  0.0975, -0.0189, -0.1221,  0.1204,\n",
       "           0.0143,  0.0501, -0.1033,  0.1014,  0.1248, -0.0580,  0.1536, -0.0496,\n",
       "          -0.1346,  0.0635,  0.1282, -0.0699,  0.0659,  0.1286, -0.0875, -0.0451,\n",
       "          -0.0752, -0.0812]]), 'layers.1.bias': tensor([-0.0799]), 'skip.weight': tensor([[ 0.0156, -0.0140,  0.0163,  0.0155,  0.0163,  0.0184, -0.0179, -0.0158,\n",
       "           0.0114,  0.0154, -0.0176, -0.0126, -0.0191,  0.0141,  0.0163, -0.0149,\n",
       "           0.0144,  0.0145,  0.0192,  0.0188,  0.0112,  0.0145,  0.0193,  0.0149,\n",
       "          -0.0170,  0.0187, -0.0174,  0.0215, -0.0181,  0.0137,  0.0168, -0.0218,\n",
       "           0.0247, -0.0207,  0.0237, -0.0161, -0.0220, -0.0156, -0.0135, -0.0204,\n",
       "          -0.0120, -0.0136,  0.0184, -0.0161,  0.0161,  0.0229, -0.0203, -0.0146,\n",
       "          -0.0219, -0.0129,  0.0168, -0.0126, -0.0168,  0.0123,  0.0156,  0.0171,\n",
       "          -0.0158, -0.0210, -0.0161,  0.0173,  0.0116,  0.0141, -0.0226,  0.0265,\n",
       "           0.0288, -0.0272,  0.0165]])}, objective=2.4953840579685442, loss=0.7364537119865417, val_objective=2.5255910362896197, val_loss=0.7666606903076174, regularization=1.1571823358535767, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.5504116311784584, state_dict={'layers.0.weight': tensor([[-0.0708,  0.0230,  0.0823,  ..., -0.0088,  0.0607,  0.0350],\n",
       "         [-0.1167,  0.0172, -0.0179,  ...,  0.0311, -0.0975, -0.0755],\n",
       "         [-0.0395, -0.0527, -0.0186,  ..., -0.2583, -0.1341, -0.0203],\n",
       "         ...,\n",
       "         [-0.0048, -0.1394, -0.0268,  ..., -0.1638, -0.0600,  0.0402],\n",
       "         [ 0.1254, -0.0219, -0.0922,  ..., -0.0249, -0.0034,  0.1259],\n",
       "         [-0.0362, -0.0215,  0.1331,  ...,  0.0492, -0.0900,  0.1643]]), 'layers.0.bias': tensor([-0.0641,  0.1412,  0.0457,  0.0620,  0.0945,  0.0933,  0.0064, -0.1489,\n",
       "          0.0072, -0.0820,  0.0698,  0.0933,  0.1276,  0.0370, -0.1490, -0.1189,\n",
       "         -0.0697, -0.1003,  0.1488,  0.0061,  0.0594,  0.1523, -0.0940,  0.0545,\n",
       "         -0.0787,  0.1797, -0.0829, -0.0472, -0.0610,  0.1089, -0.0213,  0.0226,\n",
       "         -0.0312, -0.0458, -0.0295, -0.1463,  0.0052,  0.0621,  0.1033,  0.0587,\n",
       "         -0.0425,  0.0349,  0.1174, -0.0451,  0.1279, -0.0194, -0.0693, -0.0017,\n",
       "          0.0325,  0.1186]), 'layers.1.weight': tensor([[ 0.0426,  0.1068, -0.1255, -0.0970,  0.0519, -0.0926, -0.0504, -0.0322,\n",
       "           0.1325, -0.0313,  0.0496, -0.0707,  0.0729, -0.0058, -0.0584,  0.0447,\n",
       "          -0.0775, -0.0325,  0.0393,  0.0886, -0.1064,  0.0589, -0.0847, -0.0778,\n",
       "          -0.0600,  0.1286,  0.0858,  0.0991,  0.0977, -0.0188, -0.1218,  0.1206,\n",
       "           0.0140,  0.0500, -0.1031,  0.1015,  0.1244, -0.0582,  0.1538, -0.0495,\n",
       "          -0.1344,  0.0634,  0.1283, -0.0700,  0.0658,  0.1282, -0.0876, -0.0453,\n",
       "          -0.0750, -0.0811]]), 'layers.1.bias': tensor([-0.0797]), 'skip.weight': tensor([[ 0.0156, -0.0139,  0.0163,  0.0155,  0.0163,  0.0184, -0.0178, -0.0158,\n",
       "           0.0113,  0.0154, -0.0176, -0.0125, -0.0190,  0.0140,  0.0163, -0.0149,\n",
       "           0.0143,  0.0144,  0.0191,  0.0187,  0.0111,  0.0145,  0.0192,  0.0148,\n",
       "          -0.0169,  0.0187, -0.0174,  0.0214, -0.0180,  0.0137,  0.0168, -0.0217,\n",
       "           0.0246, -0.0206,  0.0237, -0.0161, -0.0219, -0.0156, -0.0135, -0.0203,\n",
       "          -0.0120, -0.0135,  0.0184, -0.0160,  0.0161,  0.0229, -0.0202, -0.0146,\n",
       "          -0.0218, -0.0129,  0.0168, -0.0125, -0.0167,  0.0123,  0.0155,  0.0170,\n",
       "          -0.0157, -0.0209, -0.0161,  0.0173,  0.0116,  0.0140, -0.0225,  0.0264,\n",
       "           0.0288, -0.0272,  0.0164]])}, objective=2.52544682314299, loss=0.7363177537918091, val_objective=2.555557241939529, val_loss=0.7664281725883486, regularization=1.1539703607559204, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.5814198638020276, state_dict={'layers.0.weight': tensor([[-0.0708,  0.0230,  0.0823,  ..., -0.0088,  0.0607,  0.0350],\n",
       "         [-0.1166,  0.0172, -0.0179,  ...,  0.0312, -0.0976, -0.0754],\n",
       "         [-0.0396, -0.0528, -0.0186,  ..., -0.2584, -0.1340, -0.0203],\n",
       "         ...,\n",
       "         [-0.0049, -0.1390, -0.0268,  ..., -0.1638, -0.0599,  0.0402],\n",
       "         [ 0.1253, -0.0219, -0.0922,  ..., -0.0250, -0.0034,  0.1258],\n",
       "         [-0.0363, -0.0216,  0.1331,  ...,  0.0491, -0.0900,  0.1636]]), 'layers.0.bias': tensor([-0.0641,  0.1412,  0.0457,  0.0619,  0.0945,  0.0933,  0.0064, -0.1489,\n",
       "          0.0071, -0.0820,  0.0698,  0.0933,  0.1276,  0.0370, -0.1491, -0.1189,\n",
       "         -0.0697, -0.1003,  0.1488,  0.0060,  0.0593,  0.1522, -0.0940,  0.0544,\n",
       "         -0.0787,  0.1797, -0.0830, -0.0472, -0.0610,  0.1088, -0.0213,  0.0226,\n",
       "         -0.0312, -0.0458, -0.0296, -0.1463,  0.0051,  0.0621,  0.1033,  0.0587,\n",
       "         -0.0426,  0.0349,  0.1175, -0.0451,  0.1279, -0.0195, -0.0693, -0.0017,\n",
       "          0.0325,  0.1185]), 'layers.1.weight': tensor([[ 0.0427,  0.1068, -0.1256, -0.0967,  0.0518, -0.0927, -0.0504, -0.0320,\n",
       "           0.1326, -0.0313,  0.0493, -0.0706,  0.0726, -0.0054, -0.0585,  0.0447,\n",
       "          -0.0776, -0.0322,  0.0390,  0.0881, -0.1064,  0.0585, -0.0844, -0.0774,\n",
       "          -0.0598,  0.1285,  0.0854,  0.0990,  0.0979, -0.0186, -0.1216,  0.1208,\n",
       "           0.0138,  0.0500, -0.1028,  0.1016,  0.1241, -0.0583,  0.1539, -0.0495,\n",
       "          -0.1341,  0.0632,  0.1283, -0.0701,  0.0658,  0.1278, -0.0876, -0.0454,\n",
       "          -0.0749, -0.0811]]), 'layers.1.bias': tensor([-0.0794]), 'skip.weight': tensor([[ 0.0155, -0.0139,  0.0163,  0.0154,  0.0163,  0.0183, -0.0177, -0.0157,\n",
       "           0.0113,  0.0154, -0.0175, -0.0124, -0.0189,  0.0140,  0.0162, -0.0148,\n",
       "           0.0143,  0.0144,  0.0191,  0.0186,  0.0111,  0.0145,  0.0192,  0.0148,\n",
       "          -0.0169,  0.0186, -0.0173,  0.0213, -0.0179,  0.0137,  0.0168, -0.0217,\n",
       "           0.0245, -0.0205,  0.0236, -0.0160, -0.0219, -0.0156, -0.0135, -0.0202,\n",
       "          -0.0120, -0.0135,  0.0183, -0.0159,  0.0160,  0.0228, -0.0202, -0.0146,\n",
       "          -0.0218, -0.0129,  0.0168, -0.0125, -0.0167,  0.0122,  0.0155,  0.0169,\n",
       "          -0.0157, -0.0208, -0.0161,  0.0172,  0.0115,  0.0140, -0.0224,  0.0263,\n",
       "           0.0287, -0.0272,  0.0164]])}, objective=2.5559548182574945, loss=0.7361890077590942, val_objective=2.5859729690639215, val_loss=0.766207158565521, regularization=1.1507164239883423, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.613048261078068, state_dict={'layers.0.weight': tensor([[-0.0707,  0.0230,  0.0823,  ..., -0.0088,  0.0607,  0.0350],\n",
       "         [-0.1165,  0.0173, -0.0178,  ...,  0.0312, -0.0977, -0.0753],\n",
       "         [-0.0397, -0.0528, -0.0187,  ..., -0.2584, -0.1340, -0.0204],\n",
       "         ...,\n",
       "         [-0.0049, -0.1386, -0.0268,  ..., -0.1638, -0.0599,  0.0402],\n",
       "         [ 0.1252, -0.0219, -0.0923,  ..., -0.0250, -0.0034,  0.1258],\n",
       "         [-0.0364, -0.0216,  0.1331,  ...,  0.0491, -0.0899,  0.1630]]), 'layers.0.bias': tensor([-0.0640,  0.1412,  0.0457,  0.0619,  0.0945,  0.0933,  0.0064, -0.1489,\n",
       "          0.0071, -0.0820,  0.0697,  0.0933,  0.1276,  0.0370, -0.1491, -0.1189,\n",
       "         -0.0697, -0.1004,  0.1488,  0.0059,  0.0593,  0.1522, -0.0941,  0.0544,\n",
       "         -0.0787,  0.1797, -0.0831, -0.0472, -0.0609,  0.1088, -0.0214,  0.0226,\n",
       "         -0.0312, -0.0458, -0.0296, -0.1463,  0.0050,  0.0621,  0.1033,  0.0587,\n",
       "         -0.0428,  0.0349,  0.1175, -0.0451,  0.1279, -0.0195, -0.0694, -0.0017,\n",
       "          0.0325,  0.1185]), 'layers.1.weight': tensor([[ 0.0428,  0.1069, -0.1258, -0.0964,  0.0518, -0.0928, -0.0504, -0.0317,\n",
       "           0.1327, -0.0313,  0.0490, -0.0705,  0.0724, -0.0050, -0.0586,  0.0447,\n",
       "          -0.0777, -0.0319,  0.0386,  0.0876, -0.1064,  0.0580, -0.0841, -0.0771,\n",
       "          -0.0596,  0.1284,  0.0849,  0.0989,  0.0981, -0.0184, -0.1213,  0.1210,\n",
       "           0.0135,  0.0500, -0.1026,  0.1018,  0.1237, -0.0585,  0.1540, -0.0494,\n",
       "          -0.1339,  0.0631,  0.1284, -0.0702,  0.0658,  0.1274, -0.0877, -0.0457,\n",
       "          -0.0747, -0.0811]]), 'layers.1.bias': tensor([-0.0791]), 'skip.weight': tensor([[ 0.0155, -0.0139,  0.0162,  0.0154,  0.0162,  0.0182, -0.0176, -0.0157,\n",
       "           0.0113,  0.0153, -0.0175, -0.0124, -0.0189,  0.0139,  0.0162, -0.0148,\n",
       "           0.0143,  0.0144,  0.0190,  0.0185,  0.0111,  0.0145,  0.0191,  0.0147,\n",
       "          -0.0169,  0.0185, -0.0173,  0.0213, -0.0179,  0.0137,  0.0167, -0.0216,\n",
       "           0.0245, -0.0204,  0.0235, -0.0160, -0.0218, -0.0155, -0.0135, -0.0202,\n",
       "          -0.0119, -0.0134,  0.0183, -0.0159,  0.0160,  0.0227, -0.0201, -0.0146,\n",
       "          -0.0218, -0.0128,  0.0168, -0.0125, -0.0166,  0.0122,  0.0155,  0.0168,\n",
       "          -0.0157, -0.0208, -0.0161,  0.0171,  0.0115,  0.0140, -0.0224,  0.0263,\n",
       "           0.0286, -0.0271,  0.0163]])}, objective=2.586889434441836, loss=0.7360670566558838, val_objective=2.6168203836529567, val_loss=0.7659980058670044, regularization=1.1474066972732544, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.6453092262996294, state_dict={'layers.0.weight': tensor([[-0.0707,  0.0230,  0.0823,  ..., -0.0088,  0.0606,  0.0351],\n",
       "         [-0.1164,  0.0173, -0.0178,  ...,  0.0313, -0.0977, -0.0752],\n",
       "         [-0.0398, -0.0529, -0.0187,  ..., -0.2585, -0.1339, -0.0205],\n",
       "         ...,\n",
       "         [-0.0049, -0.1382, -0.0268,  ..., -0.1639, -0.0599,  0.0401],\n",
       "         [ 0.1251, -0.0219, -0.0923,  ..., -0.0251, -0.0033,  0.1257],\n",
       "         [-0.0365, -0.0216,  0.1330,  ...,  0.0490, -0.0899,  0.1623]]), 'layers.0.bias': tensor([-0.0640,  0.1412,  0.0456,  0.0619,  0.0944,  0.0932,  0.0064, -0.1490,\n",
       "          0.0071, -0.0820,  0.0697,  0.0933,  0.1275,  0.0369, -0.1491, -0.1189,\n",
       "         -0.0698, -0.1004,  0.1488,  0.0058,  0.0593,  0.1522, -0.0941,  0.0543,\n",
       "         -0.0787,  0.1797, -0.0832, -0.0473, -0.0608,  0.1088, -0.0215,  0.0227,\n",
       "         -0.0312, -0.0457, -0.0296, -0.1464,  0.0049,  0.0621,  0.1033,  0.0587,\n",
       "         -0.0429,  0.0349,  0.1176, -0.0451,  0.1279, -0.0196, -0.0694, -0.0017,\n",
       "          0.0325,  0.1185]), 'layers.1.weight': tensor([[ 0.0429,  0.1069, -0.1259, -0.0961,  0.0517, -0.0929, -0.0505, -0.0315,\n",
       "           0.1329, -0.0313,  0.0488, -0.0705,  0.0721, -0.0046, -0.0586,  0.0447,\n",
       "          -0.0777, -0.0316,  0.0383,  0.0872, -0.1064,  0.0576, -0.0838, -0.0767,\n",
       "          -0.0595,  0.1282,  0.0845,  0.0988,  0.0983, -0.0183, -0.1211,  0.1211,\n",
       "           0.0133,  0.0500, -0.1024,  0.1019,  0.1234, -0.0587,  0.1542, -0.0494,\n",
       "          -0.1337,  0.0630,  0.1284, -0.0703,  0.0657,  0.1270, -0.0877, -0.0459,\n",
       "          -0.0746, -0.0811]]), 'layers.1.bias': tensor([-0.0789]), 'skip.weight': tensor([[ 0.0154, -0.0138,  0.0162,  0.0154,  0.0162,  0.0181, -0.0176, -0.0157,\n",
       "           0.0113,  0.0153, -0.0174, -0.0123, -0.0188,  0.0138,  0.0162, -0.0148,\n",
       "           0.0143,  0.0143,  0.0189,  0.0185,  0.0111,  0.0144,  0.0191,  0.0147,\n",
       "          -0.0168,  0.0185, -0.0173,  0.0212, -0.0178,  0.0137,  0.0167, -0.0215,\n",
       "           0.0244, -0.0204,  0.0234, -0.0160, -0.0217, -0.0155, -0.0135, -0.0201,\n",
       "          -0.0119, -0.0133,  0.0183, -0.0158,  0.0159,  0.0226, -0.0200, -0.0145,\n",
       "          -0.0217, -0.0128,  0.0167, -0.0125, -0.0166,  0.0121,  0.0155,  0.0167,\n",
       "          -0.0156, -0.0207, -0.0160,  0.0171,  0.0115,  0.0140, -0.0223,  0.0262,\n",
       "           0.0286, -0.0271,  0.0162]])}, objective=2.6183173332683327, loss=0.7359520792961121, val_objective=2.648168531464744, val_loss=0.7658032774925232, regularization=1.1440799236297607, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.678215410825622, state_dict={'layers.0.weight': tensor([[-0.0706,  0.0230,  0.0823,  ..., -0.0087,  0.0606,  0.0351],\n",
       "         [-0.1163,  0.0174, -0.0177,  ...,  0.0313, -0.0978, -0.0751],\n",
       "         [-0.0399, -0.0529, -0.0188,  ..., -0.2586, -0.1339, -0.0206],\n",
       "         ...,\n",
       "         [-0.0050, -0.1378, -0.0268,  ..., -0.1639, -0.0599,  0.0401],\n",
       "         [ 0.1250, -0.0219, -0.0923,  ..., -0.0251, -0.0033,  0.1256],\n",
       "         [-0.0366, -0.0217,  0.1330,  ...,  0.0490, -0.0898,  0.1616]]), 'layers.0.bias': tensor([-0.0640,  0.1412,  0.0456,  0.0618,  0.0944,  0.0932,  0.0064, -0.1490,\n",
       "          0.0071, -0.0820,  0.0697,  0.0933,  0.1275,  0.0369, -0.1491, -0.1189,\n",
       "         -0.0698, -0.1004,  0.1488,  0.0057,  0.0593,  0.1522, -0.0942,  0.0543,\n",
       "         -0.0787,  0.1797, -0.0833, -0.0473, -0.0608,  0.1088, -0.0215,  0.0227,\n",
       "         -0.0313, -0.0457, -0.0296, -0.1464,  0.0048,  0.0621,  0.1032,  0.0586,\n",
       "         -0.0430,  0.0349,  0.1176, -0.0451,  0.1278, -0.0196, -0.0694, -0.0017,\n",
       "          0.0325,  0.1184]), 'layers.1.weight': tensor([[ 0.0430,  0.1070, -0.1260, -0.0958,  0.0517, -0.0930, -0.0505, -0.0313,\n",
       "           0.1330, -0.0313,  0.0485, -0.0704,  0.0718, -0.0042, -0.0587,  0.0447,\n",
       "          -0.0778, -0.0313,  0.0380,  0.0867, -0.1064,  0.0571, -0.0835, -0.0764,\n",
       "          -0.0593,  0.1281,  0.0841,  0.0987,  0.0985, -0.0181, -0.1209,  0.1213,\n",
       "           0.0131,  0.0500, -0.1021,  0.1020,  0.1230, -0.0589,  0.1543, -0.0493,\n",
       "          -0.1335,  0.0628,  0.1285, -0.0703,  0.0657,  0.1267, -0.0877, -0.0461,\n",
       "          -0.0744, -0.0811]]), 'layers.1.bias': tensor([-0.0786]), 'skip.weight': tensor([[ 0.0153, -0.0138,  0.0162,  0.0154,  0.0162,  0.0181, -0.0175, -0.0156,\n",
       "           0.0112,  0.0152, -0.0174, -0.0122, -0.0187,  0.0138,  0.0161, -0.0147,\n",
       "           0.0142,  0.0143,  0.0189,  0.0184,  0.0110,  0.0144,  0.0190,  0.0147,\n",
       "          -0.0168,  0.0184, -0.0172,  0.0211, -0.0177,  0.0136,  0.0166, -0.0215,\n",
       "           0.0243, -0.0203,  0.0233, -0.0160, -0.0216, -0.0154, -0.0135, -0.0200,\n",
       "          -0.0119, -0.0133,  0.0182, -0.0157,  0.0159,  0.0226, -0.0199, -0.0145,\n",
       "          -0.0217, -0.0127,  0.0167, -0.0125, -0.0166,  0.0121,  0.0154,  0.0167,\n",
       "          -0.0156, -0.0206, -0.0160,  0.0170,  0.0115,  0.0139, -0.0223,  0.0261,\n",
       "           0.0285, -0.0271,  0.0162]])}, objective=2.650221465680243, loss=0.735842764377594, val_objective=2.679993926140906, val_loss=0.7656152248382571, regularization=1.1407228708267212, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.7117797190421344, state_dict={'layers.0.weight': tensor([[-0.0706,  0.0230,  0.0824,  ..., -0.0087,  0.0606,  0.0351],\n",
       "         [-0.1162,  0.0174, -0.0177,  ...,  0.0314, -0.0979, -0.0750],\n",
       "         [-0.0400, -0.0529, -0.0188,  ..., -0.2587, -0.1338, -0.0206],\n",
       "         ...,\n",
       "         [-0.0050, -0.1373, -0.0268,  ..., -0.1639, -0.0599,  0.0401],\n",
       "         [ 0.1249, -0.0219, -0.0924,  ..., -0.0251, -0.0032,  0.1256],\n",
       "         [-0.0367, -0.0217,  0.1330,  ...,  0.0489, -0.0897,  0.1608]]), 'layers.0.bias': tensor([-0.0640,  0.1412,  0.0455,  0.0618,  0.0944,  0.0931,  0.0063, -0.1490,\n",
       "          0.0070, -0.0820,  0.0697,  0.0933,  0.1275,  0.0369, -0.1492, -0.1189,\n",
       "         -0.0698, -0.1004,  0.1488,  0.0056,  0.0593,  0.1522, -0.0943,  0.0542,\n",
       "         -0.0788,  0.1797, -0.0834, -0.0473, -0.0607,  0.1088, -0.0216,  0.0228,\n",
       "         -0.0313, -0.0457, -0.0297, -0.1464,  0.0048,  0.0621,  0.1032,  0.0586,\n",
       "         -0.0431,  0.0349,  0.1177, -0.0451,  0.1278, -0.0197, -0.0694, -0.0017,\n",
       "          0.0324,  0.1184]), 'layers.1.weight': tensor([[ 0.0431,  0.1071, -0.1261, -0.0955,  0.0517, -0.0931, -0.0505, -0.0311,\n",
       "           0.1331, -0.0313,  0.0483, -0.0704,  0.0716, -0.0038, -0.0588,  0.0448,\n",
       "          -0.0779, -0.0311,  0.0378,  0.0863, -0.1064,  0.0567, -0.0833, -0.0760,\n",
       "          -0.0592,  0.1280,  0.0838,  0.0986,  0.0987, -0.0180, -0.1207,  0.1215,\n",
       "           0.0129,  0.0500, -0.1019,  0.1021,  0.1227, -0.0591,  0.1544, -0.0493,\n",
       "          -0.1333,  0.0627,  0.1285, -0.0704,  0.0657,  0.1263, -0.0878, -0.0463,\n",
       "          -0.0743, -0.0811]]), 'layers.1.bias': tensor([-0.0783]), 'skip.weight': tensor([[ 0.0153, -0.0137,  0.0161,  0.0153,  0.0161,  0.0180, -0.0174, -0.0156,\n",
       "           0.0112,  0.0152, -0.0173, -0.0122, -0.0186,  0.0137,  0.0161, -0.0147,\n",
       "           0.0142,  0.0143,  0.0188,  0.0183,  0.0110,  0.0144,  0.0190,  0.0146,\n",
       "          -0.0167,  0.0183, -0.0172,  0.0210, -0.0176,  0.0136,  0.0166, -0.0214,\n",
       "           0.0243, -0.0202,  0.0233, -0.0159, -0.0216, -0.0154, -0.0134, -0.0199,\n",
       "          -0.0119, -0.0132,  0.0182, -0.0156,  0.0158,  0.0225, -0.0199, -0.0145,\n",
       "          -0.0217, -0.0127,  0.0167, -0.0124, -0.0165,  0.0120,  0.0154,  0.0166,\n",
       "          -0.0155, -0.0205, -0.0160,  0.0169,  0.0114,  0.0139, -0.0222,  0.0260,\n",
       "           0.0284, -0.0270,  0.0161]])}, objective=2.6826467693114684, loss=0.7357384562492371, val_objective=2.712343114640753, val_loss=0.7654348015785217, regularization=1.1373591423034668, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.7460153134229772, state_dict={'layers.0.weight': tensor([[-0.0706,  0.0230,  0.0824,  ..., -0.0087,  0.0605,  0.0351],\n",
       "         [-0.1161,  0.0175, -0.0177,  ...,  0.0315, -0.0980, -0.0749],\n",
       "         [-0.0401, -0.0530, -0.0189,  ..., -0.2588, -0.1337, -0.0207],\n",
       "         ...,\n",
       "         [-0.0051, -0.1369, -0.0268,  ..., -0.1639, -0.0598,  0.0400],\n",
       "         [ 0.1248, -0.0219, -0.0924,  ..., -0.0252, -0.0032,  0.1255],\n",
       "         [-0.0368, -0.0218,  0.1329,  ...,  0.0489, -0.0897,  0.1601]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0455,  0.0618,  0.0944,  0.0931,  0.0063, -0.1490,\n",
       "          0.0070, -0.0820,  0.0697,  0.0934,  0.1275,  0.0369, -0.1492, -0.1189,\n",
       "         -0.0698, -0.1004,  0.1488,  0.0055,  0.0593,  0.1521, -0.0943,  0.0542,\n",
       "         -0.0788,  0.1797, -0.0835, -0.0474, -0.0606,  0.1088, -0.0216,  0.0228,\n",
       "         -0.0313, -0.0457, -0.0297, -0.1464,  0.0047,  0.0621,  0.1032,  0.0586,\n",
       "         -0.0433,  0.0349,  0.1177, -0.0452,  0.1278, -0.0197, -0.0694, -0.0017,\n",
       "          0.0324,  0.1184]), 'layers.1.weight': tensor([[ 0.0432,  0.1071, -0.1262, -0.0952,  0.0517, -0.0932, -0.0506, -0.0309,\n",
       "           0.1332, -0.0313,  0.0480, -0.0703,  0.0713, -0.0034, -0.0589,  0.0448,\n",
       "          -0.0780, -0.0308,  0.0375,  0.0858, -0.1064,  0.0563, -0.0830, -0.0757,\n",
       "          -0.0591,  0.1279,  0.0834,  0.0985,  0.0989, -0.0178, -0.1205,  0.1217,\n",
       "           0.0127,  0.0500, -0.1017,  0.1023,  0.1224, -0.0593,  0.1546, -0.0493,\n",
       "          -0.1331,  0.0626,  0.1285, -0.0705,  0.0657,  0.1260, -0.0878, -0.0465,\n",
       "          -0.0742, -0.0811]]), 'layers.1.bias': tensor([-0.0781]), 'skip.weight': tensor([[ 0.0152, -0.0137,  0.0161,  0.0153,  0.0161,  0.0179, -0.0174, -0.0155,\n",
       "           0.0112,  0.0152, -0.0173, -0.0121, -0.0185,  0.0137,  0.0161, -0.0146,\n",
       "           0.0142,  0.0143,  0.0187,  0.0182,  0.0110,  0.0143,  0.0190,  0.0146,\n",
       "          -0.0167,  0.0182, -0.0171,  0.0209, -0.0176,  0.0136,  0.0166, -0.0213,\n",
       "           0.0242, -0.0201,  0.0232, -0.0159, -0.0215, -0.0154, -0.0134, -0.0198,\n",
       "          -0.0119, -0.0131,  0.0181, -0.0156,  0.0158,  0.0224, -0.0198, -0.0144,\n",
       "          -0.0216, -0.0127,  0.0167, -0.0124, -0.0165,  0.0120,  0.0154,  0.0165,\n",
       "          -0.0155, -0.0204, -0.0160,  0.0168,  0.0114,  0.0139, -0.0222,  0.0259,\n",
       "           0.0283, -0.0270,  0.0160]])}, objective=2.7156158117552813, loss=0.7356384992599487, val_objective=2.745238604952913, val_loss=0.7652612924575808, regularization=1.1339976787567139, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.7809356196914368, state_dict={'layers.0.weight': tensor([[-0.0705,  0.0231,  0.0824,  ..., -0.0086,  0.0605,  0.0352],\n",
       "         [-0.1160,  0.0175, -0.0176,  ...,  0.0315, -0.0981, -0.0747],\n",
       "         [-0.0402, -0.0530, -0.0189,  ..., -0.2589, -0.1337, -0.0208],\n",
       "         ...,\n",
       "         [-0.0051, -0.1365, -0.0269,  ..., -0.1640, -0.0598,  0.0400],\n",
       "         [ 0.1247, -0.0219, -0.0924,  ..., -0.0252, -0.0032,  0.1255],\n",
       "         [-0.0369, -0.0218,  0.1329,  ...,  0.0488, -0.0896,  0.1593]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0455,  0.0617,  0.0944,  0.0930,  0.0063, -0.1491,\n",
       "          0.0070, -0.0820,  0.0697,  0.0934,  0.1275,  0.0369, -0.1492, -0.1190,\n",
       "         -0.0699, -0.1004,  0.1488,  0.0054,  0.0593,  0.1521, -0.0944,  0.0541,\n",
       "         -0.0788,  0.1797, -0.0836, -0.0474, -0.0605,  0.1087, -0.0217,  0.0229,\n",
       "         -0.0313, -0.0457, -0.0297, -0.1464,  0.0046,  0.0621,  0.1032,  0.0586,\n",
       "         -0.0434,  0.0349,  0.1178, -0.0452,  0.1278, -0.0198, -0.0694, -0.0017,\n",
       "          0.0324,  0.1184]), 'layers.1.weight': tensor([[ 0.0433,  0.1072, -0.1263, -0.0950,  0.0516, -0.0934, -0.0506, -0.0307,\n",
       "           0.1334, -0.0313,  0.0478, -0.0703,  0.0711, -0.0030, -0.0590,  0.0448,\n",
       "          -0.0781, -0.0306,  0.0372,  0.0854, -0.1064,  0.0559, -0.0828, -0.0754,\n",
       "          -0.0590,  0.1277,  0.0830,  0.0984,  0.0991, -0.0177, -0.1203,  0.1218,\n",
       "           0.0125,  0.0500, -0.1015,  0.1024,  0.1221, -0.0595,  0.1547, -0.0492,\n",
       "          -0.1329,  0.0624,  0.1286, -0.0706,  0.0657,  0.1257, -0.0879, -0.0467,\n",
       "          -0.0740, -0.0811]]), 'layers.1.bias': tensor([-0.0778]), 'skip.weight': tensor([[ 0.0152, -0.0136,  0.0160,  0.0153,  0.0161,  0.0178, -0.0173, -0.0155,\n",
       "           0.0111,  0.0151, -0.0173, -0.0121, -0.0185,  0.0137,  0.0160, -0.0146,\n",
       "           0.0142,  0.0142,  0.0187,  0.0181,  0.0109,  0.0143,  0.0189,  0.0146,\n",
       "          -0.0167,  0.0181, -0.0171,  0.0208, -0.0175,  0.0136,  0.0165, -0.0212,\n",
       "           0.0241, -0.0200,  0.0231, -0.0159, -0.0214, -0.0153, -0.0134, -0.0198,\n",
       "          -0.0118, -0.0131,  0.0181, -0.0155,  0.0158,  0.0223, -0.0197, -0.0144,\n",
       "          -0.0216, -0.0127,  0.0166, -0.0124, -0.0164,  0.0120,  0.0154,  0.0164,\n",
       "          -0.0155, -0.0203, -0.0159,  0.0168,  0.0114,  0.0139, -0.0221,  0.0258,\n",
       "           0.0283, -0.0270,  0.0159]])}, objective=2.7491671592781985, loss=0.735541820526123, val_objective=2.7787220031807864, val_loss=0.7650966644287109, regularization=1.1306558847427368, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.8165543320852655, state_dict={'layers.0.weight': tensor([[-0.0705,  0.0231,  0.0824,  ..., -0.0086,  0.0605,  0.0352],\n",
       "         [-0.1160,  0.0176, -0.0176,  ...,  0.0316, -0.0981, -0.0746],\n",
       "         [-0.0402, -0.0530, -0.0190,  ..., -0.2589, -0.1336, -0.0209],\n",
       "         ...,\n",
       "         [-0.0051, -0.1360, -0.0269,  ..., -0.1640, -0.0598,  0.0400],\n",
       "         [ 0.1246, -0.0219, -0.0924,  ..., -0.0253, -0.0031,  0.1254],\n",
       "         [-0.0370, -0.0218,  0.1329,  ...,  0.0488, -0.0896,  0.1585]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0454,  0.0617,  0.0944,  0.0930,  0.0063, -0.1491,\n",
       "          0.0069, -0.0821,  0.0697,  0.0934,  0.1275,  0.0369, -0.1492, -0.1190,\n",
       "         -0.0699, -0.1004,  0.1487,  0.0054,  0.0593,  0.1521, -0.0944,  0.0541,\n",
       "         -0.0788,  0.1797, -0.0837, -0.0475, -0.0605,  0.1087, -0.0218,  0.0229,\n",
       "         -0.0313, -0.0457, -0.0297, -0.1464,  0.0045,  0.0621,  0.1032,  0.0585,\n",
       "         -0.0435,  0.0350,  0.1178, -0.0452,  0.1278, -0.0198, -0.0694, -0.0017,\n",
       "          0.0324,  0.1183]), 'layers.1.weight': tensor([[ 0.0434,  0.1073, -0.1264, -0.0947,  0.0516, -0.0935, -0.0507, -0.0306,\n",
       "           0.1335, -0.0313,  0.0476, -0.0702,  0.0708, -0.0027, -0.0591,  0.0448,\n",
       "          -0.0782, -0.0303,  0.0369,  0.0850, -0.1064,  0.0555, -0.0825, -0.0751,\n",
       "          -0.0589,  0.1276,  0.0827,  0.0983,  0.0993, -0.0176, -0.1201,  0.1220,\n",
       "           0.0124,  0.0500, -0.1013,  0.1025,  0.1218, -0.0597,  0.1548, -0.0492,\n",
       "          -0.1327,  0.0623,  0.1286, -0.0707,  0.0657,  0.1253, -0.0879, -0.0469,\n",
       "          -0.0739, -0.0811]]), 'layers.1.bias': tensor([-0.0776]), 'skip.weight': tensor([[ 0.0151, -0.0136,  0.0160,  0.0153,  0.0160,  0.0177, -0.0173, -0.0154,\n",
       "           0.0111,  0.0151, -0.0172, -0.0121, -0.0184,  0.0136,  0.0160, -0.0145,\n",
       "           0.0141,  0.0142,  0.0186,  0.0180,  0.0109,  0.0143,  0.0189,  0.0145,\n",
       "          -0.0166,  0.0181, -0.0171,  0.0207, -0.0175,  0.0136,  0.0165, -0.0212,\n",
       "           0.0240, -0.0199,  0.0230, -0.0159, -0.0213, -0.0153, -0.0134, -0.0197,\n",
       "          -0.0118, -0.0130,  0.0181, -0.0154,  0.0157,  0.0222, -0.0196, -0.0144,\n",
       "          -0.0216, -0.0126,  0.0166, -0.0124, -0.0164,  0.0119,  0.0153,  0.0163,\n",
       "          -0.0154, -0.0202, -0.0159,  0.0167,  0.0114,  0.0138, -0.0221,  0.0257,\n",
       "           0.0282, -0.0270,  0.0159]])}, objective=2.783237624223639, loss=0.7354486584663391, val_objective=2.812726187761237, val_loss=0.7649372220039368, regularization=1.1272929906845093, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.8528854187269708, state_dict={'layers.0.weight': tensor([[-0.0704,  0.0231,  0.0824,  ..., -0.0086,  0.0605,  0.0352],\n",
       "         [-0.1159,  0.0176, -0.0176,  ...,  0.0316, -0.0982, -0.0745],\n",
       "         [-0.0403, -0.0531, -0.0190,  ..., -0.2590, -0.1336, -0.0209],\n",
       "         ...,\n",
       "         [-0.0052, -0.1355, -0.0269,  ..., -0.1640, -0.0598,  0.0399],\n",
       "         [ 0.1245, -0.0219, -0.0925,  ..., -0.0253, -0.0031,  0.1254],\n",
       "         [-0.0371, -0.0219,  0.1329,  ...,  0.0487, -0.0895,  0.1577]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0454,  0.0617,  0.0944,  0.0930,  0.0063, -0.1491,\n",
       "          0.0069, -0.0821,  0.0697,  0.0934,  0.1275,  0.0369, -0.1493, -0.1190,\n",
       "         -0.0699, -0.1004,  0.1487,  0.0053,  0.0593,  0.1521, -0.0945,  0.0540,\n",
       "         -0.0788,  0.1797, -0.0838, -0.0475, -0.0604,  0.1087, -0.0218,  0.0229,\n",
       "         -0.0313, -0.0457, -0.0297, -0.1464,  0.0045,  0.0621,  0.1032,  0.0585,\n",
       "         -0.0436,  0.0350,  0.1179, -0.0452,  0.1277, -0.0199, -0.0694, -0.0017,\n",
       "          0.0324,  0.1183]), 'layers.1.weight': tensor([[ 0.0436,  0.1074, -0.1264, -0.0945,  0.0516, -0.0936, -0.0508, -0.0304,\n",
       "           0.1336, -0.0313,  0.0474, -0.0702,  0.0706, -0.0023, -0.0592,  0.0449,\n",
       "          -0.0783, -0.0301,  0.0367,  0.0846, -0.1064,  0.0552, -0.0823, -0.0748,\n",
       "          -0.0587,  0.1275,  0.0823,  0.0983,  0.0995, -0.0175, -0.1199,  0.1221,\n",
       "           0.0122,  0.0500, -0.1011,  0.1026,  0.1215, -0.0599,  0.1550, -0.0491,\n",
       "          -0.1325,  0.0622,  0.1286, -0.0708,  0.0657,  0.1250, -0.0880, -0.0471,\n",
       "          -0.0738, -0.0811]]), 'layers.1.bias': tensor([-0.0773]), 'skip.weight': tensor([[ 0.0151, -0.0136,  0.0160,  0.0152,  0.0160,  0.0176, -0.0173, -0.0154,\n",
       "           0.0111,  0.0150, -0.0172, -0.0120, -0.0183,  0.0136,  0.0160, -0.0145,\n",
       "           0.0141,  0.0142,  0.0185,  0.0180,  0.0109,  0.0143,  0.0188,  0.0145,\n",
       "          -0.0166,  0.0180, -0.0170,  0.0206, -0.0174,  0.0135,  0.0164, -0.0211,\n",
       "           0.0240, -0.0198,  0.0229, -0.0158, -0.0212, -0.0152, -0.0134, -0.0196,\n",
       "          -0.0118, -0.0129,  0.0180, -0.0153,  0.0157,  0.0222, -0.0196, -0.0143,\n",
       "          -0.0215, -0.0126,  0.0166, -0.0124, -0.0164,  0.0119,  0.0153,  0.0162,\n",
       "          -0.0154, -0.0201, -0.0159,  0.0166,  0.0113,  0.0138, -0.0220,  0.0257,\n",
       "           0.0281, -0.0269,  0.0158]])}, objective=2.817762260210637, loss=0.7353590130805969, val_objective=2.8471853778482714, val_loss=0.7647821307182312, regularization=1.1238704919815063, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.8899431271015101, state_dict={'layers.0.weight': tensor([[-0.0704,  0.0231,  0.0824,  ..., -0.0086,  0.0604,  0.0353],\n",
       "         [-0.1158,  0.0177, -0.0175,  ...,  0.0317, -0.0983, -0.0744],\n",
       "         [-0.0404, -0.0531, -0.0191,  ..., -0.2591, -0.1335, -0.0210],\n",
       "         ...,\n",
       "         [-0.0052, -0.1351, -0.0269,  ..., -0.1640, -0.0597,  0.0399],\n",
       "         [ 0.1244, -0.0220, -0.0925,  ..., -0.0254, -0.0031,  0.1253],\n",
       "         [-0.0372, -0.0219,  0.1328,  ...,  0.0487, -0.0894,  0.1569]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0453,  0.0616,  0.0944,  0.0929,  0.0062, -0.1491,\n",
       "          0.0069, -0.0821,  0.0697,  0.0934,  0.1275,  0.0369, -0.1493, -0.1190,\n",
       "         -0.0700, -0.1004,  0.1487,  0.0052,  0.0593,  0.1520, -0.0945,  0.0540,\n",
       "         -0.0788,  0.1797, -0.0839, -0.0475, -0.0603,  0.1087, -0.0219,  0.0230,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1464,  0.0044,  0.0621,  0.1031,  0.0585,\n",
       "         -0.0437,  0.0350,  0.1179, -0.0452,  0.1277, -0.0199, -0.0695, -0.0017,\n",
       "          0.0324,  0.1183]), 'layers.1.weight': tensor([[ 0.0437,  0.1074, -0.1265, -0.0942,  0.0516, -0.0937, -0.0508, -0.0303,\n",
       "           0.1337, -0.0313,  0.0472, -0.0701,  0.0704, -0.0020, -0.0593,  0.0449,\n",
       "          -0.0784, -0.0299,  0.0364,  0.0842, -0.1064,  0.0548, -0.0820, -0.0745,\n",
       "          -0.0586,  0.1274,  0.0820,  0.0982,  0.0996, -0.0173, -0.1198,  0.1223,\n",
       "           0.0121,  0.0500, -0.1009,  0.1028,  0.1212, -0.0601,  0.1551, -0.0491,\n",
       "          -0.1324,  0.0621,  0.1287, -0.0709,  0.0657,  0.1247, -0.0880, -0.0473,\n",
       "          -0.0737, -0.0811]]), 'layers.1.bias': tensor([-0.0770]), 'skip.weight': tensor([[ 0.0151, -0.0135,  0.0160,  0.0152,  0.0159,  0.0175, -0.0172, -0.0153,\n",
       "           0.0110,  0.0150, -0.0171, -0.0120, -0.0182,  0.0136,  0.0160, -0.0144,\n",
       "           0.0141,  0.0141,  0.0184,  0.0179,  0.0108,  0.0142,  0.0188,  0.0145,\n",
       "          -0.0165,  0.0179, -0.0170,  0.0205, -0.0174,  0.0135,  0.0164, -0.0210,\n",
       "           0.0239, -0.0198,  0.0228, -0.0158, -0.0211, -0.0152, -0.0133, -0.0195,\n",
       "          -0.0118, -0.0128,  0.0180, -0.0152,  0.0156,  0.0221, -0.0196, -0.0143,\n",
       "          -0.0215, -0.0126,  0.0165, -0.0124, -0.0163,  0.0118,  0.0153,  0.0161,\n",
       "          -0.0153, -0.0200, -0.0159,  0.0165,  0.0113,  0.0138, -0.0220,  0.0256,\n",
       "           0.0280, -0.0269,  0.0157]])}, objective=2.8527761521324626, loss=0.7352735996246338, val_objective=2.882135015963029, val_loss=0.7646324634552002, regularization=1.1204054355621338, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.9277419896435404, state_dict={'layers.0.weight': tensor([[-0.0704,  0.0231,  0.0824,  ..., -0.0085,  0.0604,  0.0353],\n",
       "         [-0.1157,  0.0177, -0.0175,  ...,  0.0317, -0.0984, -0.0743],\n",
       "         [-0.0405, -0.0531, -0.0191,  ..., -0.2592, -0.1334, -0.0211],\n",
       "         ...,\n",
       "         [-0.0052, -0.1346, -0.0269,  ..., -0.1641, -0.0597,  0.0399],\n",
       "         [ 0.1244, -0.0220, -0.0925,  ..., -0.0254, -0.0030,  0.1253],\n",
       "         [-0.0373, -0.0220,  0.1328,  ...,  0.0487, -0.0894,  0.1560]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0453,  0.0616,  0.0944,  0.0929,  0.0062, -0.1492,\n",
       "          0.0069, -0.0821,  0.0697,  0.0934,  0.1275,  0.0369, -0.1493, -0.1190,\n",
       "         -0.0700, -0.1004,  0.1487,  0.0051,  0.0593,  0.1520, -0.0946,  0.0539,\n",
       "         -0.0788,  0.1797, -0.0840, -0.0476, -0.0603,  0.1087, -0.0219,  0.0230,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1464,  0.0043,  0.0621,  0.1031,  0.0585,\n",
       "         -0.0438,  0.0350,  0.1180, -0.0452,  0.1277, -0.0200, -0.0695, -0.0017,\n",
       "          0.0323,  0.1182]), 'layers.1.weight': tensor([[ 0.0438,  0.1075, -0.1266, -0.0940,  0.0516, -0.0938, -0.0509, -0.0301,\n",
       "           0.1339, -0.0313,  0.0470, -0.0701,  0.0702, -0.0017, -0.0594,  0.0449,\n",
       "          -0.0785, -0.0297,  0.0362,  0.0838, -0.1064,  0.0545, -0.0818, -0.0743,\n",
       "          -0.0585,  0.1273,  0.0816,  0.0981,  0.0998, -0.0172, -0.1196,  0.1224,\n",
       "           0.0119,  0.0501, -0.1007,  0.1029,  0.1210, -0.0603,  0.1553, -0.0490,\n",
       "          -0.1322,  0.0620,  0.1287, -0.0710,  0.0657,  0.1244, -0.0881, -0.0475,\n",
       "          -0.0735, -0.0812]]), 'layers.1.bias': tensor([-0.0768]), 'skip.weight': tensor([[ 0.0150, -0.0135,  0.0159,  0.0152,  0.0159,  0.0174, -0.0172, -0.0153,\n",
       "           0.0110,  0.0149, -0.0171, -0.0120, -0.0182,  0.0136,  0.0159, -0.0144,\n",
       "           0.0140,  0.0141,  0.0184,  0.0178,  0.0108,  0.0142,  0.0187,  0.0144,\n",
       "          -0.0165,  0.0178, -0.0169,  0.0204, -0.0174,  0.0135,  0.0164, -0.0209,\n",
       "           0.0238, -0.0197,  0.0227, -0.0158, -0.0211, -0.0152, -0.0133, -0.0194,\n",
       "          -0.0117, -0.0127,  0.0179, -0.0151,  0.0156,  0.0220, -0.0195, -0.0143,\n",
       "          -0.0214, -0.0125,  0.0165, -0.0123, -0.0163,  0.0118,  0.0152,  0.0160,\n",
       "          -0.0153, -0.0199, -0.0159,  0.0164,  0.0113,  0.0138, -0.0220,  0.0255,\n",
       "           0.0279, -0.0269,  0.0156]])}, objective=2.888289587076633, loss=0.7351914048194885, val_objective=2.91758729654166, val_loss=0.7644891142845154, regularization=1.1169016361236572, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=1.9662968294364112, state_dict={'layers.0.weight': tensor([[-0.0703,  0.0231,  0.0825,  ..., -0.0085,  0.0604,  0.0353],\n",
       "         [-0.1157,  0.0178, -0.0174,  ...,  0.0318, -0.0984, -0.0742],\n",
       "         [-0.0406, -0.0532, -0.0191,  ..., -0.2593, -0.1334, -0.0211],\n",
       "         ...,\n",
       "         [-0.0053, -0.1342, -0.0269,  ..., -0.1641, -0.0597,  0.0398],\n",
       "         [ 0.1243, -0.0220, -0.0925,  ..., -0.0255, -0.0030,  0.1252],\n",
       "         [-0.0374, -0.0220,  0.1328,  ...,  0.0486, -0.0893,  0.1552]]), 'layers.0.bias': tensor([-0.0640,  0.1411,  0.0452,  0.0616,  0.0944,  0.0928,  0.0062, -0.1492,\n",
       "          0.0068, -0.0821,  0.0697,  0.0935,  0.1275,  0.0369, -0.1493, -0.1190,\n",
       "         -0.0700, -0.1005,  0.1487,  0.0050,  0.0593,  0.1520, -0.0946,  0.0539,\n",
       "         -0.0788,  0.1797, -0.0841, -0.0476, -0.0602,  0.1087, -0.0220,  0.0230,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1465,  0.0043,  0.0621,  0.1031,  0.0584,\n",
       "         -0.0439,  0.0350,  0.1180, -0.0452,  0.1277, -0.0200, -0.0695, -0.0017,\n",
       "          0.0323,  0.1182]), 'layers.1.weight': tensor([[ 0.0439,  0.1076, -0.1267, -0.0937,  0.0516, -0.0940, -0.0510, -0.0300,\n",
       "           0.1340, -0.0313,  0.0468, -0.0701,  0.0700, -0.0013, -0.0595,  0.0450,\n",
       "          -0.0787, -0.0295,  0.0359,  0.0835, -0.1064,  0.0541, -0.0816, -0.0740,\n",
       "          -0.0585,  0.1272,  0.0813,  0.0981,  0.1000, -0.0171, -0.1194,  0.1226,\n",
       "           0.0118,  0.0501, -0.1005,  0.1030,  0.1207, -0.0605,  0.1554, -0.0490,\n",
       "          -0.1320,  0.0619,  0.1288, -0.0710,  0.0657,  0.1240, -0.0882, -0.0477,\n",
       "          -0.0734, -0.0812]]), 'layers.1.bias': tensor([-0.0765]), 'skip.weight': tensor([[ 0.0150, -0.0134,  0.0159,  0.0152,  0.0159,  0.0173, -0.0171, -0.0153,\n",
       "           0.0110,  0.0149, -0.0170, -0.0120, -0.0181,  0.0135,  0.0159, -0.0143,\n",
       "           0.0140,  0.0141,  0.0183,  0.0177,  0.0108,  0.0142,  0.0187,  0.0144,\n",
       "          -0.0164,  0.0177, -0.0169,  0.0203, -0.0173,  0.0135,  0.0163, -0.0208,\n",
       "           0.0237, -0.0196,  0.0226, -0.0157, -0.0210, -0.0151, -0.0133, -0.0193,\n",
       "          -0.0117, -0.0127,  0.0179, -0.0151,  0.0155,  0.0219, -0.0195, -0.0142,\n",
       "          -0.0214, -0.0125,  0.0165, -0.0123, -0.0162,  0.0118,  0.0152,  0.0159,\n",
       "          -0.0153, -0.0198, -0.0158,  0.0163,  0.0112,  0.0137, -0.0219,  0.0254,\n",
       "           0.0279, -0.0268,  0.0155]])}, objective=2.9242698572664287, loss=0.7351129055023193, val_objective=2.953509929039958, val_loss=0.7643529772758484, regularization=1.1133400201797485, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.0056227660251396, state_dict={'layers.0.weight': tensor([[-0.0703,  0.0232,  0.0825,  ..., -0.0085,  0.0603,  0.0353],\n",
       "         [-0.1156,  0.0178, -0.0174,  ...,  0.0318, -0.0985, -0.0741],\n",
       "         [-0.0406, -0.0532, -0.0192,  ..., -0.2593, -0.1333, -0.0212],\n",
       "         ...,\n",
       "         [-0.0053, -0.1339, -0.0269,  ..., -0.1641, -0.0597,  0.0398],\n",
       "         [ 0.1242, -0.0220, -0.0926,  ..., -0.0255, -0.0030,  0.1252],\n",
       "         [-0.0374, -0.0220,  0.1327,  ...,  0.0486, -0.0893,  0.1543]]), 'layers.0.bias': tensor([-0.0640,  0.1410,  0.0452,  0.0616,  0.0944,  0.0928,  0.0062, -0.1492,\n",
       "          0.0068, -0.0821,  0.0697,  0.0935,  0.1275,  0.0369, -0.1494, -0.1190,\n",
       "         -0.0700, -0.1005,  0.1487,  0.0050,  0.0593,  0.1520, -0.0947,  0.0539,\n",
       "         -0.0788,  0.1797, -0.0842, -0.0476, -0.0601,  0.1087, -0.0220,  0.0231,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1465,  0.0042,  0.0621,  0.1031,  0.0584,\n",
       "         -0.0441,  0.0350,  0.1181, -0.0452,  0.1277, -0.0200, -0.0695, -0.0017,\n",
       "          0.0323,  0.1182]), 'layers.1.weight': tensor([[ 0.0440,  0.1076, -0.1268, -0.0935,  0.0516, -0.0941, -0.0511, -0.0298,\n",
       "           0.1341, -0.0314,  0.0466, -0.0701,  0.0698, -0.0010, -0.0596,  0.0450,\n",
       "          -0.0788, -0.0293,  0.0357,  0.0831, -0.1064,  0.0538, -0.0814, -0.0738,\n",
       "          -0.0584,  0.1271,  0.0810,  0.0980,  0.1002, -0.0171, -0.1193,  0.1227,\n",
       "           0.0116,  0.0501, -0.1003,  0.1032,  0.1205, -0.0607,  0.1555, -0.0490,\n",
       "          -0.1319,  0.0618,  0.1288, -0.0711,  0.0657,  0.1237, -0.0882, -0.0480,\n",
       "          -0.0733, -0.0812]]), 'layers.1.bias': tensor([-0.0763]), 'skip.weight': tensor([[ 0.0149, -0.0134,  0.0159,  0.0151,  0.0158,  0.0172, -0.0171, -0.0152,\n",
       "           0.0109,  0.0148, -0.0170, -0.0119, -0.0181,  0.0135,  0.0159, -0.0143,\n",
       "           0.0140,  0.0140,  0.0182,  0.0176,  0.0107,  0.0141,  0.0186,  0.0144,\n",
       "          -0.0164,  0.0176, -0.0168,  0.0202, -0.0173,  0.0135,  0.0163, -0.0207,\n",
       "           0.0236, -0.0195,  0.0225, -0.0157, -0.0209, -0.0151, -0.0133, -0.0192,\n",
       "          -0.0117, -0.0126,  0.0178, -0.0150,  0.0155,  0.0218, -0.0194, -0.0142,\n",
       "          -0.0213, -0.0125,  0.0164, -0.0123, -0.0162,  0.0117,  0.0152,  0.0158,\n",
       "          -0.0152, -0.0197, -0.0158,  0.0163,  0.0112,  0.0137, -0.0219,  0.0253,\n",
       "           0.0278, -0.0268,  0.0154]])}, objective=2.960700447300132, loss=0.7350379824638367, val_objective=2.9898855039865335, val_loss=0.764223039150238, regularization=1.1097114086151123, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.0457352213456423, state_dict={'layers.0.weight': tensor([[-0.0702,  0.0232,  0.0825,  ..., -0.0085,  0.0603,  0.0354],\n",
       "         [-0.1155,  0.0179, -0.0174,  ...,  0.0318, -0.0986, -0.0740],\n",
       "         [-0.0407, -0.0532, -0.0192,  ..., -0.2594, -0.1333, -0.0212],\n",
       "         ...,\n",
       "         [-0.0054, -0.1336, -0.0269,  ..., -0.1641, -0.0597,  0.0398],\n",
       "         [ 0.1241, -0.0220, -0.0926,  ..., -0.0255, -0.0029,  0.1251],\n",
       "         [-0.0375, -0.0221,  0.1327,  ...,  0.0485, -0.0892,  0.1534]]), 'layers.0.bias': tensor([-0.0640,  0.1410,  0.0452,  0.0615,  0.0944,  0.0928,  0.0062, -0.1492,\n",
       "          0.0068, -0.0821,  0.0697,  0.0935,  0.1275,  0.0369, -0.1494, -0.1190,\n",
       "         -0.0701, -0.1005,  0.1487,  0.0049,  0.0592,  0.1520, -0.0947,  0.0538,\n",
       "         -0.0788,  0.1797, -0.0843, -0.0477, -0.0601,  0.1086, -0.0221,  0.0231,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1465,  0.0041,  0.0621,  0.1031,  0.0584,\n",
       "         -0.0442,  0.0350,  0.1181, -0.0452,  0.1276, -0.0201, -0.0695, -0.0017,\n",
       "          0.0323,  0.1182]), 'layers.1.weight': tensor([[ 0.0441,  0.1077, -0.1269, -0.0933,  0.0517, -0.0942, -0.0511, -0.0297,\n",
       "           0.1342, -0.0314,  0.0464, -0.0700,  0.0696, -0.0007, -0.0597,  0.0450,\n",
       "          -0.0789, -0.0291,  0.0355,  0.0827, -0.1064,  0.0535, -0.0812, -0.0735,\n",
       "          -0.0583,  0.1270,  0.0807,  0.0980,  0.1003, -0.0170, -0.1192,  0.1229,\n",
       "           0.0115,  0.0501, -0.1001,  0.1033,  0.1202, -0.0609,  0.1557, -0.0489,\n",
       "          -0.1317,  0.0617,  0.1288, -0.0712,  0.0657,  0.1234, -0.0883, -0.0482,\n",
       "          -0.0732, -0.0813]]), 'layers.1.bias': tensor([-0.0760]), 'skip.weight': tensor([[ 0.0149, -0.0134,  0.0158,  0.0151,  0.0158,  0.0171, -0.0170, -0.0152,\n",
       "           0.0109,  0.0148, -0.0169, -0.0119, -0.0180,  0.0135,  0.0158, -0.0142,\n",
       "           0.0139,  0.0140,  0.0181,  0.0175,  0.0107,  0.0141,  0.0186,  0.0143,\n",
       "          -0.0163,  0.0175, -0.0168,  0.0201, -0.0172,  0.0134,  0.0162, -0.0207,\n",
       "           0.0235, -0.0194,  0.0224, -0.0157, -0.0208, -0.0150, -0.0133, -0.0191,\n",
       "          -0.0117, -0.0125,  0.0178, -0.0149,  0.0154,  0.0217, -0.0194, -0.0142,\n",
       "          -0.0213, -0.0125,  0.0164, -0.0123, -0.0161,  0.0117,  0.0151,  0.0157,\n",
       "          -0.0152, -0.0196, -0.0158,  0.0162,  0.0112,  0.0137, -0.0218,  0.0252,\n",
       "           0.0277, -0.0268,  0.0153]])}, objective=2.9976211408085436, loss=0.7349663972854614, val_objective=3.0267539838261217, val_loss=0.7640992403030396, regularization=1.1060349941253662, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.086649925772555, state_dict={'layers.0.weight': tensor([[-0.0702,  0.0232,  0.0825,  ..., -0.0085,  0.0603,  0.0354],\n",
       "         [-0.1154,  0.0179, -0.0173,  ...,  0.0319, -0.0986, -0.0739],\n",
       "         [-0.0408, -0.0533, -0.0193,  ..., -0.2595, -0.1332, -0.0213],\n",
       "         ...,\n",
       "         [-0.0054, -0.1332, -0.0269,  ..., -0.1642, -0.0596,  0.0397],\n",
       "         [ 0.1240, -0.0220, -0.0926,  ..., -0.0256, -0.0029,  0.1251],\n",
       "         [-0.0376, -0.0221,  0.1327,  ...,  0.0485, -0.0892,  0.1524]]), 'layers.0.bias': tensor([-0.0639,  0.1410,  0.0451,  0.0615,  0.0944,  0.0927,  0.0061, -0.1492,\n",
       "          0.0067, -0.0821,  0.0696,  0.0935,  0.1275,  0.0369, -0.1494, -0.1191,\n",
       "         -0.0701, -0.1005,  0.1487,  0.0048,  0.0592,  0.1520, -0.0948,  0.0538,\n",
       "         -0.0789,  0.1797, -0.0844, -0.0477, -0.0600,  0.1086, -0.0222,  0.0232,\n",
       "         -0.0313, -0.0456, -0.0298, -0.1465,  0.0041,  0.0621,  0.1030,  0.0583,\n",
       "         -0.0443,  0.0350,  0.1182, -0.0453,  0.1276, -0.0201, -0.0695, -0.0016,\n",
       "          0.0323,  0.1181]), 'layers.1.weight': tensor([[ 0.0442,  0.1078, -0.1269, -0.0930,  0.0517, -0.0944, -0.0512, -0.0296,\n",
       "           0.1344, -0.0314,  0.0462, -0.0700,  0.0695, -0.0004, -0.0599,  0.0451,\n",
       "          -0.0790, -0.0289,  0.0352,  0.0824, -0.1064,  0.0532, -0.0810, -0.0733,\n",
       "          -0.0582,  0.1269,  0.0804,  0.0980,  0.1005, -0.0169, -0.1190,  0.1230,\n",
       "           0.0114,  0.0501, -0.1000,  0.1034,  0.1200, -0.0611,  0.1558, -0.0489,\n",
       "          -0.1316,  0.0616,  0.1289, -0.0713,  0.0657,  0.1231, -0.0883, -0.0484,\n",
       "          -0.0731, -0.0813]]), 'layers.1.bias': tensor([-0.0758]), 'skip.weight': tensor([[ 0.0148, -0.0133,  0.0158,  0.0151,  0.0157,  0.0170, -0.0170, -0.0151,\n",
       "           0.0109,  0.0147, -0.0169, -0.0119, -0.0180,  0.0135,  0.0158, -0.0142,\n",
       "           0.0139,  0.0140,  0.0180,  0.0174,  0.0106,  0.0141,  0.0185,  0.0143,\n",
       "          -0.0163,  0.0174, -0.0167,  0.0200, -0.0172,  0.0134,  0.0162, -0.0206,\n",
       "           0.0234, -0.0193,  0.0223, -0.0157, -0.0207, -0.0150, -0.0132, -0.0190,\n",
       "          -0.0117, -0.0124,  0.0177, -0.0148,  0.0154,  0.0216, -0.0193, -0.0141,\n",
       "          -0.0213, -0.0124,  0.0164, -0.0123, -0.0161,  0.0117,  0.0151,  0.0156,\n",
       "          -0.0151, -0.0195, -0.0158,  0.0161,  0.0111,  0.0137, -0.0218,  0.0251,\n",
       "           0.0276, -0.0267,  0.0152]])}, objective=3.0350353478645777, loss=0.7348981499671936, val_objective=3.0641185998177027, val_loss=0.7639814019203186, regularization=1.1023110151290894, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.1283829242880064, state_dict={'layers.0.weight': tensor([[-0.0701,  0.0232,  0.0825,  ..., -0.0084,  0.0603,  0.0354],\n",
       "         [-0.1154,  0.0180, -0.0173,  ...,  0.0319, -0.0987, -0.0738],\n",
       "         [-0.0409, -0.0533, -0.0193,  ..., -0.2596, -0.1332, -0.0214],\n",
       "         ...,\n",
       "         [-0.0054, -0.1329, -0.0269,  ..., -0.1642, -0.0596,  0.0397],\n",
       "         [ 0.1239, -0.0220, -0.0926,  ..., -0.0256, -0.0029,  0.1250],\n",
       "         [-0.0377, -0.0222,  0.1327,  ...,  0.0485, -0.0891,  0.1515]]), 'layers.0.bias': tensor([-0.0639,  0.1410,  0.0451,  0.0615,  0.0944,  0.0927,  0.0061, -0.1493,\n",
       "          0.0067, -0.0821,  0.0696,  0.0935,  0.1275,  0.0369, -0.1494, -0.1191,\n",
       "         -0.0701, -0.1005,  0.1487,  0.0048,  0.0592,  0.1519, -0.0948,  0.0537,\n",
       "         -0.0789,  0.1797, -0.0844, -0.0477, -0.0599,  0.1086, -0.0222,  0.0232,\n",
       "         -0.0314, -0.0456, -0.0299, -0.1465,  0.0040,  0.0621,  0.1030,  0.0583,\n",
       "         -0.0444,  0.0350,  0.1182, -0.0453,  0.1276, -0.0202, -0.0695, -0.0016,\n",
       "          0.0323,  0.1181]), 'layers.1.weight': tensor([[ 4.4284e-02,  1.0789e-01, -1.2702e-01, -9.2810e-02,  5.1705e-02,\n",
       "          -9.4479e-02, -5.1313e-02, -2.9479e-02,  1.3450e-01, -3.1413e-02,\n",
       "           4.6028e-02, -7.0000e-02,  6.9277e-02, -9.1794e-05, -6.0000e-02,\n",
       "           4.5130e-02, -7.9167e-02, -2.8688e-02,  3.5018e-02,  8.2017e-02,\n",
       "          -1.0642e-01,  5.2943e-02, -8.0811e-02, -7.3096e-02, -5.8141e-02,\n",
       "           1.2676e-01,  8.0061e-02,  9.7917e-02,  1.0070e-01, -1.6822e-02,\n",
       "          -1.1888e-01,  1.2317e-01,  1.1267e-02,  5.0179e-02, -9.9802e-02,\n",
       "           1.0354e-01,  1.1973e-01, -6.1270e-02,  1.5592e-01, -4.8859e-02,\n",
       "          -1.3146e-01,  6.1479e-02,  1.2893e-01, -7.1418e-02,  6.5716e-02,\n",
       "           1.2284e-01, -8.8395e-02, -4.8624e-02, -7.3045e-02, -8.1374e-02]]), 'layers.1.bias': tensor([-0.0755]), 'skip.weight': tensor([[ 0.0148, -0.0133,  0.0158,  0.0150,  0.0157,  0.0169, -0.0169, -0.0150,\n",
       "           0.0108,  0.0147, -0.0168, -0.0119, -0.0179,  0.0134,  0.0158, -0.0141,\n",
       "           0.0139,  0.0139,  0.0179,  0.0173,  0.0106,  0.0140,  0.0185,  0.0143,\n",
       "          -0.0162,  0.0173, -0.0167,  0.0199, -0.0171,  0.0134,  0.0161, -0.0205,\n",
       "           0.0233, -0.0192,  0.0222, -0.0156, -0.0206, -0.0149, -0.0132, -0.0189,\n",
       "          -0.0116, -0.0123,  0.0177, -0.0147,  0.0153,  0.0215, -0.0193, -0.0141,\n",
       "          -0.0212, -0.0124,  0.0164, -0.0122, -0.0161,  0.0116,  0.0151,  0.0155,\n",
       "          -0.0151, -0.0194, -0.0157,  0.0160,  0.0111,  0.0136, -0.0217,  0.0250,\n",
       "           0.0275, -0.0267,  0.0151]])}, objective=3.0729338493837246, loss=0.7348331212997437, val_objective=3.101969775248898, val_loss=0.763869047164917, regularization=1.0985338687896729, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.1709505827737665, state_dict={'layers.0.weight': tensor([[-0.0701,  0.0232,  0.0825,  ..., -0.0084,  0.0602,  0.0354],\n",
       "         [-0.1153,  0.0180, -0.0173,  ...,  0.0320, -0.0988, -0.0737],\n",
       "         [-0.0409, -0.0533, -0.0194,  ..., -0.2596, -0.1331, -0.0214],\n",
       "         ...,\n",
       "         [-0.0055, -0.1325, -0.0269,  ..., -0.1642, -0.0596,  0.0397],\n",
       "         [ 0.1238, -0.0220, -0.0927,  ..., -0.0256, -0.0028,  0.1250],\n",
       "         [-0.0378, -0.0222,  0.1326,  ...,  0.0484, -0.0890,  0.1505]]), 'layers.0.bias': tensor([-0.0639,  0.1410,  0.0450,  0.0614,  0.0944,  0.0926,  0.0061, -0.1493,\n",
       "          0.0067, -0.0821,  0.0696,  0.0935,  0.1274,  0.0369, -0.1495, -0.1191,\n",
       "         -0.0701, -0.1005,  0.1486,  0.0047,  0.0592,  0.1519, -0.0949,  0.0537,\n",
       "         -0.0789,  0.1797, -0.0845, -0.0478, -0.0599,  0.1086, -0.0223,  0.0232,\n",
       "         -0.0314, -0.0456, -0.0299, -0.1465,  0.0040,  0.0621,  0.1030,  0.0583,\n",
       "         -0.0445,  0.0351,  0.1182, -0.0453,  0.1276, -0.0202, -0.0695, -0.0016,\n",
       "          0.0323,  0.1181]), 'layers.1.weight': tensor([[ 0.0444,  0.1080, -0.1271, -0.0926,  0.0517, -0.0946, -0.0514, -0.0294,\n",
       "           0.1346, -0.0314,  0.0459, -0.0700,  0.0691,  0.0002, -0.0601,  0.0452,\n",
       "          -0.0793, -0.0285,  0.0348,  0.0817, -0.1064,  0.0527, -0.0806, -0.0729,\n",
       "          -0.0581,  0.1267,  0.0798,  0.0979,  0.1009, -0.0168, -0.1187,  0.1233,\n",
       "           0.0112,  0.0502, -0.0996,  0.1037,  0.1195, -0.0615,  0.1560, -0.0488,\n",
       "          -0.1313,  0.0614,  0.1290, -0.0715,  0.0657,  0.1226, -0.0885, -0.0488,\n",
       "          -0.0730, -0.0814]]), 'layers.1.bias': tensor([-0.0753]), 'skip.weight': tensor([[ 0.0148, -0.0132,  0.0158,  0.0150,  0.0156,  0.0168, -0.0169, -0.0150,\n",
       "           0.0108,  0.0146, -0.0168, -0.0118, -0.0179,  0.0134,  0.0157, -0.0141,\n",
       "           0.0139,  0.0139,  0.0178,  0.0172,  0.0106,  0.0140,  0.0184,  0.0142,\n",
       "          -0.0162,  0.0172, -0.0166,  0.0198, -0.0171,  0.0134,  0.0161, -0.0204,\n",
       "           0.0232, -0.0191,  0.0221, -0.0156, -0.0205, -0.0149, -0.0132, -0.0188,\n",
       "          -0.0116, -0.0122,  0.0176, -0.0146,  0.0153,  0.0214, -0.0192, -0.0141,\n",
       "          -0.0212, -0.0124,  0.0163, -0.0122, -0.0160,  0.0116,  0.0150,  0.0154,\n",
       "          -0.0150, -0.0193, -0.0157,  0.0159,  0.0111,  0.0136, -0.0216,  0.0249,\n",
       "           0.0274, -0.0267,  0.0150]])}, objective=3.1113503058620084, loss=0.7347708940505981, val_objective=3.14033890563923, val_loss=0.7637594938278198, regularization=1.094718337059021, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.214369594429242, state_dict={'layers.0.weight': tensor([[-0.0701,  0.0232,  0.0825,  ..., -0.0084,  0.0602,  0.0355],\n",
       "         [-0.1152,  0.0181, -0.0172,  ...,  0.0320, -0.0989, -0.0737],\n",
       "         [-0.0410, -0.0534, -0.0194,  ..., -0.2597, -0.1331, -0.0215],\n",
       "         ...,\n",
       "         [-0.0055, -0.1321, -0.0269,  ..., -0.1642, -0.0596,  0.0396],\n",
       "         [ 0.1237, -0.0221, -0.0927,  ..., -0.0257, -0.0028,  0.1249],\n",
       "         [-0.0379, -0.0222,  0.1326,  ...,  0.0484, -0.0890,  0.1495]]), 'layers.0.bias': tensor([-0.0639,  0.1410,  0.0450,  0.0614,  0.0944,  0.0926,  0.0061, -0.1493,\n",
       "          0.0067, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1495, -0.1191,\n",
       "         -0.0702, -0.1005,  0.1486,  0.0046,  0.0592,  0.1519, -0.0949,  0.0537,\n",
       "         -0.0789,  0.1797, -0.0846, -0.0478, -0.0598,  0.1086, -0.0223,  0.0233,\n",
       "         -0.0314, -0.0455, -0.0299, -0.1465,  0.0039,  0.0621,  0.1030,  0.0583,\n",
       "         -0.0446,  0.0351,  0.1183, -0.0453,  0.1276, -0.0203, -0.0695, -0.0016,\n",
       "          0.0323,  0.1181]), 'layers.1.weight': tensor([[ 0.0445,  0.1081, -0.1272, -0.0924,  0.0518, -0.0947, -0.0515, -0.0293,\n",
       "           0.1348, -0.0314,  0.0457, -0.0700,  0.0689,  0.0005, -0.0603,  0.0452,\n",
       "          -0.0794, -0.0283,  0.0346,  0.0813, -0.1065,  0.0524, -0.0804, -0.0727,\n",
       "          -0.0580,  0.1266,  0.0795,  0.0979,  0.1010, -0.0167, -0.1186,  0.1234,\n",
       "           0.0111,  0.0502, -0.0995,  0.1038,  0.1193, -0.0617,  0.1562, -0.0488,\n",
       "          -0.1312,  0.0613,  0.1290, -0.0716,  0.0658,  0.1223, -0.0885, -0.0491,\n",
       "          -0.0729, -0.0815]]), 'layers.1.bias': tensor([-0.0750]), 'skip.weight': tensor([[ 0.0147, -0.0132,  0.0157,  0.0150,  0.0156,  0.0167, -0.0168, -0.0149,\n",
       "           0.0108,  0.0146, -0.0167, -0.0118, -0.0178,  0.0134,  0.0157, -0.0140,\n",
       "           0.0138,  0.0139,  0.0177,  0.0171,  0.0105,  0.0140,  0.0184,  0.0142,\n",
       "          -0.0161,  0.0171, -0.0166,  0.0197, -0.0170,  0.0134,  0.0160, -0.0203,\n",
       "           0.0231, -0.0189,  0.0220, -0.0156, -0.0204, -0.0148, -0.0132, -0.0187,\n",
       "          -0.0116, -0.0121,  0.0176, -0.0145,  0.0153,  0.0213, -0.0191, -0.0141,\n",
       "          -0.0211, -0.0124,  0.0163, -0.0122, -0.0160,  0.0116,  0.0150,  0.0153,\n",
       "          -0.0150, -0.0192, -0.0157,  0.0158,  0.0110,  0.0136, -0.0216,  0.0248,\n",
       "           0.0273, -0.0267,  0.0149]])}, objective=3.1502362642395045, loss=0.7347115278244019, val_objective=3.1791786704170253, val_loss=0.7636539340019226, regularization=1.0908408164978027, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.2586569863178267, state_dict={'layers.0.weight': tensor([[-0.0700,  0.0232,  0.0825,  ..., -0.0084,  0.0602,  0.0355],\n",
       "         [-0.1152,  0.0182, -0.0172,  ...,  0.0321, -0.0989, -0.0736],\n",
       "         [-0.0411, -0.0534, -0.0195,  ..., -0.2598, -0.1330, -0.0216],\n",
       "         ...,\n",
       "         [-0.0055, -0.1317, -0.0269,  ..., -0.1642, -0.0595,  0.0396],\n",
       "         [ 0.1237, -0.0221, -0.0927,  ..., -0.0257, -0.0028,  0.1249],\n",
       "         [-0.0380, -0.0223,  0.1326,  ...,  0.0483, -0.0889,  0.1485]]), 'layers.0.bias': tensor([-0.0639,  0.1410,  0.0449,  0.0614,  0.0944,  0.0926,  0.0061, -0.1493,\n",
       "          0.0066, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1495, -0.1191,\n",
       "         -0.0702, -0.1005,  0.1486,  0.0045,  0.0592,  0.1519, -0.0950,  0.0536,\n",
       "         -0.0789,  0.1797, -0.0847, -0.0478, -0.0597,  0.1086, -0.0224,  0.0233,\n",
       "         -0.0314, -0.0455, -0.0299, -0.1466,  0.0038,  0.0621,  0.1030,  0.0582,\n",
       "         -0.0447,  0.0351,  0.1183, -0.0453,  0.1275, -0.0203, -0.0696, -0.0016,\n",
       "          0.0322,  0.1180]), 'layers.1.weight': tensor([[ 0.0446,  0.1081, -0.1272, -0.0922,  0.0518, -0.0949, -0.0516, -0.0292,\n",
       "           0.1349, -0.0315,  0.0455, -0.0700,  0.0688,  0.0008, -0.0604,  0.0453,\n",
       "          -0.0796, -0.0282,  0.0344,  0.0810, -0.1065,  0.0522, -0.0803, -0.0725,\n",
       "          -0.0579,  0.1265,  0.0792,  0.0978,  0.1012, -0.0166, -0.1185,  0.1236,\n",
       "           0.0110,  0.0503, -0.0993,  0.1039,  0.1191, -0.0619,  0.1563, -0.0488,\n",
       "          -0.1311,  0.0612,  0.1291, -0.0717,  0.0658,  0.1220, -0.0886, -0.0493,\n",
       "          -0.0728, -0.0815]]), 'layers.1.bias': tensor([-0.0748]), 'skip.weight': tensor([[ 0.0147, -0.0132,  0.0157,  0.0149,  0.0155,  0.0166, -0.0168, -0.0149,\n",
       "           0.0108,  0.0145, -0.0167, -0.0118, -0.0178,  0.0134,  0.0157, -0.0140,\n",
       "           0.0138,  0.0138,  0.0176,  0.0170,  0.0105,  0.0139,  0.0183,  0.0141,\n",
       "          -0.0161,  0.0170, -0.0165,  0.0196, -0.0170,  0.0134,  0.0160, -0.0202,\n",
       "           0.0230, -0.0188,  0.0219, -0.0156, -0.0203, -0.0148, -0.0131, -0.0186,\n",
       "          -0.0115, -0.0120,  0.0176, -0.0144,  0.0152,  0.0212, -0.0191, -0.0140,\n",
       "          -0.0211, -0.0123,  0.0163, -0.0122, -0.0159,  0.0115,  0.0150,  0.0152,\n",
       "          -0.0149, -0.0191, -0.0157,  0.0157,  0.0110,  0.0136, -0.0215,  0.0246,\n",
       "           0.0272, -0.0266,  0.0148]])}, objective=3.1896116703968724, loss=0.7346547842025757, val_objective=3.2185091346722325, val_loss=0.7635522484779358, regularization=1.0869100093841553, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.303830126044183, state_dict={'layers.0.weight': tensor([[-0.0700,  0.0233,  0.0826,  ..., -0.0083,  0.0602,  0.0355],\n",
       "         [-0.1151,  0.0182, -0.0172,  ...,  0.0321, -0.0990, -0.0735],\n",
       "         [-0.0412, -0.0535, -0.0195,  ..., -0.2599, -0.1330, -0.0216],\n",
       "         ...,\n",
       "         [-0.0056, -0.1314, -0.0270,  ..., -0.1643, -0.0595,  0.0396],\n",
       "         [ 0.1236, -0.0221, -0.0928,  ..., -0.0258, -0.0027,  0.1248],\n",
       "         [-0.0381, -0.0223,  0.1325,  ...,  0.0483, -0.0889,  0.1474]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0449,  0.0613,  0.0944,  0.0925,  0.0061, -0.1493,\n",
       "          0.0066, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1495, -0.1191,\n",
       "         -0.0702, -0.1005,  0.1486,  0.0045,  0.0592,  0.1519, -0.0950,  0.0536,\n",
       "         -0.0789,  0.1797, -0.0848, -0.0479, -0.0597,  0.1086, -0.0224,  0.0233,\n",
       "         -0.0314, -0.0455, -0.0299, -0.1466,  0.0038,  0.0621,  0.1029,  0.0582,\n",
       "         -0.0448,  0.0351,  0.1184, -0.0453,  0.1275, -0.0203, -0.0696, -0.0016,\n",
       "          0.0322,  0.1180]), 'layers.1.weight': tensor([[ 0.0447,  0.1082, -0.1273, -0.0919,  0.0519, -0.0950, -0.0517, -0.0291,\n",
       "           0.1350, -0.0315,  0.0454, -0.0700,  0.0686,  0.0011, -0.0605,  0.0453,\n",
       "          -0.0797, -0.0280,  0.0342,  0.0807, -0.1065,  0.0519, -0.0801, -0.0723,\n",
       "          -0.0579,  0.1264,  0.0789,  0.0978,  0.1014, -0.0166, -0.1184,  0.1237,\n",
       "           0.0109,  0.0503, -0.0992,  0.1041,  0.1189, -0.0621,  0.1564, -0.0487,\n",
       "          -0.1310,  0.0611,  0.1291, -0.0718,  0.0658,  0.1217, -0.0886, -0.0495,\n",
       "          -0.0727, -0.0816]]), 'layers.1.bias': tensor([-0.0746]), 'skip.weight': tensor([[ 0.0146, -0.0131,  0.0157,  0.0149,  0.0155,  0.0165, -0.0167, -0.0148,\n",
       "           0.0107,  0.0145, -0.0167, -0.0118, -0.0177,  0.0133,  0.0156, -0.0139,\n",
       "           0.0138,  0.0138,  0.0175,  0.0169,  0.0104,  0.0139,  0.0183,  0.0141,\n",
       "          -0.0160,  0.0169, -0.0164,  0.0194, -0.0169,  0.0133,  0.0159, -0.0201,\n",
       "           0.0229, -0.0187,  0.0218, -0.0156, -0.0202, -0.0147, -0.0131, -0.0185,\n",
       "          -0.0115, -0.0119,  0.0175, -0.0143,  0.0152,  0.0211, -0.0190, -0.0140,\n",
       "          -0.0210, -0.0123,  0.0162, -0.0122, -0.0159,  0.0115,  0.0150,  0.0151,\n",
       "          -0.0149, -0.0191, -0.0156,  0.0156,  0.0110,  0.0135, -0.0215,  0.0245,\n",
       "           0.0271, -0.0266,  0.0147]])}, objective=3.2296154864953617, loss=0.7346005439758301, val_objective=3.258470750682221, val_loss=0.7634558081626892, regularization=1.0829856395721436, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.3499067285650668, state_dict={'layers.0.weight': tensor([[-0.0699,  0.0233,  0.0826,  ..., -0.0083,  0.0601,  0.0355],\n",
       "         [-0.1150,  0.0183, -0.0171,  ...,  0.0321, -0.0991, -0.0734],\n",
       "         [-0.0412, -0.0535, -0.0195,  ..., -0.2599, -0.1329, -0.0217],\n",
       "         ...,\n",
       "         [-0.0056, -0.1311, -0.0270,  ..., -0.1643, -0.0595,  0.0395],\n",
       "         [ 0.1235, -0.0221, -0.0928,  ..., -0.0258, -0.0027,  0.1248],\n",
       "         [-0.0381, -0.0224,  0.1325,  ...,  0.0483, -0.0888,  0.1463]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0449,  0.0613,  0.0944,  0.0925,  0.0061, -0.1494,\n",
       "          0.0066, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1495, -0.1191,\n",
       "         -0.0703, -0.1005,  0.1486,  0.0044,  0.0592,  0.1518, -0.0951,  0.0536,\n",
       "         -0.0789,  0.1797, -0.0849, -0.0479, -0.0596,  0.1085, -0.0225,  0.0234,\n",
       "         -0.0314, -0.0455, -0.0300, -0.1466,  0.0037,  0.0621,  0.1029,  0.0582,\n",
       "         -0.0449,  0.0351,  0.1184, -0.0453,  0.1275, -0.0204, -0.0696, -0.0016,\n",
       "          0.0322,  0.1180]), 'layers.1.weight': tensor([[ 0.0448,  0.1083, -0.1274, -0.0917,  0.0519, -0.0951, -0.0518, -0.0290,\n",
       "           0.1351, -0.0315,  0.0452, -0.0700,  0.0685,  0.0013, -0.0607,  0.0454,\n",
       "          -0.0799, -0.0278,  0.0340,  0.0804, -0.1065,  0.0517, -0.0799, -0.0721,\n",
       "          -0.0578,  0.1263,  0.0787,  0.0978,  0.1016, -0.0165, -0.1183,  0.1239,\n",
       "           0.0108,  0.0504, -0.0990,  0.1042,  0.1187, -0.0622,  0.1566, -0.0487,\n",
       "          -0.1308,  0.0610,  0.1292, -0.0719,  0.0659,  0.1214, -0.0887, -0.0497,\n",
       "          -0.0726, -0.0817]]), 'layers.1.bias': tensor([-0.0743]), 'skip.weight': tensor([[ 0.0146, -0.0131,  0.0157,  0.0149,  0.0154,  0.0164, -0.0167, -0.0148,\n",
       "           0.0107,  0.0144, -0.0166, -0.0117, -0.0177,  0.0133,  0.0156, -0.0138,\n",
       "           0.0137,  0.0138,  0.0174,  0.0167,  0.0104,  0.0138,  0.0182,  0.0141,\n",
       "          -0.0160,  0.0168, -0.0164,  0.0193, -0.0168,  0.0133,  0.0158, -0.0199,\n",
       "           0.0228, -0.0186,  0.0217, -0.0155, -0.0201, -0.0147, -0.0131, -0.0184,\n",
       "          -0.0115, -0.0118,  0.0175, -0.0143,  0.0152,  0.0210, -0.0190, -0.0140,\n",
       "          -0.0210, -0.0123,  0.0162, -0.0121, -0.0159,  0.0114,  0.0149,  0.0149,\n",
       "          -0.0148, -0.0190, -0.0156,  0.0155,  0.0110,  0.0135, -0.0214,  0.0244,\n",
       "           0.0270, -0.0265,  0.0146]])}, objective=3.270193068935393, loss=0.7345479130744934, val_objective=3.299008219196318, val_loss=0.7633630633354187, regularization=1.079040765762329, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.3969048631363683, state_dict={'layers.0.weight': tensor([[-0.0699,  0.0233,  0.0826,  ..., -0.0083,  0.0601,  0.0355],\n",
       "         [-0.1150,  0.0183, -0.0171,  ...,  0.0322, -0.0991, -0.0733],\n",
       "         [-0.0413, -0.0535, -0.0196,  ..., -0.2600, -0.1329, -0.0217],\n",
       "         ...,\n",
       "         [-0.0056, -0.1308, -0.0270,  ..., -0.1643, -0.0595,  0.0395],\n",
       "         [ 0.1234, -0.0221, -0.0928,  ..., -0.0258, -0.0027,  0.1248],\n",
       "         [-0.0382, -0.0224,  0.1325,  ...,  0.0482, -0.0888,  0.1452]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0448,  0.0613,  0.0944,  0.0925,  0.0060, -0.1494,\n",
       "          0.0065, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1496, -0.1191,\n",
       "         -0.0703, -0.1005,  0.1486,  0.0043,  0.0592,  0.1518, -0.0951,  0.0535,\n",
       "         -0.0789,  0.1797, -0.0849, -0.0479, -0.0596,  0.1085, -0.0225,  0.0234,\n",
       "         -0.0314, -0.0455, -0.0300, -0.1466,  0.0037,  0.0621,  0.1029,  0.0581,\n",
       "         -0.0450,  0.0351,  0.1185, -0.0453,  0.1275, -0.0204, -0.0696, -0.0016,\n",
       "          0.0322,  0.1180]), 'layers.1.weight': tensor([[ 0.0449,  0.1084, -0.1274, -0.0915,  0.0519, -0.0952, -0.0519, -0.0289,\n",
       "           0.1353, -0.0315,  0.0451, -0.0700,  0.0683,  0.0016, -0.0608,  0.0454,\n",
       "          -0.0800, -0.0277,  0.0338,  0.0801, -0.1065,  0.0514, -0.0798, -0.0719,\n",
       "          -0.0578,  0.1262,  0.0784,  0.0978,  0.1017, -0.0165, -0.1182,  0.1240,\n",
       "           0.0107,  0.0504, -0.0988,  0.1044,  0.1185, -0.0624,  0.1567, -0.0486,\n",
       "          -0.1307,  0.0609,  0.1292, -0.0720,  0.0659,  0.1212, -0.0888, -0.0499,\n",
       "          -0.0726, -0.0817]]), 'layers.1.bias': tensor([-0.0741]), 'skip.weight': tensor([[ 0.0145, -0.0131,  0.0156,  0.0148,  0.0154,  0.0163, -0.0166, -0.0147,\n",
       "           0.0107,  0.0144, -0.0166, -0.0117, -0.0176,  0.0133,  0.0156, -0.0138,\n",
       "           0.0137,  0.0137,  0.0173,  0.0166,  0.0104,  0.0138,  0.0182,  0.0140,\n",
       "          -0.0159,  0.0167, -0.0163,  0.0192, -0.0168,  0.0133,  0.0158, -0.0198,\n",
       "           0.0227, -0.0185,  0.0215, -0.0155, -0.0199, -0.0146, -0.0131, -0.0183,\n",
       "          -0.0115, -0.0118,  0.0175, -0.0142,  0.0151,  0.0209, -0.0189, -0.0139,\n",
       "          -0.0209, -0.0122,  0.0162, -0.0121, -0.0158,  0.0114,  0.0149,  0.0148,\n",
       "          -0.0147, -0.0189, -0.0156,  0.0154,  0.0109,  0.0135, -0.0214,  0.0243,\n",
       "           0.0269, -0.0265,  0.0145]])}, objective=3.3114026517939656, loss=0.734495222568512, val_objective=3.3401781053614705, val_loss=0.7632706761360168, regularization=1.075097918510437, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.4448429603990958, state_dict={'layers.0.weight': tensor([[-0.0699,  0.0233,  0.0826,  ..., -0.0083,  0.0601,  0.0356],\n",
       "         [-0.1149,  0.0184, -0.0170,  ...,  0.0322, -0.0992, -0.0732],\n",
       "         [-0.0414, -0.0536, -0.0196,  ..., -0.2601, -0.1328, -0.0218],\n",
       "         ...,\n",
       "         [-0.0057, -0.1305, -0.0270,  ..., -0.1643, -0.0595,  0.0395],\n",
       "         [ 0.1233, -0.0221, -0.0928,  ..., -0.0259, -0.0026,  0.1247],\n",
       "         [-0.0383, -0.0224,  0.1325,  ...,  0.0482, -0.0887,  0.1441]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0448,  0.0612,  0.0944,  0.0924,  0.0060, -0.1494,\n",
       "          0.0065, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1496, -0.1192,\n",
       "         -0.0703, -0.1005,  0.1486,  0.0043,  0.0592,  0.1518, -0.0952,  0.0535,\n",
       "         -0.0789,  0.1797, -0.0850, -0.0480, -0.0595,  0.1085, -0.0226,  0.0234,\n",
       "         -0.0314, -0.0455, -0.0300, -0.1466,  0.0036,  0.0621,  0.1029,  0.0581,\n",
       "         -0.0451,  0.0351,  0.1185, -0.0453,  0.1275, -0.0205, -0.0696, -0.0016,\n",
       "          0.0322,  0.1179]), 'layers.1.weight': tensor([[ 0.0450,  0.1085, -0.1275, -0.0913,  0.0520, -0.0954, -0.0520, -0.0288,\n",
       "           0.1354, -0.0315,  0.0450, -0.0700,  0.0682,  0.0019, -0.0609,  0.0455,\n",
       "          -0.0801, -0.0275,  0.0336,  0.0798, -0.1065,  0.0512, -0.0796, -0.0717,\n",
       "          -0.0577,  0.1261,  0.0781,  0.0978,  0.1019, -0.0164, -0.1181,  0.1241,\n",
       "           0.0107,  0.0505, -0.0987,  0.1045,  0.1183, -0.0626,  0.1568, -0.0486,\n",
       "          -0.1306,  0.0609,  0.1293, -0.0721,  0.0659,  0.1209, -0.0888, -0.0502,\n",
       "          -0.0725, -0.0818]]), 'layers.1.bias': tensor([-0.0739]), 'skip.weight': tensor([[ 0.0145, -0.0131,  0.0156,  0.0148,  0.0153,  0.0162, -0.0165, -0.0147,\n",
       "           0.0106,  0.0143, -0.0165, -0.0117, -0.0175,  0.0132,  0.0155, -0.0137,\n",
       "           0.0137,  0.0137,  0.0172,  0.0165,  0.0103,  0.0138,  0.0181,  0.0140,\n",
       "          -0.0158,  0.0166, -0.0163,  0.0191, -0.0167,  0.0133,  0.0157, -0.0197,\n",
       "           0.0226, -0.0184,  0.0214, -0.0155, -0.0198, -0.0145, -0.0130, -0.0182,\n",
       "          -0.0114, -0.0117,  0.0174, -0.0142,  0.0151,  0.0208, -0.0189, -0.0139,\n",
       "          -0.0208, -0.0122,  0.0162, -0.0121, -0.0158,  0.0114,  0.0149,  0.0147,\n",
       "          -0.0147, -0.0189, -0.0155,  0.0153,  0.0109,  0.0134, -0.0213,  0.0242,\n",
       "           0.0268, -0.0265,  0.0144]])}, objective=3.3531225085350966, loss=0.7344453930854797, val_objective=3.381859040269563, val_loss=0.7631819248199463, regularization=1.0711023807525635, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.493739819607078, state_dict={'layers.0.weight': tensor([[-0.0698,  0.0233,  0.0826,  ..., -0.0083,  0.0600,  0.0356],\n",
       "         [-0.1148,  0.0184, -0.0170,  ...,  0.0323, -0.0992, -0.0731],\n",
       "         [-0.0414, -0.0536, -0.0197,  ..., -0.2601, -0.1328, -0.0219],\n",
       "         ...,\n",
       "         [-0.0057, -0.1302, -0.0270,  ..., -0.1643, -0.0594,  0.0395],\n",
       "         [ 0.1232, -0.0221, -0.0929,  ..., -0.0259, -0.0026,  0.1247],\n",
       "         [-0.0384, -0.0225,  0.1325,  ...,  0.0481, -0.0887,  0.1430]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0447,  0.0612,  0.0944,  0.0924,  0.0060, -0.1494,\n",
       "          0.0065, -0.0822,  0.0696,  0.0936,  0.1274,  0.0369, -0.1496, -0.1192,\n",
       "         -0.0703, -0.1005,  0.1486,  0.0042,  0.0592,  0.1518, -0.0952,  0.0535,\n",
       "         -0.0789,  0.1797, -0.0851, -0.0480, -0.0594,  0.1085, -0.0226,  0.0235,\n",
       "         -0.0314, -0.0455, -0.0300, -0.1466,  0.0035,  0.0621,  0.1029,  0.0581,\n",
       "         -0.0452,  0.0351,  0.1186, -0.0454,  0.1275, -0.0205, -0.0696, -0.0016,\n",
       "          0.0322,  0.1179]), 'layers.1.weight': tensor([[ 0.0451,  0.1086, -0.1276, -0.0911,  0.0520, -0.0955, -0.0521, -0.0287,\n",
       "           0.1355, -0.0315,  0.0448, -0.0700,  0.0681,  0.0021, -0.0611,  0.0456,\n",
       "          -0.0803, -0.0273,  0.0334,  0.0795, -0.1066,  0.0510, -0.0794, -0.0716,\n",
       "          -0.0577,  0.1261,  0.0779,  0.0978,  0.1021, -0.0164, -0.1180,  0.1243,\n",
       "           0.0106,  0.0505, -0.0985,  0.1046,  0.1181, -0.0628,  0.1570, -0.0486,\n",
       "          -0.1305,  0.0608,  0.1293, -0.0721,  0.0660,  0.1206, -0.0889, -0.0504,\n",
       "          -0.0724, -0.0819]]), 'layers.1.bias': tensor([-0.0736]), 'skip.weight': tensor([[ 0.0144, -0.0130,  0.0156,  0.0147,  0.0153,  0.0160, -0.0165, -0.0146,\n",
       "           0.0106,  0.0143, -0.0165, -0.0117, -0.0175,  0.0132,  0.0155, -0.0136,\n",
       "           0.0137,  0.0136,  0.0171,  0.0164,  0.0103,  0.0137,  0.0180,  0.0139,\n",
       "          -0.0158,  0.0164, -0.0162,  0.0189, -0.0167,  0.0133,  0.0157, -0.0196,\n",
       "           0.0225, -0.0183,  0.0213, -0.0155, -0.0197, -0.0145, -0.0130, -0.0181,\n",
       "          -0.0114, -0.0117,  0.0174, -0.0142,  0.0151,  0.0206, -0.0188, -0.0139,\n",
       "          -0.0208, -0.0122,  0.0161, -0.0121, -0.0158,  0.0113,  0.0148,  0.0146,\n",
       "          -0.0146, -0.0188, -0.0155,  0.0151,  0.0109,  0.0134, -0.0213,  0.0241,\n",
       "           0.0266, -0.0265,  0.0143]])}, objective=3.3953800117502806, loss=0.7343972325325012, val_objective=3.424079111767828, val_loss=0.7630963325500488, regularization=1.0670651197433472, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.5436146159992195, state_dict={'layers.0.weight': tensor([[-0.0698,  0.0233,  0.0826,  ..., -0.0082,  0.0600,  0.0356],\n",
       "         [-0.1148,  0.0185, -0.0170,  ...,  0.0323, -0.0993, -0.0730],\n",
       "         [-0.0415, -0.0536, -0.0197,  ..., -0.2602, -0.1327, -0.0219],\n",
       "         ...,\n",
       "         [-0.0057, -0.1299, -0.0270,  ..., -0.1644, -0.0594,  0.0394],\n",
       "         [ 0.1232, -0.0222, -0.0929,  ..., -0.0259, -0.0026,  0.1246],\n",
       "         [-0.0385, -0.0225,  0.1324,  ...,  0.0481, -0.0886,  0.1418]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0447,  0.0612,  0.0944,  0.0924,  0.0060, -0.1494,\n",
       "          0.0065, -0.0822,  0.0696,  0.0937,  0.1274,  0.0369, -0.1496, -0.1192,\n",
       "         -0.0704, -0.1006,  0.1486,  0.0041,  0.0592,  0.1518, -0.0953,  0.0534,\n",
       "         -0.0789,  0.1797, -0.0852, -0.0480, -0.0594,  0.1085, -0.0227,  0.0235,\n",
       "         -0.0314, -0.0455, -0.0300, -0.1467,  0.0035,  0.0621,  0.1028,  0.0581,\n",
       "         -0.0453,  0.0351,  0.1186, -0.0454,  0.1274, -0.0206, -0.0696, -0.0016,\n",
       "          0.0322,  0.1179]), 'layers.1.weight': tensor([[ 0.0452,  0.1087, -0.1277, -0.0909,  0.0521, -0.0956, -0.0523, -0.0287,\n",
       "           0.1357, -0.0316,  0.0447, -0.0700,  0.0680,  0.0024, -0.0612,  0.0456,\n",
       "          -0.0804, -0.0272,  0.0332,  0.0792, -0.1066,  0.0508, -0.0793, -0.0714,\n",
       "          -0.0577,  0.1260,  0.0776,  0.0977,  0.1023, -0.0164, -0.1179,  0.1244,\n",
       "           0.0105,  0.0506, -0.0984,  0.1048,  0.1179, -0.0630,  0.1571, -0.0485,\n",
       "          -0.1304,  0.0607,  0.1294, -0.0722,  0.0660,  0.1204, -0.0889, -0.0506,\n",
       "          -0.0724, -0.0820]]), 'layers.1.bias': tensor([-0.0734]), 'skip.weight': tensor([[ 0.0144, -0.0130,  0.0156,  0.0147,  0.0152,  0.0159, -0.0164, -0.0145,\n",
       "           0.0106,  0.0143, -0.0165, -0.0116, -0.0174,  0.0132,  0.0154, -0.0136,\n",
       "           0.0136,  0.0136,  0.0170,  0.0163,  0.0102,  0.0137,  0.0180,  0.0139,\n",
       "          -0.0157,  0.0163, -0.0161,  0.0188, -0.0166,  0.0132,  0.0157, -0.0195,\n",
       "           0.0224, -0.0181,  0.0212, -0.0155, -0.0196, -0.0144, -0.0130, -0.0179,\n",
       "          -0.0114, -0.0116,  0.0173, -0.0141,  0.0150,  0.0205, -0.0187, -0.0138,\n",
       "          -0.0207, -0.0122,  0.0161, -0.0120, -0.0157,  0.0113,  0.0148,  0.0144,\n",
       "          -0.0146, -0.0188, -0.0155,  0.0150,  0.0108,  0.0134, -0.0213,  0.0239,\n",
       "           0.0265, -0.0264,  0.0142]])}, objective=3.4381528126767473, loss=0.7343515157699585, val_objective=3.4668156730702715, val_loss=0.7630143761634827, regularization=1.0629760026931763, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.5944869083192037, state_dict={'layers.0.weight': tensor([[-0.0697,  0.0233,  0.0826,  ..., -0.0082,  0.0600,  0.0356],\n",
       "         [-0.1147,  0.0185, -0.0169,  ...,  0.0323, -0.0994, -0.0729],\n",
       "         [-0.0416, -0.0537, -0.0197,  ..., -0.2603, -0.1327, -0.0220],\n",
       "         ...,\n",
       "         [-0.0057, -0.1296, -0.0270,  ..., -0.1644, -0.0594,  0.0394],\n",
       "         [ 0.1231, -0.0222, -0.0929,  ..., -0.0260, -0.0026,  0.1246],\n",
       "         [-0.0385, -0.0225,  0.1324,  ...,  0.0481, -0.0885,  0.1406]]), 'layers.0.bias': tensor([-0.0639,  0.1409,  0.0447,  0.0612,  0.0944,  0.0923,  0.0060, -0.1495,\n",
       "          0.0064, -0.0822,  0.0696,  0.0937,  0.1274,  0.0369, -0.1496, -0.1192,\n",
       "         -0.0704, -0.1006,  0.1486,  0.0041,  0.0591,  0.1518, -0.0953,  0.0534,\n",
       "         -0.0790,  0.1797, -0.0853, -0.0481, -0.0593,  0.1085, -0.0227,  0.0235,\n",
       "         -0.0314, -0.0454, -0.0300, -0.1467,  0.0034,  0.0621,  0.1028,  0.0580,\n",
       "         -0.0454,  0.0351,  0.1186, -0.0454,  0.1274, -0.0206, -0.0696, -0.0016,\n",
       "          0.0322,  0.1179]), 'layers.1.weight': tensor([[ 0.0454,  0.1088, -0.1277, -0.0907,  0.0521, -0.0957, -0.0524, -0.0286,\n",
       "           0.1358, -0.0316,  0.0446, -0.0700,  0.0678,  0.0026, -0.0614,  0.0457,\n",
       "          -0.0806, -0.0270,  0.0331,  0.0790, -0.1066,  0.0506, -0.0791, -0.0713,\n",
       "          -0.0576,  0.1259,  0.0774,  0.0977,  0.1024, -0.0163, -0.1178,  0.1245,\n",
       "           0.0105,  0.0506, -0.0983,  0.1049,  0.1177, -0.0632,  0.1572, -0.0485,\n",
       "          -0.1304,  0.0606,  0.1294, -0.0723,  0.0660,  0.1201, -0.0890, -0.0508,\n",
       "          -0.0723, -0.0821]]), 'layers.1.bias': tensor([-0.0732]), 'skip.weight': tensor([[ 0.0143, -0.0130,  0.0155,  0.0147,  0.0152,  0.0158, -0.0164, -0.0145,\n",
       "           0.0105,  0.0142, -0.0164, -0.0116, -0.0174,  0.0132,  0.0154, -0.0135,\n",
       "           0.0136,  0.0136,  0.0169,  0.0162,  0.0102,  0.0137,  0.0179,  0.0139,\n",
       "          -0.0157,  0.0162, -0.0161,  0.0187, -0.0165,  0.0132,  0.0156, -0.0194,\n",
       "           0.0223, -0.0180,  0.0211, -0.0154, -0.0195, -0.0144, -0.0130, -0.0178,\n",
       "          -0.0114, -0.0116,  0.0173, -0.0141,  0.0150,  0.0204, -0.0187, -0.0138,\n",
       "          -0.0207, -0.0121,  0.0161, -0.0120, -0.0157,  0.0112,  0.0148,  0.0143,\n",
       "          -0.0145, -0.0187, -0.0154,  0.0149,  0.0108,  0.0133, -0.0212,  0.0238,\n",
       "           0.0264, -0.0264,  0.0141]])}, objective=3.481406475985858, loss=0.7343084216117859, val_objective=3.5100334543832274, val_loss=0.7629354000091553, regularization=1.0588213205337524, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.646376646485588, state_dict={'layers.0.weight': tensor([[-0.0697,  0.0233,  0.0826,  ..., -0.0082,  0.0600,  0.0357],\n",
       "         [-0.1147,  0.0186, -0.0169,  ...,  0.0324, -0.0994, -0.0729],\n",
       "         [-0.0416, -0.0537, -0.0198,  ..., -0.2603, -0.1326, -0.0220],\n",
       "         ...,\n",
       "         [-0.0058, -0.1292, -0.0270,  ..., -0.1644, -0.0594,  0.0394],\n",
       "         [ 0.1230, -0.0222, -0.0930,  ..., -0.0260, -0.0025,  0.1246],\n",
       "         [-0.0386, -0.0226,  0.1324,  ...,  0.0480, -0.0885,  0.1394]]), 'layers.0.bias': tensor([-0.0639,  0.1408,  0.0446,  0.0611,  0.0944,  0.0923,  0.0060, -0.1495,\n",
       "          0.0064, -0.0822,  0.0696,  0.0937,  0.1274,  0.0369, -0.1497, -0.1192,\n",
       "         -0.0704, -0.1006,  0.1485,  0.0040,  0.0591,  0.1517, -0.0954,  0.0534,\n",
       "         -0.0790,  0.1796, -0.0854, -0.0481, -0.0592,  0.1085, -0.0228,  0.0236,\n",
       "         -0.0314, -0.0454, -0.0300, -0.1467,  0.0034,  0.0621,  0.1028,  0.0580,\n",
       "         -0.0455,  0.0351,  0.1187, -0.0454,  0.1274, -0.0206, -0.0697, -0.0016,\n",
       "          0.0322,  0.1178]), 'layers.1.weight': tensor([[ 0.0455,  0.1089, -0.1278, -0.0905,  0.0522, -0.0959, -0.0525, -0.0285,\n",
       "           0.1359, -0.0316,  0.0445, -0.0700,  0.0677,  0.0029, -0.0615,  0.0458,\n",
       "          -0.0807, -0.0269,  0.0329,  0.0787, -0.1066,  0.0504, -0.0790, -0.0711,\n",
       "          -0.0576,  0.1258,  0.0771,  0.0977,  0.1026, -0.0163, -0.1177,  0.1246,\n",
       "           0.0104,  0.0507, -0.0981,  0.1051,  0.1175, -0.0634,  0.1573, -0.0484,\n",
       "          -0.1303,  0.0605,  0.1295, -0.0724,  0.0661,  0.1199, -0.0891, -0.0510,\n",
       "          -0.0723, -0.0822]]), 'layers.1.bias': tensor([-0.0730]), 'skip.weight': tensor([[ 0.0143, -0.0129,  0.0155,  0.0146,  0.0151,  0.0157, -0.0163, -0.0145,\n",
       "           0.0105,  0.0142, -0.0164, -0.0116, -0.0173,  0.0131,  0.0153, -0.0135,\n",
       "           0.0136,  0.0135,  0.0168,  0.0160,  0.0101,  0.0136,  0.0178,  0.0138,\n",
       "          -0.0156,  0.0161, -0.0160,  0.0185, -0.0165,  0.0132,  0.0156, -0.0193,\n",
       "           0.0221, -0.0179,  0.0209, -0.0154, -0.0194, -0.0143, -0.0129, -0.0177,\n",
       "          -0.0113, -0.0115,  0.0173, -0.0141,  0.0150,  0.0203, -0.0186, -0.0138,\n",
       "          -0.0206, -0.0121,  0.0160, -0.0120, -0.0156,  0.0112,  0.0148,  0.0142,\n",
       "          -0.0144, -0.0186, -0.0154,  0.0148,  0.0108,  0.0133, -0.0212,  0.0237,\n",
       "           0.0263, -0.0264,  0.0139]])}, objective=3.525219535502623, loss=0.734268069267273, val_objective=3.553808188113402, val_loss=0.7628567218780518, regularization=1.054631233215332, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.6993041794152997, state_dict={'layers.0.weight': tensor([[-0.0697,  0.0234,  0.0826,  ..., -0.0082,  0.0599,  0.0357],\n",
       "         [-0.1146,  0.0186, -0.0169,  ...,  0.0324, -0.0995, -0.0728],\n",
       "         [-0.0417, -0.0537, -0.0198,  ..., -0.2604, -0.1326, -0.0221],\n",
       "         ...,\n",
       "         [-0.0058, -0.1289, -0.0270,  ..., -0.1644, -0.0593,  0.0394],\n",
       "         [ 0.1229, -0.0222, -0.0930,  ..., -0.0260, -0.0025,  0.1245],\n",
       "         [-0.0387, -0.0226,  0.1324,  ...,  0.0480, -0.0884,  0.1381]]), 'layers.0.bias': tensor([-0.0638,  0.1408,  0.0446,  0.0611,  0.0943,  0.0922,  0.0060, -0.1495,\n",
       "          0.0064, -0.0822,  0.0696,  0.0937,  0.1274,  0.0369, -0.1497, -0.1192,\n",
       "         -0.0704, -0.1006,  0.1485,  0.0040,  0.0591,  0.1517, -0.0954,  0.0533,\n",
       "         -0.0790,  0.1796, -0.0854, -0.0481, -0.0592,  0.1084, -0.0228,  0.0236,\n",
       "         -0.0314, -0.0454, -0.0301, -0.1467,  0.0033,  0.0621,  0.1028,  0.0580,\n",
       "         -0.0456,  0.0351,  0.1187, -0.0454,  0.1274, -0.0207, -0.0697, -0.0016,\n",
       "          0.0322,  0.1178]), 'layers.1.weight': tensor([[ 0.0456,  0.1090, -0.1279, -0.0903,  0.0523, -0.0960, -0.0526, -0.0284,\n",
       "           0.1361, -0.0316,  0.0444, -0.0700,  0.0676,  0.0031, -0.0617,  0.0458,\n",
       "          -0.0809, -0.0267,  0.0327,  0.0784, -0.1066,  0.0502, -0.0789, -0.0710,\n",
       "          -0.0576,  0.1257,  0.0769,  0.0977,  0.1028, -0.0163, -0.1176,  0.1248,\n",
       "           0.0104,  0.0507, -0.0980,  0.1052,  0.1174, -0.0636,  0.1575, -0.0484,\n",
       "          -0.1302,  0.0605,  0.1296, -0.0725,  0.0661,  0.1196, -0.0891, -0.0513,\n",
       "          -0.0722, -0.0823]]), 'layers.1.bias': tensor([-0.0728]), 'skip.weight': tensor([[ 0.0143, -0.0129,  0.0155,  0.0146,  0.0150,  0.0155, -0.0162, -0.0144,\n",
       "           0.0105,  0.0141, -0.0163, -0.0116, -0.0172,  0.0131,  0.0153, -0.0134,\n",
       "           0.0135,  0.0135,  0.0166,  0.0159,  0.0101,  0.0136,  0.0178,  0.0138,\n",
       "          -0.0155,  0.0159, -0.0160,  0.0184, -0.0164,  0.0132,  0.0155, -0.0191,\n",
       "           0.0220, -0.0177,  0.0208, -0.0154, -0.0192, -0.0142, -0.0129, -0.0176,\n",
       "          -0.0113, -0.0115,  0.0172, -0.0140,  0.0149,  0.0202, -0.0185, -0.0137,\n",
       "          -0.0206, -0.0121,  0.0160, -0.0120, -0.0156,  0.0112,  0.0147,  0.0142,\n",
       "          -0.0144, -0.0186, -0.0154,  0.0147,  0.0107,  0.0133, -0.0211,  0.0235,\n",
       "           0.0262, -0.0264,  0.0138]])}, objective=3.5697269358621915, loss=0.7342303991317749, val_objective=3.598274222849496, val_loss=0.7627776861190796, regularization=1.0504546165466309, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.753290263003606, state_dict={'layers.0.weight': tensor([[-0.0696,  0.0234,  0.0827,  ..., -0.0082,  0.0599,  0.0357],\n",
       "         [-0.1145,  0.0187, -0.0168,  ...,  0.0324, -0.0996, -0.0727],\n",
       "         [-0.0418, -0.0538, -0.0199,  ..., -0.2604, -0.1325, -0.0221],\n",
       "         ...,\n",
       "         [-0.0058, -0.1286, -0.0270,  ..., -0.1644, -0.0593,  0.0393],\n",
       "         [ 0.1228, -0.0222, -0.0930,  ..., -0.0261, -0.0025,  0.1245],\n",
       "         [-0.0388, -0.0226,  0.1323,  ...,  0.0480, -0.0884,  0.1369]]), 'layers.0.bias': tensor([-0.0638,  0.1408,  0.0445,  0.0611,  0.0943,  0.0922,  0.0059, -0.1495,\n",
       "          0.0064, -0.0823,  0.0696,  0.0937,  0.1274,  0.0369, -0.1497, -0.1192,\n",
       "         -0.0705, -0.1006,  0.1485,  0.0039,  0.0591,  0.1517, -0.0954,  0.0533,\n",
       "         -0.0790,  0.1796, -0.0855, -0.0482, -0.0591,  0.1084, -0.0228,  0.0236,\n",
       "         -0.0314, -0.0454, -0.0301, -0.1467,  0.0033,  0.0621,  0.1028,  0.0579,\n",
       "         -0.0457,  0.0352,  0.1188, -0.0454,  0.1274, -0.0207, -0.0697, -0.0016,\n",
       "          0.0322,  0.1178]), 'layers.1.weight': tensor([[ 0.0457,  0.1091, -0.1280, -0.0901,  0.0523, -0.0961, -0.0528, -0.0284,\n",
       "           0.1362, -0.0316,  0.0443, -0.0700,  0.0675,  0.0034, -0.0618,  0.0459,\n",
       "          -0.0811, -0.0266,  0.0325,  0.0782, -0.1066,  0.0500, -0.0787, -0.0708,\n",
       "          -0.0575,  0.1257,  0.0767,  0.0977,  0.1029, -0.0163, -0.1176,  0.1249,\n",
       "           0.0103,  0.0508, -0.0978,  0.1053,  0.1172, -0.0638,  0.1576, -0.0484,\n",
       "          -0.1301,  0.0604,  0.1296, -0.0726,  0.0662,  0.1194, -0.0892, -0.0515,\n",
       "          -0.0722, -0.0824]]), 'layers.1.bias': tensor([-0.0726]), 'skip.weight': tensor([[ 0.0142, -0.0129,  0.0154,  0.0145,  0.0150,  0.0154, -0.0162, -0.0144,\n",
       "           0.0104,  0.0141, -0.0163, -0.0115, -0.0172,  0.0131,  0.0153, -0.0133,\n",
       "           0.0135,  0.0135,  0.0165,  0.0158,  0.0101,  0.0136,  0.0177,  0.0138,\n",
       "          -0.0155,  0.0158, -0.0159,  0.0183, -0.0163,  0.0131,  0.0155, -0.0190,\n",
       "           0.0219, -0.0176,  0.0207, -0.0154, -0.0191, -0.0142, -0.0129, -0.0174,\n",
       "          -0.0113, -0.0115,  0.0172, -0.0140,  0.0149,  0.0200, -0.0185, -0.0137,\n",
       "          -0.0205, -0.0120,  0.0160, -0.0119, -0.0155,  0.0111,  0.0147,  0.0141,\n",
       "          -0.0143, -0.0185, -0.0154,  0.0145,  0.0107,  0.0133, -0.0211,  0.0234,\n",
       "           0.0260, -0.0263,  0.0137]])}, objective=3.614731320777864, loss=0.7341946363449097, val_objective=3.6432388514671037, val_loss=0.7627021670341492, regularization=1.0462161302566528, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.808356068263678, state_dict={'layers.0.weight': tensor([[-0.0696,  0.0234,  0.0827,  ..., -0.0081,  0.0599,  0.0357],\n",
       "         [-0.1145,  0.0187, -0.0168,  ...,  0.0325, -0.0996, -0.0726],\n",
       "         [-0.0418, -0.0538, -0.0199,  ..., -0.2598, -0.1325, -0.0222],\n",
       "         ...,\n",
       "         [-0.0059, -0.1283, -0.0270,  ..., -0.1645, -0.0593,  0.0393],\n",
       "         [ 0.1228, -0.0222, -0.0931,  ..., -0.0261, -0.0024,  0.1244],\n",
       "         [-0.0389, -0.0227,  0.1323,  ...,  0.0479, -0.0883,  0.1356]]), 'layers.0.bias': tensor([-0.0638,  0.1408,  0.0445,  0.0611,  0.0943,  0.0922,  0.0059, -0.1495,\n",
       "          0.0063, -0.0823,  0.0696,  0.0938,  0.1274,  0.0369, -0.1497, -0.1192,\n",
       "         -0.0705, -0.1006,  0.1485,  0.0038,  0.0591,  0.1517, -0.0955,  0.0533,\n",
       "         -0.0790,  0.1796, -0.0856, -0.0482, -0.0591,  0.1084, -0.0229,  0.0237,\n",
       "         -0.0314, -0.0454, -0.0301, -0.1468,  0.0032,  0.0621,  0.1028,  0.0579,\n",
       "         -0.0458,  0.0352,  0.1188, -0.0454,  0.1274, -0.0208, -0.0697, -0.0016,\n",
       "          0.0322,  0.1178]), 'layers.1.weight': tensor([[ 0.0458,  0.1092, -0.1280, -0.0899,  0.0524, -0.0962, -0.0529, -0.0283,\n",
       "           0.1363, -0.0316,  0.0442, -0.0700,  0.0674,  0.0036, -0.0620,  0.0460,\n",
       "          -0.0812, -0.0264,  0.0323,  0.0779, -0.1067,  0.0498, -0.0786, -0.0707,\n",
       "          -0.0575,  0.1256,  0.0764,  0.0977,  0.1031, -0.0163, -0.1175,  0.1250,\n",
       "           0.0103,  0.0509, -0.0977,  0.1055,  0.1170, -0.0640,  0.1577, -0.0483,\n",
       "          -0.1300,  0.0603,  0.1297, -0.0727,  0.0662,  0.1191, -0.0892, -0.0517,\n",
       "          -0.0722, -0.0825]]), 'layers.1.bias': tensor([-0.0724]), 'skip.weight': tensor([[ 0.0142, -0.0128,  0.0154,  0.0145,  0.0149,  0.0153, -0.0161, -0.0143,\n",
       "           0.0104,  0.0140, -0.0162, -0.0115, -0.0171,  0.0130,  0.0152, -0.0133,\n",
       "           0.0135,  0.0134,  0.0164,  0.0156,  0.0100,  0.0135,  0.0177,  0.0137,\n",
       "          -0.0154,  0.0157, -0.0158,  0.0181, -0.0163,  0.0131,  0.0155, -0.0189,\n",
       "           0.0218, -0.0175,  0.0205, -0.0153, -0.0190, -0.0141, -0.0129, -0.0173,\n",
       "          -0.0112, -0.0114,  0.0171, -0.0140,  0.0149,  0.0199, -0.0184, -0.0137,\n",
       "          -0.0204, -0.0120,  0.0159, -0.0119, -0.0155,  0.0111,  0.0147,  0.0141,\n",
       "          -0.0143, -0.0184, -0.0153,  0.0144,  0.0107,  0.0132, -0.0210,  0.0233,\n",
       "           0.0260, -0.0263,  0.0136]])}, objective=3.660440291668697, loss=0.7341609001159668, val_objective=3.6889093177574117, val_loss=0.7626299262046814, regularization=1.0419901609420776, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.864523189628952, state_dict={'layers.0.weight': tensor([[-0.0695,  0.0234,  0.0827,  ..., -0.0081,  0.0599,  0.0357],\n",
       "         [-0.1144,  0.0188, -0.0168,  ...,  0.0325, -0.0997, -0.0725],\n",
       "         [-0.0419, -0.0538, -0.0200,  ..., -0.2591, -0.1324, -0.0222],\n",
       "         ...,\n",
       "         [-0.0059, -0.1280, -0.0270,  ..., -0.1645, -0.0593,  0.0393],\n",
       "         [ 0.1227, -0.0222, -0.0931,  ..., -0.0261, -0.0024,  0.1244],\n",
       "         [-0.0389, -0.0227,  0.1323,  ...,  0.0479, -0.0883,  0.1342]]), 'layers.0.bias': tensor([-0.0638,  0.1408,  0.0445,  0.0610,  0.0943,  0.0921,  0.0059, -0.1496,\n",
       "          0.0063, -0.0823,  0.0696,  0.0938,  0.1274,  0.0369, -0.1497, -0.1193,\n",
       "         -0.0705, -0.1006,  0.1485,  0.0038,  0.0591,  0.1517, -0.0955,  0.0532,\n",
       "         -0.0790,  0.1796, -0.0857, -0.0482, -0.0590,  0.1084, -0.0229,  0.0237,\n",
       "         -0.0315, -0.0454, -0.0301, -0.1468,  0.0032,  0.0621,  0.1027,  0.0579,\n",
       "         -0.0459,  0.0352,  0.1189, -0.0454,  0.1273, -0.0208, -0.0697, -0.0016,\n",
       "          0.0322,  0.1178]), 'layers.1.weight': tensor([[ 0.0459,  0.1093, -0.1281, -0.0898,  0.0524, -0.0964, -0.0530, -0.0283,\n",
       "           0.1365, -0.0316,  0.0441, -0.0701,  0.0672,  0.0038, -0.0621,  0.0460,\n",
       "          -0.0814, -0.0263,  0.0322,  0.0777, -0.1067,  0.0497, -0.0785, -0.0706,\n",
       "          -0.0575,  0.1255,  0.0762,  0.0977,  0.1032, -0.0163, -0.1174,  0.1251,\n",
       "           0.0102,  0.0509, -0.0976,  0.1056,  0.1169, -0.0642,  0.1579, -0.0483,\n",
       "          -0.1300,  0.0602,  0.1297, -0.0728,  0.0663,  0.1189, -0.0893, -0.0519,\n",
       "          -0.0721, -0.0826]]), 'layers.1.bias': tensor([-0.0722]), 'skip.weight': tensor([[ 0.0141, -0.0128,  0.0154,  0.0145,  0.0148,  0.0151, -0.0160, -0.0143,\n",
       "           0.0104,  0.0140, -0.0162, -0.0115, -0.0170,  0.0130,  0.0152, -0.0132,\n",
       "           0.0134,  0.0134,  0.0163,  0.0155,  0.0100,  0.0135,  0.0177,  0.0137,\n",
       "          -0.0153,  0.0155, -0.0157,  0.0180, -0.0162,  0.0131,  0.0154, -0.0187,\n",
       "           0.0216, -0.0174,  0.0204, -0.0153, -0.0188, -0.0140, -0.0128, -0.0172,\n",
       "          -0.0112, -0.0114,  0.0171, -0.0139,  0.0149,  0.0198, -0.0183, -0.0136,\n",
       "          -0.0204, -0.0120,  0.0159, -0.0119, -0.0155,  0.0111,  0.0146,  0.0141,\n",
       "          -0.0142, -0.0183, -0.0153,  0.0143,  0.0106,  0.0132, -0.0210,  0.0231,\n",
       "           0.0259, -0.0263,  0.0134]])}, objective=3.706941926085333, loss=0.734127938747406, val_objective=3.7353733416431942, val_loss=0.7625593543052673, regularization=1.037804126739502, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.921813653421531, state_dict={'layers.0.weight': tensor([[-0.0695,  0.0234,  0.0827,  ..., -0.0081,  0.0598,  0.0358],\n",
       "         [-0.1143,  0.0188, -0.0167,  ...,  0.0325, -0.0998, -0.0725],\n",
       "         [-0.0419, -0.0539, -0.0200,  ..., -0.2585, -0.1324, -0.0223],\n",
       "         ...,\n",
       "         [-0.0059, -0.1277, -0.0270,  ..., -0.1645, -0.0593,  0.0393],\n",
       "         [ 0.1226, -0.0223, -0.0931,  ..., -0.0262, -0.0024,  0.1244],\n",
       "         [-0.0390, -0.0228,  0.1323,  ...,  0.0479, -0.0882,  0.1329]]), 'layers.0.bias': tensor([-0.0638,  0.1408,  0.0444,  0.0610,  0.0943,  0.0921,  0.0059, -0.1496,\n",
       "          0.0063, -0.0823,  0.0696,  0.0938,  0.1274,  0.0369, -0.1497, -0.1193,\n",
       "         -0.0705, -0.1006,  0.1485,  0.0037,  0.0591,  0.1517, -0.0956,  0.0532,\n",
       "         -0.0790,  0.1796, -0.0857, -0.0483, -0.0590,  0.1084, -0.0230,  0.0237,\n",
       "         -0.0315, -0.0454, -0.0301, -0.1468,  0.0031,  0.0621,  0.1027,  0.0579,\n",
       "         -0.0459,  0.0352,  0.1189, -0.0454,  0.1273, -0.0209, -0.0697, -0.0015,\n",
       "          0.0322,  0.1177]), 'layers.1.weight': tensor([[ 0.0460,  0.1094, -0.1282, -0.0896,  0.0525, -0.0965, -0.0532, -0.0282,\n",
       "           0.1366, -0.0316,  0.0439, -0.0701,  0.0671,  0.0040, -0.0623,  0.0461,\n",
       "          -0.0815, -0.0261,  0.0320,  0.0774, -0.1067,  0.0495, -0.0783, -0.0704,\n",
       "          -0.0574,  0.1254,  0.0760,  0.0977,  0.1034, -0.0163, -0.1174,  0.1252,\n",
       "           0.0102,  0.0510, -0.0975,  0.1058,  0.1167, -0.0643,  0.1580, -0.0482,\n",
       "          -0.1299,  0.0601,  0.1298, -0.0728,  0.0663,  0.1187, -0.0893, -0.0521,\n",
       "          -0.0721, -0.0827]]), 'layers.1.bias': tensor([-0.0720]), 'skip.weight': tensor([[ 0.0141, -0.0128,  0.0153,  0.0144,  0.0148,  0.0150, -0.0160, -0.0142,\n",
       "           0.0103,  0.0139, -0.0162, -0.0115, -0.0170,  0.0129,  0.0151, -0.0132,\n",
       "           0.0134,  0.0134,  0.0161,  0.0155,  0.0100,  0.0135,  0.0176,  0.0137,\n",
       "          -0.0153,  0.0154, -0.0157,  0.0178, -0.0161,  0.0131,  0.0154, -0.0186,\n",
       "           0.0215, -0.0173,  0.0202, -0.0153, -0.0187, -0.0140, -0.0128, -0.0170,\n",
       "          -0.0112, -0.0113,  0.0170, -0.0139,  0.0149,  0.0196, -0.0182, -0.0136,\n",
       "          -0.0203, -0.0119,  0.0158, -0.0118, -0.0154,  0.0110,  0.0146,  0.0140,\n",
       "          -0.0141, -0.0183, -0.0152,  0.0143,  0.0106,  0.0131, -0.0209,  0.0230,\n",
       "           0.0258, -0.0262,  0.0133]])}, objective=3.7543282199819665, loss=0.7340954542160034, val_objective=3.7827255416830163, val_loss=0.7624927759170532, regularization=1.033684253692627, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=2.9802499264899613, state_dict={'layers.0.weight': tensor([[-0.0695,  0.0234,  0.0827,  ..., -0.0081,  0.0598,  0.0358],\n",
       "         [-0.1143,  0.0189, -0.0167,  ...,  0.0326, -0.0998, -0.0724],\n",
       "         [-0.0420, -0.0539, -0.0200,  ..., -0.2578, -0.1323, -0.0224],\n",
       "         ...,\n",
       "         [-0.0060, -0.1274, -0.0270,  ..., -0.1645, -0.0592,  0.0392],\n",
       "         [ 0.1225, -0.0223, -0.0931,  ..., -0.0262, -0.0024,  0.1243],\n",
       "         [-0.0391, -0.0228,  0.1323,  ...,  0.0478, -0.0882,  0.1315]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0444,  0.0610,  0.0943,  0.0921,  0.0059, -0.1496,\n",
       "          0.0063, -0.0823,  0.0696,  0.0938,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0705, -0.1006,  0.1485,  0.0037,  0.0591,  0.1516, -0.0956,  0.0532,\n",
       "         -0.0790,  0.1796, -0.0858, -0.0483, -0.0589,  0.1084, -0.0230,  0.0237,\n",
       "         -0.0315, -0.0454, -0.0301, -0.1468,  0.0031,  0.0621,  0.1027,  0.0578,\n",
       "         -0.0460,  0.0352,  0.1189, -0.0454,  0.1273, -0.0209, -0.0697, -0.0015,\n",
       "          0.0322,  0.1177]), 'layers.1.weight': tensor([[ 0.0461,  0.1095, -0.1283, -0.0894,  0.0526, -0.0966, -0.0533, -0.0282,\n",
       "           0.1368, -0.0316,  0.0438, -0.0701,  0.0670,  0.0043, -0.0624,  0.0462,\n",
       "          -0.0817, -0.0260,  0.0319,  0.0772, -0.1067,  0.0493, -0.0782, -0.0703,\n",
       "          -0.0574,  0.1253,  0.0758,  0.0977,  0.1036, -0.0163, -0.1173,  0.1254,\n",
       "           0.0101,  0.0510, -0.0973,  0.1059,  0.1166, -0.0645,  0.1581, -0.0482,\n",
       "          -0.1298,  0.0601,  0.1299, -0.0729,  0.0663,  0.1184, -0.0894, -0.0523,\n",
       "          -0.0721, -0.0829]]), 'layers.1.bias': tensor([-0.0718]), 'skip.weight': tensor([[ 0.0140, -0.0127,  0.0153,  0.0144,  0.0147,  0.0148, -0.0160, -0.0142,\n",
       "           0.0103,  0.0139, -0.0161, -0.0114, -0.0169,  0.0129,  0.0151, -0.0131,\n",
       "           0.0134,  0.0133,  0.0160,  0.0154,  0.0099,  0.0134,  0.0176,  0.0136,\n",
       "          -0.0152,  0.0153, -0.0156,  0.0177, -0.0161,  0.0130,  0.0154, -0.0185,\n",
       "           0.0214, -0.0172,  0.0201, -0.0153, -0.0186, -0.0139, -0.0128, -0.0169,\n",
       "          -0.0112, -0.0113,  0.0170, -0.0139,  0.0148,  0.0195, -0.0182, -0.0135,\n",
       "          -0.0202, -0.0119,  0.0158, -0.0118, -0.0154,  0.0110,  0.0146,  0.0140,\n",
       "          -0.0140, -0.0182, -0.0152,  0.0142,  0.0106,  0.0131, -0.0209,  0.0228,\n",
       "           0.0258, -0.0262,  0.0131]])}, objective=3.8022592022307515, loss=0.7340652346611023, val_objective=3.8306269600279927, val_loss=0.7624329924583435, regularization=1.0295089483261108, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.0398549250197604, state_dict={'layers.0.weight': tensor([[-0.0694,  0.0234,  0.0827,  ..., -0.0081,  0.0598,  0.0358],\n",
       "         [-0.1142,  0.0189, -0.0167,  ...,  0.0326, -0.0999, -0.0723],\n",
       "         [-0.0421, -0.0539, -0.0201,  ..., -0.2572, -0.1323, -0.0224],\n",
       "         ...,\n",
       "         [-0.0060, -0.1270, -0.0270,  ..., -0.1645, -0.0592,  0.0392],\n",
       "         [ 0.1225, -0.0223, -0.0932,  ..., -0.0262, -0.0023,  0.1243],\n",
       "         [-0.0392, -0.0228,  0.1322,  ...,  0.0478, -0.0881,  0.1300]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0444,  0.0610,  0.0943,  0.0920,  0.0059, -0.1496,\n",
       "          0.0062, -0.0823,  0.0696,  0.0938,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0706, -0.1006,  0.1485,  0.0036,  0.0591,  0.1516, -0.0956,  0.0532,\n",
       "         -0.0790,  0.1796, -0.0859, -0.0484, -0.0588,  0.1084, -0.0231,  0.0238,\n",
       "         -0.0315, -0.0454, -0.0301, -0.1468,  0.0030,  0.0621,  0.1027,  0.0578,\n",
       "         -0.0461,  0.0352,  0.1190, -0.0454,  0.1273, -0.0209, -0.0697, -0.0015,\n",
       "          0.0321,  0.1177]), 'layers.1.weight': tensor([[ 0.0462,  0.1096, -0.1284, -0.0892,  0.0526, -0.0968, -0.0535, -0.0281,\n",
       "           0.1369, -0.0316,  0.0437, -0.0701,  0.0669,  0.0045, -0.0626,  0.0462,\n",
       "          -0.0818, -0.0259,  0.0317,  0.0769, -0.1067,  0.0491, -0.0781, -0.0702,\n",
       "          -0.0574,  0.1253,  0.0756,  0.0978,  0.1037, -0.0163, -0.1172,  0.1255,\n",
       "           0.0101,  0.0511, -0.0972,  0.1061,  0.1164, -0.0647,  0.1583, -0.0482,\n",
       "          -0.1298,  0.0600,  0.1299, -0.0730,  0.0664,  0.1182, -0.0895, -0.0526,\n",
       "          -0.0721, -0.0830]]), 'layers.1.bias': tensor([-0.0716]), 'skip.weight': tensor([[ 0.0140, -0.0127,  0.0153,  0.0143,  0.0146,  0.0147, -0.0159, -0.0141,\n",
       "           0.0103,  0.0138, -0.0161, -0.0114, -0.0168,  0.0129,  0.0150, -0.0131,\n",
       "           0.0133,  0.0133,  0.0159,  0.0153,  0.0099,  0.0134,  0.0175,  0.0136,\n",
       "          -0.0151,  0.0151, -0.0155,  0.0175, -0.0160,  0.0130,  0.0153, -0.0183,\n",
       "           0.0212, -0.0171,  0.0199, -0.0153, -0.0185, -0.0138, -0.0127, -0.0168,\n",
       "          -0.0111, -0.0112,  0.0169, -0.0138,  0.0148,  0.0193, -0.0181, -0.0135,\n",
       "          -0.0202, -0.0119,  0.0158, -0.0118, -0.0153,  0.0109,  0.0146,  0.0140,\n",
       "          -0.0140, -0.0181, -0.0152,  0.0141,  0.0105,  0.0131, -0.0209,  0.0227,\n",
       "           0.0257, -0.0262,  0.0130]])}, objective=3.8508363102608363, loss=0.7340371012687683, val_objective=3.8791759346657435, val_loss=0.7623767256736755, regularization=1.025311827659607, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.100652023520156, state_dict={'layers.0.weight': tensor([[-0.0694,  0.0234,  0.0827,  ..., -0.0080,  0.0598,  0.0358],\n",
       "         [-0.1142,  0.0189, -0.0166,  ...,  0.0326, -0.0999, -0.0722],\n",
       "         [-0.0421, -0.0540, -0.0201,  ..., -0.2565, -0.1322, -0.0225],\n",
       "         ...,\n",
       "         [-0.0060, -0.1267, -0.0271,  ..., -0.1646, -0.0592,  0.0392],\n",
       "         [ 0.1224, -0.0223, -0.0932,  ..., -0.0263, -0.0023,  0.1243],\n",
       "         [-0.0392, -0.0229,  0.1322,  ...,  0.0478, -0.0881,  0.1286]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0443,  0.0609,  0.0943,  0.0920,  0.0059, -0.1496,\n",
       "          0.0062, -0.0823,  0.0696,  0.0938,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0706, -0.1006,  0.1485,  0.0036,  0.0591,  0.1516, -0.0957,  0.0531,\n",
       "         -0.0790,  0.1796, -0.0860, -0.0484, -0.0588,  0.1084, -0.0231,  0.0238,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1468,  0.0030,  0.0621,  0.1027,  0.0578,\n",
       "         -0.0462,  0.0352,  0.1190, -0.0454,  0.1273, -0.0210, -0.0697, -0.0015,\n",
       "          0.0321,  0.1177]), 'layers.1.weight': tensor([[ 0.0462,  0.1097, -0.1284, -0.0890,  0.0527, -0.0969, -0.0536, -0.0281,\n",
       "           0.1371, -0.0317,  0.0436, -0.0701,  0.0668,  0.0047, -0.0627,  0.0463,\n",
       "          -0.0820, -0.0257,  0.0315,  0.0767, -0.1068,  0.0490, -0.0780, -0.0701,\n",
       "          -0.0574,  0.1252,  0.0753,  0.0978,  0.1039, -0.0163, -0.1172,  0.1256,\n",
       "           0.0101,  0.0512, -0.0971,  0.1062,  0.1163, -0.0649,  0.1584, -0.0481,\n",
       "          -0.1297,  0.0599,  0.1300, -0.0731,  0.0664,  0.1180, -0.0895, -0.0528,\n",
       "          -0.0720, -0.0831]]), 'layers.1.bias': tensor([-0.0714]), 'skip.weight': tensor([[ 0.0139, -0.0127,  0.0152,  0.0143,  0.0146,  0.0145, -0.0159, -0.0141,\n",
       "           0.0102,  0.0138, -0.0160, -0.0114, -0.0167,  0.0128,  0.0150, -0.0130,\n",
       "           0.0133,  0.0133,  0.0157,  0.0152,  0.0099,  0.0134,  0.0175,  0.0135,\n",
       "          -0.0150,  0.0150, -0.0155,  0.0174, -0.0160,  0.0130,  0.0153, -0.0182,\n",
       "           0.0211, -0.0171,  0.0198, -0.0152, -0.0184, -0.0138, -0.0127, -0.0166,\n",
       "          -0.0111, -0.0112,  0.0169, -0.0138,  0.0148,  0.0192, -0.0180, -0.0135,\n",
       "          -0.0201, -0.0119,  0.0157, -0.0118, -0.0153,  0.0109,  0.0145,  0.0139,\n",
       "          -0.0139, -0.0181, -0.0151,  0.0141,  0.0105,  0.0130, -0.0208,  0.0225,\n",
       "           0.0256, -0.0261,  0.0129]])}, objective=3.9001503458004656, loss=0.7340097427368164, val_objective=3.928464399812764, val_loss=0.762323796749115, regularization=1.0211209058761597, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.162665063990559, state_dict={'layers.0.weight': tensor([[-0.0693,  0.0235,  0.0827,  ..., -0.0080,  0.0597,  0.0358],\n",
       "         [-0.1141,  0.0190, -0.0166,  ...,  0.0327, -0.1000, -0.0721],\n",
       "         [-0.0422, -0.0540, -0.0202,  ..., -0.2557, -0.1322, -0.0225],\n",
       "         ...,\n",
       "         [-0.0060, -0.1264, -0.0271,  ..., -0.1646, -0.0592,  0.0392],\n",
       "         [ 0.1223, -0.0223, -0.0932,  ..., -0.0263, -0.0023,  0.1242],\n",
       "         [-0.0393, -0.0229,  0.1322,  ...,  0.0477, -0.0880,  0.1278]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0443,  0.0609,  0.0943,  0.0920,  0.0059, -0.1496,\n",
       "          0.0062, -0.0823,  0.0696,  0.0939,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0706, -0.1006,  0.1485,  0.0035,  0.0591,  0.1516, -0.0957,  0.0531,\n",
       "         -0.0790,  0.1796, -0.0860, -0.0484, -0.0587,  0.1084, -0.0231,  0.0238,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1469,  0.0029,  0.0621,  0.1027,  0.0577,\n",
       "         -0.0463,  0.0352,  0.1191, -0.0455,  0.1273, -0.0210, -0.0697, -0.0015,\n",
       "          0.0321,  0.1177]), 'layers.1.weight': tensor([[ 0.0463,  0.1098, -0.1285, -0.0888,  0.0528, -0.0971, -0.0538, -0.0280,\n",
       "           0.1372, -0.0317,  0.0435, -0.0701,  0.0667,  0.0049, -0.0629,  0.0464,\n",
       "          -0.0822, -0.0256,  0.0314,  0.0765, -0.1068,  0.0488, -0.0779, -0.0700,\n",
       "          -0.0574,  0.1251,  0.0751,  0.0978,  0.1040, -0.0163, -0.1171,  0.1257,\n",
       "           0.0100,  0.0512, -0.0970,  0.1063,  0.1161, -0.0650,  0.1586, -0.0481,\n",
       "          -0.1297,  0.0598,  0.1301, -0.0732,  0.0664,  0.1178, -0.0896, -0.0530,\n",
       "          -0.0720, -0.0833]]), 'layers.1.bias': tensor([-0.0713]), 'skip.weight': tensor([[ 0.0139, -0.0126,  0.0152,  0.0142,  0.0145,  0.0144, -0.0158, -0.0140,\n",
       "           0.0102,  0.0137, -0.0160, -0.0113, -0.0167,  0.0128,  0.0149, -0.0130,\n",
       "           0.0132,  0.0132,  0.0156,  0.0152,  0.0098,  0.0133,  0.0175,  0.0135,\n",
       "          -0.0150,  0.0148, -0.0154,  0.0172, -0.0159,  0.0130,  0.0153, -0.0180,\n",
       "           0.0209, -0.0170,  0.0196, -0.0152, -0.0184, -0.0137, -0.0127, -0.0165,\n",
       "          -0.0111, -0.0111,  0.0168, -0.0137,  0.0147,  0.0190, -0.0179, -0.0134,\n",
       "          -0.0200, -0.0118,  0.0157, -0.0117, -0.0152,  0.0109,  0.0145,  0.0139,\n",
       "          -0.0139, -0.0180, -0.0151,  0.0140,  0.0105,  0.0130, -0.0208,  0.0224,\n",
       "           0.0256, -0.0261,  0.0128]])}, objective=3.9502763851253975, loss=0.7339826226234436, val_objective=3.9785671933262337, val_loss=0.7622734308242798, regularization=1.0169568061828613, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.2259183652703705, state_dict={'layers.0.weight': tensor([[-0.0693,  0.0235,  0.0827,  ..., -0.0080,  0.0597,  0.0359],\n",
       "         [-0.1140,  0.0190, -0.0166,  ...,  0.0327, -0.1001, -0.0721],\n",
       "         [-0.0423, -0.0540, -0.0202,  ..., -0.2550, -0.1321, -0.0226],\n",
       "         ...,\n",
       "         [-0.0061, -0.1262, -0.0271,  ..., -0.1646, -0.0592,  0.0391],\n",
       "         [ 0.1223, -0.0223, -0.0933,  ..., -0.0263, -0.0022,  0.1242],\n",
       "         [-0.0394, -0.0229,  0.1322,  ...,  0.0477, -0.0880,  0.1270]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0442,  0.0609,  0.0943,  0.0920,  0.0058, -0.1497,\n",
       "          0.0062, -0.0823,  0.0696,  0.0939,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0706, -0.1006,  0.1485,  0.0035,  0.0590,  0.1516, -0.0958,  0.0531,\n",
       "         -0.0790,  0.1796, -0.0861, -0.0485, -0.0587,  0.1083, -0.0232,  0.0238,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1469,  0.0029,  0.0621,  0.1027,  0.0577,\n",
       "         -0.0463,  0.0352,  0.1191, -0.0455,  0.1272, -0.0210, -0.0697, -0.0015,\n",
       "          0.0321,  0.1177]), 'layers.1.weight': tensor([[ 0.0464,  0.1100, -0.1286, -0.0886,  0.0529, -0.0972, -0.0539, -0.0280,\n",
       "           0.1373, -0.0317,  0.0434, -0.0701,  0.0666,  0.0051, -0.0631,  0.0464,\n",
       "          -0.0823, -0.0254,  0.0312,  0.0763, -0.1068,  0.0487, -0.0778, -0.0699,\n",
       "          -0.0573,  0.1251,  0.0749,  0.0978,  0.1042, -0.0164, -0.1170,  0.1258,\n",
       "           0.0100,  0.0513, -0.0969,  0.1065,  0.1160, -0.0652,  0.1587, -0.0481,\n",
       "          -0.1296,  0.0597,  0.1301, -0.0733,  0.0665,  0.1176, -0.0896, -0.0532,\n",
       "          -0.0720, -0.0834]]), 'layers.1.bias': tensor([-0.0711]), 'skip.weight': tensor([[ 0.0139, -0.0126,  0.0152,  0.0142,  0.0145,  0.0142, -0.0158, -0.0140,\n",
       "           0.0101,  0.0137, -0.0160, -0.0113, -0.0166,  0.0128,  0.0149, -0.0130,\n",
       "           0.0132,  0.0132,  0.0155,  0.0151,  0.0098,  0.0133,  0.0174,  0.0135,\n",
       "          -0.0149,  0.0147, -0.0153,  0.0170, -0.0159,  0.0129,  0.0152, -0.0179,\n",
       "           0.0208, -0.0169,  0.0195, -0.0152, -0.0183, -0.0137, -0.0126, -0.0163,\n",
       "          -0.0111, -0.0111,  0.0168, -0.0137,  0.0147,  0.0189, -0.0179, -0.0134,\n",
       "          -0.0199, -0.0118,  0.0156, -0.0117, -0.0152,  0.0108,  0.0145,  0.0138,\n",
       "          -0.0138, -0.0179, -0.0151,  0.0139,  0.0104,  0.0130, -0.0207,  0.0222,\n",
       "           0.0255, -0.0261,  0.0127]])}, objective=4.001278434372649, loss=0.7339553236961365, val_objective=4.029547367668853, val_loss=0.7622242569923396, regularization=1.0128350257873535, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.290436732575778, state_dict={'layers.0.weight': tensor([[-0.0693,  0.0235,  0.0827,  ..., -0.0080,  0.0597,  0.0359],\n",
       "         [-0.1140,  0.0191, -0.0166,  ...,  0.0327, -0.1001, -0.0720],\n",
       "         [-0.0423, -0.0541, -0.0202,  ..., -0.2543, -0.1321, -0.0226],\n",
       "         ...,\n",
       "         [-0.0061, -0.1259, -0.0271,  ..., -0.1646, -0.0591,  0.0391],\n",
       "         [ 0.1222, -0.0223, -0.0933,  ..., -0.0263, -0.0022,  0.1241],\n",
       "         [-0.0395, -0.0230,  0.1321,  ...,  0.0477, -0.0879,  0.1262]]), 'layers.0.bias': tensor([-0.0638,  0.1407,  0.0442,  0.0609,  0.0943,  0.0919,  0.0058, -0.1497,\n",
       "          0.0061, -0.0824,  0.0696,  0.0939,  0.1273,  0.0369, -0.1498, -0.1193,\n",
       "         -0.0707, -0.1006,  0.1484,  0.0034,  0.0590,  0.1515, -0.0958,  0.0530,\n",
       "         -0.0791,  0.1796, -0.0862, -0.0485, -0.0586,  0.1083, -0.0232,  0.0239,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1469,  0.0028,  0.0621,  0.1026,  0.0577,\n",
       "         -0.0464,  0.0352,  0.1191, -0.0455,  0.1272, -0.0211, -0.0698, -0.0015,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0465,  0.1101, -0.1287, -0.0884,  0.0529, -0.0973, -0.0541, -0.0279,\n",
       "           0.1375, -0.0317,  0.0433, -0.0701,  0.0665,  0.0053, -0.0632,  0.0465,\n",
       "          -0.0825, -0.0253,  0.0311,  0.0760, -0.1068,  0.0485, -0.0777, -0.0698,\n",
       "          -0.0573,  0.1250,  0.0747,  0.0978,  0.1043, -0.0164, -0.1170,  0.1259,\n",
       "           0.0100,  0.0514, -0.0968,  0.1066,  0.1158, -0.0654,  0.1589, -0.0480,\n",
       "          -0.1296,  0.0596,  0.1302, -0.0734,  0.0665,  0.1174, -0.0897, -0.0534,\n",
       "          -0.0720, -0.0836]]), 'layers.1.bias': tensor([-0.0709]), 'skip.weight': tensor([[ 0.0138, -0.0126,  0.0151,  0.0141,  0.0144,  0.0141, -0.0157, -0.0139,\n",
       "           0.0101,  0.0136, -0.0159, -0.0113, -0.0165,  0.0127,  0.0148, -0.0129,\n",
       "           0.0132,  0.0132,  0.0154,  0.0150,  0.0098,  0.0132,  0.0174,  0.0134,\n",
       "          -0.0148,  0.0145, -0.0152,  0.0169, -0.0158,  0.0129,  0.0152, -0.0177,\n",
       "           0.0206, -0.0168,  0.0193, -0.0152, -0.0183, -0.0136, -0.0126, -0.0163,\n",
       "          -0.0110, -0.0110,  0.0167, -0.0137,  0.0147,  0.0187, -0.0178, -0.0133,\n",
       "          -0.0199, -0.0118,  0.0156, -0.0117, -0.0151,  0.0108,  0.0144,  0.0138,\n",
       "          -0.0138, -0.0178, -0.0150,  0.0138,  0.0104,  0.0129, -0.0207,  0.0221,\n",
       "           0.0254, -0.0260,  0.0126]])}, objective=4.053282863623076, loss=0.733927845954895, val_objective=4.081529981619292, val_loss=0.7621749639511108, regularization=1.0087885856628418, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.3562454672272937, state_dict={'layers.0.weight': tensor([[-0.0692,  0.0235,  0.0827,  ..., -0.0080,  0.0597,  0.0359],\n",
       "         [-0.1139,  0.0191, -0.0165,  ...,  0.0328, -0.1002, -0.0719],\n",
       "         [-0.0424, -0.0541, -0.0203,  ..., -0.2535, -0.1320, -0.0227],\n",
       "         ...,\n",
       "         [-0.0061, -0.1256, -0.0271,  ..., -0.1646, -0.0591,  0.0391],\n",
       "         [ 0.1221, -0.0224, -0.0933,  ..., -0.0264, -0.0022,  0.1241],\n",
       "         [-0.0395, -0.0230,  0.1321,  ...,  0.0476, -0.0879,  0.1254]]), 'layers.0.bias': tensor([-0.0638,  0.1406,  0.0442,  0.0608,  0.0943,  0.0919,  0.0058, -0.1497,\n",
       "          0.0061, -0.0824,  0.0696,  0.0939,  0.1273,  0.0369, -0.1499, -0.1194,\n",
       "         -0.0707, -0.1006,  0.1484,  0.0034,  0.0590,  0.1515, -0.0958,  0.0530,\n",
       "         -0.0791,  0.1796, -0.0863, -0.0485, -0.0586,  0.1083, -0.0233,  0.0239,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1469,  0.0028,  0.0621,  0.1026,  0.0577,\n",
       "         -0.0465,  0.0352,  0.1192, -0.0455,  0.1272, -0.0211, -0.0698, -0.0015,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0466,  0.1102, -0.1288, -0.0882,  0.0530, -0.0975, -0.0543, -0.0279,\n",
       "           0.1377, -0.0317,  0.0433, -0.0701,  0.0664,  0.0055, -0.0634,  0.0466,\n",
       "          -0.0826, -0.0252,  0.0310,  0.0758, -0.1069,  0.0484, -0.0776, -0.0697,\n",
       "          -0.0573,  0.1249,  0.0746,  0.0978,  0.1045, -0.0164, -0.1169,  0.1260,\n",
       "           0.0100,  0.0514, -0.0967,  0.1068,  0.1157, -0.0655,  0.1590, -0.0480,\n",
       "          -0.1295,  0.0596,  0.1303, -0.0734,  0.0665,  0.1172, -0.0897, -0.0536,\n",
       "          -0.0720, -0.0838]]), 'layers.1.bias': tensor([-0.0708]), 'skip.weight': tensor([[ 0.0137, -0.0126,  0.0151,  0.0141,  0.0144,  0.0140, -0.0156, -0.0139,\n",
       "           0.0100,  0.0136, -0.0159, -0.0112, -0.0164,  0.0127,  0.0148, -0.0129,\n",
       "           0.0131,  0.0131,  0.0153,  0.0149,  0.0097,  0.0132,  0.0173,  0.0134,\n",
       "          -0.0148,  0.0145, -0.0151,  0.0167, -0.0158,  0.0129,  0.0152, -0.0176,\n",
       "           0.0206, -0.0167,  0.0192, -0.0152, -0.0182, -0.0136, -0.0126, -0.0162,\n",
       "          -0.0110, -0.0110,  0.0167, -0.0136,  0.0147,  0.0186, -0.0177, -0.0133,\n",
       "          -0.0198, -0.0118,  0.0155, -0.0116, -0.0151,  0.0108,  0.0144,  0.0138,\n",
       "          -0.0137, -0.0177, -0.0150,  0.0138,  0.0104,  0.0129, -0.0206,  0.0220,\n",
       "           0.0254, -0.0260,  0.0125]])}, objective=4.106680059612646, loss=0.7338986396789551, val_objective=4.1349029185184385, val_loss=0.7621214985847478, regularization=1.0049269199371338, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.4233703765718397, state_dict={'layers.0.weight': tensor([[-0.0692,  0.0235,  0.0828,  ..., -0.0079,  0.0596,  0.0359],\n",
       "         [-0.1139,  0.0192, -0.0165,  ...,  0.0328, -0.1003, -0.0718],\n",
       "         [-0.0424, -0.0541, -0.0203,  ..., -0.2527, -0.1320, -0.0227],\n",
       "         ...,\n",
       "         [-0.0062, -0.1253, -0.0271,  ..., -0.1646, -0.0591,  0.0391],\n",
       "         [ 0.1221, -0.0224, -0.0934,  ..., -0.0264, -0.0022,  0.1241],\n",
       "         [-0.0396, -0.0230,  0.1321,  ...,  0.0476, -0.0878,  0.1246]]), 'layers.0.bias': tensor([-0.0638,  0.1406,  0.0441,  0.0608,  0.0943,  0.0919,  0.0058, -0.1497,\n",
       "          0.0061, -0.0824,  0.0696,  0.0939,  0.1273,  0.0369, -0.1499, -0.1194,\n",
       "         -0.0707, -0.1006,  0.1484,  0.0033,  0.0590,  0.1515, -0.0959,  0.0530,\n",
       "         -0.0791,  0.1795, -0.0863, -0.0486, -0.0585,  0.1083, -0.0233,  0.0239,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1469,  0.0027,  0.0621,  0.1026,  0.0576,\n",
       "         -0.0466,  0.0352,  0.1192, -0.0455,  0.1272, -0.0212, -0.0698, -0.0015,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0467,  0.1103, -0.1288, -0.0880,  0.0531, -0.0976, -0.0544, -0.0278,\n",
       "           0.1378, -0.0317,  0.0432, -0.0701,  0.0663,  0.0057, -0.0635,  0.0467,\n",
       "          -0.0828, -0.0250,  0.0308,  0.0756, -0.1069,  0.0483, -0.0775, -0.0697,\n",
       "          -0.0573,  0.1248,  0.0744,  0.0978,  0.1046, -0.0165, -0.1168,  0.1261,\n",
       "           0.0099,  0.0515, -0.0966,  0.1069,  0.1155, -0.0657,  0.1592, -0.0480,\n",
       "          -0.1295,  0.0595,  0.1303, -0.0735,  0.0666,  0.1170, -0.0898, -0.0538,\n",
       "          -0.0720, -0.0839]]), 'layers.1.bias': tensor([-0.0706]), 'skip.weight': tensor([[ 0.0137, -0.0125,  0.0150,  0.0140,  0.0143,  0.0139, -0.0156, -0.0138,\n",
       "           0.0100,  0.0136, -0.0158, -0.0112, -0.0163,  0.0126,  0.0147, -0.0128,\n",
       "           0.0131,  0.0131,  0.0153,  0.0148,  0.0097,  0.0132,  0.0173,  0.0133,\n",
       "          -0.0147,  0.0144, -0.0150,  0.0165, -0.0157,  0.0129,  0.0151, -0.0174,\n",
       "           0.0205, -0.0167,  0.0190, -0.0151, -0.0181, -0.0135, -0.0125, -0.0161,\n",
       "          -0.0110, -0.0109,  0.0166, -0.0136,  0.0146,  0.0184, -0.0176, -0.0133,\n",
       "          -0.0197, -0.0117,  0.0155, -0.0116, -0.0150,  0.0108,  0.0144,  0.0137,\n",
       "          -0.0136, -0.0176, -0.0149,  0.0138,  0.0104,  0.0129, -0.0205,  0.0219,\n",
       "           0.0253, -0.0259,  0.0125]])}, objective=4.160765043625265, loss=0.7338707447052002, val_objective=4.1889644183010155, val_loss=0.7620701193809509, regularization=1.001029372215271, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.4918377841032764, state_dict={'layers.0.weight': tensor([[-0.0691,  0.0235,  0.0828,  ..., -0.0079,  0.0596,  0.0359],\n",
       "         [-0.1138,  0.0192, -0.0165,  ...,  0.0328, -0.1003, -0.0718],\n",
       "         [-0.0425, -0.0542, -0.0204,  ..., -0.2519, -0.1319, -0.0228],\n",
       "         ...,\n",
       "         [-0.0062, -0.1251, -0.0271,  ..., -0.1647, -0.0591,  0.0390],\n",
       "         [ 0.1220, -0.0224, -0.0934,  ..., -0.0264, -0.0021,  0.1238],\n",
       "         [-0.0397, -0.0231,  0.1321,  ...,  0.0476, -0.0878,  0.1238]]), 'layers.0.bias': tensor([-0.0638,  0.1406,  0.0441,  0.0608,  0.0943,  0.0918,  0.0058, -0.1497,\n",
       "          0.0060, -0.0824,  0.0696,  0.0940,  0.1273,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0707, -0.1007,  0.1484,  0.0032,  0.0590,  0.1515, -0.0959,  0.0530,\n",
       "         -0.0791,  0.1795, -0.0864, -0.0486, -0.0585,  0.1083, -0.0233,  0.0239,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1470,  0.0027,  0.0621,  0.1026,  0.0576,\n",
       "         -0.0466,  0.0352,  0.1193, -0.0455,  0.1272, -0.0212, -0.0698, -0.0015,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0468,  0.1104, -0.1289, -0.0879,  0.0532, -0.0978, -0.0546, -0.0278,\n",
       "           0.1380, -0.0317,  0.0431, -0.0701,  0.0662,  0.0059, -0.0637,  0.0468,\n",
       "          -0.0829, -0.0249,  0.0307,  0.0754, -0.1069,  0.0481, -0.0774, -0.0696,\n",
       "          -0.0573,  0.1248,  0.0742,  0.0979,  0.1048, -0.0165, -0.1168,  0.1263,\n",
       "           0.0099,  0.0516, -0.0964,  0.1071,  0.1154, -0.0658,  0.1593, -0.0479,\n",
       "          -0.1294,  0.0594,  0.1304, -0.0736,  0.0666,  0.1168, -0.0899, -0.0540,\n",
       "          -0.0720, -0.0841]]), 'layers.1.bias': tensor([-0.0704]), 'skip.weight': tensor([[ 0.0136, -0.0125,  0.0150,  0.0140,  0.0143,  0.0138, -0.0155, -0.0138,\n",
       "           0.0100,  0.0135, -0.0158, -0.0112, -0.0162,  0.0126,  0.0147, -0.0128,\n",
       "           0.0130,  0.0131,  0.0152,  0.0148,  0.0097,  0.0131,  0.0173,  0.0133,\n",
       "          -0.0146,  0.0143, -0.0150,  0.0164, -0.0157,  0.0128,  0.0151, -0.0172,\n",
       "           0.0204, -0.0166,  0.0188, -0.0151, -0.0181, -0.0135, -0.0125, -0.0160,\n",
       "          -0.0110, -0.0108,  0.0166, -0.0135,  0.0146,  0.0183, -0.0175, -0.0132,\n",
       "          -0.0196, -0.0117,  0.0154, -0.0116, -0.0149,  0.0107,  0.0143,  0.0137,\n",
       "          -0.0136, -0.0176, -0.0149,  0.0137,  0.0103,  0.0128, -0.0205,  0.0218,\n",
       "           0.0252, -0.0259,  0.0124]])}, objective=4.215536601805708, loss=0.733844518661499, val_objective=4.243709631228468, val_loss=0.7620175480842586, regularization=0.997094452381134, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.5616745397853418, state_dict={'layers.0.weight': tensor([[-0.0691,  0.0235,  0.0828,  ..., -0.0079,  0.0596,  0.0359],\n",
       "         [-0.1138,  0.0193, -0.0164,  ...,  0.0328, -0.1004, -0.0717],\n",
       "         [-0.0425, -0.0542, -0.0204,  ..., -0.2511, -0.1319, -0.0228],\n",
       "         ...,\n",
       "         [-0.0062, -0.1248, -0.0271,  ..., -0.1647, -0.0591,  0.0390],\n",
       "         [ 0.1219, -0.0224, -0.0934,  ..., -0.0265, -0.0021,  0.1232],\n",
       "         [-0.0398, -0.0231,  0.1320,  ...,  0.0476, -0.0877,  0.1232]]), 'layers.0.bias': tensor([-0.0638,  0.1406,  0.0441,  0.0608,  0.0943,  0.0918,  0.0058, -0.1497,\n",
       "          0.0060, -0.0824,  0.0696,  0.0940,  0.1273,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0707, -0.1007,  0.1484,  0.0032,  0.0590,  0.1515, -0.0959,  0.0529,\n",
       "         -0.0791,  0.1795, -0.0865, -0.0486, -0.0584,  0.1083, -0.0234,  0.0240,\n",
       "         -0.0315, -0.0453, -0.0302, -0.1470,  0.0026,  0.0621,  0.1026,  0.0576,\n",
       "         -0.0467,  0.0352,  0.1193, -0.0455,  0.1272, -0.0212, -0.0698, -0.0015,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0469,  0.1105, -0.1290, -0.0877,  0.0533, -0.0979, -0.0548, -0.0278,\n",
       "           0.1381, -0.0317,  0.0430, -0.0701,  0.0661,  0.0061, -0.0639,  0.0468,\n",
       "          -0.0831, -0.0248,  0.0305,  0.0752, -0.1069,  0.0480, -0.0774, -0.0695,\n",
       "          -0.0573,  0.1247,  0.0740,  0.0979,  0.1049, -0.0165, -0.1167,  0.1264,\n",
       "           0.0099,  0.0517, -0.0963,  0.1072,  0.1153, -0.0660,  0.1595, -0.0479,\n",
       "          -0.1294,  0.0593,  0.1305, -0.0737,  0.0666,  0.1166, -0.0899, -0.0542,\n",
       "          -0.0720, -0.0843]]), 'layers.1.bias': tensor([-0.0703]), 'skip.weight': tensor([[ 0.0136, -0.0125,  0.0150,  0.0139,  0.0142,  0.0137, -0.0155, -0.0137,\n",
       "           0.0099,  0.0135, -0.0158, -0.0111, -0.0162,  0.0125,  0.0146, -0.0128,\n",
       "           0.0130,  0.0130,  0.0151,  0.0147,  0.0096,  0.0131,  0.0172,  0.0133,\n",
       "          -0.0146,  0.0142, -0.0149,  0.0162, -0.0156,  0.0128,  0.0151, -0.0171,\n",
       "           0.0203, -0.0165,  0.0187, -0.0151, -0.0180, -0.0135, -0.0125, -0.0159,\n",
       "          -0.0109, -0.0108,  0.0165, -0.0135,  0.0146,  0.0181, -0.0175, -0.0132,\n",
       "          -0.0195, -0.0117,  0.0154, -0.0116, -0.0149,  0.0107,  0.0143,  0.0136,\n",
       "          -0.0135, -0.0175, -0.0149,  0.0137,  0.0103,  0.0128, -0.0204,  0.0218,\n",
       "           0.0251, -0.0259,  0.0123]])}, objective=4.271063886762469, loss=0.7338188886642456, val_objective=4.299210213304369, val_loss=0.7619652152061462, regularization=0.9931409955024719, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.632908030581049, state_dict={'layers.0.weight': tensor([[-0.0691,  0.0235,  0.0828,  ..., -0.0079,  0.0595,  0.0360],\n",
       "         [-0.1137,  0.0193, -0.0164,  ...,  0.0329, -0.1005, -0.0716],\n",
       "         [-0.0426, -0.0542, -0.0204,  ..., -0.2503, -0.1318, -0.0229],\n",
       "         ...,\n",
       "         [-0.0062, -0.1245, -0.0271,  ..., -0.1647, -0.0590,  0.0390],\n",
       "         [ 0.1219, -0.0224, -0.0935,  ..., -0.0265, -0.0021,  0.1226],\n",
       "         [-0.0398, -0.0231,  0.1320,  ...,  0.0475, -0.0877,  0.1226]]), 'layers.0.bias': tensor([-0.0638,  0.1406,  0.0440,  0.0608,  0.0943,  0.0918,  0.0058, -0.1498,\n",
       "          0.0060, -0.0824,  0.0696,  0.0940,  0.1273,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0708, -0.1007,  0.1484,  0.0031,  0.0590,  0.1515, -0.0960,  0.0529,\n",
       "         -0.0791,  0.1795, -0.0865, -0.0487, -0.0583,  0.1083, -0.0234,  0.0240,\n",
       "         -0.0315, -0.0452, -0.0303, -0.1470,  0.0025,  0.0621,  0.1026,  0.0575,\n",
       "         -0.0468,  0.0352,  0.1194, -0.0455,  0.1271, -0.0213, -0.0698, -0.0014,\n",
       "          0.0321,  0.1176]), 'layers.1.weight': tensor([[ 0.0469,  0.1106, -0.1291, -0.0875,  0.0533, -0.0981, -0.0549, -0.0277,\n",
       "           0.1383, -0.0317,  0.0429, -0.0701,  0.0660,  0.0063, -0.0640,  0.0469,\n",
       "          -0.0832, -0.0246,  0.0304,  0.0750, -0.1069,  0.0479, -0.0773, -0.0694,\n",
       "          -0.0573,  0.1246,  0.0738,  0.0979,  0.1051, -0.0166, -0.1167,  0.1265,\n",
       "           0.0099,  0.0517, -0.0962,  0.1074,  0.1151, -0.0662,  0.1597, -0.0478,\n",
       "          -0.1294,  0.0592,  0.1306, -0.0737,  0.0667,  0.1164, -0.0900, -0.0544,\n",
       "          -0.0720, -0.0845]]), 'layers.1.bias': tensor([-0.0701]), 'skip.weight': tensor([[ 0.0135, -0.0125,  0.0149,  0.0139,  0.0142,  0.0136, -0.0155, -0.0136,\n",
       "           0.0099,  0.0134, -0.0157, -0.0111, -0.0161,  0.0125,  0.0145, -0.0127,\n",
       "           0.0130,  0.0130,  0.0150,  0.0146,  0.0096,  0.0130,  0.0172,  0.0132,\n",
       "          -0.0145,  0.0141, -0.0148,  0.0160, -0.0156,  0.0128,  0.0150, -0.0169,\n",
       "           0.0202, -0.0164,  0.0185, -0.0151, -0.0180, -0.0134, -0.0124, -0.0158,\n",
       "          -0.0109, -0.0107,  0.0165, -0.0134,  0.0145,  0.0179, -0.0174, -0.0131,\n",
       "          -0.0195, -0.0117,  0.0153, -0.0115, -0.0148,  0.0107,  0.0143,  0.0136,\n",
       "          -0.0135, -0.0174, -0.0148,  0.0136,  0.0103,  0.0128, -0.0204,  0.0217,\n",
       "           0.0250, -0.0258,  0.0123]])}, objective=4.327241232604733, loss=0.7337946891784668, val_objective=4.355360141010037, val_loss=0.7619135975837712, regularization=0.9891377687454224, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.70556619119267, state_dict={'layers.0.weight': tensor([[-0.0690,  0.0235,  0.0828,  ..., -0.0079,  0.0595,  0.0360],\n",
       "         [-0.1136,  0.0194, -0.0164,  ...,  0.0329, -0.1005, -0.0715],\n",
       "         [-0.0426, -0.0543, -0.0205,  ..., -0.2495, -0.1318, -0.0229],\n",
       "         ...,\n",
       "         [-0.0063, -0.1243, -0.0271,  ..., -0.1647, -0.0590,  0.0390],\n",
       "         [ 0.1218, -0.0224, -0.0935,  ..., -0.0265, -0.0021,  0.1220],\n",
       "         [-0.0399, -0.0232,  0.1320,  ...,  0.0475, -0.0876,  0.1220]]), 'layers.0.bias': tensor([-0.0638,  0.1405,  0.0440,  0.0607,  0.0943,  0.0918,  0.0058, -0.1498,\n",
       "          0.0060, -0.0824,  0.0696,  0.0940,  0.1273,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0708, -0.1007,  0.1484,  0.0031,  0.0590,  0.1514, -0.0960,  0.0529,\n",
       "         -0.0791,  0.1795, -0.0866, -0.0487, -0.0583,  0.1083, -0.0234,  0.0240,\n",
       "         -0.0315, -0.0452, -0.0303, -0.1470,  0.0025,  0.0621,  0.1026,  0.0575,\n",
       "         -0.0468,  0.0352,  0.1194, -0.0455,  0.1271, -0.0213, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0470,  0.1107, -0.1292, -0.0873,  0.0534, -0.0982, -0.0551, -0.0277,\n",
       "           0.1385, -0.0317,  0.0428, -0.0702,  0.0660,  0.0064, -0.0642,  0.0470,\n",
       "          -0.0834, -0.0245,  0.0302,  0.0748, -0.1070,  0.0477, -0.0772, -0.0693,\n",
       "          -0.0572,  0.1246,  0.0737,  0.0979,  0.1052, -0.0166, -0.1166,  0.1266,\n",
       "           0.0099,  0.0518, -0.0961,  0.1075,  0.1150, -0.0663,  0.1598, -0.0478,\n",
       "          -0.1293,  0.0592,  0.1306, -0.0738,  0.0667,  0.1162, -0.0900, -0.0546,\n",
       "          -0.0720, -0.0846]]), 'layers.1.bias': tensor([-0.0700]), 'skip.weight': tensor([[ 0.0135, -0.0124,  0.0149,  0.0138,  0.0141,  0.0135, -0.0154, -0.0136,\n",
       "           0.0099,  0.0134, -0.0157, -0.0111, -0.0160,  0.0125,  0.0145, -0.0127,\n",
       "           0.0129,  0.0130,  0.0149,  0.0145,  0.0096,  0.0130,  0.0171,  0.0132,\n",
       "          -0.0145,  0.0140, -0.0147,  0.0158, -0.0155,  0.0127,  0.0150, -0.0167,\n",
       "           0.0202, -0.0163,  0.0183, -0.0150, -0.0179, -0.0134, -0.0124, -0.0158,\n",
       "          -0.0109, -0.0107,  0.0164, -0.0134,  0.0145,  0.0177, -0.0173, -0.0131,\n",
       "          -0.0194, -0.0116,  0.0153, -0.0115, -0.0148,  0.0106,  0.0142,  0.0135,\n",
       "          -0.0134, -0.0173, -0.0148,  0.0136,  0.0103,  0.0127, -0.0203,  0.0216,\n",
       "           0.0249, -0.0258,  0.0122]])}, objective=4.384180279060924, loss=0.7337725758552551, val_objective=4.41227349786433, val_loss=0.7618657946586604, regularization=0.9851146936416626, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.779677515016523, state_dict={'layers.0.weight': tensor([[-0.0690,  0.0236,  0.0828,  ..., -0.0078,  0.0595,  0.0360],\n",
       "         [-0.1136,  0.0194, -0.0164,  ...,  0.0329, -0.1006, -0.0715],\n",
       "         [-0.0427, -0.0543, -0.0205,  ..., -0.2486, -0.1317, -0.0229],\n",
       "         ...,\n",
       "         [-0.0063, -0.1240, -0.0271,  ..., -0.1647, -0.0590,  0.0390],\n",
       "         [ 0.1217, -0.0224, -0.0935,  ..., -0.0265, -0.0020,  0.1215],\n",
       "         [-0.0400, -0.0232,  0.1320,  ...,  0.0475, -0.0876,  0.1215]]), 'layers.0.bias': tensor([-0.0638,  0.1405,  0.0440,  0.0607,  0.0943,  0.0918,  0.0058, -0.1498,\n",
       "          0.0059, -0.0824,  0.0695,  0.0940,  0.1272,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0708, -0.1007,  0.1484,  0.0030,  0.0590,  0.1514, -0.0960,  0.0528,\n",
       "         -0.0791,  0.1795, -0.0867, -0.0487, -0.0582,  0.1083, -0.0235,  0.0240,\n",
       "         -0.0315, -0.0452, -0.0303, -0.1470,  0.0024,  0.0621,  0.1026,  0.0575,\n",
       "         -0.0469,  0.0352,  0.1194, -0.0455,  0.1271, -0.0214, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0471,  0.1108, -0.1293, -0.0871,  0.0535, -0.0984, -0.0553, -0.0277,\n",
       "           0.1386, -0.0317,  0.0427, -0.0702,  0.0659,  0.0066, -0.0644,  0.0471,\n",
       "          -0.0835, -0.0244,  0.0301,  0.0746, -0.1070,  0.0476, -0.0771, -0.0693,\n",
       "          -0.0572,  0.1245,  0.0735,  0.0979,  0.1054, -0.0167, -0.1166,  0.1267,\n",
       "           0.0099,  0.0519, -0.0960,  0.1077,  0.1149, -0.0665,  0.1600, -0.0478,\n",
       "          -0.1293,  0.0591,  0.1307, -0.0739,  0.0667,  0.1160, -0.0901, -0.0548,\n",
       "          -0.0720, -0.0848]]), 'layers.1.bias': tensor([-0.0699]), 'skip.weight': tensor([[ 0.0134, -0.0124,  0.0148,  0.0138,  0.0140,  0.0134, -0.0154, -0.0135,\n",
       "           0.0098,  0.0133, -0.0157, -0.0110, -0.0159,  0.0124,  0.0144, -0.0127,\n",
       "           0.0129,  0.0130,  0.0149,  0.0145,  0.0095,  0.0129,  0.0171,  0.0132,\n",
       "          -0.0144,  0.0139, -0.0146,  0.0156, -0.0155,  0.0127,  0.0150, -0.0166,\n",
       "           0.0201, -0.0162,  0.0181, -0.0150, -0.0179, -0.0133, -0.0124, -0.0157,\n",
       "          -0.0108, -0.0106,  0.0163, -0.0133,  0.0145,  0.0176, -0.0173, -0.0130,\n",
       "          -0.0193, -0.0116,  0.0152, -0.0115, -0.0147,  0.0106,  0.0142,  0.0135,\n",
       "          -0.0134, -0.0172, -0.0147,  0.0135,  0.0102,  0.0127, -0.0203,  0.0215,\n",
       "           0.0249, -0.0257,  0.0121]])}, objective=4.442027780169768, loss=0.7337509393692017, val_objective=4.47009685909204, val_loss=0.7618200182914734, regularization=0.9811093211174011, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.855271065316854, state_dict={'layers.0.weight': tensor([[-0.0690,  0.0236,  0.0828,  ..., -0.0078,  0.0595,  0.0360],\n",
       "         [-0.1135,  0.0194, -0.0163,  ...,  0.0329, -0.1007, -0.0714],\n",
       "         [-0.0427, -0.0543, -0.0206,  ..., -0.2477, -0.1317, -0.0230],\n",
       "         ...,\n",
       "         [-0.0063, -0.1237, -0.0271,  ..., -0.1647, -0.0590,  0.0389],\n",
       "         [ 0.1217, -0.0224, -0.0936,  ..., -0.0266, -0.0020,  0.1211],\n",
       "         [-0.0401, -0.0232,  0.1320,  ...,  0.0474, -0.0875,  0.1211]]), 'layers.0.bias': tensor([-0.0638,  0.1405,  0.0440,  0.0607,  0.0943,  0.0917,  0.0058, -0.1498,\n",
       "          0.0059, -0.0824,  0.0695,  0.0941,  0.1272,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0708, -0.1007,  0.1484,  0.0030,  0.0589,  0.1514, -0.0960,  0.0528,\n",
       "         -0.0791,  0.1795, -0.0868, -0.0488, -0.0582,  0.1082, -0.0235,  0.0240,\n",
       "         -0.0315, -0.0452, -0.0303, -0.1471,  0.0024,  0.0621,  0.1026,  0.0575,\n",
       "         -0.0470,  0.0352,  0.1195, -0.0455,  0.1271, -0.0214, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0472,  0.1109, -0.1294, -0.0869,  0.0536, -0.0985, -0.0555, -0.0277,\n",
       "           0.1388, -0.0317,  0.0427, -0.0702,  0.0658,  0.0068, -0.0645,  0.0472,\n",
       "          -0.0837, -0.0242,  0.0299,  0.0744, -0.1070,  0.0475, -0.0771, -0.0692,\n",
       "          -0.0572,  0.1244,  0.0733,  0.0980,  0.1055, -0.0168, -0.1165,  0.1268,\n",
       "           0.0099,  0.0520, -0.0960,  0.1078,  0.1148, -0.0666,  0.1602, -0.0477,\n",
       "          -0.1293,  0.0590,  0.1308, -0.0739,  0.0668,  0.1159, -0.0901, -0.0550,\n",
       "          -0.0721, -0.0850]]), 'layers.1.bias': tensor([-0.0697]), 'skip.weight': tensor([[ 0.0134, -0.0124,  0.0148,  0.0137,  0.0140,  0.0133, -0.0153, -0.0135,\n",
       "           0.0098,  0.0133, -0.0156, -0.0110, -0.0158,  0.0124,  0.0144, -0.0126,\n",
       "           0.0128,  0.0129,  0.0148,  0.0144,  0.0095,  0.0129,  0.0171,  0.0131,\n",
       "          -0.0143,  0.0138, -0.0146,  0.0154, -0.0154,  0.0127,  0.0149, -0.0164,\n",
       "           0.0200, -0.0161,  0.0179, -0.0150, -0.0178, -0.0133, -0.0123, -0.0156,\n",
       "          -0.0108, -0.0106,  0.0163, -0.0133,  0.0145,  0.0174, -0.0172, -0.0130,\n",
       "          -0.0192, -0.0116,  0.0152, -0.0114, -0.0146,  0.0106,  0.0142,  0.0135,\n",
       "          -0.0133, -0.0171, -0.0147,  0.0135,  0.0102,  0.0127, -0.0202,  0.0214,\n",
       "           0.0248, -0.0257,  0.0121]])}, objective=4.500800089489436, loss=0.7337294220924377, val_objective=4.528843896042323, val_loss=0.7617732286453252, regularization=0.9771221280097961, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=3.932376486623191, state_dict={'layers.0.weight': tensor([[-0.0689,  0.0236,  0.0828,  ..., -0.0078,  0.0594,  0.0360],\n",
       "         [-0.1135,  0.0195, -0.0163,  ...,  0.0330, -0.1007, -0.0713],\n",
       "         [-0.0428, -0.0543, -0.0206,  ..., -0.2468, -0.1317, -0.0230],\n",
       "         ...,\n",
       "         [-0.0063, -0.1235, -0.0271,  ..., -0.1648, -0.0590,  0.0389],\n",
       "         [ 0.1216, -0.0225, -0.0936,  ..., -0.0266, -0.0020,  0.1207],\n",
       "         [-0.0401, -0.0233,  0.1319,  ...,  0.0474, -0.0875,  0.1207]]), 'layers.0.bias': tensor([-0.0637,  0.1405,  0.0439,  0.0607,  0.0943,  0.0917,  0.0057, -0.1498,\n",
       "          0.0059, -0.0824,  0.0695,  0.0941,  0.1272,  0.0370, -0.1499, -0.1194,\n",
       "         -0.0709, -0.1007,  0.1484,  0.0029,  0.0589,  0.1514, -0.0961,  0.0528,\n",
       "         -0.0791,  0.1795, -0.0868, -0.0488, -0.0581,  0.1082, -0.0236,  0.0241,\n",
       "         -0.0316, -0.0452, -0.0303, -0.1471,  0.0023,  0.0621,  0.1026,  0.0574,\n",
       "         -0.0471,  0.0352,  0.1195, -0.0455,  0.1271, -0.0214, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0473,  0.1110, -0.1295, -0.0867,  0.0536, -0.0987, -0.0556, -0.0276,\n",
       "           0.1389, -0.0317,  0.0426, -0.0702,  0.0657,  0.0069, -0.0647,  0.0472,\n",
       "          -0.0839, -0.0241,  0.0298,  0.0742, -0.1070,  0.0473, -0.0770, -0.0691,\n",
       "          -0.0572,  0.1244,  0.0732,  0.0980,  0.1056, -0.0168, -0.1165,  0.1269,\n",
       "           0.0099,  0.0520, -0.0959,  0.1080,  0.1146, -0.0668,  0.1604, -0.0477,\n",
       "          -0.1292,  0.0589,  0.1308, -0.0740,  0.0668,  0.1157, -0.0902, -0.0552,\n",
       "          -0.0721, -0.0852]]), 'layers.1.bias': tensor([-0.0696]), 'skip.weight': tensor([[ 0.0133, -0.0123,  0.0147,  0.0137,  0.0139,  0.0132, -0.0153, -0.0134,\n",
       "           0.0097,  0.0132, -0.0156, -0.0110, -0.0157,  0.0123,  0.0143, -0.0126,\n",
       "           0.0128,  0.0129,  0.0147,  0.0144,  0.0095,  0.0128,  0.0170,  0.0131,\n",
       "          -0.0143,  0.0137, -0.0145,  0.0152, -0.0154,  0.0126,  0.0149, -0.0163,\n",
       "           0.0199, -0.0160,  0.0177, -0.0149, -0.0177, -0.0132, -0.0123, -0.0155,\n",
       "          -0.0108, -0.0105,  0.0162, -0.0132,  0.0144,  0.0172, -0.0172, -0.0129,\n",
       "          -0.0191, -0.0115,  0.0151, -0.0114, -0.0146,  0.0105,  0.0141,  0.0134,\n",
       "          -0.0133, -0.0170, -0.0146,  0.0134,  0.0102,  0.0126, -0.0201,  0.0213,\n",
       "           0.0247, -0.0256,  0.0121]])}, objective=4.560517708276997, loss=0.7337071895599365, val_objective=4.5885369577162365, val_loss=0.761726438999176, regularization=0.9731546640396118, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.011024016355655, state_dict={'layers.0.weight': tensor([[-0.0689,  0.0236,  0.0828,  ..., -0.0078,  0.0594,  0.0360],\n",
       "         [-0.1134,  0.0195, -0.0163,  ...,  0.0330, -0.1008, -0.0713],\n",
       "         [-0.0428, -0.0544, -0.0206,  ..., -0.2461, -0.1316, -0.0231],\n",
       "         ...,\n",
       "         [-0.0063, -0.1232, -0.0272,  ..., -0.1648, -0.0589,  0.0389],\n",
       "         [ 0.1215, -0.0225, -0.0936,  ..., -0.0266, -0.0019,  0.1203],\n",
       "         [-0.0402, -0.0233,  0.1319,  ...,  0.0474, -0.0874,  0.1203]]), 'layers.0.bias': tensor([-0.0637,  0.1405,  0.0439,  0.0607,  0.0942,  0.0917,  0.0057, -0.1498,\n",
       "          0.0058, -0.0825,  0.0695,  0.0941,  0.1272,  0.0370, -0.1500, -0.1194,\n",
       "         -0.0709, -0.1007,  0.1484,  0.0029,  0.0589,  0.1514, -0.0961,  0.0528,\n",
       "         -0.0791,  0.1795, -0.0869, -0.0488, -0.0581,  0.1082, -0.0236,  0.0241,\n",
       "         -0.0316, -0.0452, -0.0303, -0.1471,  0.0023,  0.0621,  0.1026,  0.0574,\n",
       "         -0.0471,  0.0352,  0.1196, -0.0455,  0.1270, -0.0215, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0473,  0.1112, -0.1296, -0.0866,  0.0537, -0.0988, -0.0558, -0.0276,\n",
       "           0.1391, -0.0317,  0.0425, -0.0702,  0.0656,  0.0071, -0.0648,  0.0473,\n",
       "          -0.0840, -0.0239,  0.0296,  0.0740, -0.1070,  0.0472, -0.0769, -0.0691,\n",
       "          -0.0572,  0.1243,  0.0730,  0.0980,  0.1058, -0.0169, -0.1164,  0.1270,\n",
       "           0.0099,  0.0521, -0.0958,  0.1081,  0.1145, -0.0670,  0.1606, -0.0477,\n",
       "          -0.1292,  0.0588,  0.1309, -0.0741,  0.0668,  0.1156, -0.0903, -0.0554,\n",
       "          -0.0721, -0.0854]]), 'layers.1.bias': tensor([-0.0694]), 'skip.weight': tensor([[ 0.0132, -0.0123,  0.0147,  0.0136,  0.0139,  0.0131, -0.0152, -0.0133,\n",
       "           0.0097,  0.0132, -0.0155, -0.0109, -0.0156,  0.0123,  0.0143, -0.0125,\n",
       "           0.0127,  0.0129,  0.0147,  0.0143,  0.0095,  0.0128,  0.0170,  0.0130,\n",
       "          -0.0142,  0.0137, -0.0144,  0.0151, -0.0153,  0.0126,  0.0149, -0.0162,\n",
       "           0.0198, -0.0159,  0.0175, -0.0149, -0.0177, -0.0132, -0.0122, -0.0154,\n",
       "          -0.0107, -0.0105,  0.0161, -0.0132,  0.0144,  0.0171, -0.0171, -0.0129,\n",
       "          -0.0190, -0.0115,  0.0150, -0.0114, -0.0145,  0.0105,  0.0141,  0.0134,\n",
       "          -0.0132, -0.0169, -0.0146,  0.0134,  0.0102,  0.0126, -0.0201,  0.0212,\n",
       "           0.0246, -0.0256,  0.0120]])}, objective=4.62135286712142, loss=0.733684241771698, val_objective=4.649346844191275, val_loss=0.7616782188415523, regularization=0.9692459106445312, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.091244496682768, state_dict={'layers.0.weight': tensor([[-0.0689,  0.0236,  0.0828,  ..., -0.0078,  0.0594,  0.0361],\n",
       "         [-0.1134,  0.0196, -0.0163,  ...,  0.0330, -0.1008, -0.0712],\n",
       "         [-0.0429, -0.0544, -0.0207,  ..., -0.2455, -0.1316, -0.0231],\n",
       "         ...,\n",
       "         [-0.0064, -0.1230, -0.0272,  ..., -0.1648, -0.0589,  0.0389],\n",
       "         [ 0.1215, -0.0225, -0.0936,  ..., -0.0266, -0.0019,  0.1198],\n",
       "         [-0.0403, -0.0233,  0.1319,  ...,  0.0473, -0.0874,  0.1198]]), 'layers.0.bias': tensor([-0.0637,  0.1405,  0.0439,  0.0606,  0.0942,  0.0917,  0.0057, -0.1499,\n",
       "          0.0058, -0.0825,  0.0695,  0.0941,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0709, -0.1007,  0.1484,  0.0028,  0.0589,  0.1514, -0.0961,  0.0527,\n",
       "         -0.0792,  0.1795, -0.0870, -0.0488, -0.0581,  0.1082, -0.0236,  0.0241,\n",
       "         -0.0316, -0.0452, -0.0303, -0.1471,  0.0022,  0.0621,  0.1026,  0.0574,\n",
       "         -0.0472,  0.0352,  0.1196, -0.0455,  0.1270, -0.0215, -0.0698, -0.0014,\n",
       "          0.0321,  0.1175]), 'layers.1.weight': tensor([[ 0.0474,  0.1113, -0.1297, -0.0864,  0.0538, -0.0990, -0.0560, -0.0276,\n",
       "           0.1393, -0.0317,  0.0424, -0.0702,  0.0655,  0.0072, -0.0650,  0.0474,\n",
       "          -0.0842, -0.0238,  0.0295,  0.0738, -0.1070,  0.0471, -0.0768, -0.0690,\n",
       "          -0.0572,  0.1243,  0.0729,  0.0981,  0.1059, -0.0170, -0.1164,  0.1271,\n",
       "           0.0099,  0.0522, -0.0957,  0.1083,  0.1144, -0.0671,  0.1607, -0.0476,\n",
       "          -0.1292,  0.0588,  0.1310, -0.0741,  0.0669,  0.1154, -0.0903, -0.0556,\n",
       "          -0.0721, -0.0856]]), 'layers.1.bias': tensor([-0.0693]), 'skip.weight': tensor([[ 0.0132, -0.0123,  0.0147,  0.0136,  0.0138,  0.0130, -0.0152, -0.0133,\n",
       "           0.0097,  0.0131, -0.0155, -0.0109, -0.0155,  0.0122,  0.0142, -0.0125,\n",
       "           0.0127,  0.0128,  0.0146,  0.0143,  0.0094,  0.0128,  0.0169,  0.0130,\n",
       "          -0.0142,  0.0136, -0.0144,  0.0150, -0.0153,  0.0126,  0.0148, -0.0161,\n",
       "           0.0197, -0.0158,  0.0174, -0.0149, -0.0176, -0.0131, -0.0122, -0.0153,\n",
       "          -0.0107, -0.0104,  0.0161, -0.0131,  0.0144,  0.0170, -0.0171, -0.0128,\n",
       "          -0.0189, -0.0115,  0.0150, -0.0113, -0.0145,  0.0105,  0.0141,  0.0133,\n",
       "          -0.0132, -0.0168, -0.0145,  0.0133,  0.0102,  0.0125, -0.0200,  0.0211,\n",
       "           0.0246, -0.0255,  0.0120]])}, objective=4.68332453116018, loss=0.733663022518158, val_objective=4.711290553651635, val_loss=0.761629045009613, regularization=0.9653936624526978, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.173069386616424, state_dict={'layers.0.weight': tensor([[-0.0688,  0.0236,  0.0828,  ..., -0.0077,  0.0594,  0.0361],\n",
       "         [-0.1133,  0.0196, -0.0162,  ...,  0.0330, -0.1009, -0.0711],\n",
       "         [-0.0429, -0.0544, -0.0207,  ..., -0.2449, -0.1315, -0.0232],\n",
       "         ...,\n",
       "         [-0.0064, -0.1227, -0.0272,  ..., -0.1648, -0.0589,  0.0389],\n",
       "         [ 0.1214, -0.0225, -0.0937,  ..., -0.0267, -0.0019,  0.1194],\n",
       "         [-0.0404, -0.0234,  0.1319,  ...,  0.0473, -0.0873,  0.1194]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0438,  0.0606,  0.0942,  0.0916,  0.0057, -0.1499,\n",
       "          0.0058, -0.0825,  0.0695,  0.0941,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0709, -0.1007,  0.1484,  0.0028,  0.0589,  0.1513, -0.0962,  0.0527,\n",
       "         -0.0792,  0.1795, -0.0870, -0.0489, -0.0580,  0.1082, -0.0237,  0.0241,\n",
       "         -0.0316, -0.0452, -0.0303, -0.1471,  0.0022,  0.0621,  0.1026,  0.0573,\n",
       "         -0.0473,  0.0352,  0.1196, -0.0455,  0.1270, -0.0215, -0.0698, -0.0014,\n",
       "          0.0322,  0.1175]), 'layers.1.weight': tensor([[ 0.0475,  0.1114, -0.1298, -0.0862,  0.0539, -0.0991, -0.0562, -0.0276,\n",
       "           0.1394, -0.0317,  0.0424, -0.0703,  0.0654,  0.0074, -0.0652,  0.0475,\n",
       "          -0.0843, -0.0237,  0.0293,  0.0737, -0.1070,  0.0470, -0.0768, -0.0689,\n",
       "          -0.0572,  0.1242,  0.0727,  0.0981,  0.1061, -0.0170, -0.1163,  0.1272,\n",
       "           0.0099,  0.0522, -0.0956,  0.1084,  0.1143, -0.0673,  0.1609, -0.0476,\n",
       "          -0.1292,  0.0587,  0.1311, -0.0742,  0.0669,  0.1153, -0.0904, -0.0559,\n",
       "          -0.0722, -0.0858]]), 'layers.1.bias': tensor([-0.0692]), 'skip.weight': tensor([[ 0.0131, -0.0123,  0.0146,  0.0135,  0.0138,  0.0129, -0.0151, -0.0132,\n",
       "           0.0096,  0.0131, -0.0155, -0.0109, -0.0154,  0.0122,  0.0142, -0.0125,\n",
       "           0.0126,  0.0128,  0.0146,  0.0142,  0.0094,  0.0127,  0.0169,  0.0130,\n",
       "          -0.0141,  0.0135, -0.0143,  0.0149, -0.0152,  0.0125,  0.0148, -0.0160,\n",
       "           0.0196, -0.0157,  0.0173, -0.0149, -0.0175, -0.0131, -0.0122, -0.0152,\n",
       "          -0.0107, -0.0104,  0.0161, -0.0131,  0.0143,  0.0169, -0.0170, -0.0128,\n",
       "          -0.0188, -0.0115,  0.0149, -0.0113, -0.0144,  0.0104,  0.0140,  0.0133,\n",
       "          -0.0131, -0.0167, -0.0145,  0.0133,  0.0101,  0.0125, -0.0199,  0.0210,\n",
       "           0.0245, -0.0255,  0.0119]])}, objective=4.7464584153017935, loss=0.7336410880088806, val_objective=4.774394695075506, val_loss=0.7615773677825928, regularization=0.9615985155105591, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.256530774348753, state_dict={'layers.0.weight': tensor([[-0.0688,  0.0236,  0.0828,  ..., -0.0077,  0.0593,  0.0361],\n",
       "         [-0.1133,  0.0197, -0.0162,  ...,  0.0331, -0.1010, -0.0711],\n",
       "         [-0.0430, -0.0544, -0.0208,  ..., -0.2442, -0.1315, -0.0232],\n",
       "         ...,\n",
       "         [-0.0064, -0.1224, -0.0272,  ..., -0.1648, -0.0589,  0.0388],\n",
       "         [ 0.1213, -0.0225, -0.0937,  ..., -0.0267, -0.0019,  0.1190],\n",
       "         [-0.0404, -0.0234,  0.1318,  ...,  0.0473, -0.0873,  0.1190]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0438,  0.0606,  0.0942,  0.0916,  0.0057, -0.1499,\n",
       "          0.0057, -0.0825,  0.0695,  0.0942,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0709, -0.1007,  0.1484,  0.0027,  0.0589,  0.1513, -0.0962,  0.0527,\n",
       "         -0.0792,  0.1794, -0.0871, -0.0489, -0.0580,  0.1082, -0.0237,  0.0241,\n",
       "         -0.0316, -0.0452, -0.0304, -0.1471,  0.0021,  0.0621,  0.1026,  0.0573,\n",
       "         -0.0473,  0.0352,  0.1197, -0.0455,  0.1270, -0.0216, -0.0698, -0.0014,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0476,  0.1115, -0.1299, -0.0860,  0.0539, -0.0993, -0.0563, -0.0275,\n",
       "           0.1396, -0.0317,  0.0423, -0.0703,  0.0654,  0.0075, -0.0653,  0.0476,\n",
       "          -0.0845, -0.0235,  0.0291,  0.0735, -0.1070,  0.0469, -0.0767, -0.0689,\n",
       "          -0.0572,  0.1241,  0.0726,  0.0981,  0.1062, -0.0171, -0.1163,  0.1273,\n",
       "           0.0099,  0.0523, -0.0955,  0.1086,  0.1142, -0.0675,  0.1611, -0.0476,\n",
       "          -0.1291,  0.0586,  0.1311, -0.0743,  0.0670,  0.1151, -0.0904, -0.0561,\n",
       "          -0.0722, -0.0860]]), 'layers.1.bias': tensor([-0.0690]), 'skip.weight': tensor([[ 0.0130, -0.0122,  0.0146,  0.0135,  0.0137,  0.0128, -0.0151, -0.0131,\n",
       "           0.0096,  0.0130, -0.0154, -0.0108, -0.0153,  0.0121,  0.0141, -0.0124,\n",
       "           0.0126,  0.0128,  0.0145,  0.0142,  0.0094,  0.0127,  0.0169,  0.0129,\n",
       "          -0.0141,  0.0133, -0.0142,  0.0148, -0.0152,  0.0125,  0.0147, -0.0159,\n",
       "           0.0195, -0.0156,  0.0172, -0.0148, -0.0175, -0.0130, -0.0121, -0.0151,\n",
       "          -0.0106, -0.0103,  0.0160, -0.0130,  0.0143,  0.0168, -0.0170, -0.0127,\n",
       "          -0.0187, -0.0114,  0.0149, -0.0113, -0.0143,  0.0104,  0.0140,  0.0132,\n",
       "          -0.0131, -0.0166, -0.0144,  0.0132,  0.0101,  0.0125, -0.0199,  0.0209,\n",
       "           0.0244, -0.0254,  0.0119]])}, objective=4.810471327666739, loss=0.733620822429657, val_objective=4.838377864722708, val_loss=0.7615273594856262, regularization=0.9577871561050415, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.341661389835728, state_dict={'layers.0.weight': tensor([[-0.0687,  0.0236,  0.0828,  ..., -0.0077,  0.0593,  0.0361],\n",
       "         [-0.1132,  0.0197, -0.0162,  ...,  0.0331, -0.1010, -0.0710],\n",
       "         [-0.0430, -0.0545, -0.0208,  ..., -0.2435, -0.1314, -0.0233],\n",
       "         ...,\n",
       "         [-0.0064, -0.1222, -0.0272,  ..., -0.1648, -0.0589,  0.0388],\n",
       "         [ 0.1213, -0.0225, -0.0937,  ..., -0.0267, -0.0018,  0.1185],\n",
       "         [-0.0405, -0.0234,  0.1318,  ...,  0.0473, -0.0872,  0.1185]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0438,  0.0606,  0.0942,  0.0916,  0.0057, -0.1499,\n",
       "          0.0057, -0.0825,  0.0695,  0.0942,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0710, -0.1007,  0.1483,  0.0027,  0.0589,  0.1513, -0.0962,  0.0527,\n",
       "         -0.0792,  0.1794, -0.0871, -0.0489, -0.0579,  0.1082, -0.0237,  0.0242,\n",
       "         -0.0316, -0.0452, -0.0304, -0.1472,  0.0021,  0.0621,  0.1026,  0.0573,\n",
       "         -0.0474,  0.0352,  0.1197, -0.0455,  0.1270, -0.0216, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0476,  0.1116, -0.1300, -0.0859,  0.0540, -0.0995, -0.0565, -0.0275,\n",
       "           0.1398, -0.0317,  0.0422, -0.0703,  0.0653,  0.0077, -0.0655,  0.0477,\n",
       "          -0.0847, -0.0234,  0.0290,  0.0733, -0.1070,  0.0468, -0.0767, -0.0688,\n",
       "          -0.0572,  0.1241,  0.0724,  0.0982,  0.1063, -0.0172, -0.1163,  0.1274,\n",
       "           0.0099,  0.0524, -0.0954,  0.1088,  0.1141, -0.0677,  0.1613, -0.0476,\n",
       "          -0.1291,  0.0585,  0.1312, -0.0743,  0.0670,  0.1150, -0.0905, -0.0563,\n",
       "          -0.0722, -0.0862]]), 'layers.1.bias': tensor([-0.0689]), 'skip.weight': tensor([[ 0.0130, -0.0122,  0.0145,  0.0134,  0.0137,  0.0127, -0.0150, -0.0131,\n",
       "           0.0095,  0.0130, -0.0154, -0.0108, -0.0152,  0.0121,  0.0141, -0.0124,\n",
       "           0.0126,  0.0127,  0.0144,  0.0141,  0.0094,  0.0126,  0.0168,  0.0129,\n",
       "          -0.0140,  0.0133, -0.0142,  0.0146, -0.0151,  0.0125,  0.0147, -0.0158,\n",
       "           0.0194, -0.0155,  0.0171, -0.0148, -0.0174, -0.0130, -0.0121, -0.0150,\n",
       "          -0.0106, -0.0103,  0.0160, -0.0130,  0.0142,  0.0167, -0.0169, -0.0127,\n",
       "          -0.0186, -0.0114,  0.0148, -0.0113, -0.0142,  0.0104,  0.0139,  0.0131,\n",
       "          -0.0130, -0.0165, -0.0144,  0.0132,  0.0101,  0.0124, -0.0198,  0.0208,\n",
       "           0.0244, -0.0254,  0.0119]])}, objective=4.8754582744045125, loss=0.7336015701293945, val_objective=4.903334532300936, val_loss=0.7614778280258179, regularization=0.9539796710014343, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.428494617632443, state_dict={'layers.0.weight': tensor([[-0.0687,  0.0236,  0.0829,  ..., -0.0077,  0.0593,  0.0361],\n",
       "         [-0.1132,  0.0197, -0.0161,  ...,  0.0331, -0.1011, -0.0709],\n",
       "         [-0.0431, -0.0545, -0.0208,  ..., -0.2428, -0.1314, -0.0233],\n",
       "         ...,\n",
       "         [-0.0065, -0.1219, -0.0272,  ..., -0.1649, -0.0588,  0.0388],\n",
       "         [ 0.1212, -0.0225, -0.0938,  ..., -0.0267, -0.0018,  0.1181],\n",
       "         [-0.0406, -0.0235,  0.1318,  ...,  0.0472, -0.0872,  0.1181]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0437,  0.0605,  0.0942,  0.0916,  0.0057, -0.1499,\n",
       "          0.0057, -0.0825,  0.0695,  0.0942,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0710, -0.1007,  0.1483,  0.0026,  0.0588,  0.1513, -0.0963,  0.0526,\n",
       "         -0.0792,  0.1794, -0.0872, -0.0490, -0.0579,  0.1082, -0.0238,  0.0242,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0021,  0.0621,  0.1026,  0.0573,\n",
       "         -0.0475,  0.0352,  0.1197, -0.0455,  0.1270, -0.0216, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0477,  0.1117, -0.1301, -0.0857,  0.0541, -0.0996, -0.0567, -0.0275,\n",
       "           0.1399, -0.0317,  0.0422, -0.0704,  0.0652,  0.0078, -0.0657,  0.0478,\n",
       "          -0.0848, -0.0233,  0.0288,  0.0731, -0.1071,  0.0467, -0.0766, -0.0688,\n",
       "          -0.0572,  0.1240,  0.0723,  0.0982,  0.1065, -0.0172, -0.1162,  0.1275,\n",
       "           0.0099,  0.0524, -0.0953,  0.1089,  0.1140, -0.0678,  0.1615, -0.0475,\n",
       "          -0.1291,  0.0585,  0.1313, -0.0744,  0.0671,  0.1148, -0.0905, -0.0565,\n",
       "          -0.0723, -0.0864]]), 'layers.1.bias': tensor([-0.0688]), 'skip.weight': tensor([[ 0.0129, -0.0122,  0.0145,  0.0134,  0.0136,  0.0126, -0.0150, -0.0130,\n",
       "           0.0095,  0.0129, -0.0153, -0.0108, -0.0151,  0.0120,  0.0140, -0.0123,\n",
       "           0.0125,  0.0127,  0.0144,  0.0141,  0.0093,  0.0126,  0.0168,  0.0128,\n",
       "          -0.0140,  0.0132, -0.0141,  0.0145, -0.0151,  0.0124,  0.0147, -0.0157,\n",
       "           0.0193, -0.0154,  0.0169, -0.0148, -0.0173, -0.0129, -0.0120, -0.0150,\n",
       "          -0.0106, -0.0102,  0.0159, -0.0129,  0.0142,  0.0166, -0.0169, -0.0126,\n",
       "          -0.0185, -0.0114,  0.0147, -0.0112, -0.0142,  0.0103,  0.0139,  0.0131,\n",
       "          -0.0130, -0.0164, -0.0143,  0.0131,  0.0101,  0.0124, -0.0197,  0.0207,\n",
       "           0.0243, -0.0253,  0.0118]])}, objective=4.9414140902988315, loss=0.7335827350616455, val_objective=4.969259472989261, val_loss=0.7614281177520752, regularization=0.950171947479248, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.517064509985092, state_dict={'layers.0.weight': tensor([[-0.0687,  0.0236,  0.0829,  ..., -0.0077,  0.0593,  0.0361],\n",
       "         [-0.1131,  0.0198, -0.0161,  ...,  0.0331, -0.1012, -0.0709],\n",
       "         [-0.0431, -0.0545, -0.0209,  ..., -0.2422, -0.1313, -0.0233],\n",
       "         ...,\n",
       "         [-0.0065, -0.1216, -0.0272,  ..., -0.1649, -0.0588,  0.0388],\n",
       "         [ 0.1211, -0.0225, -0.0938,  ..., -0.0267, -0.0018,  0.1176],\n",
       "         [-0.0407, -0.0235,  0.1317,  ...,  0.0472, -0.0871,  0.1176]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0437,  0.0605,  0.0942,  0.0915,  0.0057, -0.1499,\n",
       "          0.0057, -0.0825,  0.0695,  0.0942,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0710, -0.1007,  0.1483,  0.0026,  0.0588,  0.1513, -0.0963,  0.0526,\n",
       "         -0.0792,  0.1794, -0.0873, -0.0490, -0.0578,  0.1082, -0.0238,  0.0242,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0020,  0.0621,  0.1026,  0.0572,\n",
       "         -0.0475,  0.0352,  0.1198, -0.0455,  0.1269, -0.0217, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0478,  0.1119, -0.1302, -0.0855,  0.0542, -0.0998, -0.0569, -0.0275,\n",
       "           0.1401, -0.0317,  0.0421, -0.0704,  0.0651,  0.0079, -0.0658,  0.0479,\n",
       "          -0.0850, -0.0231,  0.0287,  0.0729, -0.1071,  0.0466, -0.0765, -0.0687,\n",
       "          -0.0572,  0.1240,  0.0722,  0.0982,  0.1066, -0.0173, -0.1162,  0.1276,\n",
       "           0.0099,  0.0525, -0.0952,  0.1091,  0.1139, -0.0680,  0.1616, -0.0475,\n",
       "          -0.1291,  0.0584,  0.1314, -0.0745,  0.0671,  0.1147, -0.0906, -0.0567,\n",
       "          -0.0723, -0.0866]]), 'layers.1.bias': tensor([-0.0686]), 'skip.weight': tensor([[ 0.0128, -0.0122,  0.0144,  0.0133,  0.0136,  0.0125, -0.0149, -0.0130,\n",
       "           0.0095,  0.0129, -0.0153, -0.0107, -0.0150,  0.0120,  0.0140, -0.0123,\n",
       "           0.0125,  0.0127,  0.0143,  0.0140,  0.0093,  0.0126,  0.0167,  0.0128,\n",
       "          -0.0139,  0.0131, -0.0140,  0.0144, -0.0150,  0.0124,  0.0146, -0.0156,\n",
       "           0.0193, -0.0153,  0.0168, -0.0147, -0.0172, -0.0129, -0.0120, -0.0149,\n",
       "          -0.0105, -0.0102,  0.0159, -0.0129,  0.0142,  0.0165, -0.0168, -0.0126,\n",
       "          -0.0184, -0.0114,  0.0147, -0.0112, -0.0141,  0.0103,  0.0138,  0.0130,\n",
       "          -0.0130, -0.0164, -0.0143,  0.0131,  0.0100,  0.0124, -0.0197,  0.0206,\n",
       "           0.0242, -0.0253,  0.0118]])}, objective=5.008304399926814, loss=0.7335651516914368, val_objective=5.0361167020393935, val_loss=0.7613774538040161, regularization=0.9463533759117126, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.607405800184794, state_dict={'layers.0.weight': tensor([[-0.0686,  0.0237,  0.0829,  ..., -0.0076,  0.0592,  0.0362],\n",
       "         [-0.1131,  0.0198, -0.0161,  ...,  0.0332, -0.1012, -0.0708],\n",
       "         [-0.0432, -0.0546, -0.0209,  ..., -0.2417, -0.1313, -0.0234],\n",
       "         ...,\n",
       "         [-0.0065, -0.1213, -0.0272,  ..., -0.1649, -0.0588,  0.0388],\n",
       "         [ 0.1211, -0.0225, -0.0938,  ..., -0.0268, -0.0017,  0.1172],\n",
       "         [-0.0407, -0.0235,  0.1317,  ...,  0.0472, -0.0871,  0.1172]]), 'layers.0.bias': tensor([-0.0637,  0.1404,  0.0437,  0.0605,  0.0942,  0.0915,  0.0057, -0.1499,\n",
       "          0.0056, -0.0825,  0.0695,  0.0943,  0.1272,  0.0370, -0.1500, -0.1195,\n",
       "         -0.0710, -0.1007,  0.1483,  0.0025,  0.0588,  0.1513, -0.0963,  0.0526,\n",
       "         -0.0792,  0.1794, -0.0873, -0.0490, -0.0578,  0.1082, -0.0239,  0.0242,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0020,  0.0621,  0.1026,  0.0572,\n",
       "         -0.0476,  0.0352,  0.1198, -0.0455,  0.1269, -0.0217, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0479,  0.1120, -0.1303, -0.0854,  0.0542, -0.0999, -0.0570, -0.0275,\n",
       "           0.1403, -0.0317,  0.0420, -0.0704,  0.0650,  0.0080, -0.0660,  0.0480,\n",
       "          -0.0851, -0.0230,  0.0285,  0.0728, -0.1071,  0.0465, -0.0765, -0.0687,\n",
       "          -0.0572,  0.1239,  0.0721,  0.0983,  0.1067, -0.0174, -0.1162,  0.1277,\n",
       "           0.0099,  0.0525, -0.0952,  0.1092,  0.1138, -0.0682,  0.1618, -0.0475,\n",
       "          -0.1290,  0.0583,  0.1314, -0.0745,  0.0672,  0.1145, -0.0906, -0.0569,\n",
       "          -0.0724, -0.0868]]), 'layers.1.bias': tensor([-0.0685]), 'skip.weight': tensor([[ 0.0128, -0.0121,  0.0143,  0.0133,  0.0135,  0.0124, -0.0148, -0.0129,\n",
       "           0.0094,  0.0128, -0.0152, -0.0107, -0.0148,  0.0119,  0.0139, -0.0122,\n",
       "           0.0124,  0.0127,  0.0143,  0.0140,  0.0093,  0.0125,  0.0167,  0.0127,\n",
       "          -0.0139,  0.0130, -0.0139,  0.0143, -0.0149,  0.0124,  0.0146, -0.0155,\n",
       "           0.0192, -0.0152,  0.0167, -0.0147, -0.0172, -0.0128, -0.0120, -0.0148,\n",
       "          -0.0105, -0.0101,  0.0158, -0.0128,  0.0141,  0.0164, -0.0168, -0.0125,\n",
       "          -0.0183, -0.0113,  0.0146, -0.0112, -0.0140,  0.0103,  0.0138,  0.0130,\n",
       "          -0.0129, -0.0163, -0.0142,  0.0130,  0.0100,  0.0123, -0.0196,  0.0205,\n",
       "           0.0242, -0.0252,  0.0117]])}, objective=5.07618834396225, loss=0.7335491180419922, val_objective=5.103965717752991, val_loss=0.7613264918327332, regularization=0.9425345659255981, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.69955391618849, state_dict={'layers.0.weight': tensor([[-0.0686,  0.0237,  0.0829,  ..., -0.0076,  0.0592,  0.0362],\n",
       "         [-0.1130,  0.0199, -0.0161,  ...,  0.0332, -0.1013, -0.0708],\n",
       "         [-0.0432, -0.0546, -0.0209,  ..., -0.2411, -0.1313, -0.0234],\n",
       "         ...,\n",
       "         [-0.0065, -0.1210, -0.0272,  ..., -0.1649, -0.0588,  0.0387],\n",
       "         [ 0.1210, -0.0225, -0.0939,  ..., -0.0268, -0.0017,  0.1167],\n",
       "         [-0.0408, -0.0236,  0.1317,  ...,  0.0471, -0.0870,  0.1167]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0436,  0.0605,  0.0942,  0.0915,  0.0056, -0.1499,\n",
       "          0.0056, -0.0825,  0.0695,  0.0943,  0.1272,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0710, -0.1007,  0.1483,  0.0025,  0.0588,  0.1512, -0.0964,  0.0526,\n",
       "         -0.0792,  0.1794, -0.0874, -0.0490, -0.0577,  0.1081, -0.0239,  0.0242,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0019,  0.0621,  0.1026,  0.0572,\n",
       "         -0.0477,  0.0352,  0.1199, -0.0455,  0.1269, -0.0217, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0480,  0.1121, -0.1304, -0.0852,  0.0543, -0.1001, -0.0572, -0.0274,\n",
       "           0.1404, -0.0318,  0.0420, -0.0705,  0.0649,  0.0082, -0.0661,  0.0482,\n",
       "          -0.0853, -0.0229,  0.0284,  0.0726, -0.1071,  0.0464, -0.0764, -0.0686,\n",
       "          -0.0572,  0.1239,  0.0719,  0.0983,  0.1068, -0.0175, -0.1161,  0.1279,\n",
       "           0.0099,  0.0526, -0.0951,  0.1094,  0.1137, -0.0684,  0.1620, -0.0475,\n",
       "          -0.1290,  0.0583,  0.1315, -0.0746,  0.0672,  0.1144, -0.0907, -0.0571,\n",
       "          -0.0724, -0.0869]]), 'layers.1.bias': tensor([-0.0684]), 'skip.weight': tensor([[ 0.0127, -0.0121,  0.0143,  0.0132,  0.0135,  0.0123, -0.0148, -0.0129,\n",
       "           0.0094,  0.0128, -0.0152, -0.0106, -0.0147,  0.0119,  0.0138, -0.0122,\n",
       "           0.0124,  0.0126,  0.0142,  0.0139,  0.0092,  0.0125,  0.0166,  0.0127,\n",
       "          -0.0138,  0.0130, -0.0139,  0.0143, -0.0149,  0.0123,  0.0145, -0.0154,\n",
       "           0.0191, -0.0151,  0.0166, -0.0147, -0.0171, -0.0128, -0.0119, -0.0148,\n",
       "          -0.0105, -0.0101,  0.0158, -0.0128,  0.0141,  0.0163, -0.0167, -0.0124,\n",
       "          -0.0182, -0.0113,  0.0145, -0.0111, -0.0139,  0.0102,  0.0138,  0.0129,\n",
       "          -0.0129, -0.0162, -0.0142,  0.0130,  0.0100,  0.0123, -0.0195,  0.0204,\n",
       "           0.0241, -0.0252,  0.0117]])}, objective=5.14489505918628, loss=0.7335354685783386, val_objective=5.172635299283326, val_loss=0.7612757086753845, regularization=0.9386762380599976, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.79354499451226, state_dict={'layers.0.weight': tensor([[-0.0686,  0.0237,  0.0829,  ..., -0.0076,  0.0592,  0.0362],\n",
       "         [-0.1130,  0.0199, -0.0160,  ...,  0.0332, -0.1013, -0.0707],\n",
       "         [-0.0432, -0.0546, -0.0210,  ..., -0.2406, -0.1312, -0.0235],\n",
       "         ...,\n",
       "         [-0.0066, -0.1207, -0.0272,  ..., -0.1649, -0.0588,  0.0387],\n",
       "         [ 0.1209, -0.0226, -0.0939,  ..., -0.0268, -0.0017,  0.1162],\n",
       "         [-0.0409, -0.0236,  0.1317,  ...,  0.0471, -0.0870,  0.1162]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0436,  0.0605,  0.0942,  0.0915,  0.0056, -0.1500,\n",
       "          0.0056, -0.0825,  0.0695,  0.0943,  0.1272,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1007,  0.1483,  0.0025,  0.0588,  0.1512, -0.0964,  0.0525,\n",
       "         -0.0792,  0.1794, -0.0875, -0.0491, -0.0577,  0.1081, -0.0239,  0.0243,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0019,  0.0621,  0.1026,  0.0572,\n",
       "         -0.0477,  0.0352,  0.1199, -0.0455,  0.1269, -0.0218, -0.0698, -0.0013,\n",
       "          0.0322,  0.1174]), 'layers.1.weight': tensor([[ 0.0481,  0.1122, -0.1305, -0.0851,  0.0544, -0.1002, -0.0574, -0.0274,\n",
       "           0.1406, -0.0318,  0.0419, -0.0705,  0.0648,  0.0083, -0.0663,  0.0483,\n",
       "          -0.0855, -0.0228,  0.0282,  0.0724, -0.1072,  0.0463, -0.0763, -0.0685,\n",
       "          -0.0572,  0.1238,  0.0718,  0.0983,  0.1070, -0.0176, -0.1161,  0.1280,\n",
       "           0.0100,  0.0526, -0.0950,  0.1096,  0.1136, -0.0686,  0.1622, -0.0475,\n",
       "          -0.1290,  0.0582,  0.1316, -0.0747,  0.0673,  0.1143, -0.0908, -0.0573,\n",
       "          -0.0725, -0.0871]]), 'layers.1.bias': tensor([-0.0682]), 'skip.weight': tensor([[ 0.0126, -0.0121,  0.0142,  0.0132,  0.0134,  0.0122, -0.0147, -0.0128,\n",
       "           0.0093,  0.0127, -0.0151, -0.0106, -0.0146,  0.0119,  0.0138, -0.0121,\n",
       "           0.0123,  0.0126,  0.0142,  0.0139,  0.0092,  0.0124,  0.0166,  0.0126,\n",
       "          -0.0138,  0.0129, -0.0138,  0.0142, -0.0148,  0.0123,  0.0145, -0.0153,\n",
       "           0.0190, -0.0149,  0.0165, -0.0147, -0.0170, -0.0127, -0.0119, -0.0147,\n",
       "          -0.0104, -0.0101,  0.0157, -0.0127,  0.0141,  0.0162, -0.0166, -0.0124,\n",
       "          -0.0181, -0.0113,  0.0145, -0.0111, -0.0139,  0.0102,  0.0137,  0.0129,\n",
       "          -0.0128, -0.0161, -0.0141,  0.0129,  0.0100,  0.0123, -0.0194,  0.0204,\n",
       "           0.0241, -0.0251,  0.0116]])}, objective=5.21472556957901, loss=0.7335212826728821, val_objective=5.24243290791214, val_loss=0.761228621006012, regularization=0.9348413944244385, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.8894158944025055, state_dict={'layers.0.weight': tensor([[-0.0685,  0.0237,  0.0829,  ..., -0.0076,  0.0592,  0.0362],\n",
       "         [-0.1129,  0.0199, -0.0160,  ...,  0.0332, -0.1014, -0.0706],\n",
       "         [-0.0433, -0.0546, -0.0210,  ..., -0.2400, -0.1312, -0.0235],\n",
       "         ...,\n",
       "         [-0.0066, -0.1204, -0.0273,  ..., -0.1649, -0.0588,  0.0387],\n",
       "         [ 0.1209, -0.0226, -0.0939,  ..., -0.0268, -0.0016,  0.1157],\n",
       "         [-0.0410, -0.0236,  0.1316,  ...,  0.0471, -0.0869,  0.1157]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0436,  0.0605,  0.0942,  0.0915,  0.0056, -0.1500,\n",
       "          0.0055, -0.0826,  0.0695,  0.0943,  0.1272,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1007,  0.1483,  0.0024,  0.0588,  0.1512, -0.0964,  0.0525,\n",
       "         -0.0793,  0.1794, -0.0875, -0.0491, -0.0576,  0.1081, -0.0240,  0.0243,\n",
       "         -0.0316, -0.0451, -0.0304, -0.1472,  0.0018,  0.0621,  0.1026,  0.0571,\n",
       "         -0.0478,  0.0352,  0.1199, -0.0455,  0.1269, -0.0218, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0481,  0.1123, -0.1306, -0.0849,  0.0545, -0.1003, -0.0575, -0.0274,\n",
       "           0.1408, -0.0318,  0.0419, -0.0706,  0.0647,  0.0084, -0.0665,  0.0484,\n",
       "          -0.0856, -0.0226,  0.0281,  0.0723, -0.1072,  0.0462, -0.0763, -0.0685,\n",
       "          -0.0572,  0.1238,  0.0717,  0.0984,  0.1071, -0.0177, -0.1161,  0.1281,\n",
       "           0.0100,  0.0527, -0.0949,  0.1097,  0.1135, -0.0688,  0.1623, -0.0475,\n",
       "          -0.1290,  0.0581,  0.1317, -0.0748,  0.0673,  0.1141, -0.0908, -0.0575,\n",
       "          -0.0725, -0.0873]]), 'layers.1.bias': tensor([-0.0681]), 'skip.weight': tensor([[ 0.0126, -0.0120,  0.0142,  0.0131,  0.0134,  0.0120, -0.0147, -0.0128,\n",
       "           0.0093,  0.0126, -0.0151, -0.0106, -0.0145,  0.0118,  0.0137, -0.0121,\n",
       "           0.0123,  0.0125,  0.0141,  0.0138,  0.0092,  0.0124,  0.0165,  0.0126,\n",
       "          -0.0137,  0.0128, -0.0137,  0.0141, -0.0148,  0.0123,  0.0144, -0.0152,\n",
       "           0.0190, -0.0148,  0.0164, -0.0146, -0.0169, -0.0126, -0.0118, -0.0147,\n",
       "          -0.0104, -0.0100,  0.0157, -0.0127,  0.0140,  0.0160, -0.0166, -0.0123,\n",
       "          -0.0180, -0.0112,  0.0144, -0.0111, -0.0138,  0.0102,  0.0137,  0.0128,\n",
       "          -0.0128, -0.0161, -0.0140,  0.0129,  0.0099,  0.0122, -0.0194,  0.0203,\n",
       "           0.0240, -0.0251,  0.0116]])}, objective=5.285352324043985, loss=0.7335084080696106, val_objective=5.313024972473856, val_loss=0.7611810564994812, regularization=0.93095862865448, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=4.987204212290556, state_dict={'layers.0.weight': tensor([[-0.0685,  0.0237,  0.0829,  ..., -0.0076,  0.0591,  0.0362],\n",
       "         [-0.1129,  0.0200, -0.0160,  ...,  0.0332, -0.1015, -0.0706],\n",
       "         [-0.0433, -0.0547, -0.0210,  ..., -0.2394, -0.1311, -0.0235],\n",
       "         ...,\n",
       "         [-0.0066, -0.1201, -0.0273,  ..., -0.1649, -0.0587,  0.0387],\n",
       "         [ 0.1208, -0.0226, -0.0940,  ..., -0.0269, -0.0016,  0.1152],\n",
       "         [-0.0411, -0.0237,  0.1316,  ...,  0.0470, -0.0869,  0.1152]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0435,  0.0604,  0.0942,  0.0914,  0.0056, -0.1500,\n",
       "          0.0055, -0.0826,  0.0695,  0.0943,  0.1271,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1007,  0.1483,  0.0024,  0.0588,  0.1512, -0.0965,  0.0525,\n",
       "         -0.0793,  0.1794, -0.0876, -0.0491, -0.0576,  0.1081, -0.0240,  0.0243,\n",
       "         -0.0316, -0.0451, -0.0305, -0.1473,  0.0018,  0.0621,  0.1026,  0.0571,\n",
       "         -0.0479,  0.0352,  0.1200, -0.0455,  0.1269, -0.0218, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0482,  0.1125, -0.1307, -0.0848,  0.0545, -0.1005, -0.0577, -0.0274,\n",
       "           0.1409, -0.0318,  0.0418, -0.0706,  0.0646,  0.0085, -0.0666,  0.0485,\n",
       "          -0.0858, -0.0225,  0.0280,  0.0721, -0.1072,  0.0461, -0.0762, -0.0684,\n",
       "          -0.0572,  0.1237,  0.0716,  0.0984,  0.1072, -0.0177, -0.1161,  0.1282,\n",
       "           0.0100,  0.0527, -0.0948,  0.1099,  0.1134, -0.0690,  0.1625, -0.0475,\n",
       "          -0.1290,  0.0581,  0.1318, -0.0749,  0.0674,  0.1140, -0.0909, -0.0577,\n",
       "          -0.0726, -0.0875]]), 'layers.1.bias': tensor([-0.0680]), 'skip.weight': tensor([[ 0.0125, -0.0120,  0.0141,  0.0131,  0.0134,  0.0119, -0.0146, -0.0127,\n",
       "           0.0093,  0.0126, -0.0150, -0.0105, -0.0144,  0.0118,  0.0137, -0.0120,\n",
       "           0.0122,  0.0125,  0.0141,  0.0138,  0.0092,  0.0123,  0.0165,  0.0125,\n",
       "          -0.0137,  0.0127, -0.0136,  0.0140, -0.0147,  0.0123,  0.0144, -0.0151,\n",
       "           0.0189, -0.0147,  0.0163, -0.0146, -0.0169, -0.0126, -0.0118, -0.0146,\n",
       "          -0.0104, -0.0100,  0.0156, -0.0126,  0.0140,  0.0159, -0.0165, -0.0122,\n",
       "          -0.0179, -0.0112,  0.0143, -0.0110, -0.0137,  0.0101,  0.0137,  0.0128,\n",
       "          -0.0127, -0.0160, -0.0140,  0.0128,  0.0099,  0.0122, -0.0193,  0.0202,\n",
       "           0.0239, -0.0250,  0.0115]])}, objective=5.3569847774337696, loss=0.7334966659545898, val_objective=5.384622914774315, val_loss=0.7611348032951355, regularization=0.927070140838623, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.0869482965363675, state_dict={'layers.0.weight': tensor([[-0.0685,  0.0237,  0.0829,  ..., -0.0075,  0.0591,  0.0362],\n",
       "         [-0.1128,  0.0200, -0.0159,  ...,  0.0332, -0.1015, -0.0705],\n",
       "         [-0.0434, -0.0547, -0.0211,  ..., -0.2388, -0.1311, -0.0236],\n",
       "         ...,\n",
       "         [-0.0066, -0.1199, -0.0273,  ..., -0.1650, -0.0587,  0.0387],\n",
       "         [ 0.1208, -0.0226, -0.0940,  ..., -0.0269, -0.0016,  0.1147],\n",
       "         [-0.0411, -0.0237,  0.1316,  ...,  0.0470, -0.0868,  0.1147]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0435,  0.0604,  0.0942,  0.0914,  0.0056, -0.1500,\n",
       "          0.0055, -0.0826,  0.0695,  0.0944,  0.1271,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1008,  0.1483,  0.0023,  0.0588,  0.1512, -0.0965,  0.0525,\n",
       "         -0.0793,  0.1794, -0.0876, -0.0492, -0.0575,  0.1081, -0.0240,  0.0243,\n",
       "         -0.0316, -0.0451, -0.0305, -0.1473,  0.0018,  0.0621,  0.1026,  0.0571,\n",
       "         -0.0479,  0.0352,  0.1200, -0.0455,  0.1269, -0.0219, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0483,  0.1126, -0.1308, -0.0847,  0.0546, -0.1006, -0.0578, -0.0274,\n",
       "           0.1411, -0.0318,  0.0418, -0.0707,  0.0646,  0.0086, -0.0668,  0.0487,\n",
       "          -0.0859, -0.0224,  0.0278,  0.0720, -0.1073,  0.0461, -0.0761, -0.0684,\n",
       "          -0.0572,  0.1237,  0.0715,  0.0985,  0.1073, -0.0178, -0.1161,  0.1283,\n",
       "           0.0100,  0.0528, -0.0948,  0.1101,  0.1133, -0.0692,  0.1627, -0.0475,\n",
       "          -0.1289,  0.0580,  0.1318, -0.0749,  0.0674,  0.1139, -0.0909, -0.0579,\n",
       "          -0.0727, -0.0877]]), 'layers.1.bias': tensor([-0.0678]), 'skip.weight': tensor([[ 0.0124, -0.0120,  0.0141,  0.0130,  0.0133,  0.0118, -0.0145, -0.0127,\n",
       "           0.0092,  0.0125, -0.0150, -0.0105, -0.0143,  0.0117,  0.0136, -0.0120,\n",
       "           0.0122,  0.0125,  0.0140,  0.0137,  0.0091,  0.0123,  0.0164,  0.0125,\n",
       "          -0.0136,  0.0127, -0.0136,  0.0139, -0.0146,  0.0122,  0.0144, -0.0151,\n",
       "           0.0188, -0.0146,  0.0161, -0.0146, -0.0168, -0.0125, -0.0118, -0.0146,\n",
       "          -0.0103, -0.0099,  0.0156, -0.0126,  0.0140,  0.0158, -0.0164, -0.0122,\n",
       "          -0.0177, -0.0112,  0.0142, -0.0110, -0.0136,  0.0101,  0.0136,  0.0127,\n",
       "          -0.0127, -0.0159, -0.0139,  0.0127,  0.0099,  0.0122, -0.0192,  0.0201,\n",
       "           0.0239, -0.0250,  0.0115]])}, objective=5.42985804647215, loss=0.7334863543510437, val_objective=5.457462149560529, val_loss=0.7610904574394226, regularization=0.9232198596000671, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.188687262467095, state_dict={'layers.0.weight': tensor([[-0.0684,  0.0237,  0.0829,  ..., -0.0075,  0.0591,  0.0362],\n",
       "         [-0.1127,  0.0201, -0.0159,  ...,  0.0333, -0.1016, -0.0705],\n",
       "         [-0.0434, -0.0547, -0.0211,  ..., -0.2383, -0.1310, -0.0236],\n",
       "         ...,\n",
       "         [-0.0066, -0.1196, -0.0273,  ..., -0.1650, -0.0587,  0.0386],\n",
       "         [ 0.1207, -0.0226, -0.0940,  ..., -0.0269, -0.0016,  0.1142],\n",
       "         [-0.0412, -0.0237,  0.1316,  ...,  0.0470, -0.0868,  0.1142]]), 'layers.0.bias': tensor([-0.0637,  0.1403,  0.0435,  0.0604,  0.0942,  0.0914,  0.0056, -0.1500,\n",
       "          0.0055, -0.0826,  0.0695,  0.0944,  0.1271,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1008,  0.1483,  0.0023,  0.0587,  0.1512, -0.0965,  0.0524,\n",
       "         -0.0793,  0.1794, -0.0877, -0.0492, -0.0575,  0.1081, -0.0240,  0.0243,\n",
       "         -0.0316, -0.0451, -0.0305, -0.1473,  0.0017,  0.0621,  0.1026,  0.0571,\n",
       "         -0.0480,  0.0352,  0.1201, -0.0455,  0.1268, -0.0219, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0484,  0.1127, -0.1309, -0.0845,  0.0547, -0.1008, -0.0580, -0.0274,\n",
       "           0.1412, -0.0318,  0.0417, -0.0707,  0.0645,  0.0086, -0.0670,  0.0488,\n",
       "          -0.0861, -0.0223,  0.0277,  0.0718, -0.1073,  0.0460, -0.0761, -0.0683,\n",
       "          -0.0572,  0.1236,  0.0714,  0.0985,  0.1075, -0.0179, -0.1161,  0.1284,\n",
       "           0.0100,  0.0528, -0.0947,  0.1102,  0.1132, -0.0694,  0.1628, -0.0475,\n",
       "          -0.1289,  0.0579,  0.1319, -0.0750,  0.0675,  0.1137, -0.0910, -0.0581,\n",
       "          -0.0727, -0.0878]]), 'layers.1.bias': tensor([-0.0677]), 'skip.weight': tensor([[ 0.0124, -0.0120,  0.0140,  0.0129,  0.0133,  0.0117, -0.0145, -0.0126,\n",
       "           0.0092,  0.0124, -0.0149, -0.0104, -0.0142,  0.0117,  0.0135, -0.0120,\n",
       "           0.0121,  0.0124,  0.0140,  0.0136,  0.0091,  0.0122,  0.0164,  0.0124,\n",
       "          -0.0136,  0.0126, -0.0135,  0.0139, -0.0146,  0.0122,  0.0143, -0.0150,\n",
       "           0.0187, -0.0144,  0.0160, -0.0145, -0.0167, -0.0124, -0.0117, -0.0145,\n",
       "          -0.0103, -0.0099,  0.0156, -0.0125,  0.0139,  0.0157, -0.0164, -0.0121,\n",
       "          -0.0176, -0.0111,  0.0142, -0.0110, -0.0135,  0.0101,  0.0136,  0.0127,\n",
       "          -0.0126, -0.0158, -0.0139,  0.0127,  0.0098,  0.0121, -0.0191,  0.0200,\n",
       "           0.0238, -0.0249,  0.0114]])}, objective=5.503555596645604, loss=0.733477771282196, val_objective=5.531126023109684, val_loss=0.7610481977462769, regularization=0.919322669506073, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.292461007716437, state_dict={'layers.0.weight': tensor([[-0.0684,  0.0237,  0.0829,  ..., -0.0075,  0.0590,  0.0363],\n",
       "         [-0.1127,  0.0201, -0.0159,  ...,  0.0333, -0.1017, -0.0704],\n",
       "         [-0.0434, -0.0547, -0.0211,  ..., -0.2378, -0.1310, -0.0236],\n",
       "         ...,\n",
       "         [-0.0066, -0.1193, -0.0273,  ..., -0.1650, -0.0587,  0.0386],\n",
       "         [ 0.1206, -0.0226, -0.0940,  ..., -0.0269, -0.0015,  0.1136],\n",
       "         [-0.0413, -0.0238,  0.1315,  ...,  0.0470, -0.0867,  0.1136]]), 'layers.0.bias': tensor([-0.0637,  0.1402,  0.0435,  0.0604,  0.0942,  0.0914,  0.0056, -0.1500,\n",
       "          0.0054, -0.0826,  0.0695,  0.0944,  0.1271,  0.0370, -0.1501, -0.1195,\n",
       "         -0.0711, -0.1008,  0.1483,  0.0022,  0.0587,  0.1512, -0.0965,  0.0524,\n",
       "         -0.0793,  0.1794, -0.0877, -0.0492, -0.0574,  0.1081, -0.0241,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0305, -0.1473,  0.0017,  0.0621,  0.1026,  0.0570,\n",
       "         -0.0481,  0.0352,  0.1201, -0.0455,  0.1268, -0.0219, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0485,  0.1129, -0.1310, -0.0844,  0.0548, -0.1009, -0.0582, -0.0274,\n",
       "           0.1414, -0.0319,  0.0417, -0.0708,  0.0644,  0.0087, -0.0671,  0.0489,\n",
       "          -0.0863, -0.0221,  0.0275,  0.0716, -0.1073,  0.0459, -0.0760, -0.0683,\n",
       "          -0.0572,  0.1236,  0.0713,  0.0986,  0.1076, -0.0180, -0.1161,  0.1285,\n",
       "           0.0100,  0.0528, -0.0946,  0.1104,  0.1131, -0.0696,  0.1630, -0.0475,\n",
       "          -0.1289,  0.0579,  0.1320, -0.0751,  0.0675,  0.1136, -0.0910, -0.0583,\n",
       "          -0.0728, -0.0880]]), 'layers.1.bias': tensor([-0.0675]), 'skip.weight': tensor([[ 0.0123, -0.0119,  0.0140,  0.0129,  0.0133,  0.0115, -0.0144, -0.0126,\n",
       "           0.0092,  0.0124, -0.0149, -0.0104, -0.0141,  0.0116,  0.0135, -0.0119,\n",
       "           0.0121,  0.0124,  0.0139,  0.0136,  0.0091,  0.0122,  0.0163,  0.0124,\n",
       "          -0.0136,  0.0126, -0.0134,  0.0138, -0.0145,  0.0122,  0.0143, -0.0149,\n",
       "           0.0186, -0.0143,  0.0159, -0.0145, -0.0166, -0.0124, -0.0117, -0.0145,\n",
       "          -0.0103, -0.0099,  0.0155, -0.0125,  0.0139,  0.0155, -0.0163, -0.0121,\n",
       "          -0.0175, -0.0111,  0.0141, -0.0109, -0.0135,  0.0100,  0.0136,  0.0126,\n",
       "          -0.0126, -0.0158, -0.0138,  0.0126,  0.0098,  0.0121, -0.0190,  0.0199,\n",
       "           0.0238, -0.0248,  0.0114]])}, objective=5.5779798390138655, loss=0.7334709763526917, val_objective=5.605516708062938, val_loss=0.7610078454017639, regularization=0.9153603315353394, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.398310227870765, state_dict={'layers.0.weight': tensor([[-0.0684,  0.0237,  0.0829,  ..., -0.0075,  0.0590,  0.0363],\n",
       "         [-0.1126,  0.0202, -0.0158,  ...,  0.0333, -0.1017, -0.0703],\n",
       "         [-0.0435, -0.0548, -0.0212,  ..., -0.2373, -0.1309, -0.0237],\n",
       "         ...,\n",
       "         [-0.0067, -0.1191, -0.0273,  ..., -0.1650, -0.0587,  0.0386],\n",
       "         [ 0.1206, -0.0226, -0.0941,  ..., -0.0270, -0.0015,  0.1131],\n",
       "         [-0.0414, -0.0238,  0.1315,  ...,  0.0469, -0.0867,  0.1131]]), 'layers.0.bias': tensor([-0.0637,  0.1402,  0.0434,  0.0604,  0.0942,  0.0913,  0.0055, -0.1500,\n",
       "          0.0054, -0.0826,  0.0695,  0.0944,  0.1271,  0.0370, -0.1502, -0.1195,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0022,  0.0587,  0.1512, -0.0966,  0.0524,\n",
       "         -0.0793,  0.1794, -0.0878, -0.0492, -0.0574,  0.1081, -0.0241,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0305, -0.1473,  0.0016,  0.0621,  0.1026,  0.0570,\n",
       "         -0.0482,  0.0352,  0.1201, -0.0455,  0.1268, -0.0220, -0.0698, -0.0012,\n",
       "          0.0322,  0.1173]), 'layers.1.weight': tensor([[ 0.0486,  0.1130, -0.1311, -0.0843,  0.0548, -0.1011, -0.0583, -0.0274,\n",
       "           0.1416, -0.0319,  0.0416, -0.0708,  0.0643,  0.0088, -0.0673,  0.0491,\n",
       "          -0.0864, -0.0220,  0.0274,  0.0715, -0.1074,  0.0459, -0.0760, -0.0683,\n",
       "          -0.0573,  0.1236,  0.0712,  0.0986,  0.1077, -0.0181, -0.1161,  0.1286,\n",
       "           0.0100,  0.0529, -0.0945,  0.1106,  0.1130, -0.0698,  0.1632, -0.0476,\n",
       "          -0.1289,  0.0578,  0.1321, -0.0752,  0.0676,  0.1135, -0.0911, -0.0585,\n",
       "          -0.0729, -0.0882]]), 'layers.1.bias': tensor([-0.0674]), 'skip.weight': tensor([[ 0.0123, -0.0119,  0.0139,  0.0128,  0.0132,  0.0114, -0.0144, -0.0126,\n",
       "           0.0091,  0.0123, -0.0148, -0.0103, -0.0140,  0.0116,  0.0134, -0.0119,\n",
       "           0.0120,  0.0124,  0.0138,  0.0135,  0.0091,  0.0121,  0.0163,  0.0123,\n",
       "          -0.0135,  0.0125, -0.0134,  0.0137, -0.0145,  0.0121,  0.0143, -0.0148,\n",
       "           0.0185, -0.0142,  0.0157, -0.0145, -0.0165, -0.0123, -0.0117, -0.0144,\n",
       "          -0.0102, -0.0098,  0.0154, -0.0124,  0.0138,  0.0154, -0.0163, -0.0120,\n",
       "          -0.0174, -0.0111,  0.0140, -0.0109, -0.0134,  0.0100,  0.0135,  0.0126,\n",
       "          -0.0125, -0.0157, -0.0137,  0.0126,  0.0098,  0.0120, -0.0190,  0.0199,\n",
       "           0.0237, -0.0248,  0.0113]])}, objective=5.653317081458382, loss=0.733465313911438, val_objective=5.680821108348183, val_loss=0.760969340801239, regularization=0.9113688468933105, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.506276432428181, state_dict={'layers.0.weight': tensor([[-0.0683,  0.0237,  0.0829,  ..., -0.0075,  0.0590,  0.0363],\n",
       "         [-0.1126,  0.0202, -0.0158,  ...,  0.0333, -0.1018, -0.0703],\n",
       "         [-0.0435, -0.0548, -0.0212,  ..., -0.2368, -0.1309, -0.0237],\n",
       "         ...,\n",
       "         [-0.0067, -0.1188, -0.0273,  ..., -0.1650, -0.0587,  0.0386],\n",
       "         [ 0.1205, -0.0226, -0.0941,  ..., -0.0270, -0.0015,  0.1125],\n",
       "         [-0.0414, -0.0238,  0.1315,  ...,  0.0469, -0.0866,  0.1125]]), 'layers.0.bias': tensor([-0.0637,  0.1402,  0.0434,  0.0603,  0.0941,  0.0913,  0.0055, -0.1500,\n",
       "          0.0054, -0.0826,  0.0695,  0.0945,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0021,  0.0587,  0.1511, -0.0966,  0.0524,\n",
       "         -0.0793,  0.1794, -0.0879, -0.0493, -0.0573,  0.1081, -0.0241,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0305, -0.1473,  0.0016,  0.0621,  0.1026,  0.0570,\n",
       "         -0.0482,  0.0352,  0.1202, -0.0455,  0.1268, -0.0220, -0.0697, -0.0011,\n",
       "          0.0322,  0.1172]), 'layers.1.weight': tensor([[ 0.0487,  0.1131, -0.1312, -0.0841,  0.0549, -0.1012, -0.0585, -0.0274,\n",
       "           0.1417, -0.0319,  0.0416, -0.0709,  0.0642,  0.0089, -0.0675,  0.0492,\n",
       "          -0.0866, -0.0219,  0.0272,  0.0713, -0.1074,  0.0458, -0.0759, -0.0682,\n",
       "          -0.0573,  0.1235,  0.0711,  0.0986,  0.1078, -0.0182, -0.1161,  0.1288,\n",
       "           0.0100,  0.0529, -0.0945,  0.1108,  0.1129, -0.0700,  0.1633, -0.0476,\n",
       "          -0.1289,  0.0578,  0.1321, -0.0753,  0.0676,  0.1134, -0.0911, -0.0587,\n",
       "          -0.0729, -0.0884]]), 'layers.1.bias': tensor([-0.0673]), 'skip.weight': tensor([[ 0.0122, -0.0119,  0.0139,  0.0128,  0.0132,  0.0113, -0.0143, -0.0125,\n",
       "           0.0091,  0.0122, -0.0148, -0.0103, -0.0139,  0.0115,  0.0133, -0.0118,\n",
       "           0.0120,  0.0123,  0.0138,  0.0134,  0.0090,  0.0121,  0.0162,  0.0123,\n",
       "          -0.0135,  0.0124, -0.0133,  0.0136, -0.0144,  0.0121,  0.0142, -0.0147,\n",
       "           0.0185, -0.0141,  0.0156, -0.0144, -0.0164, -0.0122, -0.0116, -0.0144,\n",
       "          -0.0102, -0.0098,  0.0154, -0.0123,  0.0138,  0.0153, -0.0162, -0.0119,\n",
       "          -0.0172, -0.0110,  0.0139, -0.0109, -0.0133,  0.0100,  0.0135,  0.0125,\n",
       "          -0.0125, -0.0156, -0.0137,  0.0125,  0.0098,  0.0120, -0.0189,  0.0198,\n",
       "           0.0237, -0.0247,  0.0113]])}, objective=5.729707470819862, loss=0.7334601879119873, val_objective=5.75717251627198, val_loss=0.7609252333641052, regularization=0.9073731303215027, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.616401961076745, state_dict={'layers.0.weight': tensor([[-0.0683,  0.0237,  0.0829,  ..., -0.0075,  0.0590,  0.0363],\n",
       "         [-0.1125,  0.0203, -0.0158,  ...,  0.0333, -0.1019, -0.0702],\n",
       "         [-0.0436, -0.0548, -0.0212,  ..., -0.2363, -0.1309, -0.0237],\n",
       "         ...,\n",
       "         [-0.0067, -0.1185, -0.0273,  ..., -0.1650, -0.0586,  0.0386],\n",
       "         [ 0.1205, -0.0226, -0.0941,  ..., -0.0270, -0.0014,  0.1120],\n",
       "         [-0.0415, -0.0239,  0.1315,  ...,  0.0469, -0.0866,  0.1120]]), 'layers.0.bias': tensor([-0.0637,  0.1402,  0.0434,  0.0603,  0.0941,  0.0913,  0.0055, -0.1501,\n",
       "          0.0053, -0.0826,  0.0695,  0.0945,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0021,  0.0587,  0.1511, -0.0966,  0.0524,\n",
       "         -0.0793,  0.1794, -0.0879, -0.0493, -0.0573,  0.1081, -0.0242,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0305, -0.1473,  0.0016,  0.0620,  0.1026,  0.0570,\n",
       "         -0.0483,  0.0352,  0.1202, -0.0455,  0.1268, -0.0220, -0.0697, -0.0011,\n",
       "          0.0322,  0.1172]), 'layers.1.weight': tensor([[ 0.0487,  0.1132, -0.1313, -0.0840,  0.0550, -0.1013, -0.0586, -0.0274,\n",
       "           0.1419, -0.0319,  0.0415, -0.0710,  0.0641,  0.0089, -0.0676,  0.0493,\n",
       "          -0.0867, -0.0218,  0.0271,  0.0712, -0.1075,  0.0457, -0.0759, -0.0682,\n",
       "          -0.0573,  0.1235,  0.0711,  0.0987,  0.1079, -0.0183, -0.1161,  0.1289,\n",
       "           0.0101,  0.0529, -0.0944,  0.1109,  0.1128, -0.0703,  0.1635, -0.0476,\n",
       "          -0.1289,  0.0577,  0.1322, -0.0754,  0.0677,  0.1132, -0.0912, -0.0589,\n",
       "          -0.0730, -0.0886]]), 'layers.1.bias': tensor([-0.0671]), 'skip.weight': tensor([[ 0.0122, -0.0119,  0.0138,  0.0127,  0.0132,  0.0111, -0.0143, -0.0125,\n",
       "           0.0091,  0.0122, -0.0147, -0.0103, -0.0138,  0.0115,  0.0133, -0.0118,\n",
       "           0.0119,  0.0123,  0.0137,  0.0134,  0.0090,  0.0120,  0.0162,  0.0122,\n",
       "          -0.0134,  0.0124, -0.0132,  0.0135, -0.0143,  0.0121,  0.0142, -0.0146,\n",
       "           0.0184, -0.0140,  0.0155, -0.0144, -0.0163, -0.0122, -0.0116, -0.0143,\n",
       "          -0.0102, -0.0097,  0.0153, -0.0123,  0.0138,  0.0151, -0.0161, -0.0119,\n",
       "          -0.0171, -0.0110,  0.0138, -0.0108, -0.0132,  0.0099,  0.0135,  0.0125,\n",
       "          -0.0124, -0.0156, -0.0136,  0.0125,  0.0097,  0.0120, -0.0188,  0.0197,\n",
       "           0.0236, -0.0247,  0.0112]])}, objective=5.806985152173311, loss=0.7334566712379456, val_objective=5.834409964490206, val_loss=0.7608814835548401, regularization=0.9033414125442505, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.72873000029828, state_dict={'layers.0.weight': tensor([[-0.0683,  0.0238,  0.0829,  ..., -0.0074,  0.0589,  0.0363],\n",
       "         [-0.1125,  0.0203, -0.0157,  ...,  0.0334, -0.1019, -0.0702],\n",
       "         [-0.0436, -0.0548, -0.0213,  ..., -0.2357, -0.1308, -0.0238],\n",
       "         ...,\n",
       "         [-0.0067, -0.1182, -0.0273,  ..., -0.1650, -0.0586,  0.0386],\n",
       "         [ 0.1204, -0.0226, -0.0942,  ..., -0.0270, -0.0014,  0.1115],\n",
       "         [-0.0416, -0.0239,  0.1314,  ...,  0.0468, -0.0865,  0.1115]]), 'layers.0.bias': tensor([-0.0636,  0.1402,  0.0433,  0.0603,  0.0941,  0.0912,  0.0055, -0.1501,\n",
       "          0.0053, -0.0827,  0.0695,  0.0945,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0020,  0.0587,  0.1511, -0.0967,  0.0523,\n",
       "         -0.0793,  0.1794, -0.0880, -0.0493, -0.0572,  0.1080, -0.0242,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0305, -0.1474,  0.0015,  0.0620,  0.1026,  0.0569,\n",
       "         -0.0484,  0.0352,  0.1202, -0.0455,  0.1268, -0.0221, -0.0697, -0.0011,\n",
       "          0.0322,  0.1172]), 'layers.1.weight': tensor([[ 0.0488,  0.1134, -0.1314, -0.0839,  0.0551, -0.1015, -0.0588, -0.0274,\n",
       "           0.1421, -0.0319,  0.0415, -0.0710,  0.0640,  0.0090, -0.0678,  0.0495,\n",
       "          -0.0869, -0.0217,  0.0269,  0.0710, -0.1075,  0.0457, -0.0758, -0.0681,\n",
       "          -0.0573,  0.1235,  0.0710,  0.0987,  0.1080, -0.0184, -0.1161,  0.1290,\n",
       "           0.0101,  0.0530, -0.0943,  0.1111,  0.1127, -0.0705,  0.1637, -0.0476,\n",
       "          -0.1288,  0.0576,  0.1323, -0.0755,  0.0678,  0.1131, -0.0912, -0.0591,\n",
       "          -0.0731, -0.0888]]), 'layers.1.bias': tensor([-0.0670]), 'skip.weight': tensor([[ 0.0121, -0.0118,  0.0138,  0.0127,  0.0132,  0.0110, -0.0142, -0.0124,\n",
       "           0.0090,  0.0121, -0.0147, -0.0102, -0.0138,  0.0114,  0.0132, -0.0117,\n",
       "           0.0119,  0.0123,  0.0137,  0.0133,  0.0090,  0.0119,  0.0161,  0.0122,\n",
       "          -0.0134,  0.0123, -0.0132,  0.0135, -0.0142,  0.0120,  0.0142, -0.0145,\n",
       "           0.0183, -0.0140,  0.0153, -0.0144, -0.0162, -0.0121, -0.0115, -0.0143,\n",
       "          -0.0101, -0.0097,  0.0153, -0.0122,  0.0137,  0.0150, -0.0160, -0.0118,\n",
       "          -0.0170, -0.0110,  0.0138, -0.0108, -0.0131,  0.0099,  0.0134,  0.0124,\n",
       "          -0.0124, -0.0155, -0.0135,  0.0124,  0.0097,  0.0119, -0.0187,  0.0196,\n",
       "           0.0236, -0.0246,  0.0112]])}, objective=5.885313170926594, loss=0.7334541082382202, val_objective=5.912692862527393, val_loss=0.7608337998390198, regularization=0.8993021249771118, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.843304600304246, state_dict={'layers.0.weight': tensor([[-0.0682,  0.0238,  0.0829,  ..., -0.0074,  0.0589,  0.0363],\n",
       "         [-0.1124,  0.0203, -0.0157,  ...,  0.0334, -0.1020, -0.0701],\n",
       "         [-0.0436, -0.0548, -0.0213,  ..., -0.2352, -0.1308, -0.0238],\n",
       "         ...,\n",
       "         [-0.0067, -0.1179, -0.0274,  ..., -0.1651, -0.0586,  0.0385],\n",
       "         [ 0.1204, -0.0226, -0.0942,  ..., -0.0270, -0.0014,  0.1110],\n",
       "         [-0.0417, -0.0239,  0.1314,  ...,  0.0468, -0.0865,  0.1110]]), 'layers.0.bias': tensor([-0.0636,  0.1401,  0.0433,  0.0603,  0.0941,  0.0912,  0.0055, -0.1501,\n",
       "          0.0053, -0.0827,  0.0694,  0.0945,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0020,  0.0587,  0.1511, -0.0967,  0.0523,\n",
       "         -0.0793,  0.1794, -0.0880, -0.0493, -0.0572,  0.1080, -0.0242,  0.0244,\n",
       "         -0.0317, -0.0451, -0.0306, -0.1474,  0.0015,  0.0620,  0.1026,  0.0569,\n",
       "         -0.0485,  0.0352,  0.1203, -0.0455,  0.1268, -0.0221, -0.0697, -0.0011,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0489,  0.1135, -0.1315, -0.0837,  0.0551, -0.1016, -0.0589, -0.0274,\n",
       "           0.1422, -0.0319,  0.0415, -0.0711,  0.0639,  0.0091, -0.0680,  0.0496,\n",
       "          -0.0870, -0.0215,  0.0268,  0.0709, -0.1076,  0.0456, -0.0758, -0.0681,\n",
       "          -0.0574,  0.1234,  0.0709,  0.0988,  0.1081, -0.0185, -0.1161,  0.1291,\n",
       "           0.0101,  0.0530, -0.0943,  0.1113,  0.1126, -0.0707,  0.1639, -0.0476,\n",
       "          -0.1288,  0.0576,  0.1324, -0.0756,  0.0678,  0.1130, -0.0913, -0.0593,\n",
       "          -0.0732, -0.0890]]), 'layers.1.bias': tensor([-0.0669]), 'skip.weight': tensor([[ 0.0121, -0.0118,  0.0137,  0.0126,  0.0131,  0.0108, -0.0142, -0.0124,\n",
       "           0.0090,  0.0120, -0.0146, -0.0102, -0.0137,  0.0114,  0.0131, -0.0117,\n",
       "           0.0118,  0.0122,  0.0136,  0.0132,  0.0090,  0.0119,  0.0161,  0.0121,\n",
       "          -0.0133,  0.0123, -0.0131,  0.0134, -0.0142,  0.0120,  0.0141, -0.0144,\n",
       "           0.0182, -0.0139,  0.0152, -0.0143, -0.0161, -0.0121, -0.0115, -0.0142,\n",
       "          -0.0101, -0.0097,  0.0152, -0.0122,  0.0137,  0.0149, -0.0160, -0.0117,\n",
       "          -0.0169, -0.0109,  0.0137, -0.0108, -0.0130,  0.0099,  0.0134,  0.0123,\n",
       "          -0.0123, -0.0154, -0.0134,  0.0124,  0.0097,  0.0119, -0.0186,  0.0195,\n",
       "           0.0235, -0.0246,  0.0111]])}, objective=5.964646674445313, loss=0.733451783657074, val_objective=5.991980053237122, val_loss=0.7607851624488831, regularization=0.8952459692955017, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=5.9601706923103315, state_dict={'layers.0.weight': tensor([[-0.0682,  0.0238,  0.0830,  ..., -0.0074,  0.0589,  0.0363],\n",
       "         [-0.1124,  0.0204, -0.0157,  ...,  0.0334, -0.1021, -0.0701],\n",
       "         [-0.0436, -0.0548, -0.0213,  ..., -0.2346, -0.1307, -0.0238],\n",
       "         ...,\n",
       "         [-0.0067, -0.1176, -0.0274,  ..., -0.1651, -0.0586,  0.0385],\n",
       "         [ 0.1201, -0.0226, -0.0942,  ..., -0.0270, -0.0014,  0.1105],\n",
       "         [-0.0417, -0.0239,  0.1314,  ...,  0.0468, -0.0864,  0.1105]]), 'layers.0.bias': tensor([-0.0636,  0.1401,  0.0433,  0.0603,  0.0941,  0.0912,  0.0055, -0.1501,\n",
       "          0.0053, -0.0827,  0.0694,  0.0945,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1483,  0.0019,  0.0587,  0.1511, -0.0967,  0.0523,\n",
       "         -0.0794,  0.1794, -0.0881, -0.0494, -0.0571,  0.1080, -0.0242,  0.0245,\n",
       "         -0.0317, -0.0451, -0.0306, -0.1474,  0.0015,  0.0620,  0.1026,  0.0569,\n",
       "         -0.0485,  0.0352,  0.1203, -0.0455,  0.1267, -0.0221, -0.0697, -0.0011,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0490,  0.1136, -0.1317, -0.0836,  0.0552, -0.1017, -0.0591, -0.0274,\n",
       "           0.1424, -0.0320,  0.0414, -0.0711,  0.0638,  0.0092, -0.0681,  0.0498,\n",
       "          -0.0872, -0.0214,  0.0266,  0.0708, -0.1076,  0.0456, -0.0757, -0.0680,\n",
       "          -0.0574,  0.1234,  0.0708,  0.0988,  0.1082, -0.0186, -0.1161,  0.1292,\n",
       "           0.0101,  0.0530, -0.0942,  0.1115,  0.1125, -0.0709,  0.1641, -0.0477,\n",
       "          -0.1288,  0.0575,  0.1325, -0.0757,  0.0679,  0.1129, -0.0913, -0.0596,\n",
       "          -0.0733, -0.0892]]), 'layers.1.bias': tensor([-0.0667]), 'skip.weight': tensor([[ 0.0120, -0.0118,  0.0137,  0.0125,  0.0131,  0.0107, -0.0141, -0.0123,\n",
       "           0.0090,  0.0120, -0.0145, -0.0102, -0.0136,  0.0113,  0.0130, -0.0116,\n",
       "           0.0118,  0.0122,  0.0136,  0.0132,  0.0089,  0.0118,  0.0160,  0.0121,\n",
       "          -0.0133,  0.0122, -0.0130,  0.0133, -0.0141,  0.0120,  0.0141, -0.0144,\n",
       "           0.0181, -0.0138,  0.0150, -0.0143, -0.0160, -0.0120, -0.0115, -0.0142,\n",
       "          -0.0100, -0.0096,  0.0152, -0.0121,  0.0136,  0.0147, -0.0159, -0.0117,\n",
       "          -0.0168, -0.0109,  0.0136, -0.0107, -0.0129,  0.0099,  0.0133,  0.0123,\n",
       "          -0.0123, -0.0154, -0.0134,  0.0123,  0.0096,  0.0118, -0.0185,  0.0194,\n",
       "           0.0235, -0.0245,  0.0111]])}, objective=6.044853140210225, loss=0.7334509491920471, val_objective=6.0721390737047924, val_loss=0.760736882686615, regularization=0.8911493420600891, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.079374106156538, state_dict={'layers.0.weight': tensor([[-0.0682,  0.0238,  0.0830,  ..., -0.0074,  0.0589,  0.0363],\n",
       "         [-0.1123,  0.0204, -0.0156,  ...,  0.0334, -0.1021, -0.0700],\n",
       "         [-0.0437, -0.0549, -0.0214,  ..., -0.2341, -0.1307, -0.0238],\n",
       "         ...,\n",
       "         [-0.0068, -0.1173, -0.0274,  ..., -0.1651, -0.0586,  0.0385],\n",
       "         [ 0.1197, -0.0226, -0.0943,  ..., -0.0271, -0.0013,  0.1101],\n",
       "         [-0.0418, -0.0240,  0.1314,  ...,  0.0467, -0.0864,  0.1101]]), 'layers.0.bias': tensor([-0.0636,  0.1401,  0.0433,  0.0602,  0.0941,  0.0912,  0.0055, -0.1501,\n",
       "          0.0052, -0.0827,  0.0694,  0.0946,  0.1271,  0.0370, -0.1502, -0.1196,\n",
       "         -0.0712, -0.1008,  0.1482,  0.0019,  0.0586,  0.1511, -0.0968,  0.0523,\n",
       "         -0.0794,  0.1794, -0.0881, -0.0494, -0.0571,  0.1080, -0.0243,  0.0245,\n",
       "         -0.0317, -0.0451, -0.0306, -0.1474,  0.0014,  0.0620,  0.1026,  0.0569,\n",
       "         -0.0486,  0.0352,  0.1203, -0.0455,  0.1267, -0.0222, -0.0697, -0.0011,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0491,  0.1138, -0.1318, -0.0835,  0.0553, -0.1019, -0.0592, -0.0274,\n",
       "           0.1426, -0.0320,  0.0414, -0.0712,  0.0637,  0.0092, -0.0683,  0.0499,\n",
       "          -0.0874, -0.0213,  0.0265,  0.0706, -0.1076,  0.0455, -0.0757, -0.0680,\n",
       "          -0.0574,  0.1233,  0.0708,  0.0989,  0.1083, -0.0188, -0.1161,  0.1293,\n",
       "           0.0101,  0.0531, -0.0941,  0.1116,  0.1125, -0.0711,  0.1642, -0.0477,\n",
       "          -0.1288,  0.0575,  0.1325, -0.0758,  0.0679,  0.1128, -0.0914, -0.0598,\n",
       "          -0.0733, -0.0894]]), 'layers.1.bias': tensor([-0.0666]), 'skip.weight': tensor([[ 0.0120, -0.0117,  0.0136,  0.0125,  0.0131,  0.0105, -0.0140, -0.0123,\n",
       "           0.0089,  0.0119, -0.0145, -0.0101, -0.0135,  0.0113,  0.0130, -0.0116,\n",
       "           0.0117,  0.0121,  0.0135,  0.0131,  0.0089,  0.0118,  0.0159,  0.0120,\n",
       "          -0.0132,  0.0121, -0.0129,  0.0133, -0.0140,  0.0119,  0.0140, -0.0143,\n",
       "           0.0180, -0.0137,  0.0149, -0.0143, -0.0159, -0.0119, -0.0114, -0.0141,\n",
       "          -0.0100, -0.0096,  0.0151, -0.0121,  0.0136,  0.0146, -0.0158, -0.0116,\n",
       "          -0.0167, -0.0109,  0.0136, -0.0107, -0.0128,  0.0098,  0.0133,  0.0122,\n",
       "          -0.0122, -0.0153, -0.0133,  0.0123,  0.0096,  0.0118, -0.0184,  0.0193,\n",
       "           0.0234, -0.0244,  0.0110]])}, objective=6.126046951958233, loss=0.7334510087966919, val_objective=6.153285142132336, val_loss=0.7606891989707947, regularization=0.8870314359664917, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.200961588279669, state_dict={'layers.0.weight': tensor([[-0.0681,  0.0238,  0.0830,  ..., -0.0074,  0.0588,  0.0364],\n",
       "         [-0.1123,  0.0205, -0.0156,  ...,  0.0334, -0.1022, -0.0700],\n",
       "         [-0.0437, -0.0549, -0.0214,  ..., -0.2335, -0.1306, -0.0239],\n",
       "         ...,\n",
       "         [-0.0068, -0.1170, -0.0274,  ..., -0.1651, -0.0586,  0.0385],\n",
       "         [ 0.1192, -0.0226, -0.0943,  ..., -0.0271, -0.0013,  0.1097],\n",
       "         [-0.0419, -0.0240,  0.1313,  ...,  0.0467, -0.0863,  0.1097]]), 'layers.0.bias': tensor([-0.0636,  0.1401,  0.0432,  0.0602,  0.0941,  0.0912,  0.0055, -0.1501,\n",
       "          0.0052, -0.0827,  0.0694,  0.0946,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0018,  0.0586,  0.1511, -0.0968,  0.0522,\n",
       "         -0.0794,  0.1793, -0.0882, -0.0494, -0.0571,  0.1080, -0.0243,  0.0245,\n",
       "         -0.0317, -0.0451, -0.0306, -0.1474,  0.0014,  0.0620,  0.1026,  0.0568,\n",
       "         -0.0487,  0.0352,  0.1203, -0.0455,  0.1267, -0.0222, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0492,  0.1139, -0.1319, -0.0834,  0.0554, -0.1020, -0.0594, -0.0274,\n",
       "           0.1427, -0.0320,  0.0413, -0.0712,  0.0636,  0.0093, -0.0685,  0.0501,\n",
       "          -0.0875, -0.0212,  0.0264,  0.0705, -0.1077,  0.0454, -0.0756, -0.0680,\n",
       "          -0.0575,  0.1233,  0.0707,  0.0989,  0.1084, -0.0189, -0.1161,  0.1294,\n",
       "           0.0101,  0.0531, -0.0940,  0.1118,  0.1124, -0.0713,  0.1644, -0.0477,\n",
       "          -0.1288,  0.0574,  0.1326, -0.0759,  0.0680,  0.1127, -0.0914, -0.0600,\n",
       "          -0.0734, -0.0896]]), 'layers.1.bias': tensor([-0.0664]), 'skip.weight': tensor([[ 0.0119, -0.0117,  0.0135,  0.0124,  0.0130,  0.0104, -0.0140, -0.0123,\n",
       "           0.0089,  0.0118, -0.0144, -0.0101, -0.0134,  0.0112,  0.0129, -0.0115,\n",
       "           0.0117,  0.0121,  0.0134,  0.0130,  0.0089,  0.0117,  0.0159,  0.0120,\n",
       "          -0.0132,  0.0121, -0.0129,  0.0132, -0.0139,  0.0119,  0.0140, -0.0142,\n",
       "           0.0179, -0.0137,  0.0147, -0.0142, -0.0158, -0.0119, -0.0114, -0.0140,\n",
       "          -0.0099, -0.0095,  0.0151, -0.0120,  0.0136,  0.0144, -0.0157, -0.0116,\n",
       "          -0.0166, -0.0108,  0.0135, -0.0107, -0.0127,  0.0098,  0.0133,  0.0122,\n",
       "          -0.0121, -0.0152, -0.0132,  0.0122,  0.0096,  0.0118, -0.0183,  0.0192,\n",
       "           0.0233, -0.0244,  0.0110]])}, objective=6.208330795596467, loss=0.7334515452384949, val_objective=6.235522494147645, val_loss=0.7606432437896729, regularization=0.8829081058502197, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.324980820045263, state_dict={'layers.0.weight': tensor([[-0.0681,  0.0238,  0.0830,  ..., -0.0073,  0.0588,  0.0364],\n",
       "         [-0.1122,  0.0205, -0.0156,  ...,  0.0334, -0.1022, -0.0699],\n",
       "         [-0.0437, -0.0549, -0.0214,  ..., -0.2329, -0.1306, -0.0239],\n",
       "         ...,\n",
       "         [-0.0068, -0.1167, -0.0274,  ..., -0.1651, -0.0585,  0.0385],\n",
       "         [ 0.1188, -0.0227, -0.0943,  ..., -0.0271, -0.0013,  0.1092],\n",
       "         [-0.0420, -0.0240,  0.1313,  ...,  0.0467, -0.0863,  0.1092]]), 'layers.0.bias': tensor([-0.0636,  0.1400,  0.0432,  0.0602,  0.0941,  0.0911,  0.0054, -0.1501,\n",
       "          0.0052, -0.0827,  0.0694,  0.0946,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0018,  0.0586,  0.1511, -0.0968,  0.0522,\n",
       "         -0.0794,  0.1793, -0.0882, -0.0495, -0.0570,  0.1080, -0.0243,  0.0245,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1474,  0.0014,  0.0620,  0.1027,  0.0568,\n",
       "         -0.0488,  0.0352,  0.1204, -0.0455,  0.1267, -0.0222, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0492,  0.1140, -0.1320, -0.0832,  0.0555, -0.1021, -0.0596, -0.0274,\n",
       "           0.1429, -0.0320,  0.0413, -0.0713,  0.0636,  0.0093, -0.0687,  0.0503,\n",
       "          -0.0877, -0.0211,  0.0262,  0.0704, -0.1077,  0.0454, -0.0756, -0.0679,\n",
       "          -0.0575,  0.1233,  0.0707,  0.0990,  0.1085, -0.0190, -0.1162,  0.1296,\n",
       "           0.0102,  0.0532, -0.0940,  0.1120,  0.1123, -0.0715,  0.1646, -0.0477,\n",
       "          -0.1288,  0.0573,  0.1327, -0.0760,  0.0681,  0.1126, -0.0915, -0.0602,\n",
       "          -0.0735, -0.0898]]), 'layers.1.bias': tensor([-0.0663]), 'skip.weight': tensor([[ 0.0119, -0.0117,  0.0135,  0.0124,  0.0130,  0.0103, -0.0139, -0.0122,\n",
       "           0.0088,  0.0117, -0.0144, -0.0100, -0.0133,  0.0112,  0.0128, -0.0115,\n",
       "           0.0117,  0.0121,  0.0134,  0.0129,  0.0088,  0.0117,  0.0158,  0.0119,\n",
       "          -0.0131,  0.0120, -0.0128,  0.0131, -0.0139,  0.0119,  0.0140, -0.0141,\n",
       "           0.0178, -0.0136,  0.0146, -0.0142, -0.0157, -0.0118, -0.0113, -0.0140,\n",
       "          -0.0099, -0.0095,  0.0150, -0.0119,  0.0135,  0.0143, -0.0157, -0.0115,\n",
       "          -0.0165, -0.0108,  0.0134, -0.0106, -0.0126,  0.0098,  0.0132,  0.0121,\n",
       "          -0.0121, -0.0151, -0.0132,  0.0122,  0.0096,  0.0117, -0.0183,  0.0191,\n",
       "           0.0233, -0.0243,  0.0109]])}, objective=6.291762406736377, loss=0.7334527373313904, val_objective=6.318911249547962, val_loss=0.7606015801429749, regularization=0.8787868022918701, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.451480436446168, state_dict={'layers.0.weight': tensor([[-0.0681,  0.0238,  0.0830,  ..., -0.0073,  0.0588,  0.0364],\n",
       "         [-0.1122,  0.0206, -0.0155,  ...,  0.0335, -0.1023, -0.0699],\n",
       "         [-0.0438, -0.0549, -0.0215,  ..., -0.2323, -0.1305, -0.0239],\n",
       "         ...,\n",
       "         [-0.0068, -0.1164, -0.0274,  ..., -0.1651, -0.0585,  0.0385],\n",
       "         [ 0.1183, -0.0227, -0.0944,  ..., -0.0271, -0.0012,  0.1087],\n",
       "         [-0.0420, -0.0241,  0.1313,  ...,  0.0466, -0.0862,  0.1087]]), 'layers.0.bias': tensor([-0.0636,  0.1400,  0.0432,  0.0602,  0.0941,  0.0911,  0.0054, -0.1501,\n",
       "          0.0052, -0.0827,  0.0694,  0.0946,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0018,  0.0586,  0.1511, -0.0968,  0.0522,\n",
       "         -0.0794,  0.1793, -0.0883, -0.0495, -0.0570,  0.1080, -0.0244,  0.0245,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1474,  0.0013,  0.0620,  0.1027,  0.0568,\n",
       "         -0.0489,  0.0352,  0.1204, -0.0455,  0.1267, -0.0222, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0493,  0.1142, -0.1321, -0.0831,  0.0556, -0.1023, -0.0597, -0.0274,\n",
       "           0.1431, -0.0320,  0.0412, -0.0713,  0.0635,  0.0094, -0.0688,  0.0504,\n",
       "          -0.0878, -0.0209,  0.0261,  0.0703, -0.1078,  0.0453, -0.0755, -0.0679,\n",
       "          -0.0576,  0.1232,  0.0706,  0.0990,  0.1086, -0.0191, -0.1162,  0.1297,\n",
       "           0.0102,  0.0532, -0.0939,  0.1122,  0.1122, -0.0717,  0.1648, -0.0478,\n",
       "          -0.1288,  0.0573,  0.1328, -0.0760,  0.0681,  0.1125, -0.0915, -0.0604,\n",
       "          -0.0736, -0.0900]]), 'layers.1.bias': tensor([-0.0662]), 'skip.weight': tensor([[ 0.0118, -0.0116,  0.0134,  0.0123,  0.0129,  0.0102, -0.0139, -0.0122,\n",
       "           0.0088,  0.0116, -0.0143, -0.0100, -0.0132,  0.0112,  0.0127, -0.0114,\n",
       "           0.0116,  0.0120,  0.0133,  0.0129,  0.0088,  0.0116,  0.0158,  0.0119,\n",
       "          -0.0131,  0.0120, -0.0127,  0.0130, -0.0138,  0.0119,  0.0139, -0.0139,\n",
       "           0.0177, -0.0135,  0.0144, -0.0141, -0.0156, -0.0117, -0.0113, -0.0139,\n",
       "          -0.0099, -0.0095,  0.0150, -0.0119,  0.0135,  0.0141, -0.0156, -0.0114,\n",
       "          -0.0164, -0.0107,  0.0133, -0.0106, -0.0125,  0.0097,  0.0132,  0.0121,\n",
       "          -0.0120, -0.0151, -0.0131,  0.0121,  0.0095,  0.0117, -0.0182,  0.0190,\n",
       "           0.0232, -0.0243,  0.0109]])}, objective=6.376127610476251, loss=0.7334555983543396, val_objective=6.403232047827478, val_loss=0.7605600357055664, regularization=0.8746321201324463, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.5805100451750915, state_dict={'layers.0.weight': tensor([[-0.0681,  0.0238,  0.0830,  ..., -0.0073,  0.0588,  0.0364],\n",
       "         [-0.1121,  0.0206, -0.0155,  ...,  0.0335, -0.1024, -0.0698],\n",
       "         [-0.0438, -0.0549, -0.0215,  ..., -0.2318, -0.1305, -0.0239],\n",
       "         ...,\n",
       "         [-0.0068, -0.1161, -0.0274,  ..., -0.1651, -0.0585,  0.0384],\n",
       "         [ 0.1178, -0.0227, -0.0944,  ..., -0.0271, -0.0012,  0.1083],\n",
       "         [-0.0421, -0.0241,  0.1313,  ...,  0.0466, -0.0862,  0.1083]]), 'layers.0.bias': tensor([-0.0636,  0.1400,  0.0432,  0.0602,  0.0941,  0.0911,  0.0054, -0.1502,\n",
       "          0.0051, -0.0827,  0.0694,  0.0947,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0017,  0.0586,  0.1510, -0.0969,  0.0522,\n",
       "         -0.0794,  0.1793, -0.0884, -0.0495, -0.0569,  0.1080, -0.0244,  0.0245,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1474,  0.0013,  0.0620,  0.1027,  0.0568,\n",
       "         -0.0490,  0.0352,  0.1204, -0.0455,  0.1267, -0.0223, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0494,  0.1143, -0.1322, -0.0830,  0.0556, -0.1024, -0.0599, -0.0274,\n",
       "           0.1433, -0.0320,  0.0412, -0.0714,  0.0634,  0.0094, -0.0690,  0.0506,\n",
       "          -0.0879, -0.0208,  0.0260,  0.0701, -0.1078,  0.0453, -0.0755, -0.0679,\n",
       "          -0.0576,  0.1232,  0.0705,  0.0991,  0.1087, -0.0192, -0.1162,  0.1298,\n",
       "           0.0102,  0.0533, -0.0938,  0.1124,  0.1121, -0.0719,  0.1650, -0.0478,\n",
       "          -0.1288,  0.0572,  0.1329, -0.0761,  0.0682,  0.1125, -0.0916, -0.0606,\n",
       "          -0.0736, -0.0902]]), 'layers.1.bias': tensor([-0.0660]), 'skip.weight': tensor([[ 0.0118, -0.0116,  0.0134,  0.0122,  0.0129,  0.0102, -0.0138, -0.0122,\n",
       "           0.0088,  0.0116, -0.0143, -0.0100, -0.0130,  0.0111,  0.0127, -0.0114,\n",
       "           0.0116,  0.0120,  0.0133,  0.0128,  0.0088,  0.0116,  0.0157,  0.0118,\n",
       "          -0.0130,  0.0119, -0.0127,  0.0129, -0.0137,  0.0118,  0.0139, -0.0139,\n",
       "           0.0176, -0.0135,  0.0143, -0.0141, -0.0155, -0.0117, -0.0113, -0.0138,\n",
       "          -0.0098, -0.0094,  0.0150, -0.0118,  0.0134,  0.0139, -0.0156, -0.0114,\n",
       "          -0.0163, -0.0107,  0.0133, -0.0106, -0.0124,  0.0097,  0.0132,  0.0120,\n",
       "          -0.0120, -0.0150, -0.0130,  0.0120,  0.0095,  0.0116, -0.0181,  0.0189,\n",
       "           0.0232, -0.0242,  0.0108]])}, objective=6.461650155917175, loss=0.7334595322608948, val_objective=6.488708876505859, val_loss=0.7605182528495789, regularization=0.8704782128334045, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.712120246078594, state_dict={'layers.0.weight': tensor([[-0.0680,  0.0238,  0.0830,  ..., -0.0073,  0.0587,  0.0364],\n",
       "         [-0.1121,  0.0206, -0.0155,  ...,  0.0335, -0.1024, -0.0698],\n",
       "         [-0.0438, -0.0549, -0.0215,  ..., -0.2313, -0.1305, -0.0239],\n",
       "         ...,\n",
       "         [-0.0068, -0.1158, -0.0274,  ..., -0.1651, -0.0585,  0.0384],\n",
       "         [ 0.1174, -0.0227, -0.0944,  ..., -0.0271, -0.0012,  0.1079],\n",
       "         [-0.0422, -0.0241,  0.1312,  ...,  0.0466, -0.0862,  0.1079]]), 'layers.0.bias': tensor([-0.0636,  0.1400,  0.0432,  0.0601,  0.0941,  0.0911,  0.0054, -0.1502,\n",
       "          0.0051, -0.0827,  0.0694,  0.0947,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0017,  0.0586,  0.1510, -0.0969,  0.0521,\n",
       "         -0.0794,  0.1793, -0.0884, -0.0495, -0.0569,  0.1080, -0.0244,  0.0246,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1474,  0.0013,  0.0620,  0.1027,  0.0567,\n",
       "         -0.0490,  0.0352,  0.1205, -0.0455,  0.1266, -0.0223, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0494,  0.1144, -0.1323, -0.0829,  0.0557, -0.1025, -0.0600, -0.0274,\n",
       "           0.1434, -0.0320,  0.0412, -0.0714,  0.0633,  0.0095, -0.0692,  0.0507,\n",
       "          -0.0881, -0.0207,  0.0258,  0.0700, -0.1079,  0.0452, -0.0754, -0.0679,\n",
       "          -0.0577,  0.1232,  0.0705,  0.0991,  0.1088, -0.0193, -0.1162,  0.1299,\n",
       "           0.0102,  0.0533, -0.0938,  0.1125,  0.1120, -0.0721,  0.1652, -0.0478,\n",
       "          -0.1287,  0.0571,  0.1330, -0.0762,  0.0683,  0.1124, -0.0916, -0.0608,\n",
       "          -0.0737, -0.0904]]), 'layers.1.bias': tensor([-0.0659]), 'skip.weight': tensor([[ 0.0117, -0.0116,  0.0133,  0.0122,  0.0129,  0.0101, -0.0137, -0.0121,\n",
       "           0.0087,  0.0115, -0.0142, -0.0099, -0.0129,  0.0111,  0.0126, -0.0113,\n",
       "           0.0115,  0.0119,  0.0132,  0.0127,  0.0088,  0.0115,  0.0157,  0.0117,\n",
       "          -0.0130,  0.0118, -0.0126,  0.0128, -0.0136,  0.0118,  0.0139, -0.0138,\n",
       "           0.0175, -0.0134,  0.0141, -0.0141, -0.0154, -0.0116, -0.0112, -0.0138,\n",
       "          -0.0098, -0.0094,  0.0149, -0.0117,  0.0134,  0.0138, -0.0155, -0.0113,\n",
       "          -0.0162, -0.0107,  0.0132, -0.0105, -0.0123,  0.0097,  0.0131,  0.0120,\n",
       "          -0.0119, -0.0149, -0.0130,  0.0120,  0.0095,  0.0116, -0.0180,  0.0188,\n",
       "           0.0231, -0.0241,  0.0108]])}, objective=6.548147159387775, loss=0.7334638833999634, val_objective=6.575158911516376, val_loss=0.7604756355285645, regularization=0.8662960529327393, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.846362651000166, state_dict={'layers.0.weight': tensor([[-0.0680,  0.0238,  0.0830,  ..., -0.0073,  0.0587,  0.0364],\n",
       "         [-0.1121,  0.0207, -0.0154,  ...,  0.0335, -0.1025, -0.0697],\n",
       "         [-0.0439, -0.0549, -0.0216,  ..., -0.2308, -0.1304, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1154, -0.0274,  ..., -0.1652, -0.0585,  0.0384],\n",
       "         [ 0.1169, -0.0227, -0.0945,  ..., -0.0272, -0.0011,  0.1074],\n",
       "         [-0.0422, -0.0241,  0.1312,  ...,  0.0465, -0.0861,  0.1074]]), 'layers.0.bias': tensor([-0.0636,  0.1399,  0.0431,  0.0601,  0.0941,  0.0911,  0.0054, -0.1502,\n",
       "          0.0051, -0.0827,  0.0694,  0.0947,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0713, -0.1008,  0.1482,  0.0016,  0.0586,  0.1510, -0.0969,  0.0521,\n",
       "         -0.0794,  0.1793, -0.0885, -0.0496, -0.0568,  0.1080, -0.0244,  0.0246,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1475,  0.0012,  0.0620,  0.1027,  0.0567,\n",
       "         -0.0491,  0.0352,  0.1205, -0.0455,  0.1266, -0.0223, -0.0697, -0.0010,\n",
       "          0.0323,  0.1172]), 'layers.1.weight': tensor([[ 0.0495,  0.1146, -0.1324, -0.0828,  0.0558, -0.1027, -0.0602, -0.0274,\n",
       "           0.1436, -0.0320,  0.0411, -0.0715,  0.0632,  0.0095, -0.0694,  0.0509,\n",
       "          -0.0882, -0.0206,  0.0257,  0.0699, -0.1079,  0.0451, -0.0754, -0.0678,\n",
       "          -0.0577,  0.1231,  0.0704,  0.0992,  0.1089, -0.0195, -0.1162,  0.1300,\n",
       "           0.0103,  0.0533, -0.0937,  0.1127,  0.1119, -0.0723,  0.1654, -0.0478,\n",
       "          -0.1287,  0.0571,  0.1331, -0.0763,  0.0683,  0.1123, -0.0917, -0.0610,\n",
       "          -0.0738, -0.0906]]), 'layers.1.bias': tensor([-0.0658]), 'skip.weight': tensor([[ 0.0117, -0.0115,  0.0132,  0.0121,  0.0128,  0.0100, -0.0137, -0.0121,\n",
       "           0.0087,  0.0114, -0.0142, -0.0099, -0.0128,  0.0110,  0.0125, -0.0112,\n",
       "           0.0115,  0.0119,  0.0131,  0.0126,  0.0087,  0.0115,  0.0156,  0.0117,\n",
       "          -0.0129,  0.0118, -0.0125,  0.0128, -0.0135,  0.0118,  0.0138, -0.0137,\n",
       "           0.0174, -0.0133,  0.0139, -0.0140, -0.0153, -0.0116, -0.0112, -0.0137,\n",
       "          -0.0097, -0.0094,  0.0149, -0.0117,  0.0133,  0.0136, -0.0155, -0.0112,\n",
       "          -0.0161, -0.0106,  0.0131, -0.0105, -0.0122,  0.0096,  0.0131,  0.0119,\n",
       "          -0.0118, -0.0148, -0.0129,  0.0119,  0.0094,  0.0115, -0.0179,  0.0186,\n",
       "           0.0231, -0.0241,  0.0107]])}, objective=6.635735585733854, loss=0.7334683537483215, val_objective=6.66270096544882, val_loss=0.7604337334632874, regularization=0.8621026277542114, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=6.983289904020169, state_dict={'layers.0.weight': tensor([[-0.0680,  0.0238,  0.0830,  ..., -0.0073,  0.0587,  0.0364],\n",
       "         [-0.1120,  0.0207, -0.0154,  ...,  0.0335, -0.1025, -0.0697],\n",
       "         [-0.0439, -0.0549, -0.0216,  ..., -0.2303, -0.1304, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1151, -0.0274,  ..., -0.1652, -0.0585,  0.0384],\n",
       "         [ 0.1164, -0.0227, -0.0945,  ..., -0.0272, -0.0011,  0.1070],\n",
       "         [-0.0423, -0.0242,  0.1312,  ...,  0.0465, -0.0861,  0.1070]]), 'layers.0.bias': tensor([-0.0636,  0.1399,  0.0431,  0.0601,  0.0941,  0.0910,  0.0054, -0.1502,\n",
       "          0.0051, -0.0828,  0.0694,  0.0947,  0.1271,  0.0370, -0.1503, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0016,  0.0586,  0.1510, -0.0970,  0.0521,\n",
       "         -0.0794,  0.1793, -0.0885, -0.0496, -0.0568,  0.1079, -0.0245,  0.0246,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1475,  0.0012,  0.0620,  0.1027,  0.0567,\n",
       "         -0.0492,  0.0352,  0.1205, -0.0455,  0.1266, -0.0224, -0.0697, -0.0009,\n",
       "          0.0323,  0.1171]), 'layers.1.weight': tensor([[ 0.0496,  0.1147, -0.1325, -0.0827,  0.0559, -0.1028, -0.0604, -0.0274,\n",
       "           0.1438, -0.0320,  0.0411, -0.0716,  0.0632,  0.0096, -0.0695,  0.0510,\n",
       "          -0.0884, -0.0205,  0.0256,  0.0698, -0.1080,  0.0451, -0.0754, -0.0678,\n",
       "          -0.0577,  0.1231,  0.0704,  0.0992,  0.1090, -0.0196, -0.1163,  0.1301,\n",
       "           0.0103,  0.0534, -0.0936,  0.1129,  0.1118, -0.0725,  0.1656, -0.0479,\n",
       "          -0.1287,  0.0570,  0.1332, -0.0764,  0.0684,  0.1122, -0.0917, -0.0612,\n",
       "          -0.0739, -0.0908]]), 'layers.1.bias': tensor([-0.0657]), 'skip.weight': tensor([[ 0.0116, -0.0115,  0.0132,  0.0120,  0.0128,  0.0099, -0.0136, -0.0120,\n",
       "           0.0086,  0.0113, -0.0141, -0.0098, -0.0127,  0.0110,  0.0125, -0.0112,\n",
       "           0.0114,  0.0119,  0.0131,  0.0126,  0.0087,  0.0114,  0.0156,  0.0116,\n",
       "          -0.0129,  0.0117, -0.0125,  0.0127, -0.0135,  0.0117,  0.0138, -0.0137,\n",
       "           0.0173, -0.0133,  0.0138, -0.0140, -0.0152, -0.0115, -0.0111, -0.0136,\n",
       "          -0.0097, -0.0093,  0.0148, -0.0116,  0.0133,  0.0134, -0.0154, -0.0112,\n",
       "          -0.0160, -0.0106,  0.0130, -0.0105, -0.0121,  0.0096,  0.0130,  0.0119,\n",
       "          -0.0118, -0.0147, -0.0129,  0.0119,  0.0094,  0.0115, -0.0179,  0.0185,\n",
       "           0.0230, -0.0240,  0.0107]])}, objective=6.724727752851176, loss=0.7334734797477722, val_objective=6.7516467005478615, val_loss=0.760392427444458, regularization=0.8579415082931519, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.1229557021005725, state_dict={'layers.0.weight': tensor([[-0.0679,  0.0238,  0.0830,  ..., -0.0073,  0.0586,  0.0364],\n",
       "         [-0.1120,  0.0208, -0.0153,  ...,  0.0336, -0.1026, -0.0696],\n",
       "         [-0.0439, -0.0550, -0.0216,  ..., -0.2298, -0.1303, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1147, -0.0275,  ..., -0.1652, -0.0584,  0.0384],\n",
       "         [ 0.1159, -0.0227, -0.0946,  ..., -0.0272, -0.0011,  0.1065],\n",
       "         [-0.0424, -0.0242,  0.1310,  ...,  0.0465, -0.0860,  0.1065]]), 'layers.0.bias': tensor([-0.0636,  0.1399,  0.0431,  0.0601,  0.0941,  0.0910,  0.0054, -0.1502,\n",
       "          0.0050, -0.0828,  0.0694,  0.0948,  0.1271,  0.0370, -0.1504, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0015,  0.0585,  0.1510, -0.0970,  0.0521,\n",
       "         -0.0794,  0.1793, -0.0886, -0.0496, -0.0568,  0.1079, -0.0245,  0.0246,\n",
       "         -0.0317, -0.0450, -0.0306, -0.1475,  0.0012,  0.0620,  0.1027,  0.0567,\n",
       "         -0.0493,  0.0352,  0.1206, -0.0455,  0.1266, -0.0224, -0.0697, -0.0009,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0496,  0.1148, -0.1326, -0.0825,  0.0559, -0.1030, -0.0605, -0.0274,\n",
       "           0.1440, -0.0320,  0.0411, -0.0716,  0.0631,  0.0096, -0.0697,  0.0512,\n",
       "          -0.0885, -0.0204,  0.0254,  0.0697, -0.1080,  0.0450, -0.0753, -0.0678,\n",
       "          -0.0578,  0.1230,  0.0703,  0.0993,  0.1091, -0.0197, -0.1163,  0.1302,\n",
       "           0.0103,  0.0534, -0.0935,  0.1131,  0.1117, -0.0727,  0.1658, -0.0479,\n",
       "          -0.1287,  0.0569,  0.1333, -0.0765,  0.0685,  0.1122, -0.0918, -0.0614,\n",
       "          -0.0740, -0.0911]]), 'layers.1.bias': tensor([-0.0655]), 'skip.weight': tensor([[ 0.0116, -0.0115,  0.0131,  0.0120,  0.0128,  0.0099, -0.0136, -0.0120,\n",
       "           0.0086,  0.0112, -0.0141, -0.0098, -0.0126,  0.0109,  0.0124, -0.0111,\n",
       "           0.0114,  0.0118,  0.0130,  0.0125,  0.0087,  0.0114,  0.0155,  0.0116,\n",
       "          -0.0128,  0.0116, -0.0124,  0.0126, -0.0134,  0.0117,  0.0137, -0.0136,\n",
       "           0.0171, -0.0132,  0.0137, -0.0139, -0.0151, -0.0115, -0.0111, -0.0136,\n",
       "          -0.0097, -0.0093,  0.0148, -0.0115,  0.0132,  0.0133, -0.0153, -0.0111,\n",
       "          -0.0159, -0.0106,  0.0129, -0.0104, -0.0121,  0.0096,  0.0130,  0.0118,\n",
       "          -0.0117, -0.0146, -0.0128,  0.0118,  0.0094,  0.0114, -0.0178,  0.0184,\n",
       "           0.0230, -0.0239,  0.0107]])}, objective=6.81491369800871, loss=0.7334789037704468, val_objective=6.841781743338758, val_loss=0.7603469491004944, regularization=0.853779673576355, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.265414816142584, state_dict={'layers.0.weight': tensor([[-0.0679,  0.0238,  0.0830,  ..., -0.0072,  0.0586,  0.0365],\n",
       "         [-0.1119,  0.0208, -0.0153,  ...,  0.0336, -0.1027, -0.0696],\n",
       "         [-0.0440, -0.0550, -0.0216,  ..., -0.2294, -0.1303, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1144, -0.0275,  ..., -0.1652, -0.0584,  0.0384],\n",
       "         [ 0.1155, -0.0227, -0.0946,  ..., -0.0272, -0.0011,  0.1061],\n",
       "         [-0.0424, -0.0242,  0.1304,  ...,  0.0464, -0.0860,  0.1061]]), 'layers.0.bias': tensor([-0.0636,  0.1398,  0.0431,  0.0601,  0.0941,  0.0910,  0.0054, -0.1502,\n",
       "          0.0050, -0.0828,  0.0694,  0.0948,  0.1271,  0.0370, -0.1504, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0015,  0.0585,  0.1510, -0.0970,  0.0521,\n",
       "         -0.0795,  0.1793, -0.0886, -0.0497, -0.0567,  0.1079, -0.0245,  0.0246,\n",
       "         -0.0317, -0.0450, -0.0307, -0.1475,  0.0011,  0.0620,  0.1027,  0.0566,\n",
       "         -0.0494,  0.0352,  0.1206, -0.0455,  0.1266, -0.0224, -0.0697, -0.0009,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0497,  0.1150, -0.1327, -0.0824,  0.0560, -0.1031, -0.0607, -0.0274,\n",
       "           0.1441, -0.0320,  0.0410, -0.0717,  0.0630,  0.0096, -0.0699,  0.0514,\n",
       "          -0.0887, -0.0202,  0.0253,  0.0696, -0.1080,  0.0450, -0.0753, -0.0678,\n",
       "          -0.0579,  0.1230,  0.0703,  0.0993,  0.1092, -0.0198, -0.1164,  0.1304,\n",
       "           0.0103,  0.0535, -0.0935,  0.1133,  0.1116, -0.0729,  0.1660, -0.0479,\n",
       "          -0.1287,  0.0569,  0.1334, -0.0766,  0.0686,  0.1121, -0.0918, -0.0616,\n",
       "          -0.0741, -0.0913]]), 'layers.1.bias': tensor([-0.0654]), 'skip.weight': tensor([[ 0.0115, -0.0114,  0.0130,  0.0119,  0.0127,  0.0098, -0.0135, -0.0119,\n",
       "           0.0086,  0.0111, -0.0140, -0.0097, -0.0125,  0.0109,  0.0123, -0.0111,\n",
       "           0.0113,  0.0118,  0.0129,  0.0124,  0.0086,  0.0113,  0.0155,  0.0115,\n",
       "          -0.0127,  0.0116, -0.0123,  0.0125, -0.0133,  0.0116,  0.0137, -0.0135,\n",
       "           0.0170, -0.0131,  0.0136, -0.0139, -0.0150, -0.0114, -0.0110, -0.0135,\n",
       "          -0.0096, -0.0092,  0.0147, -0.0114,  0.0132,  0.0131, -0.0153, -0.0110,\n",
       "          -0.0158, -0.0105,  0.0129, -0.0104, -0.0120,  0.0095,  0.0130,  0.0118,\n",
       "          -0.0116, -0.0146, -0.0127,  0.0118,  0.0093,  0.0114, -0.0177,  0.0183,\n",
       "           0.0229, -0.0239,  0.0106]])}, objective=6.906732767273862, loss=0.7334845066070557, val_objective=6.933540194680173, val_loss=0.7602919340133667, regularization=0.8496759533882141, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.410723112465436, state_dict={'layers.0.weight': tensor([[-0.0679,  0.0238,  0.0830,  ..., -0.0072,  0.0586,  0.0365],\n",
       "         [-0.1119,  0.0209, -0.0153,  ...,  0.0336, -0.1027, -0.0696],\n",
       "         [-0.0440, -0.0550, -0.0217,  ..., -0.2289, -0.1302, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1140, -0.0275,  ..., -0.1652, -0.0584,  0.0383],\n",
       "         [ 0.1150, -0.0227, -0.0946,  ..., -0.0272, -0.0010,  0.1056],\n",
       "         [-0.0425, -0.0242,  0.1298,  ...,  0.0464, -0.0859,  0.1056]]), 'layers.0.bias': tensor([-0.0636,  0.1398,  0.0431,  0.0600,  0.0941,  0.0910,  0.0053, -0.1502,\n",
       "          0.0050, -0.0828,  0.0694,  0.0948,  0.1271,  0.0371, -0.1504, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0015,  0.0585,  0.1510, -0.0970,  0.0520,\n",
       "         -0.0795,  0.1793, -0.0887, -0.0497, -0.0567,  0.1079, -0.0246,  0.0246,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1475,  0.0011,  0.0620,  0.1027,  0.0566,\n",
       "         -0.0494,  0.0352,  0.1206, -0.0455,  0.1265, -0.0224, -0.0697, -0.0009,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0498,  0.1151, -0.1328, -0.0823,  0.0561, -0.1032, -0.0609, -0.0274,\n",
       "           0.1443, -0.0320,  0.0410, -0.0717,  0.0629,  0.0097, -0.0701,  0.0515,\n",
       "          -0.0888, -0.0201,  0.0252,  0.0695, -0.1081,  0.0449, -0.0753, -0.0678,\n",
       "          -0.0579,  0.1230,  0.0703,  0.0994,  0.1093, -0.0200, -0.1164,  0.1305,\n",
       "           0.0103,  0.0535, -0.0934,  0.1135,  0.1115, -0.0731,  0.1662, -0.0479,\n",
       "          -0.1287,  0.0568,  0.1335, -0.0767,  0.0686,  0.1120, -0.0919, -0.0618,\n",
       "          -0.0742, -0.0915]]), 'layers.1.bias': tensor([-0.0653]), 'skip.weight': tensor([[ 0.0115, -0.0114,  0.0130,  0.0119,  0.0127,  0.0097, -0.0135, -0.0119,\n",
       "           0.0085,  0.0111, -0.0140, -0.0097, -0.0124,  0.0108,  0.0122, -0.0110,\n",
       "           0.0113,  0.0117,  0.0129,  0.0124,  0.0086,  0.0113,  0.0154,  0.0114,\n",
       "          -0.0127,  0.0116, -0.0122,  0.0124, -0.0133,  0.0116,  0.0137, -0.0135,\n",
       "           0.0169, -0.0131,  0.0134, -0.0138, -0.0149, -0.0113, -0.0110, -0.0134,\n",
       "          -0.0096, -0.0092,  0.0147, -0.0114,  0.0131,  0.0130, -0.0152, -0.0109,\n",
       "          -0.0157, -0.0105,  0.0128, -0.0104, -0.0119,  0.0095,  0.0129,  0.0117,\n",
       "          -0.0115, -0.0145, -0.0127,  0.0117,  0.0093,  0.0113, -0.0176,  0.0182,\n",
       "           0.0229, -0.0238,  0.0106]])}, objective=7.0002152363715435, loss=0.7334908246994019, val_objective=7.026960972970512, val_loss=0.7602365612983704, regularization=0.8456292748451233, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.5589375747147445, state_dict={'layers.0.weight': tensor([[-0.0678,  0.0238,  0.0830,  ..., -0.0072,  0.0586,  0.0365],\n",
       "         [-0.1118,  0.0209, -0.0152,  ...,  0.0336, -0.1028, -0.0695],\n",
       "         [-0.0440, -0.0550, -0.0217,  ..., -0.2283, -0.1302, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1136, -0.0275,  ..., -0.1652, -0.0584,  0.0383],\n",
       "         [ 0.1145, -0.0227, -0.0947,  ..., -0.0272, -0.0010,  0.1051],\n",
       "         [-0.0426, -0.0243,  0.1292,  ...,  0.0464, -0.0859,  0.1051]]), 'layers.0.bias': tensor([-0.0636,  0.1398,  0.0431,  0.0600,  0.0941,  0.0910,  0.0053, -0.1502,\n",
       "          0.0049, -0.0828,  0.0694,  0.0948,  0.1271,  0.0371, -0.1504, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0014,  0.0585,  0.1510, -0.0971,  0.0520,\n",
       "         -0.0795,  0.1792, -0.0887, -0.0497, -0.0566,  0.1079, -0.0246,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1475,  0.0011,  0.0619,  0.1027,  0.0566,\n",
       "         -0.0495,  0.0352,  0.1207, -0.0455,  0.1265, -0.0225, -0.0697, -0.0008,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0498,  0.1152, -0.1330, -0.0822,  0.0562, -0.1034, -0.0611, -0.0274,\n",
       "           0.1445, -0.0320,  0.0410, -0.0718,  0.0629,  0.0097, -0.0702,  0.0517,\n",
       "          -0.0890, -0.0200,  0.0251,  0.0694, -0.1081,  0.0448, -0.0752, -0.0677,\n",
       "          -0.0580,  0.1229,  0.0702,  0.0995,  0.1093, -0.0201, -0.1164,  0.1306,\n",
       "           0.0104,  0.0535, -0.0933,  0.1137,  0.1114, -0.0733,  0.1664, -0.0480,\n",
       "          -0.1287,  0.0567,  0.1336, -0.0768,  0.0687,  0.1119, -0.0919, -0.0620,\n",
       "          -0.0743, -0.0918]]), 'layers.1.bias': tensor([-0.0652]), 'skip.weight': tensor([[ 0.0115, -0.0114,  0.0129,  0.0118,  0.0126,  0.0097, -0.0134, -0.0119,\n",
       "           0.0085,  0.0110, -0.0139, -0.0097, -0.0123,  0.0108,  0.0122, -0.0110,\n",
       "           0.0112,  0.0117,  0.0128,  0.0123,  0.0086,  0.0112,  0.0154,  0.0114,\n",
       "          -0.0126,  0.0115, -0.0122,  0.0124, -0.0132,  0.0116,  0.0136, -0.0134,\n",
       "           0.0168, -0.0130,  0.0133, -0.0138, -0.0149, -0.0113, -0.0110, -0.0133,\n",
       "          -0.0095, -0.0092,  0.0146, -0.0113,  0.0131,  0.0129, -0.0152, -0.0109,\n",
       "          -0.0156, -0.0104,  0.0127, -0.0103, -0.0119,  0.0095,  0.0129,  0.0116,\n",
       "          -0.0115, -0.0144, -0.0126,  0.0116,  0.0093,  0.0113, -0.0175,  0.0181,\n",
       "           0.0228, -0.0237,  0.0105]])}, objective=7.09500883597121, loss=0.7334979772567749, val_objective=7.121694193065021, val_loss=0.7601833343505859, regularization=0.8415879607200623, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.7101163262090395, state_dict={'layers.0.weight': tensor([[-0.0678,  0.0238,  0.0830,  ..., -0.0072,  0.0585,  0.0365],\n",
       "         [-0.1118,  0.0210, -0.0152,  ...,  0.0336, -0.1028, -0.0695],\n",
       "         [-0.0441, -0.0550, -0.0217,  ..., -0.2278, -0.1301, -0.0240],\n",
       "         ...,\n",
       "         [-0.0069, -0.1133, -0.0275,  ..., -0.1652, -0.0584,  0.0383],\n",
       "         [ 0.1140, -0.0227, -0.0947,  ..., -0.0272, -0.0010,  0.1046],\n",
       "         [-0.0426, -0.0243,  0.1285,  ...,  0.0463, -0.0858,  0.1046]]), 'layers.0.bias': tensor([-0.0636,  0.1398,  0.0431,  0.0600,  0.0941,  0.0909,  0.0053, -0.1502,\n",
       "          0.0049, -0.0828,  0.0694,  0.0948,  0.1271,  0.0371, -0.1504, -0.1196,\n",
       "         -0.0714, -0.1008,  0.1482,  0.0014,  0.0585,  0.1509, -0.0971,  0.0520,\n",
       "         -0.0795,  0.1792, -0.0888, -0.0497, -0.0566,  0.1079, -0.0246,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1476,  0.0011,  0.0619,  0.1027,  0.0566,\n",
       "         -0.0496,  0.0351,  0.1207, -0.0455,  0.1265, -0.0225, -0.0697, -0.0008,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0499,  0.1154, -0.1331, -0.0821,  0.0563, -0.1035, -0.0612, -0.0274,\n",
       "           0.1447, -0.0320,  0.0410, -0.0718,  0.0628,  0.0097, -0.0704,  0.0519,\n",
       "          -0.0891, -0.0199,  0.0249,  0.0693, -0.1082,  0.0448, -0.0752, -0.0677,\n",
       "          -0.0580,  0.1229,  0.0702,  0.0995,  0.1094, -0.0202, -0.1165,  0.1307,\n",
       "           0.0104,  0.0536, -0.0933,  0.1139,  0.1114, -0.0736,  0.1667, -0.0480,\n",
       "          -0.1287,  0.0567,  0.1337, -0.0769,  0.0688,  0.1119, -0.0920, -0.0622,\n",
       "          -0.0744, -0.0920]]), 'layers.1.bias': tensor([-0.0651]), 'skip.weight': tensor([[ 0.0114, -0.0113,  0.0129,  0.0117,  0.0126,  0.0096, -0.0134, -0.0118,\n",
       "           0.0084,  0.0110, -0.0139, -0.0096, -0.0122,  0.0107,  0.0121, -0.0109,\n",
       "           0.0112,  0.0116,  0.0128,  0.0122,  0.0085,  0.0112,  0.0153,  0.0113,\n",
       "          -0.0126,  0.0115, -0.0121,  0.0123, -0.0131,  0.0115,  0.0136, -0.0133,\n",
       "           0.0167, -0.0130,  0.0132, -0.0137, -0.0148, -0.0112, -0.0109, -0.0133,\n",
       "          -0.0095, -0.0091,  0.0146, -0.0112,  0.0130,  0.0128, -0.0151, -0.0108,\n",
       "          -0.0155, -0.0104,  0.0126, -0.0103, -0.0118,  0.0094,  0.0128,  0.0116,\n",
       "          -0.0114, -0.0143, -0.0126,  0.0116,  0.0093,  0.0112, -0.0174,  0.0180,\n",
       "           0.0228, -0.0236,  0.0105]])}, objective=7.191071017200955, loss=0.7335054874420166, val_objective=7.217694683487424, val_loss=0.7601291537284851, regularization=0.8375445008277893, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=7.86431865273322, state_dict={'layers.0.weight': tensor([[-0.0678,  0.0238,  0.0831,  ..., -0.0072,  0.0585,  0.0365],\n",
       "         [-0.1117,  0.0210, -0.0151,  ...,  0.0336, -0.1029, -0.0694],\n",
       "         [-0.0441, -0.0550, -0.0218,  ..., -0.2273, -0.1301, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1129, -0.0275,  ..., -0.1652, -0.0584,  0.0383],\n",
       "         [ 0.1136, -0.0227, -0.0947,  ..., -0.0273, -0.0010,  0.1041],\n",
       "         [-0.0427, -0.0243,  0.1279,  ...,  0.0463, -0.0858,  0.1041]]), 'layers.0.bias': tensor([-0.0636,  0.1397,  0.0430,  0.0600,  0.0941,  0.0909,  0.0053, -0.1503,\n",
       "          0.0049, -0.0828,  0.0694,  0.0949,  0.1271,  0.0371, -0.1504, -0.1196,\n",
       "         -0.0715, -0.1008,  0.1482,  0.0013,  0.0585,  0.1509, -0.0971,  0.0520,\n",
       "         -0.0795,  0.1792, -0.0888, -0.0498, -0.0566,  0.1079, -0.0246,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1476,  0.0010,  0.0619,  0.1027,  0.0566,\n",
       "         -0.0497,  0.0351,  0.1207, -0.0455,  0.1265, -0.0225, -0.0697, -0.0008,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0500,  0.1155, -0.1332, -0.0820,  0.0563, -0.1037, -0.0614, -0.0274,\n",
       "           0.1448, -0.0320,  0.0409, -0.0719,  0.0627,  0.0097, -0.0706,  0.0520,\n",
       "          -0.0893, -0.0198,  0.0248,  0.0692, -0.1082,  0.0447, -0.0752, -0.0677,\n",
       "          -0.0581,  0.1228,  0.0702,  0.0996,  0.1095, -0.0203, -0.1165,  0.1308,\n",
       "           0.0104,  0.0536, -0.0932,  0.1141,  0.1113, -0.0738,  0.1669, -0.0480,\n",
       "          -0.1287,  0.0566,  0.1338, -0.0770,  0.0689,  0.1118, -0.0920, -0.0623,\n",
       "          -0.0745, -0.0922]]), 'layers.1.bias': tensor([-0.0650]), 'skip.weight': tensor([[ 0.0114, -0.0113,  0.0128,  0.0117,  0.0126,  0.0095, -0.0133, -0.0118,\n",
       "           0.0084,  0.0109, -0.0138, -0.0096, -0.0121,  0.0106,  0.0120, -0.0109,\n",
       "           0.0111,  0.0116,  0.0127,  0.0122,  0.0085,  0.0111,  0.0152,  0.0113,\n",
       "          -0.0125,  0.0114, -0.0120,  0.0123, -0.0130,  0.0115,  0.0136, -0.0132,\n",
       "           0.0165, -0.0129,  0.0131, -0.0137, -0.0147, -0.0111, -0.0109, -0.0132,\n",
       "          -0.0094, -0.0091,  0.0145, -0.0111,  0.0130,  0.0127, -0.0150, -0.0108,\n",
       "          -0.0154, -0.0104,  0.0125, -0.0103, -0.0117,  0.0094,  0.0128,  0.0115,\n",
       "          -0.0113, -0.0143, -0.0125,  0.0115,  0.0092,  0.0112, -0.0173,  0.0179,\n",
       "           0.0227, -0.0236,  0.0104]])}, objective=7.288168134508984, loss=0.7335147261619568, val_objective=7.314728262244122, val_loss=0.7600748538970947, regularization=0.833467423915863, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.021605025787885, state_dict={'layers.0.weight': tensor([[-0.0677,  0.0238,  0.0831,  ..., -0.0072,  0.0585,  0.0365],\n",
       "         [-0.1117,  0.0210, -0.0151,  ...,  0.0337, -0.1030, -0.0694],\n",
       "         [-0.0441, -0.0550, -0.0218,  ..., -0.2267, -0.1300, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1125, -0.0275,  ..., -0.1652, -0.0583,  0.0383],\n",
       "         [ 0.1132, -0.0227, -0.0948,  ..., -0.0273, -0.0009,  0.1036],\n",
       "         [-0.0428, -0.0243,  0.1272,  ...,  0.0462, -0.0857,  0.1036]]), 'layers.0.bias': tensor([-0.0636,  0.1397,  0.0430,  0.0600,  0.0941,  0.0909,  0.0053, -0.1503,\n",
       "          0.0049, -0.0828,  0.0694,  0.0949,  0.1271,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1008,  0.1482,  0.0013,  0.0585,  0.1509, -0.0971,  0.0520,\n",
       "         -0.0795,  0.1792, -0.0889, -0.0498, -0.0565,  0.1079, -0.0247,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1476,  0.0010,  0.0619,  0.1027,  0.0565,\n",
       "         -0.0497,  0.0351,  0.1208, -0.0455,  0.1265, -0.0226, -0.0697, -0.0008,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0500,  0.1157, -0.1333, -0.0819,  0.0564, -0.1038, -0.0616, -0.0274,\n",
       "           0.1450, -0.0320,  0.0409, -0.0720,  0.0626,  0.0097, -0.0708,  0.0522,\n",
       "          -0.0894, -0.0196,  0.0247,  0.0691, -0.1083,  0.0447, -0.0751, -0.0677,\n",
       "          -0.0581,  0.1228,  0.0702,  0.0996,  0.1095, -0.0205, -0.1166,  0.1309,\n",
       "           0.0105,  0.0536, -0.0931,  0.1142,  0.1112, -0.0740,  0.1671, -0.0481,\n",
       "          -0.1287,  0.0565,  0.1339, -0.0771,  0.0690,  0.1117, -0.0921, -0.0625,\n",
       "          -0.0746, -0.0924]]), 'layers.1.bias': tensor([-0.0649]), 'skip.weight': tensor([[ 0.0113, -0.0112,  0.0127,  0.0116,  0.0125,  0.0094, -0.0132, -0.0117,\n",
       "           0.0084,  0.0109, -0.0138, -0.0095, -0.0121,  0.0106,  0.0119, -0.0108,\n",
       "           0.0111,  0.0115,  0.0127,  0.0121,  0.0085,  0.0111,  0.0152,  0.0112,\n",
       "          -0.0124,  0.0114, -0.0119,  0.0122, -0.0130,  0.0115,  0.0135, -0.0132,\n",
       "           0.0164, -0.0128,  0.0129, -0.0136, -0.0146, -0.0111, -0.0108, -0.0131,\n",
       "          -0.0094, -0.0091,  0.0144, -0.0111,  0.0129,  0.0126, -0.0150, -0.0107,\n",
       "          -0.0153, -0.0103,  0.0124, -0.0102, -0.0117,  0.0094,  0.0128,  0.0115,\n",
       "          -0.0113, -0.0142, -0.0124,  0.0114,  0.0092,  0.0111, -0.0172,  0.0178,\n",
       "           0.0227, -0.0235,  0.0104]])}, objective=7.386667576205148, loss=0.7335258722305298, val_objective=7.4131635097378625, val_loss=0.7600218057632446, regularization=0.8294028043746948, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.182037126303642, state_dict={'layers.0.weight': tensor([[-0.0677,  0.0238,  0.0831,  ..., -0.0071,  0.0585,  0.0365],\n",
       "         [-0.1117,  0.0211, -0.0150,  ...,  0.0337, -0.1030, -0.0693],\n",
       "         [-0.0442, -0.0550, -0.0218,  ..., -0.2262, -0.1300, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1121, -0.0275,  ..., -0.1652, -0.0583,  0.0383],\n",
       "         [ 0.1127, -0.0227, -0.0948,  ..., -0.0273, -0.0009,  0.1031],\n",
       "         [-0.0428, -0.0243,  0.1266,  ...,  0.0462, -0.0857,  0.1031]]), 'layers.0.bias': tensor([-0.0636,  0.1397,  0.0430,  0.0599,  0.0941,  0.0909,  0.0053, -0.1503,\n",
       "          0.0048, -0.0829,  0.0694,  0.0949,  0.1270,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1008,  0.1482,  0.0012,  0.0585,  0.1509, -0.0972,  0.0519,\n",
       "         -0.0795,  0.1792, -0.0889, -0.0498, -0.0565,  0.1079, -0.0247,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1476,  0.0010,  0.0619,  0.1027,  0.0565,\n",
       "         -0.0498,  0.0351,  0.1208, -0.0455,  0.1265, -0.0226, -0.0696, -0.0008,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0501,  0.1158, -0.1334, -0.0819,  0.0565, -0.1039, -0.0617, -0.0274,\n",
       "           0.1452, -0.0320,  0.0409, -0.0720,  0.0626,  0.0097, -0.0710,  0.0524,\n",
       "          -0.0895, -0.0195,  0.0246,  0.0690, -0.1083,  0.0446, -0.0751, -0.0677,\n",
       "          -0.0582,  0.1228,  0.0702,  0.0997,  0.1096, -0.0206, -0.1166,  0.1310,\n",
       "           0.0105,  0.0536, -0.0931,  0.1144,  0.1111, -0.0742,  0.1673, -0.0481,\n",
       "          -0.1287,  0.0565,  0.1340, -0.0771,  0.0691,  0.1117, -0.0921, -0.0627,\n",
       "          -0.0747, -0.0927]]), 'layers.1.bias': tensor([-0.0648]), 'skip.weight': tensor([[ 0.0113, -0.0112,  0.0127,  0.0116,  0.0125,  0.0093, -0.0132, -0.0117,\n",
       "           0.0083,  0.0108, -0.0137, -0.0095, -0.0120,  0.0105,  0.0119, -0.0108,\n",
       "           0.0110,  0.0115,  0.0126,  0.0120,  0.0085,  0.0110,  0.0151,  0.0111,\n",
       "          -0.0124,  0.0113, -0.0119,  0.0122, -0.0129,  0.0114,  0.0135, -0.0131,\n",
       "           0.0163, -0.0128,  0.0128, -0.0136, -0.0146, -0.0110, -0.0108, -0.0130,\n",
       "          -0.0093, -0.0091,  0.0144, -0.0110,  0.0128,  0.0125, -0.0149, -0.0107,\n",
       "          -0.0152, -0.0103,  0.0123, -0.0102, -0.0116,  0.0093,  0.0127,  0.0114,\n",
       "          -0.0112, -0.0141, -0.0124,  0.0114,  0.0092,  0.0111, -0.0171,  0.0177,\n",
       "           0.0226, -0.0235,  0.0103]])}, objective=7.486379624203829, loss=0.7335382699966431, val_objective=7.512804210976748, val_loss=0.7599628567695618, regularization=0.8253251910209656, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.345677868829716, state_dict={'layers.0.weight': tensor([[-0.0677,  0.0238,  0.0831,  ..., -0.0071,  0.0584,  0.0365],\n",
       "         [-0.1116,  0.0211, -0.0150,  ...,  0.0337, -0.1031, -0.0693],\n",
       "         [-0.0442, -0.0550, -0.0218,  ..., -0.2256, -0.1299, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1117, -0.0275,  ..., -0.1652, -0.0583,  0.0383],\n",
       "         [ 0.1122, -0.0228, -0.0948,  ..., -0.0273, -0.0009,  0.1027],\n",
       "         [-0.0429, -0.0244,  0.1259,  ...,  0.0462, -0.0856,  0.1027]]), 'layers.0.bias': tensor([-0.0636,  0.1396,  0.0430,  0.0599,  0.0941,  0.0909,  0.0053, -0.1503,\n",
       "          0.0048, -0.0829,  0.0694,  0.0949,  0.1270,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1009,  0.1482,  0.0012,  0.0585,  0.1509, -0.0972,  0.0519,\n",
       "         -0.0795,  0.1792, -0.0890, -0.0498, -0.0564,  0.1078, -0.0247,  0.0247,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1476,  0.0009,  0.0619,  0.1027,  0.0565,\n",
       "         -0.0499,  0.0351,  0.1208, -0.0455,  0.1265, -0.0226, -0.0696, -0.0007,\n",
       "          0.0324,  0.1171]), 'layers.1.weight': tensor([[ 0.0502,  0.1159, -0.1335, -0.0818,  0.0565, -0.1041, -0.0619, -0.0274,\n",
       "           0.1454, -0.0320,  0.0409, -0.0721,  0.0625,  0.0097, -0.0711,  0.0525,\n",
       "          -0.0897, -0.0194,  0.0245,  0.0690, -0.1084,  0.0446, -0.0751, -0.0676,\n",
       "          -0.0582,  0.1228,  0.0701,  0.0997,  0.1097, -0.0207, -0.1167,  0.1311,\n",
       "           0.0105,  0.0536, -0.0930,  0.1146,  0.1110, -0.0744,  0.1675, -0.0481,\n",
       "          -0.1286,  0.0564,  0.1341, -0.0772,  0.0692,  0.1116, -0.0922, -0.0629,\n",
       "          -0.0748, -0.0929]]), 'layers.1.bias': tensor([-0.0646]), 'skip.weight': tensor([[ 0.0112, -0.0112,  0.0126,  0.0115,  0.0124,  0.0093, -0.0131, -0.0116,\n",
       "           0.0083,  0.0107, -0.0136, -0.0094, -0.0119,  0.0105,  0.0118, -0.0107,\n",
       "           0.0110,  0.0115,  0.0125,  0.0120,  0.0084,  0.0110,  0.0151,  0.0111,\n",
       "          -0.0123,  0.0113, -0.0118,  0.0121, -0.0128,  0.0114,  0.0134, -0.0130,\n",
       "           0.0161, -0.0127,  0.0127, -0.0135, -0.0145, -0.0109, -0.0107, -0.0130,\n",
       "          -0.0093, -0.0090,  0.0143, -0.0109,  0.0128,  0.0124, -0.0148, -0.0106,\n",
       "          -0.0151, -0.0102,  0.0122, -0.0101, -0.0115,  0.0093,  0.0127,  0.0113,\n",
       "          -0.0111, -0.0141, -0.0123,  0.0113,  0.0091,  0.0110, -0.0170,  0.0176,\n",
       "           0.0226, -0.0234,  0.0103]])}, objective=7.587624619591661, loss=0.7335514426231384, val_objective=7.613977025139756, val_loss=0.7599038481712341, regularization=0.8212721943855286, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.51259142620631, state_dict={'layers.0.weight': tensor([[-0.0676,  0.0238,  0.0831,  ..., -0.0071,  0.0584,  0.0366],\n",
       "         [-0.1116,  0.0212, -0.0150,  ...,  0.0337, -0.1031, -0.0692],\n",
       "         [-0.0442, -0.0550, -0.0219,  ..., -0.2250, -0.1299, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1112, -0.0275,  ..., -0.1653, -0.0583,  0.0382],\n",
       "         [ 0.1118, -0.0228, -0.0949,  ..., -0.0273, -0.0008,  0.1022],\n",
       "         [-0.0429, -0.0244,  0.1252,  ...,  0.0461, -0.0856,  0.1022]]), 'layers.0.bias': tensor([-0.0636,  0.1396,  0.0430,  0.0599,  0.0941,  0.0908,  0.0053, -0.1503,\n",
       "          0.0048, -0.0829,  0.0694,  0.0949,  0.1270,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1009,  0.1482,  0.0012,  0.0585,  0.1509, -0.0972,  0.0519,\n",
       "         -0.0796,  0.1792, -0.0890, -0.0499, -0.0564,  0.1078, -0.0247,  0.0248,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1477,  0.0009,  0.0619,  0.1027,  0.0565,\n",
       "         -0.0499,  0.0351,  0.1209, -0.0455,  0.1264, -0.0227, -0.0696, -0.0007,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0502,  0.1161, -0.1336, -0.0817,  0.0566, -0.1042, -0.0621, -0.0274,\n",
       "           0.1455, -0.0320,  0.0409, -0.0722,  0.0624,  0.0096, -0.0713,  0.0527,\n",
       "          -0.0898, -0.0192,  0.0244,  0.0689, -0.1084,  0.0445, -0.0750, -0.0676,\n",
       "          -0.0582,  0.1227,  0.0701,  0.0998,  0.1097, -0.0208, -0.1168,  0.1312,\n",
       "           0.0106,  0.0536, -0.0929,  0.1148,  0.1109, -0.0746,  0.1677, -0.0481,\n",
       "          -0.1286,  0.0564,  0.1342, -0.0773,  0.0693,  0.1115, -0.0922, -0.0631,\n",
       "          -0.0749, -0.0931]]), 'layers.1.bias': tensor([-0.0645]), 'skip.weight': tensor([[ 0.0112, -0.0111,  0.0125,  0.0114,  0.0124,  0.0092, -0.0131, -0.0116,\n",
       "           0.0082,  0.0107, -0.0136, -0.0094, -0.0119,  0.0104,  0.0117, -0.0107,\n",
       "           0.0109,  0.0114,  0.0125,  0.0119,  0.0084,  0.0109,  0.0150,  0.0110,\n",
       "          -0.0122,  0.0112, -0.0117,  0.0120, -0.0127,  0.0113,  0.0134, -0.0129,\n",
       "           0.0160, -0.0127,  0.0126, -0.0135, -0.0144, -0.0109, -0.0107, -0.0129,\n",
       "          -0.0092, -0.0090,  0.0143, -0.0108,  0.0127,  0.0123, -0.0148, -0.0106,\n",
       "          -0.0150, -0.0102,  0.0121, -0.0101, -0.0115,  0.0093,  0.0126,  0.0113,\n",
       "          -0.0111, -0.0140, -0.0122,  0.0112,  0.0091,  0.0109, -0.0169,  0.0175,\n",
       "           0.0225, -0.0233,  0.0102]])}, objective=7.690423334450908, loss=0.7335641980171204, val_objective=7.716705883355327, val_loss=0.7598467469215393, regularization=0.8172433972358704, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.682843254730436, state_dict={'layers.0.weight': tensor([[-0.0676,  0.0239,  0.0831,  ..., -0.0071,  0.0584,  0.0366],\n",
       "         [-0.1113,  0.0212, -0.0149,  ...,  0.0337, -0.1032, -0.0692],\n",
       "         [-0.0443, -0.0550, -0.0219,  ..., -0.2244, -0.1298, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1108, -0.0276,  ..., -0.1653, -0.0583,  0.0382],\n",
       "         [ 0.1113, -0.0228, -0.0949,  ..., -0.0273, -0.0008,  0.1017],\n",
       "         [-0.0430, -0.0244,  0.1245,  ...,  0.0461, -0.0855,  0.1017]]), 'layers.0.bias': tensor([-0.0635,  0.1396,  0.0430,  0.0599,  0.0940,  0.0908,  0.0052, -0.1503,\n",
       "          0.0048, -0.0829,  0.0694,  0.0950,  0.1270,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1009,  0.1482,  0.0011,  0.0584,  0.1509, -0.0973,  0.0519,\n",
       "         -0.0796,  0.1792, -0.0891, -0.0499, -0.0564,  0.1078, -0.0248,  0.0248,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1477,  0.0009,  0.0619,  0.1027,  0.0564,\n",
       "         -0.0500,  0.0351,  0.1209, -0.0455,  0.1264, -0.0227, -0.0696, -0.0007,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0503,  0.1163, -0.1338, -0.0816,  0.0566, -0.1043, -0.0623, -0.0274,\n",
       "           0.1457, -0.0320,  0.0410, -0.0723,  0.0624,  0.0096, -0.0714,  0.0529,\n",
       "          -0.0900, -0.0191,  0.0243,  0.0688, -0.1084,  0.0445, -0.0750, -0.0676,\n",
       "          -0.0583,  0.1227,  0.0702,  0.0999,  0.1098, -0.0209, -0.1168,  0.1314,\n",
       "           0.0106,  0.0536, -0.0928,  0.1150,  0.1108, -0.0749,  0.1679, -0.0482,\n",
       "          -0.1286,  0.0563,  0.1343, -0.0774,  0.0695,  0.1115, -0.0922, -0.0632,\n",
       "          -0.0750, -0.0933]]), 'layers.1.bias': tensor([-0.0644]), 'skip.weight': tensor([[ 0.0111, -0.0111,  0.0124,  0.0114,  0.0124,  0.0091, -0.0130, -0.0116,\n",
       "           0.0082,  0.0106, -0.0135, -0.0093, -0.0118,  0.0104,  0.0116, -0.0106,\n",
       "           0.0109,  0.0114,  0.0124,  0.0119,  0.0084,  0.0109,  0.0150,  0.0110,\n",
       "          -0.0122,  0.0112, -0.0116,  0.0120, -0.0126,  0.0113,  0.0134, -0.0128,\n",
       "           0.0159, -0.0126,  0.0125, -0.0134, -0.0144, -0.0108, -0.0106, -0.0128,\n",
       "          -0.0092, -0.0090,  0.0142, -0.0108,  0.0127,  0.0122, -0.0147, -0.0105,\n",
       "          -0.0149, -0.0101,  0.0120, -0.0101, -0.0114,  0.0092,  0.0126,  0.0112,\n",
       "          -0.0110, -0.0139, -0.0122,  0.0112,  0.0091,  0.0109, -0.0168,  0.0174,\n",
       "           0.0224, -0.0233,  0.0102]])}, objective=7.794244151533211, loss=0.73357754945755, val_objective=7.820456009328926, val_loss=0.7597894072532654, regularization=0.8131744861602783, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=8.856500119825045, state_dict={'layers.0.weight': tensor([[-0.0676,  0.0239,  0.0831,  ..., -0.0071,  0.0583,  0.0366],\n",
       "         [-0.1109,  0.0212, -0.0149,  ...,  0.0337, -0.1033, -0.0692],\n",
       "         [-0.0443, -0.0551, -0.0219,  ..., -0.2238, -0.1298, -0.0241],\n",
       "         ...,\n",
       "         [-0.0070, -0.1104, -0.0276,  ..., -0.1653, -0.0583,  0.0382],\n",
       "         [ 0.1109, -0.0228, -0.0949,  ..., -0.0273, -0.0008,  0.1012],\n",
       "         [-0.0431, -0.0244,  0.1238,  ...,  0.0461, -0.0855,  0.1012]]), 'layers.0.bias': tensor([-0.0635,  0.1395,  0.0429,  0.0599,  0.0940,  0.0908,  0.0052, -0.1503,\n",
       "          0.0047, -0.0829,  0.0694,  0.0950,  0.1270,  0.0371, -0.1505, -0.1196,\n",
       "         -0.0715, -0.1009,  0.1482,  0.0011,  0.0584,  0.1509, -0.0973,  0.0518,\n",
       "         -0.0796,  0.1792, -0.0891, -0.0499, -0.0563,  0.1078, -0.0248,  0.0248,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1477,  0.0008,  0.0619,  0.1027,  0.0564,\n",
       "         -0.0501,  0.0351,  0.1209, -0.0455,  0.1264, -0.0228, -0.0696, -0.0007,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0503,  0.1164, -0.1339, -0.0816,  0.0567, -0.1044, -0.0624, -0.0274,\n",
       "           0.1459, -0.0320,  0.0410, -0.0724,  0.0623,  0.0096, -0.0716,  0.0530,\n",
       "          -0.0901, -0.0190,  0.0242,  0.0688, -0.1085,  0.0444, -0.0750, -0.0675,\n",
       "          -0.0583,  0.1227,  0.0702,  0.0999,  0.1098, -0.0210, -0.1169,  0.1315,\n",
       "           0.0107,  0.0536, -0.0927,  0.1153,  0.1108, -0.0751,  0.1681, -0.0482,\n",
       "          -0.1286,  0.0563,  0.1345, -0.0775,  0.0696,  0.1114, -0.0923, -0.0634,\n",
       "          -0.0751, -0.0936]]), 'layers.1.bias': tensor([-0.0643]), 'skip.weight': tensor([[ 0.0111, -0.0110,  0.0124,  0.0113,  0.0123,  0.0090, -0.0129, -0.0115,\n",
       "           0.0082,  0.0106, -0.0134, -0.0093, -0.0118,  0.0103,  0.0115, -0.0106,\n",
       "           0.0108,  0.0113,  0.0123,  0.0118,  0.0084,  0.0109,  0.0149,  0.0109,\n",
       "          -0.0121,  0.0111, -0.0115,  0.0119, -0.0125,  0.0112,  0.0133, -0.0127,\n",
       "           0.0157, -0.0126,  0.0124, -0.0134, -0.0143, -0.0107, -0.0106, -0.0127,\n",
       "          -0.0091, -0.0089,  0.0142, -0.0107,  0.0126,  0.0121, -0.0147, -0.0105,\n",
       "          -0.0149, -0.0101,  0.0119, -0.0100, -0.0114,  0.0092,  0.0125,  0.0112,\n",
       "          -0.0110, -0.0139, -0.0121,  0.0111,  0.0090,  0.0108, -0.0167,  0.0173,\n",
       "           0.0224, -0.0232,  0.0101]])}, objective=7.89917066457924, loss=0.7335925698280334, val_objective=7.9253084338015, val_loss=0.759730339050293, regularization=0.8090755939483643, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.033630122221545, state_dict={'layers.0.weight': tensor([[-0.0675,  0.0239,  0.0831,  ..., -0.0071,  0.0583,  0.0366],\n",
       "         [-0.1104,  0.0213, -0.0149,  ...,  0.0338, -0.1033, -0.0691],\n",
       "         [-0.0443, -0.0551, -0.0219,  ..., -0.2233, -0.1297, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1099, -0.0276,  ..., -0.1653, -0.0583,  0.0382],\n",
       "         [ 0.1104, -0.0228, -0.0950,  ..., -0.0274, -0.0008,  0.1007],\n",
       "         [-0.0431, -0.0244,  0.1230,  ...,  0.0460, -0.0854,  0.1007]]), 'layers.0.bias': tensor([-0.0635,  0.1395,  0.0429,  0.0599,  0.0940,  0.0908,  0.0052, -0.1503,\n",
       "          0.0047, -0.0829,  0.0694,  0.0950,  0.1270,  0.0371, -0.1506, -0.1196,\n",
       "         -0.0716, -0.1009,  0.1482,  0.0010,  0.0584,  0.1509, -0.0973,  0.0518,\n",
       "         -0.0796,  0.1791, -0.0892, -0.0499, -0.0563,  0.1078, -0.0248,  0.0248,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1477,  0.0008,  0.0619,  0.1027,  0.0564,\n",
       "         -0.0502,  0.0351,  0.1210, -0.0454,  0.1264, -0.0228, -0.0696, -0.0007,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0504,  0.1166, -0.1340, -0.0815,  0.0567, -0.1045, -0.0626, -0.0274,\n",
       "           0.1461, -0.0320,  0.0410, -0.0724,  0.0623,  0.0095, -0.0717,  0.0532,\n",
       "          -0.0903, -0.0188,  0.0241,  0.0688, -0.1085,  0.0444, -0.0749, -0.0675,\n",
       "          -0.0583,  0.1227,  0.0702,  0.1000,  0.1099, -0.0211, -0.1170,  0.1316,\n",
       "           0.0107,  0.0536, -0.0927,  0.1155,  0.1107, -0.0753,  0.1683, -0.0482,\n",
       "          -0.1286,  0.0562,  0.1346, -0.0776,  0.0697,  0.1113, -0.0923, -0.0636,\n",
       "          -0.0751, -0.0938]]), 'layers.1.bias': tensor([-0.0642]), 'skip.weight': tensor([[ 0.0110, -0.0110,  0.0123,  0.0113,  0.0123,  0.0090, -0.0129, -0.0115,\n",
       "           0.0081,  0.0105, -0.0134, -0.0093, -0.0117,  0.0103,  0.0114, -0.0105,\n",
       "           0.0108,  0.0113,  0.0123,  0.0118,  0.0083,  0.0108,  0.0149,  0.0108,\n",
       "          -0.0120,  0.0110, -0.0114,  0.0119, -0.0125,  0.0112,  0.0133, -0.0127,\n",
       "           0.0156, -0.0125,  0.0123, -0.0133, -0.0142, -0.0107, -0.0106, -0.0126,\n",
       "          -0.0091, -0.0089,  0.0142, -0.0106,  0.0125,  0.0120, -0.0146, -0.0104,\n",
       "          -0.0148, -0.0100,  0.0118, -0.0100, -0.0113,  0.0091,  0.0125,  0.0111,\n",
       "          -0.0109, -0.0138, -0.0120,  0.0110,  0.0090,  0.0108, -0.0166,  0.0172,\n",
       "           0.0223, -0.0232,  0.0101]])}, objective=8.005469243464127, loss=0.7336096167564392, val_objective=8.03153179162468, val_loss=0.7596721649169922, regularization=0.8049764633178711, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.214302724665977, state_dict={'layers.0.weight': tensor([[-0.0675,  0.0239,  0.0831,  ..., -0.0071,  0.0583,  0.0366],\n",
       "         [-0.1099,  0.0213, -0.0148,  ...,  0.0338, -0.1034, -0.0691],\n",
       "         [-0.0444, -0.0551, -0.0220,  ..., -0.2228, -0.1297, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1095, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1099, -0.0228, -0.0950,  ..., -0.0274, -0.0007,  0.1002],\n",
       "         [-0.0432, -0.0244,  0.1223,  ...,  0.0460, -0.0854,  0.1002]]), 'layers.0.bias': tensor([-0.0635,  0.1394,  0.0429,  0.0598,  0.0940,  0.0908,  0.0052, -0.1503,\n",
       "          0.0047, -0.0829,  0.0694,  0.0950,  0.1270,  0.0371, -0.1506, -0.1196,\n",
       "         -0.0716, -0.1009,  0.1482,  0.0010,  0.0584,  0.1509, -0.0974,  0.0518,\n",
       "         -0.0796,  0.1791, -0.0892, -0.0500, -0.0563,  0.1078, -0.0248,  0.0248,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1477,  0.0008,  0.0619,  0.1027,  0.0564,\n",
       "         -0.0502,  0.0351,  0.1210, -0.0454,  0.1264, -0.0228, -0.0696, -0.0007,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0505,  0.1168, -0.1341, -0.0814,  0.0568, -0.1047, -0.0628, -0.0274,\n",
       "           0.1463, -0.0321,  0.0411, -0.0725,  0.0622,  0.0095, -0.0719,  0.0534,\n",
       "          -0.0904, -0.0187,  0.0240,  0.0687, -0.1085,  0.0443, -0.0749, -0.0674,\n",
       "          -0.0584,  0.1227,  0.0702,  0.1000,  0.1100, -0.0212, -0.1170,  0.1317,\n",
       "           0.0108,  0.0536, -0.0926,  0.1157,  0.1106, -0.0755,  0.1686, -0.0482,\n",
       "          -0.1286,  0.0562,  0.1347, -0.0777,  0.0699,  0.1113, -0.0924, -0.0637,\n",
       "          -0.0752, -0.0940]]), 'layers.1.bias': tensor([-0.0641]), 'skip.weight': tensor([[ 0.0110, -0.0110,  0.0122,  0.0112,  0.0122,  0.0089, -0.0128, -0.0114,\n",
       "           0.0081,  0.0105, -0.0133, -0.0092, -0.0117,  0.0102,  0.0113, -0.0105,\n",
       "           0.0108,  0.0112,  0.0122,  0.0117,  0.0083,  0.0108,  0.0148,  0.0108,\n",
       "          -0.0119,  0.0110, -0.0114,  0.0118, -0.0124,  0.0112,  0.0132, -0.0126,\n",
       "           0.0154, -0.0125,  0.0122, -0.0133, -0.0141, -0.0106, -0.0105, -0.0125,\n",
       "          -0.0090, -0.0088,  0.0141, -0.0105,  0.0125,  0.0119, -0.0145, -0.0104,\n",
       "          -0.0147, -0.0100,  0.0118, -0.0099, -0.0113,  0.0091,  0.0124,  0.0110,\n",
       "          -0.0108, -0.0137, -0.0119,  0.0110,  0.0090,  0.0107, -0.0165,  0.0171,\n",
       "           0.0223, -0.0231,  0.0100]])}, objective=8.113048978330786, loss=0.7336271405220032, val_objective=8.139033742429907, val_loss=0.7596119046211243, regularization=0.8008660078048706, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.398588779159297, state_dict={'layers.0.weight': tensor([[-0.0675,  0.0239,  0.0831,  ..., -0.0070,  0.0583,  0.0366],\n",
       "         [-0.1095,  0.0213, -0.0148,  ...,  0.0338, -0.1034, -0.0690],\n",
       "         [-0.0444, -0.0551, -0.0220,  ..., -0.2223, -0.1296, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1091, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1095, -0.0228, -0.0950,  ..., -0.0274, -0.0007,  0.0998],\n",
       "         [-0.0432, -0.0245,  0.1215,  ...,  0.0459, -0.0853,  0.0998]]), 'layers.0.bias': tensor([-0.0635,  0.1394,  0.0429,  0.0598,  0.0940,  0.0907,  0.0052, -0.1504,\n",
       "          0.0047, -0.0830,  0.0694,  0.0950,  0.1270,  0.0371, -0.1506, -0.1197,\n",
       "         -0.0716, -0.1009,  0.1482,  0.0010,  0.0584,  0.1508, -0.0974,  0.0518,\n",
       "         -0.0796,  0.1791, -0.0893, -0.0500, -0.0562,  0.1078, -0.0248,  0.0249,\n",
       "         -0.0318, -0.0450, -0.0307, -0.1478,  0.0008,  0.0619,  0.1027,  0.0564,\n",
       "         -0.0503,  0.0351,  0.1211, -0.0454,  0.1264, -0.0229, -0.0696, -0.0006,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0505,  0.1169, -0.1342, -0.0814,  0.0568, -0.1048, -0.0629, -0.0274,\n",
       "           0.1464, -0.0321,  0.0411, -0.0726,  0.0622,  0.0094, -0.0720,  0.0535,\n",
       "          -0.0905, -0.0185,  0.0239,  0.0687, -0.1085,  0.0443, -0.0749, -0.0674,\n",
       "          -0.0584,  0.1227,  0.0702,  0.1001,  0.1100, -0.0213, -0.1171,  0.1318,\n",
       "           0.0108,  0.0536, -0.0925,  0.1159,  0.1105, -0.0758,  0.1688, -0.0482,\n",
       "          -0.1286,  0.0561,  0.1348, -0.0778,  0.0700,  0.1112, -0.0924, -0.0639,\n",
       "          -0.0753, -0.0943]]), 'layers.1.bias': tensor([-0.0640]), 'skip.weight': tensor([[ 0.0109, -0.0109,  0.0122,  0.0111,  0.0122,  0.0088, -0.0127, -0.0114,\n",
       "           0.0080,  0.0104, -0.0133, -0.0092, -0.0116,  0.0102,  0.0112, -0.0104,\n",
       "           0.0107,  0.0112,  0.0122,  0.0116,  0.0083,  0.0107,  0.0147,  0.0107,\n",
       "          -0.0119,  0.0109, -0.0113,  0.0117, -0.0123,  0.0111,  0.0132, -0.0125,\n",
       "           0.0153, -0.0124,  0.0120, -0.0132, -0.0141, -0.0106, -0.0104, -0.0124,\n",
       "          -0.0090, -0.0088,  0.0140, -0.0105,  0.0124,  0.0118, -0.0145, -0.0103,\n",
       "          -0.0146, -0.0099,  0.0117, -0.0099, -0.0112,  0.0091,  0.0124,  0.0110,\n",
       "          -0.0108, -0.0137, -0.0119,  0.0109,  0.0089,  0.0107, -0.0164,  0.0170,\n",
       "           0.0222, -0.0230,  0.0100]])}, objective=8.221734765732121, loss=0.733646035194397, val_objective=8.247639838421177, val_loss=0.7595511078834534, regularization=0.796724796295166, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.586560554742483, state_dict={'layers.0.weight': tensor([[-0.0674,  0.0239,  0.0831,  ..., -0.0070,  0.0582,  0.0366],\n",
       "         [-0.1090,  0.0214, -0.0148,  ...,  0.0338, -0.1035, -0.0690],\n",
       "         [-0.0444, -0.0551, -0.0220,  ..., -0.2218, -0.1296, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1087, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1090, -0.0228, -0.0951,  ..., -0.0274, -0.0007,  0.0993],\n",
       "         [-0.0433, -0.0245,  0.1208,  ...,  0.0459, -0.0853,  0.0993]]), 'layers.0.bias': tensor([-0.0635,  0.1394,  0.0429,  0.0598,  0.0940,  0.0907,  0.0052, -0.1504,\n",
       "          0.0047, -0.0830,  0.0694,  0.0950,  0.1270,  0.0371, -0.1506, -0.1197,\n",
       "         -0.0716, -0.1009,  0.1481,  0.0009,  0.0584,  0.1508, -0.0974,  0.0517,\n",
       "         -0.0796,  0.1791, -0.0893, -0.0500, -0.0562,  0.1078, -0.0249,  0.0249,\n",
       "         -0.0318, -0.0449, -0.0307, -0.1478,  0.0007,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0504,  0.0351,  0.1211, -0.0454,  0.1263, -0.0229, -0.0696, -0.0006,\n",
       "          0.0325,  0.1171]), 'layers.1.weight': tensor([[ 0.0506,  0.1171, -0.1343, -0.0814,  0.0569, -0.1049, -0.0631, -0.0275,\n",
       "           0.1466, -0.0321,  0.0411, -0.0727,  0.0621,  0.0093, -0.0722,  0.0537,\n",
       "          -0.0907, -0.0184,  0.0238,  0.0687, -0.1085,  0.0442, -0.0748, -0.0673,\n",
       "          -0.0584,  0.1227,  0.0702,  0.1001,  0.1101, -0.0214, -0.1172,  0.1320,\n",
       "           0.0109,  0.0536, -0.0925,  0.1161,  0.1105, -0.0760,  0.1690, -0.0482,\n",
       "          -0.1285,  0.0561,  0.1350, -0.0778,  0.0701,  0.1111, -0.0924, -0.0640,\n",
       "          -0.0754, -0.0945]]), 'layers.1.bias': tensor([-0.0640]), 'skip.weight': tensor([[ 0.0109, -0.0109,  0.0121,  0.0111,  0.0121,  0.0088, -0.0127, -0.0113,\n",
       "           0.0080,  0.0104, -0.0132, -0.0091, -0.0115,  0.0101,  0.0111, -0.0104,\n",
       "           0.0107,  0.0111,  0.0121,  0.0116,  0.0083,  0.0107,  0.0147,  0.0107,\n",
       "          -0.0118,  0.0109, -0.0112,  0.0117, -0.0122,  0.0111,  0.0131, -0.0125,\n",
       "           0.0151, -0.0123,  0.0120, -0.0132, -0.0140, -0.0105, -0.0104, -0.0123,\n",
       "          -0.0089, -0.0088,  0.0140, -0.0104,  0.0123,  0.0117, -0.0144, -0.0103,\n",
       "          -0.0145, -0.0099,  0.0116, -0.0099, -0.0112,  0.0090,  0.0124,  0.0109,\n",
       "          -0.0107, -0.0136, -0.0118,  0.0108,  0.0089,  0.0106, -0.0163,  0.0170,\n",
       "           0.0222, -0.0230,  0.0099]])}, objective=8.331953943220164, loss=0.7336657047271729, val_objective=8.357778728452708, val_loss=0.7594904899597159, regularization=0.7925979495048523, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.778291765837333, state_dict={'layers.0.weight': tensor([[-0.0674,  0.0239,  0.0831,  ..., -0.0070,  0.0582,  0.0366],\n",
       "         [-0.1086,  0.0214, -0.0147,  ...,  0.0338, -0.1036, -0.0689],\n",
       "         [-0.0445, -0.0551, -0.0220,  ..., -0.2212, -0.1295, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1083, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1086, -0.0228, -0.0951,  ..., -0.0274, -0.0007,  0.0988],\n",
       "         [-0.0433, -0.0245,  0.1202,  ...,  0.0459, -0.0852,  0.0988]]), 'layers.0.bias': tensor([-0.0635,  0.1393,  0.0428,  0.0598,  0.0940,  0.0907,  0.0052, -0.1504,\n",
       "          0.0046, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1506, -0.1197,\n",
       "         -0.0716, -0.1009,  0.1481,  0.0009,  0.0584,  0.1508, -0.0975,  0.0517,\n",
       "         -0.0796,  0.1791, -0.0894, -0.0500, -0.0562,  0.1078, -0.0249,  0.0249,\n",
       "         -0.0318, -0.0449, -0.0307, -0.1478,  0.0007,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0505,  0.0351,  0.1211, -0.0454,  0.1263, -0.0229, -0.0695, -0.0006,\n",
       "          0.0326,  0.1171]), 'layers.1.weight': tensor([[ 0.0506,  0.1173, -0.1345, -0.0813,  0.0569, -0.1050, -0.0633, -0.0275,\n",
       "           0.1468, -0.0321,  0.0412, -0.0728,  0.0621,  0.0093, -0.0723,  0.0539,\n",
       "          -0.0908, -0.0183,  0.0238,  0.0687, -0.1086,  0.0442, -0.0748, -0.0673,\n",
       "          -0.0585,  0.1227,  0.0703,  0.1002,  0.1101, -0.0215, -0.1173,  0.1321,\n",
       "           0.0110,  0.0536, -0.0924,  0.1163,  0.1104, -0.0762,  0.1692, -0.0482,\n",
       "          -0.1285,  0.0560,  0.1351, -0.0779,  0.0703,  0.1110, -0.0925, -0.0642,\n",
       "          -0.0755, -0.0947]]), 'layers.1.bias': tensor([-0.0639]), 'skip.weight': tensor([[ 0.0109, -0.0108,  0.0120,  0.0110,  0.0121,  0.0087, -0.0126, -0.0113,\n",
       "           0.0080,  0.0103, -0.0131, -0.0091, -0.0115,  0.0101,  0.0110, -0.0103,\n",
       "           0.0107,  0.0111,  0.0120,  0.0115,  0.0082,  0.0107,  0.0146,  0.0106,\n",
       "          -0.0117,  0.0108, -0.0111,  0.0116, -0.0121,  0.0110,  0.0131, -0.0124,\n",
       "           0.0150, -0.0123,  0.0119, -0.0131, -0.0139, -0.0105, -0.0103, -0.0122,\n",
       "          -0.0088, -0.0087,  0.0139, -0.0103,  0.0123,  0.0116, -0.0144, -0.0102,\n",
       "          -0.0144, -0.0098,  0.0115, -0.0098, -0.0111,  0.0090,  0.0123,  0.0109,\n",
       "          -0.0107, -0.0135, -0.0117,  0.0107,  0.0089,  0.0106, -0.0162,  0.0169,\n",
       "           0.0221, -0.0229,  0.0099]])}, objective=8.444101711151108, loss=0.733687162399292, val_objective=8.46983798348616, val_loss=0.7594234347343445, regularization=0.7885236740112305, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=9.97385760115408, state_dict={'layers.0.weight': tensor([[-0.0674,  0.0239,  0.0832,  ..., -0.0070,  0.0582,  0.0367],\n",
       "         [-0.1082,  0.0214, -0.0147,  ...,  0.0338, -0.1036, -0.0689],\n",
       "         [-0.0445, -0.0551, -0.0221,  ..., -0.2207, -0.1295, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1078, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1082, -0.0228, -0.0951,  ..., -0.0274, -0.0006,  0.0983],\n",
       "         [-0.0434, -0.0245,  0.1196,  ...,  0.0458, -0.0852,  0.0983]]), 'layers.0.bias': tensor([-0.0635,  0.1393,  0.0428,  0.0598,  0.0940,  0.0907,  0.0052, -0.1504,\n",
       "          0.0046, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1507, -0.1197,\n",
       "         -0.0716, -0.1009,  0.1481,  0.0008,  0.0584,  0.1508, -0.0975,  0.0517,\n",
       "         -0.0797,  0.1791, -0.0894, -0.0501, -0.0561,  0.1077, -0.0249,  0.0249,\n",
       "         -0.0318, -0.0449, -0.0307, -0.1478,  0.0007,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0505,  0.0351,  0.1212, -0.0454,  0.1263, -0.0230, -0.0695, -0.0006,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0507,  0.1174, -0.1346, -0.0813,  0.0569, -0.1051, -0.0634, -0.0275,\n",
       "           0.1470, -0.0321,  0.0412, -0.0729,  0.0621,  0.0092, -0.0724,  0.0540,\n",
       "          -0.0910, -0.0181,  0.0237,  0.0686, -0.1086,  0.0442, -0.0748, -0.0672,\n",
       "          -0.0585,  0.1227,  0.0703,  0.1002,  0.1102, -0.0216, -0.1174,  0.1322,\n",
       "           0.0110,  0.0536, -0.0923,  0.1165,  0.1103, -0.0765,  0.1695, -0.0481,\n",
       "          -0.1285,  0.0560,  0.1353, -0.0780,  0.0704,  0.1110, -0.0925, -0.0643,\n",
       "          -0.0756, -0.0950]]), 'layers.1.bias': tensor([-0.0638]), 'skip.weight': tensor([[ 0.0108, -0.0108,  0.0120,  0.0109,  0.0120,  0.0086, -0.0125, -0.0112,\n",
       "           0.0079,  0.0102, -0.0131, -0.0091, -0.0114,  0.0100,  0.0110, -0.0103,\n",
       "           0.0106,  0.0110,  0.0119,  0.0115,  0.0082,  0.0106,  0.0146,  0.0105,\n",
       "          -0.0116,  0.0108, -0.0110,  0.0115, -0.0120,  0.0110,  0.0131, -0.0123,\n",
       "           0.0149, -0.0122,  0.0118, -0.0131, -0.0138, -0.0104, -0.0103, -0.0121,\n",
       "          -0.0088, -0.0087,  0.0139, -0.0102,  0.0122,  0.0116, -0.0143, -0.0102,\n",
       "          -0.0144, -0.0098,  0.0114, -0.0098, -0.0111,  0.0090,  0.0123,  0.0108,\n",
       "          -0.0106, -0.0135, -0.0117,  0.0106,  0.0088,  0.0105, -0.0160,  0.0168,\n",
       "           0.0221, -0.0229,  0.0098]])}, objective=8.557648730021466, loss=0.7337096929550171, val_objective=8.583288025599469, val_loss=0.75934898853302, regularization=0.7844446301460266, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=10.173334753177162, state_dict={'layers.0.weight': tensor([[-0.0673,  0.0239,  0.0832,  ..., -0.0070,  0.0582,  0.0367],\n",
       "         [-0.1077,  0.0215, -0.0147,  ...,  0.0339, -0.1037, -0.0689],\n",
       "         [-0.0445, -0.0551, -0.0221,  ..., -0.2202, -0.1294, -0.0241],\n",
       "         ...,\n",
       "         [-0.0071, -0.1074, -0.0276,  ..., -0.1653, -0.0582,  0.0382],\n",
       "         [ 0.1077, -0.0228, -0.0952,  ..., -0.0274, -0.0006,  0.0978],\n",
       "         [-0.0434, -0.0245,  0.1190,  ...,  0.0458, -0.0851,  0.0978]]), 'layers.0.bias': tensor([-0.0635,  0.1392,  0.0428,  0.0598,  0.0940,  0.0906,  0.0052, -0.1504,\n",
       "          0.0046, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1507, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0008,  0.0584,  0.1508, -0.0975,  0.0517,\n",
       "         -0.0797,  0.1791, -0.0895, -0.0501, -0.0561,  0.1077, -0.0249,  0.0249,\n",
       "         -0.0318, -0.0449, -0.0307, -0.1478,  0.0006,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0506,  0.0351,  0.1212, -0.0454,  0.1263, -0.0230, -0.0695, -0.0006,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0507,  0.1176, -0.1347, -0.0812,  0.0570, -0.1052, -0.0636, -0.0275,\n",
       "           0.1471, -0.0321,  0.0413, -0.0730,  0.0620,  0.0091, -0.0726,  0.0542,\n",
       "          -0.0911, -0.0180,  0.0236,  0.0686, -0.1086,  0.0441, -0.0747, -0.0672,\n",
       "          -0.0586,  0.1227,  0.0703,  0.1003,  0.1103, -0.0217, -0.1174,  0.1323,\n",
       "           0.0111,  0.0536, -0.0922,  0.1168,  0.1102, -0.0767,  0.1697, -0.0481,\n",
       "          -0.1285,  0.0560,  0.1354, -0.0781,  0.0705,  0.1109, -0.0926, -0.0645,\n",
       "          -0.0757, -0.0952]]), 'layers.1.bias': tensor([-0.0637]), 'skip.weight': tensor([[ 0.0108, -0.0107,  0.0119,  0.0109,  0.0120,  0.0086, -0.0125, -0.0112,\n",
       "           0.0079,  0.0102, -0.0130, -0.0090, -0.0114,  0.0099,  0.0108, -0.0102,\n",
       "           0.0106,  0.0110,  0.0119,  0.0114,  0.0082,  0.0106,  0.0145,  0.0105,\n",
       "          -0.0115,  0.0107, -0.0110,  0.0114, -0.0119,  0.0109,  0.0130, -0.0123,\n",
       "           0.0148, -0.0121,  0.0117, -0.0130, -0.0137, -0.0103, -0.0102, -0.0120,\n",
       "          -0.0087, -0.0087,  0.0138, -0.0102,  0.0122,  0.0115, -0.0142, -0.0102,\n",
       "          -0.0143, -0.0098,  0.0113, -0.0097, -0.0110,  0.0089,  0.0122,  0.0108,\n",
       "          -0.0106, -0.0134, -0.0116,  0.0106,  0.0088,  0.0105, -0.0159,  0.0167,\n",
       "           0.0220, -0.0228,  0.0098]])}, objective=8.672290057436163, loss=0.7337329387664795, val_objective=8.697829276815588, val_loss=0.7592721581459045, regularization=0.7803298830986023, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=10.376801448240705, state_dict={'layers.0.weight': tensor([[-0.0673,  0.0239,  0.0832,  ..., -0.0070,  0.0581,  0.0367],\n",
       "         [-0.1072,  0.0215, -0.0146,  ...,  0.0339, -0.1037, -0.0688],\n",
       "         [-0.0446, -0.0551, -0.0221,  ..., -0.2196, -0.1294, -0.0242],\n",
       "         ...,\n",
       "         [-0.0071, -0.1069, -0.0276,  ..., -0.1653, -0.0581,  0.0381],\n",
       "         [ 0.1072, -0.0228, -0.0952,  ..., -0.0274, -0.0006,  0.0973],\n",
       "         [-0.0435, -0.0245,  0.1184,  ...,  0.0458, -0.0851,  0.0973]]), 'layers.0.bias': tensor([-0.0635,  0.1392,  0.0428,  0.0597,  0.0940,  0.0906,  0.0051, -0.1504,\n",
       "          0.0046, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1507, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0007,  0.0584,  0.1508, -0.0975,  0.0517,\n",
       "         -0.0797,  0.1790, -0.0895, -0.0501, -0.0561,  0.1077, -0.0249,  0.0249,\n",
       "         -0.0318, -0.0449, -0.0307, -0.1478,  0.0006,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0507,  0.0351,  0.1213, -0.0454,  0.1263, -0.0230, -0.0695, -0.0006,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0508,  0.1178, -0.1348, -0.0812,  0.0570, -0.1053, -0.0637, -0.0275,\n",
       "           0.1473, -0.0321,  0.0413, -0.0731,  0.0620,  0.0090, -0.0727,  0.0544,\n",
       "          -0.0913, -0.0178,  0.0236,  0.0686, -0.1087,  0.0441, -0.0747, -0.0671,\n",
       "          -0.0586,  0.1227,  0.0703,  0.1003,  0.1103, -0.0218, -0.1175,  0.1325,\n",
       "           0.0111,  0.0536, -0.0922,  0.1170,  0.1102, -0.0769,  0.1699, -0.0481,\n",
       "          -0.1285,  0.0559,  0.1356, -0.0782,  0.0707,  0.1108, -0.0926, -0.0646,\n",
       "          -0.0758, -0.0954]]), 'layers.1.bias': tensor([-0.0637]), 'skip.weight': tensor([[ 0.0107, -0.0107,  0.0118,  0.0108,  0.0119,  0.0085, -0.0124, -0.0111,\n",
       "           0.0078,  0.0101, -0.0129, -0.0090, -0.0113,  0.0099,  0.0107, -0.0101,\n",
       "           0.0105,  0.0109,  0.0118,  0.0114,  0.0081,  0.0105,  0.0144,  0.0104,\n",
       "          -0.0115,  0.0107, -0.0109,  0.0114, -0.0118,  0.0109,  0.0130, -0.0122,\n",
       "           0.0146, -0.0121,  0.0116, -0.0130, -0.0136, -0.0103, -0.0102, -0.0119,\n",
       "          -0.0087, -0.0087,  0.0138, -0.0101,  0.0121,  0.0114, -0.0142, -0.0101,\n",
       "          -0.0142, -0.0097,  0.0113, -0.0097, -0.0110,  0.0089,  0.0122,  0.0107,\n",
       "          -0.0105, -0.0133, -0.0115,  0.0105,  0.0088,  0.0104, -0.0158,  0.0166,\n",
       "           0.0220, -0.0227,  0.0097]])}, objective=8.787865802647023, loss=0.7337580919265747, val_objective=8.81330756843224, val_loss=0.759199857711792, regularization=0.7761647701263428, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=10.58433747720552, state_dict={'layers.0.weight': tensor([[-0.0673,  0.0239,  0.0832,  ..., -0.0069,  0.0581,  0.0367],\n",
       "         [-0.1067,  0.0215, -0.0146,  ...,  0.0339, -0.1038, -0.0688],\n",
       "         [-0.0446, -0.0551, -0.0221,  ..., -0.2191, -0.1293, -0.0242],\n",
       "         ...,\n",
       "         [-0.0071, -0.1065, -0.0276,  ..., -0.1654, -0.0581,  0.0381],\n",
       "         [ 0.1067, -0.0228, -0.0952,  ..., -0.0274, -0.0005,  0.0967],\n",
       "         [-0.0435, -0.0245,  0.1177,  ...,  0.0457, -0.0850,  0.0967]]), 'layers.0.bias': tensor([-0.0635,  0.1392,  0.0428,  0.0597,  0.0940,  0.0906,  0.0051, -0.1504,\n",
       "          0.0045, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1507, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0007,  0.0584,  0.1508, -0.0976,  0.0516,\n",
       "         -0.0797,  0.1790, -0.0896, -0.0501, -0.0560,  0.1077, -0.0249,  0.0249,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1478,  0.0006,  0.0618,  0.1027,  0.0563,\n",
       "         -0.0507,  0.0351,  0.1213, -0.0454,  0.1263, -0.0231, -0.0695, -0.0006,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0508,  0.1179, -0.1350, -0.0812,  0.0571, -0.1055, -0.0639, -0.0275,\n",
       "           0.1475, -0.0321,  0.0414, -0.0732,  0.0620,  0.0089, -0.0728,  0.0545,\n",
       "          -0.0914, -0.0177,  0.0235,  0.0686, -0.1087,  0.0441, -0.0746, -0.0671,\n",
       "          -0.0586,  0.1227,  0.0704,  0.1004,  0.1104, -0.0219, -0.1176,  0.1326,\n",
       "           0.0112,  0.0537, -0.0921,  0.1172,  0.1101, -0.0772,  0.1702, -0.0481,\n",
       "          -0.1284,  0.0559,  0.1357, -0.0783,  0.0708,  0.1108, -0.0926, -0.0648,\n",
       "          -0.0758, -0.0956]]), 'layers.1.bias': tensor([-0.0636]), 'skip.weight': tensor([[ 0.0107, -0.0106,  0.0118,  0.0108,  0.0119,  0.0085, -0.0123, -0.0111,\n",
       "           0.0078,  0.0100, -0.0129, -0.0089, -0.0113,  0.0098,  0.0106, -0.0101,\n",
       "           0.0105,  0.0109,  0.0117,  0.0113,  0.0081,  0.0105,  0.0144,  0.0104,\n",
       "          -0.0114,  0.0106, -0.0108,  0.0113, -0.0117,  0.0108,  0.0129, -0.0121,\n",
       "           0.0145, -0.0120,  0.0115, -0.0129, -0.0136, -0.0102, -0.0101, -0.0118,\n",
       "          -0.0086, -0.0086,  0.0137, -0.0100,  0.0121,  0.0114, -0.0141, -0.0101,\n",
       "          -0.0141, -0.0097,  0.0112, -0.0096, -0.0109,  0.0089,  0.0121,  0.0106,\n",
       "          -0.0104, -0.0132, -0.0114,  0.0104,  0.0087,  0.0104, -0.0157,  0.0165,\n",
       "           0.0219, -0.0227,  0.0097]])}, objective=8.905332046749427, loss=0.7337830066680908, val_objective=8.93068053126557, val_loss=0.7591314911842346, regularization=0.7720416188240051, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=10.79602422674963, state_dict={'layers.0.weight': tensor([[-0.0672,  0.0239,  0.0832,  ..., -0.0069,  0.0581,  0.0367],\n",
       "         [-0.1063,  0.0216, -0.0146,  ...,  0.0339, -0.1038, -0.0687],\n",
       "         [-0.0446, -0.0551, -0.0222,  ..., -0.2185, -0.1293, -0.0242],\n",
       "         ...,\n",
       "         [-0.0071, -0.1060, -0.0276,  ..., -0.1654, -0.0581,  0.0381],\n",
       "         [ 0.1063, -0.0227, -0.0953,  ..., -0.0275, -0.0005,  0.0962],\n",
       "         [-0.0436, -0.0246,  0.1171,  ...,  0.0457, -0.0850,  0.0962]]), 'layers.0.bias': tensor([-0.0635,  0.1391,  0.0427,  0.0597,  0.0940,  0.0906,  0.0051, -0.1504,\n",
       "          0.0045, -0.0830,  0.0694,  0.0951,  0.1270,  0.0371, -0.1507, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0007,  0.0584,  0.1508, -0.0976,  0.0516,\n",
       "         -0.0797,  0.1790, -0.0896, -0.0502, -0.0560,  0.1077, -0.0250,  0.0249,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0006,  0.0618,  0.1027,  0.0562,\n",
       "         -0.0508,  0.0351,  0.1214, -0.0454,  0.1262, -0.0231, -0.0695, -0.0005,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0509,  0.1181, -0.1351, -0.0812,  0.0571, -0.1056, -0.0640, -0.0275,\n",
       "           0.1477, -0.0321,  0.0414, -0.0733,  0.0620,  0.0089, -0.0729,  0.0547,\n",
       "          -0.0916, -0.0176,  0.0235,  0.0686, -0.1087,  0.0440, -0.0746, -0.0671,\n",
       "          -0.0587,  0.1227,  0.0704,  0.1004,  0.1104, -0.0220, -0.1177,  0.1327,\n",
       "           0.0113,  0.0537, -0.0920,  0.1175,  0.1100, -0.0774,  0.1704, -0.0481,\n",
       "          -0.1284,  0.0559,  0.1359, -0.0784,  0.0709,  0.1107, -0.0927, -0.0649,\n",
       "          -0.0759, -0.0959]]), 'layers.1.bias': tensor([-0.0635]), 'skip.weight': tensor([[ 0.0106, -0.0106,  0.0117,  0.0107,  0.0118,  0.0084, -0.0122, -0.0110,\n",
       "           0.0078,  0.0100, -0.0128, -0.0089, -0.0112,  0.0098,  0.0105, -0.0101,\n",
       "           0.0104,  0.0108,  0.0116,  0.0112,  0.0081,  0.0104,  0.0143,  0.0103,\n",
       "          -0.0113,  0.0105, -0.0107,  0.0112, -0.0117,  0.0108,  0.0129, -0.0120,\n",
       "           0.0144, -0.0120,  0.0114, -0.0128, -0.0135, -0.0102, -0.0101, -0.0117,\n",
       "          -0.0085, -0.0086,  0.0137, -0.0100,  0.0120,  0.0113, -0.0141, -0.0100,\n",
       "          -0.0140, -0.0096,  0.0111, -0.0096, -0.0109,  0.0088,  0.0121,  0.0106,\n",
       "          -0.0104, -0.0132, -0.0114,  0.0104,  0.0087,  0.0103, -0.0156,  0.0164,\n",
       "           0.0219, -0.0226,  0.0096]])}, objective=9.02427892460359, loss=0.7338080406188965, val_objective=9.049536452431807, val_loss=0.759065568447113, regularization=0.7679188847541809, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=11.011944711284622, state_dict={'layers.0.weight': tensor([[-0.0672,  0.0239,  0.0832,  ..., -0.0069,  0.0581,  0.0367],\n",
       "         [-0.1058,  0.0216, -0.0145,  ...,  0.0339, -0.1039, -0.0687],\n",
       "         [-0.0447, -0.0551, -0.0222,  ..., -0.2179, -0.1292, -0.0242],\n",
       "         ...,\n",
       "         [-0.0072, -0.1055, -0.0277,  ..., -0.1654, -0.0581,  0.0381],\n",
       "         [ 0.1058, -0.0227, -0.0953,  ..., -0.0275, -0.0005,  0.0956],\n",
       "         [-0.0436, -0.0246,  0.1164,  ...,  0.0457, -0.0849,  0.0956]]), 'layers.0.bias': tensor([-0.0635,  0.1391,  0.0427,  0.0597,  0.0940,  0.0906,  0.0051, -0.1504,\n",
       "          0.0045, -0.0830,  0.0694,  0.0952,  0.1270,  0.0371, -0.1508, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0006,  0.0584,  0.1508, -0.0976,  0.0516,\n",
       "         -0.0797,  0.1790, -0.0897, -0.0502, -0.0559,  0.1077, -0.0250,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0005,  0.0618,  0.1027,  0.0562,\n",
       "         -0.0509,  0.0351,  0.1214, -0.0454,  0.1262, -0.0231, -0.0694, -0.0005,\n",
       "          0.0326,  0.1172]), 'layers.1.weight': tensor([[ 0.0509,  0.1183, -0.1352, -0.0812,  0.0571, -0.1057, -0.0642, -0.0275,\n",
       "           0.1479, -0.0321,  0.0415, -0.0734,  0.0620,  0.0088, -0.0731,  0.0549,\n",
       "          -0.0917, -0.0174,  0.0234,  0.0685, -0.1088,  0.0440, -0.0746, -0.0670,\n",
       "          -0.0587,  0.1227,  0.0704,  0.1005,  0.1105, -0.0221, -0.1178,  0.1328,\n",
       "           0.0113,  0.0537, -0.0920,  0.1177,  0.1099, -0.0776,  0.1706, -0.0481,\n",
       "          -0.1284,  0.0558,  0.1361, -0.0785,  0.0710,  0.1107, -0.0927, -0.0651,\n",
       "          -0.0760, -0.0961]]), 'layers.1.bias': tensor([-0.0635]), 'skip.weight': tensor([[ 0.0106, -0.0105,  0.0116,  0.0106,  0.0118,  0.0084, -0.0122, -0.0110,\n",
       "           0.0077,  0.0099, -0.0128, -0.0089, -0.0111,  0.0097,  0.0104, -0.0100,\n",
       "           0.0104,  0.0108,  0.0116,  0.0112,  0.0080,  0.0104,  0.0142,  0.0102,\n",
       "          -0.0113,  0.0105, -0.0106,  0.0111, -0.0116,  0.0107,  0.0128, -0.0120,\n",
       "           0.0143, -0.0119,  0.0114, -0.0128, -0.0134, -0.0101, -0.0100, -0.0116,\n",
       "          -0.0085, -0.0086,  0.0136, -0.0099,  0.0119,  0.0112, -0.0140, -0.0100,\n",
       "          -0.0139, -0.0096,  0.0110, -0.0095, -0.0109,  0.0088,  0.0120,  0.0105,\n",
       "          -0.0103, -0.0131, -0.0113,  0.0103,  0.0087,  0.0103, -0.0155,  0.0163,\n",
       "           0.0218, -0.0225,  0.0096]])}, objective=9.144548413266051, loss=0.7338341474533081, val_objective=9.169710216034758, val_loss=0.7589959502220154, regularization=0.7637810111045837, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=11.232183605510315, state_dict={'layers.0.weight': tensor([[-0.0672,  0.0239,  0.0832,  ..., -0.0069,  0.0580,  0.0367],\n",
       "         [-0.1053,  0.0216, -0.0145,  ...,  0.0339, -0.1039, -0.0686],\n",
       "         [-0.0447, -0.0551, -0.0222,  ..., -0.2173, -0.1292, -0.0242],\n",
       "         ...,\n",
       "         [-0.0072, -0.1050, -0.0277,  ..., -0.1654, -0.0581,  0.0381],\n",
       "         [ 0.1053, -0.0227, -0.0953,  ..., -0.0275, -0.0005,  0.0951],\n",
       "         [-0.0437, -0.0246,  0.1157,  ...,  0.0456, -0.0849,  0.0951]]), 'layers.0.bias': tensor([-0.0635,  0.1390,  0.0427,  0.0597,  0.0940,  0.0905,  0.0051, -0.1504,\n",
       "          0.0045, -0.0831,  0.0694,  0.0952,  0.1270,  0.0371, -0.1508, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0006,  0.0584,  0.1507, -0.0977,  0.0516,\n",
       "         -0.0798,  0.1790, -0.0897, -0.0502, -0.0559,  0.1077, -0.0250,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0005,  0.0618,  0.1027,  0.0562,\n",
       "         -0.0509,  0.0351,  0.1215, -0.0454,  0.1262, -0.0232, -0.0694, -0.0005,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0510,  0.1184, -0.1353, -0.0811,  0.0572, -0.1058, -0.0643, -0.0275,\n",
       "           0.1480, -0.0321,  0.0415, -0.0735,  0.0620,  0.0087, -0.0732,  0.0550,\n",
       "          -0.0919, -0.0173,  0.0234,  0.0685, -0.1088,  0.0440, -0.0745, -0.0670,\n",
       "          -0.0588,  0.1227,  0.0705,  0.1006,  0.1106, -0.0222, -0.1179,  0.1330,\n",
       "           0.0114,  0.0537, -0.0919,  0.1180,  0.1098, -0.0779,  0.1708, -0.0481,\n",
       "          -0.1284,  0.0558,  0.1362, -0.0786,  0.0712,  0.1106, -0.0928, -0.0653,\n",
       "          -0.0761, -0.0963]]), 'layers.1.bias': tensor([-0.0634]), 'skip.weight': tensor([[ 0.0105, -0.0105,  0.0116,  0.0106,  0.0117,  0.0083, -0.0121, -0.0109,\n",
       "           0.0077,  0.0098, -0.0127, -0.0088, -0.0111,  0.0097,  0.0103, -0.0100,\n",
       "           0.0103,  0.0107,  0.0115,  0.0111,  0.0080,  0.0104,  0.0142,  0.0102,\n",
       "          -0.0112,  0.0104, -0.0105,  0.0111, -0.0115,  0.0107,  0.0128, -0.0119,\n",
       "           0.0142, -0.0118,  0.0113, -0.0127, -0.0133, -0.0101, -0.0100, -0.0115,\n",
       "          -0.0084, -0.0085,  0.0136, -0.0099,  0.0119,  0.0112, -0.0139, -0.0099,\n",
       "          -0.0138, -0.0095,  0.0109, -0.0095, -0.0108,  0.0088,  0.0120,  0.0105,\n",
       "          -0.0103, -0.0130, -0.0113,  0.0102,  0.0086,  0.0102, -0.0154,  0.0162,\n",
       "           0.0217, -0.0225,  0.0095]])}, objective=9.266412734538587, loss=0.7338597774505615, val_objective=9.291470944434675, val_loss=0.7589179873466492, regularization=0.7596521973609924, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=11.456827277620521, state_dict={'layers.0.weight': tensor([[-0.0672,  0.0239,  0.0832,  ..., -0.0069,  0.0580,  0.0367],\n",
       "         [-0.1047,  0.0217, -0.0144,  ...,  0.0339, -0.1040, -0.0686],\n",
       "         [-0.0448, -0.0552, -0.0223,  ..., -0.2167, -0.1291, -0.0242],\n",
       "         ...,\n",
       "         [-0.0072, -0.1045, -0.0277,  ..., -0.1654, -0.0581,  0.0381],\n",
       "         [ 0.1047, -0.0227, -0.0953,  ..., -0.0275, -0.0004,  0.0946],\n",
       "         [-0.0437, -0.0246,  0.1150,  ...,  0.0456, -0.0848,  0.0946]]), 'layers.0.bias': tensor([-0.0635,  0.1390,  0.0427,  0.0597,  0.0940,  0.0905,  0.0051, -0.1505,\n",
       "          0.0045, -0.0831,  0.0694,  0.0952,  0.1270,  0.0371, -0.1508, -0.1197,\n",
       "         -0.0717, -0.1009,  0.1481,  0.0005,  0.0584,  0.1507, -0.0977,  0.0515,\n",
       "         -0.0798,  0.1789, -0.0898, -0.0503, -0.0559,  0.1077, -0.0250,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0005,  0.0618,  0.1027,  0.0562,\n",
       "         -0.0510,  0.0351,  0.1215, -0.0454,  0.1262, -0.0232, -0.0694, -0.0005,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0510,  0.1186, -0.1355, -0.0811,  0.0572, -0.1059, -0.0645, -0.0275,\n",
       "           0.1482, -0.0322,  0.0416, -0.0736,  0.0620,  0.0086, -0.0733,  0.0552,\n",
       "          -0.0920, -0.0171,  0.0234,  0.0685, -0.1089,  0.0440, -0.0745, -0.0670,\n",
       "          -0.0588,  0.1226,  0.0705,  0.1006,  0.1106, -0.0223, -0.1180,  0.1331,\n",
       "           0.0115,  0.0537, -0.0918,  0.1182,  0.1098, -0.0781,  0.1711, -0.0481,\n",
       "          -0.1284,  0.0558,  0.1364, -0.0787,  0.0713,  0.1105, -0.0928, -0.0654,\n",
       "          -0.0762, -0.0966]]), 'layers.1.bias': tensor([-0.0634]), 'skip.weight': tensor([[ 0.0105, -0.0104,  0.0115,  0.0105,  0.0116,  0.0082, -0.0120, -0.0109,\n",
       "           0.0076,  0.0098, -0.0127, -0.0088, -0.0110,  0.0096,  0.0102, -0.0099,\n",
       "           0.0103,  0.0107,  0.0114,  0.0111,  0.0080,  0.0103,  0.0141,  0.0101,\n",
       "          -0.0111,  0.0104, -0.0104,  0.0110, -0.0114,  0.0106,  0.0127, -0.0118,\n",
       "           0.0141, -0.0117,  0.0112, -0.0127, -0.0132, -0.0100, -0.0099, -0.0114,\n",
       "          -0.0084, -0.0085,  0.0135, -0.0098,  0.0118,  0.0111, -0.0139, -0.0099,\n",
       "          -0.0137, -0.0095,  0.0109, -0.0094, -0.0108,  0.0087,  0.0119,  0.0104,\n",
       "          -0.0102, -0.0129, -0.0112,  0.0102,  0.0086,  0.0102, -0.0153,  0.0161,\n",
       "           0.0217, -0.0224,  0.0095]])}, objective=9.389559845121093, loss=0.7338870167732239, val_objective=9.414509753377624, val_loss=0.7588369250297546, regularization=0.7555034756660461, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=11.685963823172932, state_dict={'layers.0.weight': tensor([[-0.0671,  0.0239,  0.0832,  ..., -0.0069,  0.0580,  0.0367],\n",
       "         [-0.1042,  0.0217, -0.0144,  ...,  0.0340, -0.1040, -0.0685],\n",
       "         [-0.0448, -0.0552, -0.0223,  ..., -0.2161, -0.1291, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1040, -0.0277,  ..., -0.1654, -0.0580,  0.0381],\n",
       "         [ 0.1042, -0.0227, -0.0954,  ..., -0.0275, -0.0004,  0.0940],\n",
       "         [-0.0438, -0.0246,  0.1143,  ...,  0.0455, -0.0848,  0.0940]]), 'layers.0.bias': tensor([-0.0635,  0.1390,  0.0427,  0.0597,  0.0940,  0.0905,  0.0051, -0.1505,\n",
       "          0.0044, -0.0831,  0.0695,  0.0952,  0.1270,  0.0371, -0.1508, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0005,  0.0584,  0.1507, -0.0977,  0.0515,\n",
       "         -0.0798,  0.1789, -0.0898, -0.0503, -0.0558,  0.1077, -0.0250,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0005,  0.0618,  0.1027,  0.0561,\n",
       "         -0.0511,  0.0351,  0.1216, -0.0454,  0.1262, -0.0232, -0.0694, -0.0005,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0511,  0.1188, -0.1356, -0.0811,  0.0573, -0.1060, -0.0646, -0.0275,\n",
       "           0.1484, -0.0322,  0.0416, -0.0737,  0.0620,  0.0085, -0.0735,  0.0554,\n",
       "          -0.0922, -0.0170,  0.0233,  0.0685, -0.1089,  0.0439, -0.0744, -0.0670,\n",
       "          -0.0589,  0.1226,  0.0705,  0.1007,  0.1107, -0.0224, -0.1181,  0.1332,\n",
       "           0.0115,  0.0537, -0.0918,  0.1185,  0.1097, -0.0783,  0.1713, -0.0481,\n",
       "          -0.1283,  0.0558,  0.1366, -0.0787,  0.0714,  0.1105, -0.0929, -0.0656,\n",
       "          -0.0763, -0.0968]]), 'layers.1.bias': tensor([-0.0633]), 'skip.weight': tensor([[ 0.0104, -0.0104,  0.0114,  0.0105,  0.0116,  0.0082, -0.0119, -0.0108,\n",
       "           0.0076,  0.0097, -0.0126, -0.0087, -0.0109,  0.0095,  0.0101, -0.0099,\n",
       "           0.0103,  0.0106,  0.0114,  0.0110,  0.0079,  0.0103,  0.0140,  0.0100,\n",
       "          -0.0110,  0.0103, -0.0103,  0.0109, -0.0113,  0.0106,  0.0127, -0.0117,\n",
       "           0.0139, -0.0117,  0.0111, -0.0126, -0.0132, -0.0099, -0.0099, -0.0113,\n",
       "          -0.0083, -0.0085,  0.0135, -0.0097,  0.0118,  0.0110, -0.0138, -0.0099,\n",
       "          -0.0137, -0.0094,  0.0108, -0.0094, -0.0107,  0.0087,  0.0119,  0.0103,\n",
       "          -0.0102, -0.0129, -0.0112,  0.0101,  0.0085,  0.0101, -0.0152,  0.0161,\n",
       "           0.0216, -0.0223,  0.0094]])}, objective=9.514303505990759, loss=0.7339154481887817, val_objective=9.539138854120031, val_loss=0.7587507963180542, regularization=0.7513619065284729, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=11.91968309963639, state_dict={'layers.0.weight': tensor([[-0.0671,  0.0239,  0.0832,  ..., -0.0068,  0.0580,  0.0367],\n",
       "         [-0.1037,  0.0217, -0.0144,  ...,  0.0340, -0.1041, -0.0685],\n",
       "         [-0.0448, -0.0552, -0.0223,  ..., -0.2155, -0.1290, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1034, -0.0277,  ..., -0.1654, -0.0580,  0.0381],\n",
       "         [ 0.1037, -0.0227, -0.0954,  ..., -0.0275, -0.0004,  0.0935],\n",
       "         [-0.0439, -0.0246,  0.1136,  ...,  0.0455, -0.0847,  0.0935]]), 'layers.0.bias': tensor([-0.0635,  0.1389,  0.0426,  0.0597,  0.0940,  0.0905,  0.0051, -0.1505,\n",
       "          0.0044, -0.0831,  0.0695,  0.0952,  0.1271,  0.0371, -0.1509, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0005,  0.0584,  0.1507, -0.0978,  0.0515,\n",
       "         -0.0798,  0.1789, -0.0899, -0.0503, -0.0558,  0.1077, -0.0250,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0005,  0.0618,  0.1027,  0.0561,\n",
       "         -0.0511,  0.0351,  0.1216, -0.0454,  0.1262, -0.0233, -0.0694, -0.0005,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0511,  0.1189, -0.1357, -0.0811,  0.0573, -0.1061, -0.0648, -0.0276,\n",
       "           0.1486, -0.0322,  0.0417, -0.0738,  0.0620,  0.0084, -0.0736,  0.0555,\n",
       "          -0.0923, -0.0169,  0.0233,  0.0685, -0.1090,  0.0439, -0.0744, -0.0669,\n",
       "          -0.0589,  0.1226,  0.0706,  0.1007,  0.1107, -0.0225, -0.1182,  0.1333,\n",
       "           0.0116,  0.0538, -0.0917,  0.1187,  0.1096, -0.0786,  0.1715, -0.0481,\n",
       "          -0.1283,  0.0557,  0.1367, -0.0788,  0.0716,  0.1104, -0.0929, -0.0657,\n",
       "          -0.0763, -0.0970]]), 'layers.1.bias': tensor([-0.0632]), 'skip.weight': tensor([[ 0.0104, -0.0103,  0.0114,  0.0104,  0.0115,  0.0081, -0.0119, -0.0108,\n",
       "           0.0076,  0.0096, -0.0125, -0.0087, -0.0109,  0.0095,  0.0100, -0.0098,\n",
       "           0.0102,  0.0106,  0.0113,  0.0109,  0.0079,  0.0102,  0.0140,  0.0100,\n",
       "          -0.0110,  0.0103, -0.0102,  0.0108, -0.0112,  0.0105,  0.0126, -0.0117,\n",
       "           0.0138, -0.0116,  0.0111, -0.0125, -0.0131, -0.0099, -0.0098, -0.0112,\n",
       "          -0.0083, -0.0084,  0.0134, -0.0097,  0.0117,  0.0110, -0.0138, -0.0098,\n",
       "          -0.0136, -0.0094,  0.0107, -0.0093, -0.0107,  0.0087,  0.0118,  0.0103,\n",
       "          -0.0101, -0.0128, -0.0111,  0.0100,  0.0085,  0.0101, -0.0151,  0.0160,\n",
       "           0.0215, -0.0223,  0.0093]])}, objective=9.640363515835803, loss=0.7339456081390381, val_objective=9.665081740838092, val_loss=0.7586638331413269, regularization=0.7472025752067566, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=12.158076761629118, state_dict={'layers.0.weight': tensor([[-0.0671,  0.0239,  0.0832,  ..., -0.0068,  0.0579,  0.0367],\n",
       "         [-0.1031,  0.0218, -0.0143,  ...,  0.0340, -0.1041, -0.0684],\n",
       "         [-0.0449, -0.0552, -0.0223,  ..., -0.2148, -0.1290, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1029, -0.0277,  ..., -0.1654, -0.0580,  0.0381],\n",
       "         [ 0.1031, -0.0227, -0.0954,  ..., -0.0275, -0.0004,  0.0929],\n",
       "         [-0.0439, -0.0246,  0.1128,  ...,  0.0455, -0.0846,  0.0929]]), 'layers.0.bias': tensor([-0.0635,  0.1389,  0.0426,  0.0597,  0.0940,  0.0905,  0.0051, -0.1505,\n",
       "          0.0044, -0.0831,  0.0695,  0.0952,  0.1271,  0.0371, -0.1509, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0004,  0.0584,  0.1507, -0.0978,  0.0515,\n",
       "         -0.0798,  0.1789, -0.0899, -0.0503, -0.0558,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0004,  0.0618,  0.1027,  0.0561,\n",
       "         -0.0512,  0.0351,  0.1217, -0.0454,  0.1261, -0.0233, -0.0694, -0.0004,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0512,  0.1191, -0.1359, -0.0811,  0.0573, -0.1062, -0.0649, -0.0276,\n",
       "           0.1487, -0.0322,  0.0417, -0.0739,  0.0620,  0.0083, -0.0737,  0.0557,\n",
       "          -0.0925, -0.0167,  0.0233,  0.0685, -0.1090,  0.0439, -0.0744, -0.0669,\n",
       "          -0.0589,  0.1226,  0.0706,  0.1008,  0.1108, -0.0225, -0.1183,  0.1334,\n",
       "           0.0117,  0.0538, -0.0916,  0.1190,  0.1095, -0.0788,  0.1718, -0.0481,\n",
       "          -0.1283,  0.0557,  0.1369, -0.0789,  0.0717,  0.1104, -0.0929, -0.0659,\n",
       "          -0.0764, -0.0973]]), 'layers.1.bias': tensor([-0.0632]), 'skip.weight': tensor([[ 0.0103, -0.0103,  0.0113,  0.0103,  0.0115,  0.0081, -0.0118, -0.0107,\n",
       "           0.0075,  0.0096, -0.0125, -0.0087, -0.0108,  0.0094,  0.0098, -0.0098,\n",
       "           0.0102,  0.0105,  0.0112,  0.0109,  0.0079,  0.0102,  0.0139,  0.0099,\n",
       "          -0.0109,  0.0102, -0.0101,  0.0107, -0.0111,  0.0105,  0.0126, -0.0116,\n",
       "           0.0137, -0.0115,  0.0110, -0.0125, -0.0130, -0.0098, -0.0098, -0.0112,\n",
       "          -0.0082, -0.0084,  0.0134, -0.0096,  0.0117,  0.0109, -0.0137, -0.0098,\n",
       "          -0.0135, -0.0093,  0.0107, -0.0093, -0.0106,  0.0086,  0.0118,  0.0102,\n",
       "          -0.0100, -0.0127, -0.0110,  0.0099,  0.0085,  0.0100, -0.0150,  0.0159,\n",
       "           0.0215, -0.0222,  0.0093]])}, objective=9.767500177241242, loss=0.7339763045310974, val_objective=9.792100385046876, val_loss=0.758576512336731, regularization=0.7430059909820557, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=12.4012382968617, state_dict={'layers.0.weight': tensor([[-0.0670,  0.0239,  0.0832,  ..., -0.0068,  0.0579,  0.0368],\n",
       "         [-0.1026,  0.0218, -0.0143,  ...,  0.0340, -0.1042, -0.0684],\n",
       "         [-0.0449, -0.0552, -0.0224,  ..., -0.2142, -0.1289, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1023, -0.0277,  ..., -0.1654, -0.0580,  0.0381],\n",
       "         [ 0.1026, -0.0227, -0.0955,  ..., -0.0275, -0.0003,  0.0924],\n",
       "         [-0.0440, -0.0247,  0.1121,  ...,  0.0454, -0.0846,  0.0924]]), 'layers.0.bias': tensor([-0.0635,  0.1388,  0.0426,  0.0597,  0.0940,  0.0904,  0.0050, -0.1505,\n",
       "          0.0044, -0.0831,  0.0695,  0.0953,  0.1271,  0.0371, -0.1509, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0004,  0.0584,  0.1507, -0.0978,  0.0515,\n",
       "         -0.0798,  0.1788, -0.0900, -0.0504, -0.0557,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0307, -0.1479,  0.0004,  0.0618,  0.1027,  0.0561,\n",
       "         -0.0513,  0.0351,  0.1217, -0.0454,  0.1261, -0.0233, -0.0694, -0.0004,\n",
       "          0.0327,  0.1172]), 'layers.1.weight': tensor([[ 0.0512,  0.1192, -0.1360, -0.0811,  0.0574, -0.1064, -0.0651, -0.0276,\n",
       "           0.1489, -0.0322,  0.0418, -0.0740,  0.0620,  0.0082, -0.0738,  0.0558,\n",
       "          -0.0926, -0.0166,  0.0233,  0.0685, -0.1091,  0.0439, -0.0743, -0.0669,\n",
       "          -0.0590,  0.1226,  0.0707,  0.1009,  0.1108, -0.0226, -0.1184,  0.1336,\n",
       "           0.0117,  0.0538, -0.0916,  0.1192,  0.1094, -0.0791,  0.1720, -0.0481,\n",
       "          -0.1283,  0.0557,  0.1371, -0.0790,  0.0718,  0.1103, -0.0930, -0.0660,\n",
       "          -0.0765, -0.0975]]), 'layers.1.bias': tensor([-0.0631]), 'skip.weight': tensor([[ 0.0103, -0.0102,  0.0112,  0.0103,  0.0114,  0.0080, -0.0117, -0.0107,\n",
       "           0.0075,  0.0095, -0.0124, -0.0086, -0.0107,  0.0094,  0.0097, -0.0097,\n",
       "           0.0101,  0.0105,  0.0111,  0.0108,  0.0078,  0.0101,  0.0138,  0.0099,\n",
       "          -0.0108,  0.0102, -0.0100,  0.0106, -0.0111,  0.0104,  0.0125, -0.0115,\n",
       "           0.0136, -0.0115,  0.0109, -0.0124, -0.0130, -0.0098, -0.0097, -0.0111,\n",
       "          -0.0081, -0.0084,  0.0133, -0.0096,  0.0116,  0.0108, -0.0136, -0.0097,\n",
       "          -0.0134, -0.0093,  0.0106, -0.0092, -0.0106,  0.0086,  0.0117,  0.0102,\n",
       "          -0.0100, -0.0126, -0.0110,  0.0099,  0.0084,  0.0100, -0.0149,  0.0159,\n",
       "           0.0214, -0.0221,  0.0092]])}, objective=9.895670752251478, loss=0.7340078353881836, val_objective=9.920153896534773, val_loss=0.7584909796714783, regularization=0.7387700080871582, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=12.649263062798935, state_dict={'layers.0.weight': tensor([[-0.0670,  0.0239,  0.0832,  ..., -0.0068,  0.0579,  0.0368],\n",
       "         [-0.1020,  0.0218, -0.0143,  ...,  0.0340, -0.1042, -0.0684],\n",
       "         [-0.0449, -0.0552, -0.0224,  ..., -0.2135, -0.1289, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1018, -0.0277,  ..., -0.1655, -0.0580,  0.0381],\n",
       "         [ 0.1020, -0.0227, -0.0955,  ..., -0.0275, -0.0003,  0.0918],\n",
       "         [-0.0440, -0.0247,  0.1113,  ...,  0.0454, -0.0845,  0.0918]]), 'layers.0.bias': tensor([-0.0634,  0.1388,  0.0426,  0.0596,  0.0940,  0.0904,  0.0050, -0.1505,\n",
       "          0.0044, -0.0831,  0.0695,  0.0953,  0.1271,  0.0371, -0.1509, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0003,  0.0584,  0.1507, -0.0979,  0.0514,\n",
       "         -0.0798,  0.1788, -0.0900, -0.0504, -0.0557,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0306, -0.1479,  0.0004,  0.0618,  0.1027,  0.0561,\n",
       "         -0.0514,  0.0351,  0.1218, -0.0454,  0.1261, -0.0233, -0.0693, -0.0004,\n",
       "          0.0328,  0.1172]), 'layers.1.weight': tensor([[ 0.0513,  0.1194, -0.1361, -0.0811,  0.0574, -0.1065, -0.0652, -0.0276,\n",
       "           0.1491, -0.0322,  0.0418, -0.0741,  0.0620,  0.0081, -0.0740,  0.0560,\n",
       "          -0.0928, -0.0164,  0.0233,  0.0685, -0.1091,  0.0439, -0.0743, -0.0669,\n",
       "          -0.0590,  0.1226,  0.0707,  0.1009,  0.1109, -0.0227, -0.1185,  0.1337,\n",
       "           0.0118,  0.0538, -0.0915,  0.1195,  0.1094, -0.0793,  0.1723, -0.0481,\n",
       "          -0.1282,  0.0557,  0.1373, -0.0791,  0.0720,  0.1103, -0.0930, -0.0662,\n",
       "          -0.0766, -0.0977]]), 'layers.1.bias': tensor([-0.0631]), 'skip.weight': tensor([[ 0.0102, -0.0102,  0.0111,  0.0102,  0.0114,  0.0079, -0.0116, -0.0106,\n",
       "           0.0075,  0.0094, -0.0124, -0.0086, -0.0107,  0.0093,  0.0096, -0.0097,\n",
       "           0.0101,  0.0104,  0.0110,  0.0107,  0.0078,  0.0101,  0.0137,  0.0098,\n",
       "          -0.0108,  0.0101, -0.0099,  0.0106, -0.0110,  0.0104,  0.0124, -0.0114,\n",
       "           0.0135, -0.0114,  0.0108, -0.0123, -0.0129, -0.0097, -0.0097, -0.0110,\n",
       "          -0.0081, -0.0083,  0.0133, -0.0095,  0.0115,  0.0108, -0.0136, -0.0097,\n",
       "          -0.0133, -0.0092,  0.0105, -0.0092, -0.0105,  0.0086,  0.0117,  0.0101,\n",
       "          -0.0099, -0.0125, -0.0109,  0.0098,  0.0084,  0.0099, -0.0148,  0.0158,\n",
       "           0.0213, -0.0220,  0.0092]])}, objective=10.025051841053507, loss=0.7340415716171265, val_objective=10.049413749489329, val_loss=0.758403480052948, regularization=0.7345100045204163, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=12.902248324054915, state_dict={'layers.0.weight': tensor([[-0.0670,  0.0239,  0.0833,  ..., -0.0068,  0.0579,  0.0368],\n",
       "         [-0.1015,  0.0219, -0.0142,  ...,  0.0340, -0.1043, -0.0683],\n",
       "         [-0.0450, -0.0552, -0.0224,  ..., -0.2128, -0.1288, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1012, -0.0277,  ..., -0.1655, -0.0580,  0.0381],\n",
       "         [ 0.1015, -0.0227, -0.0955,  ..., -0.0275, -0.0003,  0.0912],\n",
       "         [-0.0441, -0.0247,  0.1105,  ...,  0.0454, -0.0845,  0.0912]]), 'layers.0.bias': tensor([-0.0634,  0.1388,  0.0426,  0.0596,  0.0940,  0.0904,  0.0050, -0.1505,\n",
       "          0.0043, -0.0831,  0.0695,  0.0953,  0.1271,  0.0371, -0.1510, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0003,  0.0584,  0.1507, -0.0979,  0.0514,\n",
       "         -0.0799,  0.1788, -0.0901, -0.0504, -0.0557,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0306, -0.1479,  0.0004,  0.0618,  0.1027,  0.0560,\n",
       "         -0.0514,  0.0351,  0.1218, -0.0454,  0.1261, -0.0234, -0.0693, -0.0004,\n",
       "          0.0328,  0.1172]), 'layers.1.weight': tensor([[ 0.0513,  0.1195, -0.1363, -0.0811,  0.0575, -0.1066, -0.0653, -0.0276,\n",
       "           0.1493, -0.0322,  0.0419, -0.0742,  0.0620,  0.0080, -0.0741,  0.0562,\n",
       "          -0.0929, -0.0163,  0.0233,  0.0685, -0.1091,  0.0439, -0.0742, -0.0668,\n",
       "          -0.0591,  0.1226,  0.0708,  0.1010,  0.1109, -0.0228, -0.1186,  0.1338,\n",
       "           0.0119,  0.0539, -0.0914,  0.1197,  0.1093, -0.0795,  0.1725, -0.0481,\n",
       "          -0.1282,  0.0557,  0.1375, -0.0792,  0.0721,  0.1102, -0.0931, -0.0664,\n",
       "          -0.0767, -0.0980]]), 'layers.1.bias': tensor([-0.0630]), 'skip.weight': tensor([[ 0.0101, -0.0101,  0.0110,  0.0101,  0.0113,  0.0079, -0.0116, -0.0106,\n",
       "           0.0074,  0.0094, -0.0123, -0.0086, -0.0106,  0.0093,  0.0095, -0.0096,\n",
       "           0.0100,  0.0103,  0.0110,  0.0107,  0.0078,  0.0100,  0.0137,  0.0098,\n",
       "          -0.0107,  0.0100, -0.0098,  0.0105, -0.0109,  0.0103,  0.0124, -0.0114,\n",
       "           0.0133, -0.0113,  0.0108, -0.0123, -0.0128, -0.0097, -0.0096, -0.0110,\n",
       "          -0.0080, -0.0083,  0.0132, -0.0095,  0.0115,  0.0107, -0.0135, -0.0096,\n",
       "          -0.0131, -0.0092,  0.0104, -0.0091, -0.0105,  0.0085,  0.0116,  0.0100,\n",
       "          -0.0099, -0.0124, -0.0109,  0.0097,  0.0084,  0.0099, -0.0147,  0.0157,\n",
       "           0.0213, -0.0220,  0.0091]])}, objective=10.155401843442803, loss=0.7340779304504395, val_objective=10.179639953031426, val_loss=0.7583160400390625, regularization=0.7302079200744629, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=13.160293290536012, state_dict={'layers.0.weight': tensor([[-0.0669,  0.0239,  0.0833,  ..., -0.0068,  0.0578,  0.0368],\n",
       "         [-0.1009,  0.0219, -0.0142,  ...,  0.0340, -0.1043, -0.0683],\n",
       "         [-0.0450, -0.0552, -0.0224,  ..., -0.2121, -0.1288, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1006, -0.0277,  ..., -0.1655, -0.0580,  0.0381],\n",
       "         [ 0.1009, -0.0227, -0.0956,  ..., -0.0275, -0.0003,  0.0906],\n",
       "         [-0.0441, -0.0247,  0.1097,  ...,  0.0453, -0.0844,  0.0906]]), 'layers.0.bias': tensor([-0.0634,  0.1387,  0.0426,  0.0596,  0.0940,  0.0904,  0.0050, -0.1505,\n",
       "          0.0043, -0.0831,  0.0695,  0.0953,  0.1271,  0.0371, -0.1510, -0.1197,\n",
       "         -0.0718, -0.1009,  0.1481,  0.0003,  0.0584,  0.1507, -0.0979,  0.0514,\n",
       "         -0.0799,  0.1788, -0.0901, -0.0505, -0.0556,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0449, -0.0306, -0.1479,  0.0004,  0.0618,  0.1027,  0.0560,\n",
       "         -0.0515,  0.0351,  0.1219, -0.0454,  0.1261, -0.0234, -0.0693, -0.0004,\n",
       "          0.0328,  0.1172]), 'layers.1.weight': tensor([[ 0.0514,  0.1197, -0.1364, -0.0811,  0.0575, -0.1067, -0.0655, -0.0276,\n",
       "           0.1494, -0.0322,  0.0420, -0.0743,  0.0620,  0.0079, -0.0742,  0.0563,\n",
       "          -0.0931, -0.0162,  0.0233,  0.0685, -0.1092,  0.0438, -0.0742, -0.0668,\n",
       "          -0.0591,  0.1226,  0.0708,  0.1010,  0.1110, -0.0229, -0.1187,  0.1339,\n",
       "           0.0119,  0.0539, -0.0914,  0.1200,  0.1092, -0.0798,  0.1728, -0.0481,\n",
       "          -0.1282,  0.0557,  0.1376, -0.0793,  0.0722,  0.1102, -0.0931, -0.0665,\n",
       "          -0.0767, -0.0982]]), 'layers.1.bias': tensor([-0.0630]), 'skip.weight': tensor([[ 0.0101, -0.0101,  0.0110,  0.0101,  0.0112,  0.0078, -0.0115, -0.0105,\n",
       "           0.0074,  0.0093, -0.0123, -0.0085, -0.0105,  0.0092,  0.0094, -0.0096,\n",
       "           0.0100,  0.0103,  0.0109,  0.0106,  0.0077,  0.0099,  0.0136,  0.0097,\n",
       "          -0.0106,  0.0100, -0.0097,  0.0104, -0.0109,  0.0103,  0.0123, -0.0113,\n",
       "           0.0132, -0.0113,  0.0107, -0.0122, -0.0128, -0.0096, -0.0096, -0.0109,\n",
       "          -0.0080, -0.0082,  0.0131, -0.0094,  0.0114,  0.0106, -0.0134, -0.0096,\n",
       "          -0.0130, -0.0091,  0.0103, -0.0090, -0.0104,  0.0085,  0.0116,  0.0100,\n",
       "          -0.0098, -0.0123, -0.0108,  0.0097,  0.0083,  0.0098, -0.0147,  0.0157,\n",
       "           0.0212, -0.0219,  0.0091]])}, objective=10.28705541004315, loss=0.7341170310974121, val_objective=10.311167634622008, val_loss=0.7582292556762695, regularization=0.7258909940719604, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=13.423499156346733, state_dict={'layers.0.weight': tensor([[-0.0669,  0.0239,  0.0833,  ..., -0.0067,  0.0578,  0.0368],\n",
       "         [-0.1004,  0.0219, -0.0142,  ...,  0.0341, -0.1044, -0.0682],\n",
       "         [-0.0450, -0.0552, -0.0224,  ..., -0.2114, -0.1287, -0.0241],\n",
       "         ...,\n",
       "         [-0.0072, -0.1000, -0.0277,  ..., -0.1655, -0.0579,  0.0380],\n",
       "         [ 0.1004, -0.0227, -0.0956,  ..., -0.0276, -0.0002,  0.0900],\n",
       "         [-0.0441, -0.0247,  0.1089,  ...,  0.0453, -0.0844,  0.0900]]), 'layers.0.bias': tensor([-0.0634,  0.1387,  0.0426,  0.0596,  0.0940,  0.0904,  0.0050, -0.1505,\n",
       "          0.0043, -0.0831,  0.0695,  0.0953,  0.1271,  0.0371, -0.1510, -0.1197,\n",
       "         -0.0718, -0.1010,  0.1481,  0.0002,  0.0584,  0.1506, -0.0979,  0.0514,\n",
       "         -0.0799,  0.1787, -0.0901, -0.0505, -0.0556,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0448, -0.0306, -0.1479,  0.0003,  0.0618,  0.1027,  0.0560,\n",
       "         -0.0516,  0.0351,  0.1219, -0.0454,  0.1261, -0.0234, -0.0693, -0.0003,\n",
       "          0.0328,  0.1172]), 'layers.1.weight': tensor([[ 0.0514,  0.1198, -0.1365, -0.0811,  0.0576, -0.1068, -0.0657, -0.0276,\n",
       "           0.1496, -0.0322,  0.0420, -0.0744,  0.0621,  0.0077, -0.0744,  0.0565,\n",
       "          -0.0932, -0.0160,  0.0233,  0.0685, -0.1092,  0.0438, -0.0742, -0.0668,\n",
       "          -0.0592,  0.1226,  0.0708,  0.1011,  0.1110, -0.0230, -0.1188,  0.1340,\n",
       "           0.0120,  0.0539, -0.0913,  0.1202,  0.1091, -0.0800,  0.1730, -0.0481,\n",
       "          -0.1282,  0.0557,  0.1378, -0.0793,  0.0724,  0.1102, -0.0932, -0.0667,\n",
       "          -0.0768, -0.0985]]), 'layers.1.bias': tensor([-0.0629]), 'skip.weight': tensor([[ 0.0100, -0.0100,  0.0109,  0.0100,  0.0112,  0.0078, -0.0114, -0.0105,\n",
       "           0.0073,  0.0092, -0.0122, -0.0085, -0.0105,  0.0091,  0.0093, -0.0095,\n",
       "           0.0099,  0.0102,  0.0108,  0.0105,  0.0077,  0.0099,  0.0135,  0.0096,\n",
       "          -0.0106,  0.0099, -0.0096,  0.0103, -0.0108,  0.0102,  0.0123, -0.0112,\n",
       "           0.0131, -0.0112,  0.0106, -0.0121, -0.0127, -0.0096, -0.0095, -0.0108,\n",
       "          -0.0079, -0.0082,  0.0131, -0.0093,  0.0113,  0.0106, -0.0134, -0.0096,\n",
       "          -0.0129, -0.0091,  0.0103, -0.0090, -0.0103,  0.0085,  0.0115,  0.0099,\n",
       "          -0.0097, -0.0122, -0.0108,  0.0096,  0.0083,  0.0098, -0.0146,  0.0156,\n",
       "           0.0211, -0.0218,  0.0090]])}, objective=10.419902025136347, loss=0.7341563701629639, val_objective=10.443888185891504, val_loss=0.7581425309181213, regularization=0.7215514779090881, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=13.691969139473667, state_dict={'layers.0.weight': tensor([[-6.6868e-02,  2.3943e-02,  8.3273e-02,  ..., -6.7312e-03,\n",
       "           5.7778e-02,  3.6781e-02],\n",
       "         [-9.9809e-02,  2.1953e-02, -1.4119e-02,  ...,  3.4070e-02,\n",
       "          -1.0446e-01, -6.8206e-02],\n",
       "         [-4.5053e-02, -5.5200e-02, -2.2472e-02,  ..., -2.1064e-01,\n",
       "          -1.2868e-01, -2.4060e-02],\n",
       "         ...,\n",
       "         [-7.2107e-03, -9.9476e-02, -2.7754e-02,  ..., -1.6551e-01,\n",
       "          -5.7933e-02,  3.8040e-02],\n",
       "         [ 9.9809e-02, -2.2709e-02, -9.5620e-02,  ..., -2.7571e-02,\n",
       "          -2.0062e-04,  8.9397e-02],\n",
       "         [-4.4199e-02, -2.4705e-02,  1.0806e-01,  ...,  4.5274e-02,\n",
       "          -8.4321e-02,  8.9397e-02]]), 'layers.0.bias': tensor([-0.0634,  0.1386,  0.0425,  0.0596,  0.0940,  0.0903,  0.0050, -0.1505,\n",
       "          0.0043, -0.0832,  0.0695,  0.0953,  0.1271,  0.0371, -0.1510, -0.1197,\n",
       "         -0.0719, -0.1010,  0.1481,  0.0002,  0.0583,  0.1506, -0.0980,  0.0513,\n",
       "         -0.0799,  0.1787, -0.0902, -0.0505, -0.0556,  0.1076, -0.0251,  0.0250,\n",
       "         -0.0319, -0.0448, -0.0306, -0.1479,  0.0003,  0.0618,  0.1027,  0.0560,\n",
       "         -0.0516,  0.0351,  0.1220, -0.0454,  0.1260, -0.0235, -0.0693, -0.0003,\n",
       "          0.0328,  0.1173]), 'layers.1.weight': tensor([[ 0.0514,  0.1200, -0.1367, -0.0811,  0.0576, -0.1069, -0.0658, -0.0276,\n",
       "           0.1498, -0.0323,  0.0421, -0.0745,  0.0621,  0.0076, -0.0745,  0.0566,\n",
       "          -0.0934, -0.0159,  0.0233,  0.0685, -0.1092,  0.0438, -0.0741, -0.0667,\n",
       "          -0.0592,  0.1226,  0.0709,  0.1012,  0.1111, -0.0231, -0.1189,  0.1341,\n",
       "           0.0121,  0.0540, -0.0912,  0.1205,  0.1091, -0.0802,  0.1733, -0.0481,\n",
       "          -0.1282,  0.0556,  0.1380, -0.0794,  0.0725,  0.1101, -0.0932, -0.0668,\n",
       "          -0.0769, -0.0987]]), 'layers.1.bias': tensor([-0.0629]), 'skip.weight': tensor([[ 0.0100, -0.0099,  0.0108,  0.0100,  0.0111,  0.0077, -0.0113, -0.0104,\n",
       "           0.0073,  0.0091, -0.0122, -0.0085, -0.0104,  0.0091,  0.0092, -0.0095,\n",
       "           0.0099,  0.0102,  0.0107,  0.0105,  0.0077,  0.0098,  0.0135,  0.0096,\n",
       "          -0.0105,  0.0099, -0.0095,  0.0102, -0.0107,  0.0102,  0.0122, -0.0111,\n",
       "           0.0130, -0.0112,  0.0106, -0.0121, -0.0126, -0.0095, -0.0094, -0.0107,\n",
       "          -0.0079, -0.0082,  0.0130, -0.0093,  0.0113,  0.0105, -0.0133, -0.0095,\n",
       "          -0.0128, -0.0090,  0.0102, -0.0089, -0.0103,  0.0084,  0.0115,  0.0098,\n",
       "          -0.0097, -0.0121, -0.0107,  0.0095,  0.0082,  0.0097, -0.0145,  0.0155,\n",
       "           0.0211, -0.0217,  0.0089]])}, objective=10.55391886621717, loss=0.7341963648796082, val_objective=10.577781526148353, val_loss=0.758059024810791, regularization=0.7171884775161743, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=13.96580852226314, state_dict={'layers.0.weight': tensor([[-6.6836e-02,  2.3945e-02,  8.3280e-02,  ..., -6.7146e-03,\n",
       "           5.7752e-02,  3.6786e-02],\n",
       "         [-9.9234e-02,  2.1989e-02, -1.4080e-02,  ...,  3.4083e-02,\n",
       "          -1.0451e-01, -6.8168e-02],\n",
       "         [-4.5083e-02, -5.5203e-02, -2.2497e-02,  ..., -2.0989e-01,\n",
       "          -1.2864e-01, -2.4046e-02],\n",
       "         ...,\n",
       "         [-7.2137e-03, -9.8908e-02, -2.7764e-02,  ..., -1.6552e-01,\n",
       "          -5.7917e-02,  3.8032e-02],\n",
       "         [ 9.9234e-02, -2.2709e-02, -9.5651e-02,  ..., -2.7582e-02,\n",
       "          -1.7621e-04,  8.8812e-02],\n",
       "         [-4.4247e-02, -2.4709e-02,  1.0730e-01,  ...,  4.5240e-02,\n",
       "          -8.4266e-02,  8.8812e-02]]), 'layers.0.bias': tensor([-6.3415e-02,  1.3858e-01,  4.2526e-02,  5.9593e-02,  9.3952e-02,\n",
       "          9.0322e-02,  5.0041e-03, -1.5055e-01,  4.2589e-03, -8.3162e-02,\n",
       "          6.9514e-02,  9.5344e-02,  1.2707e-01,  3.7096e-02, -1.5105e-01,\n",
       "         -1.1972e-01, -7.1861e-02, -1.0096e-01,  1.4810e-01,  1.5581e-04,\n",
       "          5.8331e-02,  1.5062e-01, -9.8003e-02,  5.1309e-02, -7.9933e-02,\n",
       "          1.7867e-01, -9.0245e-02, -5.0546e-02, -5.5521e-02,  1.0757e-01,\n",
       "         -2.5138e-02,  2.4965e-02, -3.1925e-02, -4.4825e-02, -3.0629e-02,\n",
       "         -1.4789e-01,  3.0374e-04,  6.1795e-02,  1.0275e-01,  5.5966e-02,\n",
       "         -5.1682e-02,  3.5054e-02,  1.2202e-01, -4.5416e-02,  1.2603e-01,\n",
       "         -2.3480e-02, -6.9282e-02, -3.0992e-04,  3.2842e-02,  1.1726e-01]), 'layers.1.weight': tensor([[ 0.0515,  0.1201, -0.1368, -0.0811,  0.0576, -0.1070, -0.0660, -0.0277,\n",
       "           0.1499, -0.0323,  0.0422, -0.0746,  0.0621,  0.0075, -0.0746,  0.0568,\n",
       "          -0.0936, -0.0157,  0.0233,  0.0686, -0.1093,  0.0438, -0.0741, -0.0667,\n",
       "          -0.0593,  0.1226,  0.0710,  0.1012,  0.1111, -0.0232, -0.1190,  0.1343,\n",
       "           0.0122,  0.0540, -0.0911,  0.1208,  0.1090, -0.0805,  0.1735, -0.0480,\n",
       "          -0.1281,  0.0556,  0.1381, -0.0795,  0.0727,  0.1101, -0.0933, -0.0670,\n",
       "          -0.0770, -0.0990]]), 'layers.1.bias': tensor([-0.0628]), 'skip.weight': tensor([[ 0.0099, -0.0099,  0.0107,  0.0099,  0.0110,  0.0077, -0.0112, -0.0104,\n",
       "           0.0073,  0.0091, -0.0121, -0.0084, -0.0103,  0.0090,  0.0091, -0.0094,\n",
       "           0.0098,  0.0101,  0.0107,  0.0104,  0.0076,  0.0098,  0.0134,  0.0095,\n",
       "          -0.0104,  0.0098, -0.0094,  0.0101, -0.0106,  0.0101,  0.0122, -0.0110,\n",
       "           0.0129, -0.0111,  0.0105, -0.0120, -0.0125, -0.0094, -0.0094, -0.0107,\n",
       "          -0.0078, -0.0081,  0.0130, -0.0092,  0.0112,  0.0104, -0.0132, -0.0095,\n",
       "          -0.0127, -0.0090,  0.0101, -0.0089, -0.0102,  0.0084,  0.0114,  0.0098,\n",
       "          -0.0096, -0.0120, -0.0106,  0.0094,  0.0082,  0.0097, -0.0144,  0.0154,\n",
       "           0.0210, -0.0216,  0.0089]])}, objective=10.688937023622959, loss=0.7342373728752136, val_objective=10.712672308428257, val_loss=0.7579726576805115, regularization=0.7127907872200012, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=14.245124692708403, state_dict={'layers.0.weight': tensor([[-6.6805e-02,  2.3948e-02,  8.3286e-02,  ..., -6.6979e-03,\n",
       "           5.7726e-02,  3.6791e-02],\n",
       "         [-9.8647e-02,  2.2026e-02, -1.4039e-02,  ...,  3.4096e-02,\n",
       "          -1.0456e-01, -6.8129e-02],\n",
       "         [-4.5117e-02, -5.5208e-02, -2.2523e-02,  ..., -2.0913e-01,\n",
       "          -1.2859e-01, -2.4032e-02],\n",
       "         ...,\n",
       "         [-7.2147e-03, -9.8328e-02, -2.7774e-02,  ..., -1.6553e-01,\n",
       "          -5.7902e-02,  3.8024e-02],\n",
       "         [ 9.8647e-02, -2.2710e-02, -9.5683e-02,  ..., -2.7594e-02,\n",
       "          -1.5175e-04,  8.8220e-02],\n",
       "         [-4.4296e-02, -2.4712e-02,  1.0652e-01,  ...,  4.5206e-02,\n",
       "          -8.4212e-02,  8.8220e-02]]), 'layers.0.bias': tensor([-6.3408e-02,  1.3854e-01,  4.2516e-02,  5.9584e-02,  9.3949e-02,\n",
       "          9.0301e-02,  4.9985e-03, -1.5056e-01,  4.2347e-03, -8.3172e-02,\n",
       "          6.9523e-02,  9.5357e-02,  1.2706e-01,  3.7097e-02, -1.5108e-01,\n",
       "         -1.1972e-01, -7.1869e-02, -1.0096e-01,  1.4810e-01,  1.2066e-04,\n",
       "          5.8318e-02,  1.5061e-01, -9.8032e-02,  5.1285e-02, -7.9950e-02,\n",
       "          1.7864e-01, -9.0292e-02, -5.0576e-02, -5.5485e-02,  1.0756e-01,\n",
       "         -2.5144e-02,  2.4965e-02, -3.1930e-02, -4.4816e-02, -3.0625e-02,\n",
       "         -1.4788e-01,  2.8581e-04,  6.1795e-02,  1.0276e-01,  5.5947e-02,\n",
       "         -5.1747e-02,  3.5053e-02,  1.2207e-01, -4.5418e-02,  1.2602e-01,\n",
       "         -2.3508e-02, -6.9272e-02, -2.9315e-04,  3.2859e-02,  1.1727e-01]), 'layers.1.weight': tensor([[ 0.0515,  0.1203, -0.1370, -0.0811,  0.0577, -0.1071, -0.0661, -0.0277,\n",
       "           0.1501, -0.0323,  0.0422, -0.0747,  0.0621,  0.0074, -0.0747,  0.0569,\n",
       "          -0.0937, -0.0156,  0.0233,  0.0686, -0.1093,  0.0438, -0.0741, -0.0667,\n",
       "          -0.0593,  0.1226,  0.0710,  0.1013,  0.1112, -0.0233, -0.1191,  0.1344,\n",
       "           0.0123,  0.0540, -0.0911,  0.1210,  0.1089, -0.0807,  0.1738, -0.0480,\n",
       "          -0.1281,  0.0556,  0.1383, -0.0796,  0.0728,  0.1101, -0.0933, -0.0671,\n",
       "          -0.0770, -0.0992]]), 'layers.1.bias': tensor([-0.0628]), 'skip.weight': tensor([[ 0.0099, -0.0098,  0.0107,  0.0098,  0.0110,  0.0076, -0.0111, -0.0103,\n",
       "           0.0072,  0.0090, -0.0121, -0.0084, -0.0102,  0.0090,  0.0090, -0.0094,\n",
       "           0.0098,  0.0100,  0.0106,  0.0103,  0.0076,  0.0097,  0.0133,  0.0095,\n",
       "          -0.0104,  0.0097, -0.0094,  0.0100, -0.0105,  0.0100,  0.0121, -0.0110,\n",
       "           0.0127, -0.0110,  0.0104, -0.0119, -0.0124, -0.0094, -0.0093, -0.0106,\n",
       "          -0.0078, -0.0081,  0.0129, -0.0092,  0.0111,  0.0104, -0.0132, -0.0094,\n",
       "          -0.0126, -0.0089,  0.0100, -0.0088, -0.0102,  0.0083,  0.0114,  0.0097,\n",
       "          -0.0096, -0.0119, -0.0106,  0.0094,  0.0082,  0.0096, -0.0143,  0.0154,\n",
       "           0.0209, -0.0215,  0.0088]])}, objective=10.824532555592398, loss=0.7342811822891235, val_objective=10.8481405844811, val_loss=0.7578892111778259, regularization=0.7083301544189453, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=14.530027186562572, state_dict={'layers.0.weight': tensor([[-6.6775e-02,  2.3949e-02,  8.3293e-02,  ..., -6.6808e-03,\n",
       "           5.7699e-02,  3.6796e-02],\n",
       "         [-9.8048e-02,  2.2064e-02, -1.3997e-02,  ...,  3.4109e-02,\n",
       "          -1.0461e-01, -6.8088e-02],\n",
       "         [-4.5152e-02, -5.5213e-02, -2.2552e-02,  ..., -2.0835e-01,\n",
       "          -1.2854e-01, -2.4016e-02],\n",
       "         ...,\n",
       "         [-7.2138e-03, -9.7737e-02, -2.7784e-02,  ..., -1.6555e-01,\n",
       "          -5.7885e-02,  3.8015e-02],\n",
       "         [ 9.8048e-02, -2.2712e-02, -9.5715e-02,  ..., -2.7606e-02,\n",
       "          -1.2689e-04,  8.7660e-02],\n",
       "         [-4.4343e-02, -2.4713e-02,  1.0573e-01,  ...,  4.5172e-02,\n",
       "          -8.4158e-02,  8.7660e-02]]), 'layers.0.bias': tensor([-6.3400e-02,  1.3850e-01,  4.2509e-02,  5.9575e-02,  9.3945e-02,\n",
       "          9.0278e-02,  4.9931e-03, -1.5057e-01,  4.2102e-03, -8.3182e-02,\n",
       "          6.9533e-02,  9.5371e-02,  1.2706e-01,  3.7098e-02, -1.5111e-01,\n",
       "         -1.1973e-01, -7.1874e-02, -1.0097e-01,  1.4810e-01,  8.5295e-05,\n",
       "          5.8305e-02,  1.5060e-01, -9.8060e-02,  5.1262e-02, -7.9966e-02,\n",
       "          1.7861e-01, -9.0339e-02, -5.0606e-02, -5.5448e-02,  1.0755e-01,\n",
       "         -2.5148e-02,  2.4966e-02, -3.1935e-02, -4.4808e-02, -3.0621e-02,\n",
       "         -1.4788e-01,  2.6830e-04,  6.1795e-02,  1.0276e-01,  5.5929e-02,\n",
       "         -5.1812e-02,  3.5052e-02,  1.2211e-01, -4.5420e-02,  1.2600e-01,\n",
       "         -2.3536e-02, -6.9263e-02, -2.7642e-04,  3.2877e-02,  1.1728e-01]), 'layers.1.weight': tensor([[ 0.0516,  0.1204, -0.1371, -0.0810,  0.0577, -0.1073, -0.0663, -0.0277,\n",
       "           0.1503, -0.0323,  0.0423, -0.0748,  0.0622,  0.0073, -0.0749,  0.0571,\n",
       "          -0.0939, -0.0155,  0.0233,  0.0686, -0.1093,  0.0438, -0.0740, -0.0667,\n",
       "          -0.0594,  0.1226,  0.0711,  0.1013,  0.1112, -0.0234, -0.1192,  0.1345,\n",
       "           0.0124,  0.0541, -0.0910,  0.1213,  0.1089, -0.0810,  0.1740, -0.0480,\n",
       "          -0.1281,  0.0556,  0.1385, -0.0797,  0.0730,  0.1100, -0.0934, -0.0673,\n",
       "          -0.0771, -0.0995]]), 'layers.1.bias': tensor([-0.0627]), 'skip.weight': tensor([[ 0.0098, -0.0098,  0.0106,  0.0097,  0.0109,  0.0076, -0.0110, -0.0102,\n",
       "           0.0072,  0.0090, -0.0120, -0.0083, -0.0102,  0.0089,  0.0089, -0.0093,\n",
       "           0.0097,  0.0100,  0.0105,  0.0102,  0.0075,  0.0097,  0.0132,  0.0094,\n",
       "          -0.0103,  0.0097, -0.0093,  0.0099, -0.0105,  0.0100,  0.0121, -0.0109,\n",
       "           0.0126, -0.0110,  0.0103, -0.0119, -0.0124, -0.0093, -0.0093, -0.0105,\n",
       "          -0.0077, -0.0081,  0.0128, -0.0091,  0.0111,  0.0103, -0.0131, -0.0094,\n",
       "          -0.0125, -0.0089,  0.0100, -0.0088, -0.0101,  0.0083,  0.0113,  0.0096,\n",
       "          -0.0095, -0.0119, -0.0105,  0.0093,  0.0081,  0.0096, -0.0142,  0.0153,\n",
       "           0.0208, -0.0214,  0.0088]])}, objective=10.96124598414991, loss=0.7343248724937439, val_objective=10.984723478866554, val_loss=0.7578023672103882, regularization=0.703847348690033, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=14.820627730293824, state_dict={'layers.0.weight': tensor([[-6.6746e-02,  2.3951e-02,  8.3299e-02,  ..., -6.6634e-03,\n",
       "           5.7673e-02,  3.6801e-02],\n",
       "         [-9.7438e-02,  2.2099e-02, -1.3955e-02,  ...,  3.4121e-02,\n",
       "          -1.0466e-01, -6.8045e-02],\n",
       "         [-4.5189e-02, -5.5222e-02, -2.2582e-02,  ..., -2.0756e-01,\n",
       "          -1.2850e-01, -2.3998e-02],\n",
       "         ...,\n",
       "         [-7.2117e-03, -9.7135e-02, -2.7795e-02,  ..., -1.6557e-01,\n",
       "          -5.7868e-02,  3.8006e-02],\n",
       "         [ 9.7438e-02, -2.2714e-02, -9.5748e-02,  ..., -2.7618e-02,\n",
       "          -1.0196e-04,  8.7114e-02],\n",
       "         [-4.4390e-02, -2.4715e-02,  1.0493e-01,  ...,  4.5137e-02,\n",
       "          -8.4104e-02,  8.7114e-02]]), 'layers.0.bias': tensor([-6.3393e-02,  1.3846e-01,  4.2503e-02,  5.9567e-02,  9.3942e-02,\n",
       "          9.0255e-02,  4.9878e-03, -1.5058e-01,  4.1849e-03, -8.3192e-02,\n",
       "          6.9543e-02,  9.5384e-02,  1.2706e-01,  3.7098e-02, -1.5113e-01,\n",
       "         -1.1974e-01, -7.1877e-02, -1.0097e-01,  1.4810e-01,  4.9264e-05,\n",
       "          5.8291e-02,  1.5059e-01, -9.8087e-02,  5.1238e-02, -7.9982e-02,\n",
       "          1.7858e-01, -9.0385e-02, -5.0636e-02, -5.5411e-02,  1.0754e-01,\n",
       "         -2.5150e-02,  2.4967e-02, -3.1940e-02, -4.4799e-02, -3.0616e-02,\n",
       "         -1.4788e-01,  2.5146e-04,  6.1795e-02,  1.0277e-01,  5.5911e-02,\n",
       "         -5.1878e-02,  3.5050e-02,  1.2216e-01, -4.5422e-02,  1.2599e-01,\n",
       "         -2.3565e-02, -6.9253e-02, -2.5885e-04,  3.2896e-02,  1.1729e-01]), 'layers.1.weight': tensor([[ 0.0516,  0.1206, -0.1372, -0.0810,  0.0577, -0.1074, -0.0665, -0.0277,\n",
       "           0.1504, -0.0323,  0.0424, -0.0749,  0.0622,  0.0071, -0.0750,  0.0572,\n",
       "          -0.0941, -0.0153,  0.0233,  0.0686, -0.1094,  0.0438, -0.0740, -0.0666,\n",
       "          -0.0594,  0.1226,  0.0711,  0.1014,  0.1113, -0.0235, -0.1193,  0.1346,\n",
       "           0.0125,  0.0541, -0.0909,  0.1215,  0.1088, -0.0812,  0.1742, -0.0480,\n",
       "          -0.1281,  0.0557,  0.1386, -0.0797,  0.0732,  0.1100, -0.0934, -0.0675,\n",
       "          -0.0772, -0.0997]]), 'layers.1.bias': tensor([-0.0627]), 'skip.weight': tensor([[ 0.0097, -0.0097,  0.0105,  0.0097,  0.0108,  0.0075, -0.0109, -0.0102,\n",
       "           0.0071,  0.0089, -0.0119, -0.0083, -0.0101,  0.0089,  0.0089, -0.0092,\n",
       "           0.0097,  0.0099,  0.0104,  0.0101,  0.0075,  0.0096,  0.0131,  0.0093,\n",
       "          -0.0103,  0.0096, -0.0092,  0.0098, -0.0104,  0.0099,  0.0120, -0.0108,\n",
       "           0.0125, -0.0109,  0.0102, -0.0118, -0.0123, -0.0092, -0.0092, -0.0105,\n",
       "          -0.0076, -0.0080,  0.0128, -0.0091,  0.0110,  0.0103, -0.0130, -0.0093,\n",
       "          -0.0124, -0.0088,  0.0099, -0.0087, -0.0100,  0.0083,  0.0113,  0.0096,\n",
       "          -0.0094, -0.0118, -0.0104,  0.0092,  0.0081,  0.0095, -0.0141,  0.0152,\n",
       "           0.0208, -0.0214,  0.0087]])}, objective=11.0986191233671, loss=0.7343714237213135, val_objective=11.121961553958684, val_loss=0.7577138543128967, regularization=0.6993123292922974, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=15.1170402848997, state_dict={'layers.0.weight': tensor([[-6.6716e-02,  2.3953e-02,  8.3305e-02,  ..., -6.6457e-03,\n",
       "           5.7647e-02,  3.6805e-02],\n",
       "         [-9.6815e-02,  2.2133e-02, -1.3914e-02,  ...,  3.4133e-02,\n",
       "          -1.0471e-01, -6.8001e-02],\n",
       "         [-4.5228e-02, -5.5231e-02, -2.2614e-02,  ..., -2.0675e-01,\n",
       "          -1.2845e-01, -2.3981e-02],\n",
       "         ...,\n",
       "         [-7.2089e-03, -9.6520e-02, -2.7805e-02,  ..., -1.6558e-01,\n",
       "          -5.7851e-02,  3.7999e-02],\n",
       "         [ 9.6815e-02, -2.2715e-02, -9.5781e-02,  ..., -2.7631e-02,\n",
       "          -7.7661e-05,  8.6574e-02],\n",
       "         [-4.4435e-02, -2.4717e-02,  1.0410e-01,  ...,  4.5102e-02,\n",
       "          -8.4050e-02,  8.6574e-02]]), 'layers.0.bias': tensor([-6.3385e-02,  1.3842e-01,  4.2498e-02,  5.9558e-02,  9.3939e-02,\n",
       "          9.0231e-02,  4.9825e-03, -1.5059e-01,  4.1581e-03, -8.3202e-02,\n",
       "          6.9553e-02,  9.5396e-02,  1.2706e-01,  3.7099e-02, -1.5116e-01,\n",
       "         -1.1974e-01, -7.1878e-02, -1.0097e-01,  1.4809e-01,  1.2631e-05,\n",
       "          5.8276e-02,  1.5058e-01, -9.8114e-02,  5.1215e-02, -7.9997e-02,\n",
       "          1.7854e-01, -9.0432e-02, -5.0666e-02, -5.5374e-02,  1.0753e-01,\n",
       "         -2.5152e-02,  2.4970e-02, -3.1945e-02, -4.4790e-02, -3.0613e-02,\n",
       "         -1.4787e-01,  2.3546e-04,  6.1795e-02,  1.0277e-01,  5.5893e-02,\n",
       "         -5.1946e-02,  3.5048e-02,  1.2221e-01, -4.5424e-02,  1.2597e-01,\n",
       "         -2.3595e-02, -6.9245e-02, -2.4076e-04,  3.2916e-02,  1.1729e-01]), 'layers.1.weight': tensor([[ 0.0517,  0.1207, -0.1374, -0.0810,  0.0578, -0.1075, -0.0666, -0.0278,\n",
       "           0.1506, -0.0323,  0.0425, -0.0751,  0.0623,  0.0070, -0.0751,  0.0573,\n",
       "          -0.0943, -0.0152,  0.0233,  0.0687, -0.1094,  0.0438, -0.0740, -0.0666,\n",
       "          -0.0595,  0.1226,  0.0712,  0.1014,  0.1113, -0.0236, -0.1195,  0.1347,\n",
       "           0.0126,  0.0541, -0.0909,  0.1218,  0.1087, -0.0814,  0.1745, -0.0480,\n",
       "          -0.1281,  0.0557,  0.1388, -0.0798,  0.0733,  0.1100, -0.0935, -0.0676,\n",
       "          -0.0773, -0.1000]]), 'layers.1.bias': tensor([-0.0627]), 'skip.weight': tensor([[ 0.0097, -0.0097,  0.0104,  0.0096,  0.0108,  0.0075, -0.0109, -0.0101,\n",
       "           0.0071,  0.0088, -0.0119, -0.0083, -0.0100,  0.0088,  0.0088, -0.0092,\n",
       "           0.0096,  0.0098,  0.0103,  0.0101,  0.0075,  0.0095,  0.0131,  0.0093,\n",
       "          -0.0102,  0.0095, -0.0091,  0.0097, -0.0103,  0.0099,  0.0120, -0.0107,\n",
       "           0.0124, -0.0109,  0.0102, -0.0117, -0.0122, -0.0092, -0.0092, -0.0104,\n",
       "          -0.0076, -0.0080,  0.0127, -0.0090,  0.0109,  0.0102, -0.0129, -0.0093,\n",
       "          -0.0122, -0.0088,  0.0098, -0.0086, -0.0100,  0.0082,  0.0112,  0.0095,\n",
       "          -0.0094, -0.0117, -0.0104,  0.0092,  0.0080,  0.0095, -0.0140,  0.0151,\n",
       "           0.0207, -0.0213,  0.0087]])}, objective=11.237245566147879, loss=0.7344203591346741, val_objective=11.260454065102651, val_loss=0.757628858089447, regularization=0.6947672963142395, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=15.419381090597694, state_dict={'layers.0.weight': tensor([[-6.6687e-02,  2.3956e-02,  8.3313e-02,  ..., -6.6282e-03,\n",
       "           5.7621e-02,  3.6809e-02],\n",
       "         [-9.6222e-02,  2.2166e-02, -1.3873e-02,  ...,  3.4145e-02,\n",
       "          -1.0476e-01, -6.7955e-02],\n",
       "         [-4.5268e-02, -5.5242e-02, -2.2645e-02,  ..., -2.0600e-01,\n",
       "          -1.2840e-01, -2.3965e-02],\n",
       "         ...,\n",
       "         [-7.2050e-03, -9.5892e-02, -2.7815e-02,  ..., -1.6560e-01,\n",
       "          -5.7833e-02,  3.7992e-02],\n",
       "         [ 9.6222e-02, -2.2716e-02, -9.5813e-02,  ..., -2.7644e-02,\n",
       "          -5.4339e-05,  8.6024e-02],\n",
       "         [-4.4480e-02, -2.4720e-02,  1.0327e-01,  ...,  4.5068e-02,\n",
       "          -8.3997e-02,  8.6024e-02]]), 'layers.0.bias': tensor([-6.3378e-02,  1.3838e-01,  4.2493e-02,  5.9550e-02,  9.3937e-02,\n",
       "          9.0206e-02,  4.9773e-03, -1.5060e-01,  4.1305e-03, -8.3211e-02,\n",
       "          6.9563e-02,  9.5408e-02,  1.2706e-01,  3.7099e-02, -1.5118e-01,\n",
       "         -1.1975e-01, -7.1879e-02, -1.0098e-01,  1.4809e-01, -2.4414e-05,\n",
       "          5.8261e-02,  1.5057e-01, -9.8140e-02,  5.1192e-02, -8.0012e-02,\n",
       "          1.7851e-01, -9.0480e-02, -5.0696e-02, -5.5337e-02,  1.0752e-01,\n",
       "         -2.5154e-02,  2.4975e-02, -3.1950e-02, -4.4781e-02, -3.0609e-02,\n",
       "         -1.4787e-01,  2.1940e-04,  6.1795e-02,  1.0278e-01,  5.5874e-02,\n",
       "         -5.2016e-02,  3.5046e-02,  1.2226e-01, -4.5427e-02,  1.2595e-01,\n",
       "         -2.3627e-02, -6.9236e-02, -2.2255e-04,  3.2936e-02,  1.1730e-01]), 'layers.1.weight': tensor([[ 0.0517,  0.1209, -0.1375, -0.0810,  0.0578, -0.1076, -0.0668, -0.0278,\n",
       "           0.1508, -0.0323,  0.0425, -0.0752,  0.0623,  0.0069, -0.0752,  0.0575,\n",
       "          -0.0945, -0.0150,  0.0234,  0.0687, -0.1094,  0.0437, -0.0740, -0.0666,\n",
       "          -0.0595,  0.1226,  0.0712,  0.1015,  0.1113, -0.0237, -0.1196,  0.1348,\n",
       "           0.0127,  0.0542, -0.0908,  0.1221,  0.1087, -0.0817,  0.1747, -0.0480,\n",
       "          -0.1281,  0.0557,  0.1390, -0.0799,  0.0735,  0.1100, -0.0935, -0.0678,\n",
       "          -0.0774, -0.1002]]), 'layers.1.bias': tensor([-0.0626]), 'skip.weight': tensor([[ 0.0096, -0.0096,  0.0103,  0.0095,  0.0107,  0.0074, -0.0108, -0.0101,\n",
       "           0.0070,  0.0088, -0.0118, -0.0082, -0.0099,  0.0087,  0.0087, -0.0091,\n",
       "           0.0095,  0.0098,  0.0102,  0.0100,  0.0074,  0.0095,  0.0130,  0.0092,\n",
       "          -0.0101,  0.0095, -0.0091,  0.0096, -0.0102,  0.0098,  0.0119, -0.0107,\n",
       "           0.0123, -0.0108,  0.0101, -0.0116, -0.0121, -0.0091, -0.0091, -0.0103,\n",
       "          -0.0075, -0.0079,  0.0126, -0.0089,  0.0108,  0.0101, -0.0129, -0.0092,\n",
       "          -0.0121, -0.0088,  0.0097, -0.0086, -0.0099,  0.0082,  0.0112,  0.0094,\n",
       "          -0.0093, -0.0116, -0.0103,  0.0091,  0.0080,  0.0094, -0.0139,  0.0150,\n",
       "           0.0206, -0.0212,  0.0086]])}, objective=11.377238519502457, loss=0.7344696521759033, val_objective=11.400315947843369, val_loss=0.7575470805168152, regularization=0.6902202367782593, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=15.727768712409649, state_dict={'layers.0.weight': tensor([[-6.6658e-02,  2.3959e-02,  8.3320e-02,  ..., -6.6108e-03,\n",
       "           5.7595e-02,  3.6812e-02],\n",
       "         [-9.5622e-02,  2.2197e-02, -1.3832e-02,  ...,  3.4157e-02,\n",
       "          -1.0481e-01, -6.7907e-02],\n",
       "         [-4.5310e-02, -5.5253e-02, -2.2677e-02,  ..., -2.0524e-01,\n",
       "          -1.2835e-01, -2.3949e-02],\n",
       "         ...,\n",
       "         [-7.2006e-03, -9.5252e-02, -2.7826e-02,  ..., -1.6562e-01,\n",
       "          -5.7817e-02,  3.7986e-02],\n",
       "         [ 9.5622e-02, -2.2717e-02, -9.5846e-02,  ..., -2.7658e-02,\n",
       "          -3.1686e-05,  8.5463e-02],\n",
       "         [-4.4524e-02, -2.4724e-02,  1.0241e-01,  ...,  4.5033e-02,\n",
       "          -8.3943e-02,  8.5463e-02]]), 'layers.0.bias': tensor([-6.3371e-02,  1.3834e-01,  4.2486e-02,  5.9542e-02,  9.3936e-02,\n",
       "          9.0180e-02,  4.9720e-03, -1.5061e-01,  4.1027e-03, -8.3221e-02,\n",
       "          6.9574e-02,  9.5419e-02,  1.2706e-01,  3.7100e-02, -1.5120e-01,\n",
       "         -1.1975e-01, -7.1878e-02, -1.0098e-01,  1.4809e-01, -6.1707e-05,\n",
       "          5.8246e-02,  1.5056e-01, -9.8165e-02,  5.1170e-02, -8.0028e-02,\n",
       "          1.7848e-01, -9.0527e-02, -5.0725e-02, -5.5299e-02,  1.0751e-01,\n",
       "         -2.5155e-02,  2.4982e-02, -3.1955e-02, -4.4771e-02, -3.0605e-02,\n",
       "         -1.4786e-01,  2.0275e-04,  6.1795e-02,  1.0279e-01,  5.5855e-02,\n",
       "         -5.2086e-02,  3.5044e-02,  1.2231e-01, -4.5429e-02,  1.2594e-01,\n",
       "         -2.3658e-02, -6.9227e-02, -2.0430e-04,  3.2957e-02,  1.1731e-01]), 'layers.1.weight': tensor([[ 0.0518,  0.1210, -0.1377, -0.0810,  0.0579, -0.1077, -0.0669, -0.0278,\n",
       "           0.1509, -0.0324,  0.0426, -0.0753,  0.0624,  0.0068, -0.0753,  0.0576,\n",
       "          -0.0947, -0.0149,  0.0234,  0.0687, -0.1094,  0.0437, -0.0739, -0.0666,\n",
       "          -0.0596,  0.1226,  0.0713,  0.1015,  0.1114, -0.0238, -0.1197,  0.1349,\n",
       "           0.0128,  0.0542, -0.0907,  0.1223,  0.1086, -0.0819,  0.1750, -0.0479,\n",
       "          -0.1281,  0.0557,  0.1391, -0.0800,  0.0736,  0.1099, -0.0936, -0.0679,\n",
       "          -0.0774, -0.1005]]), 'layers.1.bias': tensor([-0.0626]), 'skip.weight': tensor([[ 0.0096, -0.0095,  0.0102,  0.0094,  0.0106,  0.0074, -0.0107, -0.0100,\n",
       "           0.0070,  0.0087, -0.0118, -0.0082, -0.0099,  0.0087,  0.0086, -0.0091,\n",
       "           0.0095,  0.0097,  0.0102,  0.0099,  0.0074,  0.0094,  0.0129,  0.0092,\n",
       "          -0.0101,  0.0094, -0.0090,  0.0094, -0.0102,  0.0097,  0.0118, -0.0106,\n",
       "           0.0122, -0.0108,  0.0100, -0.0116, -0.0120, -0.0090, -0.0090, -0.0102,\n",
       "          -0.0075, -0.0079,  0.0126, -0.0089,  0.0108,  0.0100, -0.0128, -0.0092,\n",
       "          -0.0120, -0.0087,  0.0096, -0.0085, -0.0099,  0.0081,  0.0111,  0.0093,\n",
       "          -0.0093, -0.0116, -0.0102,  0.0091,  0.0079,  0.0094, -0.0138,  0.0150,\n",
       "           0.0205, -0.0211,  0.0085]])}, objective=11.518457430260137, loss=0.7345198392868042, val_objective=11.541401999847844, val_loss=0.7574644088745117, regularization=0.6856622695922852, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=16.042324086657842, state_dict={'layers.0.weight': tensor([[-6.6629e-02,  2.3962e-02,  8.3328e-02,  ..., -6.5937e-03,\n",
       "           5.7570e-02,  3.6815e-02],\n",
       "         [-9.5010e-02,  2.2227e-02, -1.3792e-02,  ...,  3.4170e-02,\n",
       "          -1.0486e-01, -6.7856e-02],\n",
       "         [-4.5352e-02, -5.5264e-02, -2.2709e-02,  ..., -2.0451e-01,\n",
       "          -1.2829e-01, -2.3932e-02],\n",
       "         ...,\n",
       "         [-7.1965e-03, -9.4599e-02, -2.7836e-02,  ..., -1.6564e-01,\n",
       "          -5.7800e-02,  3.7981e-02],\n",
       "         [ 9.5010e-02, -2.2718e-02, -9.5878e-02,  ..., -2.7673e-02,\n",
       "          -9.4194e-06,  8.4891e-02],\n",
       "         [-4.4568e-02, -2.4727e-02,  1.0160e-01,  ...,  4.4998e-02,\n",
       "          -8.3888e-02,  8.4891e-02]]), 'layers.0.bias': tensor([-6.3364e-02,  1.3831e-01,  4.2480e-02,  5.9534e-02,  9.3934e-02,\n",
       "          9.0155e-02,  4.9665e-03, -1.5062e-01,  4.0759e-03, -8.3229e-02,\n",
       "          6.9584e-02,  9.5431e-02,  1.2706e-01,  3.7100e-02, -1.5123e-01,\n",
       "         -1.1975e-01, -7.1876e-02, -1.0098e-01,  1.4809e-01, -9.9281e-05,\n",
       "          5.8230e-02,  1.5054e-01, -9.8189e-02,  5.1148e-02, -8.0043e-02,\n",
       "          1.7845e-01, -9.0576e-02, -5.0754e-02, -5.5261e-02,  1.0750e-01,\n",
       "         -2.5157e-02,  2.4990e-02, -3.1960e-02, -4.4761e-02, -3.0600e-02,\n",
       "         -1.4786e-01,  1.8509e-04,  6.1797e-02,  1.0280e-01,  5.5836e-02,\n",
       "         -5.2158e-02,  3.5041e-02,  1.2236e-01, -4.5431e-02,  1.2592e-01,\n",
       "         -2.3690e-02, -6.9217e-02, -1.8574e-04,  3.2977e-02,  1.1731e-01]), 'layers.1.weight': tensor([[ 0.0518,  0.1212, -0.1378, -0.0810,  0.0579, -0.1078, -0.0671, -0.0278,\n",
       "           0.1511, -0.0324,  0.0427, -0.0754,  0.0624,  0.0067, -0.0755,  0.0578,\n",
       "          -0.0948, -0.0148,  0.0234,  0.0687, -0.1095,  0.0437, -0.0739, -0.0666,\n",
       "          -0.0597,  0.1227,  0.0713,  0.1016,  0.1114, -0.0239, -0.1198,  0.1350,\n",
       "           0.0129,  0.0543, -0.0907,  0.1226,  0.1086, -0.0822,  0.1752, -0.0479,\n",
       "          -0.1281,  0.0557,  0.1393, -0.0800,  0.0738,  0.1099, -0.0936, -0.0681,\n",
       "          -0.0775, -0.1008]]), 'layers.1.bias': tensor([-0.0626]), 'skip.weight': tensor([[ 0.0095, -0.0095,  0.0102,  0.0094,  0.0106,  0.0073, -0.0106, -0.0099,\n",
       "           0.0070,  0.0086, -0.0117, -0.0082, -0.0098,  0.0086,  0.0085, -0.0090,\n",
       "           0.0094,  0.0096,  0.0101,  0.0098,  0.0073,  0.0094,  0.0128,  0.0091,\n",
       "          -0.0100,  0.0093, -0.0089,  0.0093, -0.0101,  0.0097,  0.0118, -0.0105,\n",
       "           0.0121, -0.0107,  0.0099, -0.0115, -0.0119, -0.0090, -0.0090, -0.0102,\n",
       "          -0.0074, -0.0078,  0.0125, -0.0088,  0.0107,  0.0100, -0.0127, -0.0091,\n",
       "          -0.0119, -0.0087,  0.0095, -0.0085, -0.0098,  0.0081,  0.0110,  0.0093,\n",
       "          -0.0092, -0.0115, -0.0102,  0.0090,  0.0079,  0.0093, -0.0137,  0.0149,\n",
       "           0.0205, -0.0210,  0.0085]])}, objective=11.66073638489699, loss=0.7345731854438782, val_objective=11.683540347127673, val_loss=0.7573771476745605, regularization=0.6810835599899292, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=16.363170568391, state_dict={'layers.0.weight': tensor([[-6.6601e-02,  2.3964e-02,  8.3335e-02,  ..., -6.5771e-03,\n",
       "           5.7543e-02,  3.6818e-02],\n",
       "         [-9.4387e-02,  2.2256e-02, -1.3752e-02,  ...,  3.4182e-02,\n",
       "          -1.0491e-01, -6.7805e-02],\n",
       "         [-4.5395e-02, -5.5277e-02, -2.2741e-02,  ..., -2.0380e-01,\n",
       "          -1.2824e-01, -2.3915e-02],\n",
       "         ...,\n",
       "         [-7.1920e-03, -9.3933e-02, -2.7847e-02,  ..., -1.6566e-01,\n",
       "          -5.7784e-02,  3.7978e-02],\n",
       "         [ 9.4387e-02, -2.2718e-02, -9.5911e-02,  ..., -2.7688e-02,\n",
       "           1.2440e-05,  8.4343e-02],\n",
       "         [-4.4612e-02, -2.4731e-02,  1.0080e-01,  ...,  4.4961e-02,\n",
       "          -8.3833e-02,  8.4343e-02]]), 'layers.0.bias': tensor([-6.3357e-02,  1.3827e-01,  4.2477e-02,  5.9526e-02,  9.3932e-02,\n",
       "          9.0130e-02,  4.9610e-03, -1.5063e-01,  4.0503e-03, -8.3238e-02,\n",
       "          6.9595e-02,  9.5443e-02,  1.2706e-01,  3.7101e-02, -1.5125e-01,\n",
       "         -1.1976e-01, -7.1875e-02, -1.0099e-01,  1.4809e-01, -1.3753e-04,\n",
       "          5.8214e-02,  1.5053e-01, -9.8212e-02,  5.1126e-02, -8.0059e-02,\n",
       "          1.7842e-01, -9.0626e-02, -5.0782e-02, -5.5223e-02,  1.0749e-01,\n",
       "         -2.5158e-02,  2.4998e-02, -3.1966e-02, -4.4749e-02, -3.0594e-02,\n",
       "         -1.4785e-01,  1.6573e-04,  6.1798e-02,  1.0281e-01,  5.5816e-02,\n",
       "         -5.2230e-02,  3.5039e-02,  1.2241e-01, -4.5433e-02,  1.2590e-01,\n",
       "         -2.3722e-02, -6.9204e-02, -1.6618e-04,  3.2998e-02,  1.1732e-01]), 'layers.1.weight': tensor([[ 0.0518,  0.1214, -0.1379, -0.0810,  0.0579, -0.1079, -0.0672, -0.0278,\n",
       "           0.1513, -0.0324,  0.0428, -0.0755,  0.0625,  0.0066, -0.0756,  0.0579,\n",
       "          -0.0950, -0.0146,  0.0235,  0.0688, -0.1095,  0.0437, -0.0739, -0.0666,\n",
       "          -0.0597,  0.1227,  0.0714,  0.1016,  0.1115, -0.0240, -0.1199,  0.1351,\n",
       "           0.0130,  0.0544, -0.0906,  0.1229,  0.1085, -0.0824,  0.1755, -0.0479,\n",
       "          -0.1281,  0.0558,  0.1395, -0.0801,  0.0739,  0.1099, -0.0937, -0.0683,\n",
       "          -0.0776, -0.1010]]), 'layers.1.bias': tensor([-0.0626]), 'skip.weight': tensor([[ 0.0094, -0.0094,  0.0101,  0.0093,  0.0105,  0.0073, -0.0105, -0.0099,\n",
       "           0.0069,  0.0086, -0.0116, -0.0081, -0.0097,  0.0086,  0.0084, -0.0089,\n",
       "           0.0094,  0.0096,  0.0100,  0.0098,  0.0073,  0.0093,  0.0127,  0.0090,\n",
       "          -0.0099,  0.0092, -0.0089,  0.0092, -0.0100,  0.0096,  0.0117, -0.0104,\n",
       "           0.0120, -0.0107,  0.0098, -0.0114, -0.0119, -0.0089, -0.0089, -0.0101,\n",
       "          -0.0074, -0.0078,  0.0124, -0.0087,  0.0106,  0.0099, -0.0126, -0.0091,\n",
       "          -0.0118, -0.0086,  0.0095, -0.0084, -0.0097,  0.0081,  0.0110,  0.0092,\n",
       "          -0.0091, -0.0114, -0.0101,  0.0089,  0.0078,  0.0093, -0.0136,  0.0148,\n",
       "           0.0204, -0.0209,  0.0084]])}, objective=11.803866559303753, loss=0.7346289753913879, val_objective=11.826528841293804, val_loss=0.7572912573814392, regularization=0.6764726638793945, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=16.69043397975882, state_dict={'layers.0.weight': tensor([[-6.6575e-02,  2.3964e-02,  8.3342e-02,  ..., -6.5607e-03,\n",
       "           5.7517e-02,  3.6820e-02],\n",
       "         [-9.3751e-02,  2.2283e-02, -1.3715e-02,  ...,  3.4196e-02,\n",
       "          -1.0496e-01, -6.7753e-02],\n",
       "         [-4.5436e-02, -5.5290e-02, -2.2771e-02,  ..., -2.0307e-01,\n",
       "          -1.2819e-01, -2.3896e-02],\n",
       "         ...,\n",
       "         [-7.1881e-03, -9.3253e-02, -2.7858e-02,  ..., -1.6567e-01,\n",
       "          -5.7769e-02,  3.7974e-02],\n",
       "         [ 9.3751e-02, -2.2718e-02, -9.5944e-02,  ..., -2.7703e-02,\n",
       "           3.4047e-05,  8.3786e-02],\n",
       "         [-4.4655e-02, -2.4733e-02,  9.9979e-02,  ...,  4.4924e-02,\n",
       "          -8.3776e-02,  8.3786e-02]]), 'layers.0.bias': tensor([-6.3349e-02,  1.3823e-01,  4.2475e-02,  5.9520e-02,  9.3930e-02,\n",
       "          9.0105e-02,  4.9550e-03, -1.5063e-01,  4.0260e-03, -8.3246e-02,\n",
       "          6.9606e-02,  9.5456e-02,  1.2706e-01,  3.7101e-02, -1.5127e-01,\n",
       "         -1.1976e-01, -7.1872e-02, -1.0099e-01,  1.4809e-01, -1.7590e-04,\n",
       "          5.8197e-02,  1.5052e-01, -9.8233e-02,  5.1106e-02, -8.0075e-02,\n",
       "          1.7839e-01, -9.0676e-02, -5.0811e-02, -5.5184e-02,  1.0748e-01,\n",
       "         -2.5158e-02,  2.5006e-02, -3.1971e-02, -4.4738e-02, -3.0587e-02,\n",
       "         -1.4784e-01,  1.4517e-04,  6.1799e-02,  1.0282e-01,  5.5795e-02,\n",
       "         -5.2303e-02,  3.5037e-02,  1.2246e-01, -4.5433e-02,  1.2588e-01,\n",
       "         -2.3754e-02, -6.9189e-02, -1.4571e-04,  3.3019e-02,  1.1733e-01]), 'layers.1.weight': tensor([[ 0.0519,  0.1215, -0.1381, -0.0810,  0.0580, -0.1080, -0.0674, -0.0279,\n",
       "           0.1514, -0.0324,  0.0428, -0.0756,  0.0626,  0.0064, -0.0757,  0.0580,\n",
       "          -0.0952, -0.0145,  0.0235,  0.0688, -0.1095,  0.0437, -0.0738, -0.0666,\n",
       "          -0.0598,  0.1227,  0.0715,  0.1017,  0.1115, -0.0241, -0.1200,  0.1352,\n",
       "           0.0131,  0.0544, -0.0906,  0.1231,  0.1084, -0.0826,  0.1757, -0.0479,\n",
       "          -0.1281,  0.0558,  0.1396, -0.0802,  0.0740,  0.1099, -0.0938, -0.0684,\n",
       "          -0.0777, -0.1013]]), 'layers.1.bias': tensor([-0.0626]), 'skip.weight': tensor([[ 0.0094, -0.0093,  0.0100,  0.0092,  0.0104,  0.0072, -0.0104, -0.0098,\n",
       "           0.0069,  0.0085, -0.0116, -0.0081, -0.0097,  0.0085,  0.0083, -0.0089,\n",
       "           0.0093,  0.0095,  0.0099,  0.0097,  0.0072,  0.0092,  0.0126,  0.0090,\n",
       "          -0.0098,  0.0092, -0.0088,  0.0091, -0.0099,  0.0095,  0.0117, -0.0104,\n",
       "           0.0119, -0.0106,  0.0098, -0.0113, -0.0118, -0.0088, -0.0088, -0.0100,\n",
       "          -0.0073, -0.0078,  0.0123, -0.0087,  0.0106,  0.0098, -0.0125, -0.0090,\n",
       "          -0.0117, -0.0086,  0.0094, -0.0084, -0.0097,  0.0080,  0.0109,  0.0092,\n",
       "          -0.0091, -0.0113, -0.0100,  0.0089,  0.0078,  0.0092, -0.0135,  0.0148,\n",
       "           0.0203, -0.0208,  0.0084]])}, objective=11.948483481651982, loss=0.7346876859664917, val_objective=11.97100068593665, val_loss=0.7572048902511597, regularization=0.6718696355819702, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=17.024242659353995, state_dict={'layers.0.weight': tensor([[-6.6548e-02,  2.3964e-02,  8.3347e-02,  ..., -6.5444e-03,\n",
       "           5.7490e-02,  3.6823e-02],\n",
       "         [-9.3141e-02,  2.2310e-02, -1.3679e-02,  ...,  3.4210e-02,\n",
       "          -1.0500e-01, -6.7702e-02],\n",
       "         [-4.5476e-02, -5.5303e-02, -2.2800e-02,  ..., -2.0233e-01,\n",
       "          -1.2814e-01, -2.3877e-02],\n",
       "         ...,\n",
       "         [-7.1853e-03, -9.2560e-02, -2.7870e-02,  ..., -1.6569e-01,\n",
       "          -5.7755e-02,  3.7972e-02],\n",
       "         [ 9.3141e-02, -2.2715e-02, -9.5976e-02,  ..., -2.7718e-02,\n",
       "           5.5376e-05,  8.3218e-02],\n",
       "         [-4.4698e-02, -2.4735e-02,  9.9142e-02,  ...,  4.4886e-02,\n",
       "          -8.3719e-02,  8.3218e-02]]), 'layers.0.bias': tensor([-6.3341e-02,  1.3819e-01,  4.2475e-02,  5.9514e-02,  9.3928e-02,\n",
       "          9.0082e-02,  4.9487e-03, -1.5064e-01,  4.0013e-03, -8.3254e-02,\n",
       "          6.9618e-02,  9.5467e-02,  1.2706e-01,  3.7102e-02, -1.5129e-01,\n",
       "         -1.1977e-01, -7.1870e-02, -1.0099e-01,  1.4809e-01, -2.1432e-04,\n",
       "          5.8179e-02,  1.5051e-01, -9.8253e-02,  5.1087e-02, -8.0091e-02,\n",
       "          1.7836e-01, -9.0727e-02, -5.0840e-02, -5.5145e-02,  1.0747e-01,\n",
       "         -2.5157e-02,  2.5013e-02, -3.1976e-02, -4.4726e-02, -3.0578e-02,\n",
       "         -1.4784e-01,  1.2397e-04,  6.1801e-02,  1.0282e-01,  5.5774e-02,\n",
       "         -5.2375e-02,  3.5037e-02,  1.2250e-01, -4.5434e-02,  1.2586e-01,\n",
       "         -2.3786e-02, -6.9172e-02, -1.2454e-04,  3.3041e-02,  1.1734e-01]), 'layers.1.weight': tensor([[ 0.0519,  0.1216, -0.1382, -0.0810,  0.0580, -0.1082, -0.0675, -0.0279,\n",
       "           0.1516, -0.0325,  0.0429, -0.0757,  0.0627,  0.0063, -0.0758,  0.0582,\n",
       "          -0.0954, -0.0144,  0.0235,  0.0688, -0.1096,  0.0436, -0.0738, -0.0666,\n",
       "          -0.0598,  0.1227,  0.0715,  0.1018,  0.1115, -0.0242, -0.1201,  0.1353,\n",
       "           0.0132,  0.0545, -0.0905,  0.1234,  0.1084, -0.0829,  0.1760, -0.0479,\n",
       "          -0.1281,  0.0558,  0.1398, -0.0803,  0.0742,  0.1099, -0.0938, -0.0686,\n",
       "          -0.0778, -0.1015]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0093, -0.0093,  0.0099,  0.0091,  0.0104,  0.0072, -0.0103, -0.0097,\n",
       "           0.0068,  0.0084, -0.0115, -0.0080, -0.0096,  0.0084,  0.0082, -0.0088,\n",
       "           0.0092,  0.0094,  0.0098,  0.0096,  0.0072,  0.0092,  0.0125,  0.0089,\n",
       "          -0.0098,  0.0091, -0.0087,  0.0090, -0.0099,  0.0095,  0.0116, -0.0103,\n",
       "           0.0118, -0.0105,  0.0097, -0.0112, -0.0117, -0.0088, -0.0088, -0.0099,\n",
       "          -0.0073, -0.0077,  0.0123, -0.0086,  0.0105,  0.0097, -0.0125, -0.0090,\n",
       "          -0.0116, -0.0085,  0.0093, -0.0083, -0.0096,  0.0080,  0.0108,  0.0091,\n",
       "          -0.0090, -0.0112, -0.0100,  0.0088,  0.0078,  0.0092, -0.0134,  0.0147,\n",
       "           0.0202, -0.0207,  0.0083]])}, objective=12.094111041688246, loss=0.734749436378479, val_objective=12.116479770802778, val_loss=0.7571181654930115, regularization=0.6672462224960327, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=17.364727512541076, state_dict={'layers.0.weight': tensor([[-6.6522e-02,  2.3964e-02,  8.3353e-02,  ..., -6.5280e-03,\n",
       "           5.7463e-02,  3.6825e-02],\n",
       "         [-9.2569e-02,  2.2337e-02, -1.3643e-02,  ...,  3.4225e-02,\n",
       "          -1.0505e-01, -6.7652e-02],\n",
       "         [-4.5519e-02, -5.5314e-02, -2.2829e-02,  ..., -2.0157e-01,\n",
       "          -1.2810e-01, -2.3858e-02],\n",
       "         ...,\n",
       "         [-7.1834e-03, -9.1853e-02, -2.7882e-02,  ..., -1.6571e-01,\n",
       "          -5.7740e-02,  3.7970e-02],\n",
       "         [ 9.2569e-02, -2.2711e-02, -9.6008e-02,  ..., -2.7734e-02,\n",
       "           7.6335e-05,  8.2638e-02],\n",
       "         [-4.4741e-02, -2.4734e-02,  9.8289e-02,  ...,  4.4847e-02,\n",
       "          -8.3662e-02,  8.2638e-02]]), 'layers.0.bias': tensor([-6.3333e-02,  1.3816e-01,  4.2478e-02,  5.9510e-02,  9.3925e-02,\n",
       "          9.0059e-02,  4.9417e-03, -1.5065e-01,  3.9744e-03, -8.3262e-02,\n",
       "          6.9630e-02,  9.5478e-02,  1.2707e-01,  3.7103e-02, -1.5131e-01,\n",
       "         -1.1978e-01, -7.1868e-02, -1.0100e-01,  1.4809e-01, -2.5322e-04,\n",
       "          5.8161e-02,  1.5050e-01, -9.8273e-02,  5.1069e-02, -8.0107e-02,\n",
       "          1.7833e-01, -9.0778e-02, -5.0868e-02, -5.5105e-02,  1.0746e-01,\n",
       "         -2.5157e-02,  2.5018e-02, -3.1980e-02, -4.4714e-02, -3.0569e-02,\n",
       "         -1.4783e-01,  1.0262e-04,  6.1803e-02,  1.0283e-01,  5.5753e-02,\n",
       "         -5.2446e-02,  3.5036e-02,  1.2255e-01, -4.5434e-02,  1.2585e-01,\n",
       "         -2.3820e-02, -6.9154e-02, -1.0270e-04,  3.3063e-02,  1.1734e-01]), 'layers.1.weight': tensor([[ 0.0519,  0.1218, -0.1384, -0.0810,  0.0580, -0.1083, -0.0677, -0.0279,\n",
       "           0.1517, -0.0325,  0.0430, -0.0758,  0.0628,  0.0062, -0.0759,  0.0583,\n",
       "          -0.0956, -0.0143,  0.0236,  0.0688, -0.1096,  0.0436, -0.0738, -0.0666,\n",
       "          -0.0599,  0.1227,  0.0716,  0.1018,  0.1116, -0.0243, -0.1202,  0.1354,\n",
       "           0.0133,  0.0546, -0.0905,  0.1237,  0.1083, -0.0831,  0.1762, -0.0479,\n",
       "          -0.1281,  0.0558,  0.1400, -0.0804,  0.0743,  0.1099, -0.0939, -0.0688,\n",
       "          -0.0779, -0.1018]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0093, -0.0092,  0.0098,  0.0091,  0.0103,  0.0071, -0.0101, -0.0097,\n",
       "           0.0068,  0.0084, -0.0115, -0.0080, -0.0095,  0.0084,  0.0082, -0.0088,\n",
       "           0.0092,  0.0094,  0.0098,  0.0095,  0.0072,  0.0091,  0.0124,  0.0088,\n",
       "          -0.0097,  0.0090, -0.0087,  0.0089, -0.0098,  0.0094,  0.0115, -0.0103,\n",
       "           0.0117, -0.0105,  0.0096, -0.0111, -0.0116, -0.0087, -0.0087, -0.0098,\n",
       "          -0.0072, -0.0077,  0.0122, -0.0085,  0.0105,  0.0097, -0.0124, -0.0089,\n",
       "          -0.0115, -0.0085,  0.0092, -0.0083, -0.0095,  0.0079,  0.0108,  0.0090,\n",
       "          -0.0089, -0.0112, -0.0099,  0.0087,  0.0077,  0.0091, -0.0133,  0.0146,\n",
       "           0.0202, -0.0206,  0.0083]])}, objective=12.24063497676035, loss=0.7348113656044006, val_objective=12.262857674495184, val_loss=0.7570340633392334, regularization=0.6625974178314209, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=17.7120220627919, state_dict={'layers.0.weight': tensor([[-6.6496e-02,  2.3963e-02,  8.3358e-02,  ..., -6.5113e-03,\n",
       "           5.7436e-02,  3.6828e-02],\n",
       "         [-9.1989e-02,  2.2364e-02, -1.3608e-02,  ...,  3.4241e-02,\n",
       "          -1.0509e-01, -6.7601e-02],\n",
       "         [-4.5565e-02, -5.5324e-02, -2.2857e-02,  ..., -2.0080e-01,\n",
       "          -1.2805e-01, -2.3840e-02],\n",
       "         ...,\n",
       "         [-7.1827e-03, -9.1139e-02, -2.7895e-02,  ..., -1.6573e-01,\n",
       "          -5.7727e-02,  3.7970e-02],\n",
       "         [ 9.1989e-02, -2.2704e-02, -9.6039e-02,  ..., -2.7750e-02,\n",
       "           9.7180e-05,  8.2047e-02],\n",
       "         [-4.4783e-02, -2.4733e-02,  9.7437e-02,  ...,  4.4807e-02,\n",
       "          -8.3604e-02,  8.2047e-02]]), 'layers.0.bias': tensor([-6.3326e-02,  1.3812e-01,  4.2483e-02,  5.9506e-02,  9.3923e-02,\n",
       "          9.0036e-02,  4.9339e-03, -1.5066e-01,  3.9464e-03, -8.3269e-02,\n",
       "          6.9642e-02,  9.5489e-02,  1.2707e-01,  3.7103e-02, -1.5134e-01,\n",
       "         -1.1978e-01, -7.1866e-02, -1.0100e-01,  1.4809e-01, -2.9261e-04,\n",
       "          5.8141e-02,  1.5048e-01, -9.8292e-02,  5.1053e-02, -8.0124e-02,\n",
       "          1.7830e-01, -9.0830e-02, -5.0896e-02, -5.5064e-02,  1.0745e-01,\n",
       "         -2.5157e-02,  2.5024e-02, -3.1985e-02, -4.4701e-02, -3.0559e-02,\n",
       "         -1.4782e-01,  8.1040e-05,  6.1806e-02,  1.0284e-01,  5.5732e-02,\n",
       "         -5.2516e-02,  3.5036e-02,  1.2260e-01, -4.5434e-02,  1.2583e-01,\n",
       "         -2.3856e-02, -6.9134e-02, -8.0850e-05,  3.3085e-02,  1.1735e-01]), 'layers.1.weight': tensor([[ 0.0520,  0.1219, -0.1386, -0.0810,  0.0581, -0.1084, -0.0678, -0.0280,\n",
       "           0.1519, -0.0325,  0.0430, -0.0759,  0.0628,  0.0061, -0.0760,  0.0584,\n",
       "          -0.0958, -0.0141,  0.0236,  0.0688, -0.1097,  0.0436, -0.0738, -0.0666,\n",
       "          -0.0599,  0.1227,  0.0716,  0.1019,  0.1116, -0.0244, -0.1204,  0.1355,\n",
       "           0.0135,  0.0547, -0.0905,  0.1240,  0.1082, -0.0833,  0.1765, -0.0479,\n",
       "          -0.1281,  0.0559,  0.1401, -0.0805,  0.0744,  0.1099, -0.0940, -0.0689,\n",
       "          -0.0780, -0.1020]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0092, -0.0091,  0.0097,  0.0090,  0.0102,  0.0071, -0.0100, -0.0096,\n",
       "           0.0067,  0.0083, -0.0114, -0.0080, -0.0095,  0.0083,  0.0081, -0.0087,\n",
       "           0.0091,  0.0093,  0.0097,  0.0095,  0.0071,  0.0090,  0.0124,  0.0088,\n",
       "          -0.0096,  0.0090, -0.0086,  0.0088, -0.0097,  0.0093,  0.0115, -0.0102,\n",
       "           0.0115, -0.0104,  0.0095, -0.0111, -0.0115, -0.0086, -0.0087, -0.0097,\n",
       "          -0.0072, -0.0076,  0.0121, -0.0084,  0.0104,  0.0096, -0.0123, -0.0089,\n",
       "          -0.0113, -0.0084,  0.0091, -0.0082, -0.0095,  0.0079,  0.0107,  0.0090,\n",
       "          -0.0089, -0.0111, -0.0099,  0.0086,  0.0077,  0.0091, -0.0132,  0.0145,\n",
       "           0.0201, -0.0204,  0.0082]])}, objective=12.387874033484904, loss=0.7348754405975342, val_objective=12.409947481189219, val_loss=0.7569488883018494, regularization=0.6579146385192871, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=18.06626250404774, state_dict={'layers.0.weight': tensor([[-6.6470e-02,  2.3963e-02,  8.3363e-02,  ..., -6.4945e-03,\n",
       "           5.7410e-02,  3.6830e-02],\n",
       "         [-9.1398e-02,  2.2391e-02, -1.3574e-02,  ...,  3.4258e-02,\n",
       "          -1.0514e-01, -6.7549e-02],\n",
       "         [-4.5613e-02, -5.5330e-02, -2.2883e-02,  ..., -2.0001e-01,\n",
       "          -1.2800e-01, -2.3825e-02],\n",
       "         ...,\n",
       "         [-7.1830e-03, -9.0461e-02, -2.7908e-02,  ..., -1.6575e-01,\n",
       "          -5.7713e-02,  3.7969e-02],\n",
       "         [ 9.1398e-02, -2.2697e-02, -9.6069e-02,  ..., -2.7767e-02,\n",
       "           1.1772e-04,  8.1457e-02],\n",
       "         [-4.4825e-02, -2.4730e-02,  9.6632e-02,  ...,  4.4766e-02,\n",
       "          -8.3548e-02,  8.1457e-02]]), 'layers.0.bias': tensor([-6.3320e-02,  1.3809e-01,  4.2488e-02,  5.9501e-02,  9.3922e-02,\n",
       "          9.0012e-02,  4.9256e-03, -1.5067e-01,  3.9186e-03, -8.3276e-02,\n",
       "          6.9654e-02,  9.5498e-02,  1.2707e-01,  3.7104e-02, -1.5136e-01,\n",
       "         -1.1978e-01, -7.1864e-02, -1.0100e-01,  1.4809e-01, -3.3244e-04,\n",
       "          5.8121e-02,  1.5047e-01, -9.8312e-02,  5.1037e-02, -8.0141e-02,\n",
       "          1.7827e-01, -9.0881e-02, -5.0923e-02, -5.5022e-02,  1.0744e-01,\n",
       "         -2.5157e-02,  2.5030e-02, -3.1990e-02, -4.4689e-02, -3.0547e-02,\n",
       "         -1.4781e-01,  5.9991e-05,  6.1809e-02,  1.0284e-01,  5.5712e-02,\n",
       "         -5.2586e-02,  3.5036e-02,  1.2265e-01, -4.5434e-02,  1.2581e-01,\n",
       "         -2.3892e-02, -6.9115e-02, -5.8934e-05,  3.3108e-02,  1.1735e-01]), 'layers.1.weight': tensor([[ 0.0520,  0.1221, -0.1387, -0.0810,  0.0581, -0.1085, -0.0679, -0.0280,\n",
       "           0.1521, -0.0326,  0.0431, -0.0760,  0.0629,  0.0060, -0.0761,  0.0585,\n",
       "          -0.0960, -0.0140,  0.0237,  0.0688, -0.1097,  0.0435, -0.0737, -0.0666,\n",
       "          -0.0600,  0.1227,  0.0717,  0.1019,  0.1116, -0.0245, -0.1205,  0.1356,\n",
       "           0.0136,  0.0548, -0.0904,  0.1243,  0.1082, -0.0836,  0.1767, -0.0479,\n",
       "          -0.1281,  0.0559,  0.1403, -0.0806,  0.0745,  0.1099, -0.0940, -0.0691,\n",
       "          -0.0781, -0.1023]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0091, -0.0090,  0.0097,  0.0089,  0.0102,  0.0070, -0.0099, -0.0095,\n",
       "           0.0067,  0.0083, -0.0113, -0.0079, -0.0094,  0.0083,  0.0080, -0.0086,\n",
       "           0.0090,  0.0092,  0.0096,  0.0094,  0.0071,  0.0090,  0.0123,  0.0087,\n",
       "          -0.0096,  0.0089, -0.0086,  0.0087, -0.0097,  0.0092,  0.0114, -0.0102,\n",
       "           0.0114, -0.0103,  0.0094, -0.0110, -0.0114, -0.0086, -0.0086, -0.0097,\n",
       "          -0.0071, -0.0076,  0.0120, -0.0084,  0.0104,  0.0095, -0.0122, -0.0088,\n",
       "          -0.0113, -0.0084,  0.0090, -0.0082, -0.0094,  0.0078,  0.0106,  0.0089,\n",
       "          -0.0088, -0.0110, -0.0098,  0.0086,  0.0076,  0.0090, -0.0131,  0.0144,\n",
       "           0.0200, -0.0203,  0.0081]])}, objective=12.536616182301143, loss=0.7349382638931274, val_objective=12.558543956253628, val_loss=0.7568660378456116, regularization=0.6532440185546875, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=18.427587754128695, state_dict={'layers.0.weight': tensor([[-6.6444e-02,  2.3962e-02,  8.3368e-02,  ..., -6.4776e-03,\n",
       "           5.7384e-02,  3.6833e-02],\n",
       "         [-9.0795e-02,  2.2416e-02, -1.3542e-02,  ...,  3.4275e-02,\n",
       "          -1.0519e-01, -6.7496e-02],\n",
       "         [-4.5662e-02, -5.5334e-02, -2.2907e-02,  ..., -1.9920e-01,\n",
       "          -1.2796e-01, -2.3811e-02],\n",
       "         ...,\n",
       "         [-7.1838e-03, -8.9786e-02, -2.7921e-02,  ..., -1.6577e-01,\n",
       "          -5.7700e-02,  3.7968e-02],\n",
       "         [ 9.0795e-02, -2.2688e-02, -9.5835e-02,  ..., -2.7785e-02,\n",
       "           1.3809e-04,  8.0919e-02],\n",
       "         [-4.4867e-02, -2.4727e-02,  9.5835e-02,  ...,  4.4724e-02,\n",
       "          -8.3492e-02,  8.0919e-02]]), 'layers.0.bias': tensor([-6.3312e-02,  1.3806e-01,  4.2493e-02,  5.9496e-02,  9.3920e-02,\n",
       "          8.9989e-02,  4.9173e-03, -1.5068e-01,  3.8913e-03, -8.3282e-02,\n",
       "          6.9666e-02,  9.5506e-02,  1.2707e-01,  3.7104e-02, -1.5138e-01,\n",
       "         -1.1979e-01, -7.1863e-02, -1.0101e-01,  1.4809e-01, -3.7260e-04,\n",
       "          5.8101e-02,  1.5046e-01, -9.8332e-02,  5.1021e-02, -8.0159e-02,\n",
       "          1.7824e-01, -9.0933e-02, -5.0950e-02, -5.4980e-02,  1.0744e-01,\n",
       "         -2.5157e-02,  2.5035e-02, -3.1995e-02, -4.4676e-02, -3.0534e-02,\n",
       "         -1.4780e-01,  3.9222e-05,  6.1813e-02,  1.0284e-01,  5.5691e-02,\n",
       "         -5.2655e-02,  3.5037e-02,  1.2269e-01, -4.5435e-02,  1.2579e-01,\n",
       "         -2.3929e-02, -6.9094e-02, -3.6880e-05,  3.3131e-02,  1.1736e-01]), 'layers.1.weight': tensor([[ 0.0520,  0.1222, -0.1389, -0.0810,  0.0581, -0.1086, -0.0681, -0.0280,\n",
       "           0.1522, -0.0326,  0.0431, -0.0761,  0.0630,  0.0059, -0.0762,  0.0587,\n",
       "          -0.0962, -0.0139,  0.0237,  0.0688, -0.1098,  0.0435, -0.0737, -0.0667,\n",
       "          -0.0601,  0.1227,  0.0717,  0.1020,  0.1117, -0.0246, -0.1206,  0.1357,\n",
       "           0.0137,  0.0548, -0.0904,  0.1246,  0.1081, -0.0838,  0.1770, -0.0479,\n",
       "          -0.1281,  0.0560,  0.1405, -0.0806,  0.0746,  0.1099, -0.0941, -0.0693,\n",
       "          -0.0782, -0.1025]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0091, -0.0090,  0.0096,  0.0089,  0.0101,  0.0070, -0.0098, -0.0095,\n",
       "           0.0066,  0.0082, -0.0112, -0.0079, -0.0093,  0.0082,  0.0079, -0.0086,\n",
       "           0.0090,  0.0091,  0.0095,  0.0093,  0.0070,  0.0089,  0.0122,  0.0086,\n",
       "          -0.0095,  0.0088, -0.0085,  0.0086, -0.0096,  0.0092,  0.0114, -0.0101,\n",
       "           0.0113, -0.0103,  0.0094, -0.0109, -0.0113, -0.0085, -0.0085, -0.0096,\n",
       "          -0.0071, -0.0075,  0.0119, -0.0083,  0.0103,  0.0094, -0.0122, -0.0088,\n",
       "          -0.0112, -0.0083,  0.0089, -0.0081, -0.0093,  0.0078,  0.0106,  0.0089,\n",
       "          -0.0087, -0.0109, -0.0097,  0.0085,  0.0076,  0.0090, -0.0130,  0.0144,\n",
       "           0.0199, -0.0202,  0.0081]])}, objective=12.686026050332684, loss=0.7350034117698669, val_objective=12.707807912114758, val_loss=0.7567852735519409, regularization=0.6485397219657898, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=18.79613950921127, state_dict={'layers.0.weight': tensor([[-6.6419e-02,  2.3961e-02,  8.3372e-02,  ..., -6.4609e-03,\n",
       "           5.7357e-02,  3.6836e-02],\n",
       "         [-9.0179e-02,  2.2440e-02, -1.3511e-02,  ...,  3.4295e-02,\n",
       "          -1.0523e-01, -6.7443e-02],\n",
       "         [-4.5710e-02, -5.5336e-02, -2.2931e-02,  ..., -1.9838e-01,\n",
       "          -1.2791e-01, -2.3799e-02],\n",
       "         ...,\n",
       "         [-7.1846e-03, -8.9131e-02, -2.7934e-02,  ..., -1.6579e-01,\n",
       "          -5.7688e-02,  3.7967e-02],\n",
       "         [ 9.0179e-02, -2.2679e-02, -9.5069e-02,  ..., -2.7803e-02,\n",
       "           1.5829e-04,  8.0371e-02],\n",
       "         [-4.4908e-02, -2.4722e-02,  9.5069e-02,  ...,  4.4681e-02,\n",
       "          -8.3436e-02,  8.0371e-02]]), 'layers.0.bias': tensor([-6.3305e-02,  1.3802e-01,  4.2499e-02,  5.9491e-02,  9.3918e-02,\n",
       "          8.9965e-02,  4.9092e-03, -1.5068e-01,  3.8647e-03, -8.3288e-02,\n",
       "          6.9678e-02,  9.5513e-02,  1.2707e-01,  3.7105e-02, -1.5140e-01,\n",
       "         -1.1979e-01, -7.1861e-02, -1.0101e-01,  1.4809e-01, -4.1345e-04,\n",
       "          5.8081e-02,  1.5045e-01, -9.8352e-02,  5.1004e-02, -8.0178e-02,\n",
       "          1.7822e-01, -9.0985e-02, -5.0977e-02, -5.4939e-02,  1.0743e-01,\n",
       "         -2.5157e-02,  2.5040e-02, -3.1999e-02, -4.4662e-02, -3.0521e-02,\n",
       "         -1.4780e-01,  1.8910e-05,  6.1818e-02,  1.0284e-01,  5.5670e-02,\n",
       "         -5.2725e-02,  3.5038e-02,  1.2274e-01, -4.5435e-02,  1.2578e-01,\n",
       "         -2.3965e-02, -6.9074e-02, -1.5005e-05,  3.3155e-02,  1.1737e-01]), 'layers.1.weight': tensor([[ 0.0520,  0.1224, -0.1390, -0.0810,  0.0582, -0.1088, -0.0682, -0.0281,\n",
       "           0.1524, -0.0327,  0.0431, -0.0762,  0.0632,  0.0058, -0.0763,  0.0588,\n",
       "          -0.0964, -0.0138,  0.0238,  0.0688, -0.1099,  0.0435, -0.0737, -0.0667,\n",
       "          -0.0601,  0.1227,  0.0718,  0.1020,  0.1117, -0.0248, -0.1207,  0.1358,\n",
       "           0.0138,  0.0549, -0.0904,  0.1249,  0.1080, -0.0841,  0.1772, -0.0479,\n",
       "          -0.1281,  0.0560,  0.1407, -0.0807,  0.0747,  0.1099, -0.0942, -0.0694,\n",
       "          -0.0783, -0.1028]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0090, -0.0089,  0.0095,  0.0088,  0.0100,  0.0069, -0.0097, -0.0094,\n",
       "           0.0066,  0.0082, -0.0112, -0.0078, -0.0092,  0.0081,  0.0078, -0.0085,\n",
       "           0.0089,  0.0091,  0.0095,  0.0092,  0.0070,  0.0088,  0.0121,  0.0086,\n",
       "          -0.0094,  0.0087, -0.0084,  0.0085, -0.0095,  0.0091,  0.0113, -0.0101,\n",
       "           0.0112, -0.0102,  0.0093, -0.0108, -0.0112, -0.0084, -0.0085, -0.0095,\n",
       "          -0.0070, -0.0075,  0.0119, -0.0082,  0.0102,  0.0094, -0.0121, -0.0087,\n",
       "          -0.0111, -0.0083,  0.0088, -0.0081, -0.0093,  0.0078,  0.0105,  0.0088,\n",
       "          -0.0086, -0.0108, -0.0097,  0.0084,  0.0075,  0.0089, -0.0129,  0.0143,\n",
       "           0.0198, -0.0201,  0.0080]])}, objective=12.836596906780999, loss=0.7350716590881348, val_objective=12.858239591717522, val_loss=0.7567143440246582, regularization=0.6438303589820862, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=19.172062299395495, state_dict={'layers.0.weight': tensor([[-6.6394e-02,  2.3961e-02,  8.3377e-02,  ..., -6.4440e-03,\n",
       "           5.7331e-02,  3.6839e-02],\n",
       "         [-8.9552e-02,  2.2463e-02, -1.3482e-02,  ...,  3.4314e-02,\n",
       "          -1.0528e-01, -6.7388e-02],\n",
       "         [-4.5756e-02, -5.5339e-02, -2.2955e-02,  ..., -1.9754e-01,\n",
       "          -1.2786e-01, -2.3788e-02],\n",
       "         ...,\n",
       "         [-7.1848e-03, -8.8462e-02, -2.7947e-02,  ..., -1.6581e-01,\n",
       "          -5.7676e-02,  3.7967e-02],\n",
       "         [ 8.9552e-02, -2.2669e-02, -9.4288e-02,  ..., -2.7822e-02,\n",
       "           1.7841e-04,  7.9812e-02],\n",
       "         [-4.4949e-02, -2.4715e-02,  9.4288e-02,  ...,  4.4638e-02,\n",
       "          -8.3381e-02,  7.9812e-02]]), 'layers.0.bias': tensor([-6.3298e-02,  1.3799e-01,  4.2507e-02,  5.9485e-02,  9.3916e-02,\n",
       "          8.9944e-02,  4.9010e-03, -1.5069e-01,  3.8406e-03, -8.3293e-02,\n",
       "          6.9690e-02,  9.5520e-02,  1.2707e-01,  3.7105e-02, -1.5143e-01,\n",
       "         -1.1980e-01, -7.1860e-02, -1.0101e-01,  1.4809e-01, -4.5440e-04,\n",
       "          5.8062e-02,  1.5043e-01, -9.8371e-02,  5.0987e-02, -8.0197e-02,\n",
       "          1.7819e-01, -9.1038e-02, -5.1006e-02, -5.4897e-02,  1.0742e-01,\n",
       "         -2.5156e-02,  2.5044e-02, -3.2004e-02, -4.4648e-02, -3.0507e-02,\n",
       "         -1.4779e-01, -1.2782e-06,  6.1823e-02,  1.0283e-01,  5.5649e-02,\n",
       "         -5.2795e-02,  3.5039e-02,  1.2280e-01, -4.5435e-02,  1.2576e-01,\n",
       "         -2.4001e-02, -6.9053e-02,  6.9401e-06,  3.3179e-02,  1.1737e-01]), 'layers.1.weight': tensor([[ 0.0521,  0.1225, -0.1392, -0.0810,  0.0582, -0.1089, -0.0683, -0.0281,\n",
       "           0.1525, -0.0327,  0.0432, -0.0763,  0.0633,  0.0057, -0.0764,  0.0589,\n",
       "          -0.0966, -0.0137,  0.0239,  0.0688, -0.1100,  0.0435, -0.0737, -0.0668,\n",
       "          -0.0602,  0.1228,  0.0718,  0.1021,  0.1117, -0.0249, -0.1208,  0.1359,\n",
       "           0.0139,  0.0550, -0.0904,  0.1252,  0.1079, -0.0843,  0.1775, -0.0479,\n",
       "          -0.1281,  0.0560,  0.1409, -0.0808,  0.0747,  0.1099, -0.0942, -0.0696,\n",
       "          -0.0784, -0.1030]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0090, -0.0088,  0.0094,  0.0088,  0.0100,  0.0069, -0.0096, -0.0093,\n",
       "           0.0065,  0.0081, -0.0111, -0.0078, -0.0092,  0.0081,  0.0078, -0.0084,\n",
       "           0.0089,  0.0090,  0.0094,  0.0091,  0.0069,  0.0088,  0.0120,  0.0085,\n",
       "          -0.0094,  0.0087, -0.0084,  0.0085, -0.0095,  0.0090,  0.0112, -0.0100,\n",
       "           0.0111, -0.0102,  0.0092, -0.0107, -0.0111, -0.0083, -0.0084, -0.0094,\n",
       "          -0.0070, -0.0074,  0.0118, -0.0081,  0.0102,  0.0093, -0.0120, -0.0087,\n",
       "          -0.0110, -0.0082,  0.0087, -0.0080, -0.0092,  0.0077,  0.0104,  0.0088,\n",
       "          -0.0086, -0.0107, -0.0096,  0.0084,  0.0074,  0.0089, -0.0128,  0.0142,\n",
       "           0.0198, -0.0200,  0.0080]])}, objective=12.987436582496304, loss=0.7351426482200623, val_objective=13.008934428146024, val_loss=0.7566404938697815, regularization=0.6390702128410339, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=19.555503545383406, state_dict={'layers.0.weight': tensor([[-0.0664,  0.0240,  0.0834,  ..., -0.0064,  0.0573,  0.0368],\n",
       "         [-0.0889,  0.0225, -0.0135,  ...,  0.0343, -0.1053, -0.0673],\n",
       "         [-0.0458, -0.0553, -0.0230,  ..., -0.1967, -0.1278, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0878, -0.0280,  ..., -0.1658, -0.0577,  0.0380],\n",
       "         [ 0.0889, -0.0227, -0.0935,  ..., -0.0278,  0.0002,  0.0792],\n",
       "         [-0.0450, -0.0247,  0.0935,  ...,  0.0446, -0.0833,  0.0792]]), 'layers.0.bias': tensor([-6.3291e-02,  1.3796e-01,  4.2515e-02,  5.9479e-02,  9.3914e-02,\n",
       "          8.9926e-02,  4.8927e-03, -1.5070e-01,  3.8201e-03, -8.3299e-02,\n",
       "          6.9702e-02,  9.5527e-02,  1.2708e-01,  3.7106e-02, -1.5145e-01,\n",
       "         -1.1980e-01, -7.1859e-02, -1.0102e-01,  1.4809e-01, -4.9512e-04,\n",
       "          5.8044e-02,  1.5042e-01, -9.8389e-02,  5.0969e-02, -8.0216e-02,\n",
       "          1.7816e-01, -9.1091e-02, -5.1034e-02, -5.4855e-02,  1.0741e-01,\n",
       "         -2.5154e-02,  2.5047e-02, -3.2009e-02, -4.4634e-02, -3.0492e-02,\n",
       "         -1.4778e-01, -2.1467e-05,  6.1828e-02,  1.0283e-01,  5.5628e-02,\n",
       "         -5.2865e-02,  3.5039e-02,  1.2285e-01, -4.5434e-02,  1.2574e-01,\n",
       "         -2.4034e-02, -6.9032e-02,  2.9023e-05,  3.3204e-02,  1.1737e-01]), 'layers.1.weight': tensor([[ 0.0521,  0.1226, -0.1394, -0.0810,  0.0582, -0.1090, -0.0684, -0.0281,\n",
       "           0.1527, -0.0328,  0.0432, -0.0764,  0.0634,  0.0056, -0.0765,  0.0590,\n",
       "          -0.0969, -0.0136,  0.0239,  0.0688, -0.1100,  0.0434, -0.0737, -0.0668,\n",
       "          -0.0602,  0.1228,  0.0719,  0.1022,  0.1118, -0.0250, -0.1208,  0.1360,\n",
       "           0.0140,  0.0551, -0.0903,  0.1255,  0.1079, -0.0845,  0.1777, -0.0479,\n",
       "          -0.1281,  0.0561,  0.1411, -0.0809,  0.0748,  0.1099, -0.0943, -0.0698,\n",
       "          -0.0785, -0.1032]]), 'layers.1.bias': tensor([-0.0625]), 'skip.weight': tensor([[ 0.0089, -0.0088,  0.0093,  0.0087,  0.0099,  0.0068, -0.0095, -0.0093,\n",
       "           0.0065,  0.0080, -0.0110, -0.0077, -0.0091,  0.0080,  0.0077, -0.0084,\n",
       "           0.0088,  0.0089,  0.0093,  0.0090,  0.0069,  0.0087,  0.0119,  0.0084,\n",
       "          -0.0093,  0.0086, -0.0083,  0.0084, -0.0094,  0.0089,  0.0111, -0.0099,\n",
       "           0.0110, -0.0101,  0.0091, -0.0106, -0.0110, -0.0083, -0.0084, -0.0093,\n",
       "          -0.0069, -0.0074,  0.0117, -0.0081,  0.0101,  0.0092, -0.0119, -0.0086,\n",
       "          -0.0109, -0.0081,  0.0086, -0.0079, -0.0091,  0.0077,  0.0104,  0.0087,\n",
       "          -0.0085, -0.0107, -0.0095,  0.0083,  0.0074,  0.0088, -0.0127,  0.0141,\n",
       "           0.0197, -0.0199,  0.0079]])}, objective=13.138536002664653, loss=0.7352157235145569, val_objective=13.159882094888774, val_loss=0.756561815738678, regularization=0.6342623829841614, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=19.946613616291074, state_dict={'layers.0.weight': tensor([[-0.0663,  0.0240,  0.0834,  ..., -0.0064,  0.0573,  0.0368],\n",
       "         [-0.0883,  0.0225, -0.0134,  ...,  0.0344, -0.1054, -0.0673],\n",
       "         [-0.0458, -0.0553, -0.0230,  ..., -0.1958, -0.1278, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0871, -0.0280,  ..., -0.1659, -0.0577,  0.0380],\n",
       "         [ 0.0883, -0.0226, -0.0927,  ..., -0.0279,  0.0002,  0.0787],\n",
       "         [-0.0450, -0.0247,  0.0927,  ...,  0.0446, -0.0833,  0.0787]]), 'layers.0.bias': tensor([-6.3284e-02,  1.3792e-01,  4.2524e-02,  5.9473e-02,  9.3912e-02,\n",
       "          8.9910e-02,  4.8839e-03, -1.5070e-01,  3.8029e-03, -8.3305e-02,\n",
       "          6.9713e-02,  9.5534e-02,  1.2708e-01,  3.7106e-02, -1.5147e-01,\n",
       "         -1.1981e-01, -7.1857e-02, -1.0102e-01,  1.4809e-01, -5.3572e-04,\n",
       "          5.8028e-02,  1.5041e-01, -9.8407e-02,  5.0951e-02, -8.0235e-02,\n",
       "          1.7813e-01, -9.1143e-02, -5.1061e-02, -5.4813e-02,  1.0740e-01,\n",
       "         -2.5151e-02,  2.5049e-02, -3.2014e-02, -4.4620e-02, -3.0476e-02,\n",
       "         -1.4778e-01, -4.1990e-05,  6.1833e-02,  1.0283e-01,  5.5608e-02,\n",
       "         -5.2935e-02,  3.5039e-02,  1.2290e-01, -4.5434e-02,  1.2573e-01,\n",
       "         -2.4067e-02, -6.9010e-02,  5.1231e-05,  3.3230e-02,  1.1738e-01]), 'layers.1.weight': tensor([[ 0.0521,  0.1228, -0.1395, -0.0810,  0.0583, -0.1091, -0.0685, -0.0282,\n",
       "           0.1528, -0.0328,  0.0432, -0.0765,  0.0635,  0.0055, -0.0766,  0.0591,\n",
       "          -0.0971, -0.0135,  0.0240,  0.0687, -0.1101,  0.0434, -0.0736, -0.0669,\n",
       "          -0.0603,  0.1228,  0.0720,  0.1022,  0.1118, -0.0251, -0.1209,  0.1361,\n",
       "           0.0141,  0.0552, -0.0903,  0.1258,  0.1078, -0.0847,  0.1780, -0.0480,\n",
       "          -0.1281,  0.0561,  0.1413, -0.0811,  0.0749,  0.1099, -0.0944, -0.0700,\n",
       "          -0.0786, -0.1035]]), 'layers.1.bias': tensor([-0.0624]), 'skip.weight': tensor([[ 0.0088, -0.0087,  0.0093,  0.0087,  0.0098,  0.0068, -0.0094, -0.0092,\n",
       "           0.0064,  0.0080, -0.0110, -0.0077, -0.0090,  0.0079,  0.0076, -0.0083,\n",
       "           0.0087,  0.0088,  0.0092,  0.0090,  0.0068,  0.0086,  0.0118,  0.0084,\n",
       "          -0.0092,  0.0085, -0.0082,  0.0083, -0.0093,  0.0089,  0.0111, -0.0099,\n",
       "           0.0109, -0.0100,  0.0090, -0.0105, -0.0109, -0.0082, -0.0083, -0.0093,\n",
       "          -0.0069, -0.0073,  0.0116, -0.0080,  0.0100,  0.0092, -0.0118, -0.0086,\n",
       "          -0.0108, -0.0081,  0.0085, -0.0079, -0.0091,  0.0076,  0.0103,  0.0087,\n",
       "          -0.0084, -0.0106, -0.0095,  0.0082,  0.0073,  0.0087, -0.0126,  0.0141,\n",
       "           0.0196, -0.0197,  0.0079]])}, objective=13.290459133144513, loss=0.7352898120880127, val_objective=13.311640895362988, val_loss=0.756471574306488, regularization=0.6294386386871338, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=20.345545888616897, state_dict={'layers.0.weight': tensor([[-0.0663,  0.0240,  0.0834,  ..., -0.0064,  0.0573,  0.0368],\n",
       "         [-0.0876,  0.0225, -0.0134,  ...,  0.0344, -0.1054, -0.0672],\n",
       "         [-0.0459, -0.0553, -0.0230,  ..., -0.1949, -0.1277, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0864, -0.0280,  ..., -0.1659, -0.0576,  0.0380],\n",
       "         [ 0.0876, -0.0226, -0.0919,  ..., -0.0279,  0.0002,  0.0781],\n",
       "         [-0.0451, -0.0247,  0.0919,  ...,  0.0445, -0.0832,  0.0781]]), 'layers.0.bias': tensor([-6.3277e-02,  1.3788e-01,  4.2535e-02,  5.9467e-02,  9.3909e-02,\n",
       "          8.9897e-02,  4.8749e-03, -1.5071e-01,  3.7865e-03, -8.3311e-02,\n",
       "          6.9724e-02,  9.5541e-02,  1.2709e-01,  3.7107e-02, -1.5150e-01,\n",
       "         -1.1982e-01, -7.1855e-02, -1.0102e-01,  1.4809e-01, -5.7610e-04,\n",
       "          5.8014e-02,  1.5039e-01, -9.8425e-02,  5.0932e-02, -8.0255e-02,\n",
       "          1.7809e-01, -9.1195e-02, -5.1087e-02, -5.4771e-02,  1.0739e-01,\n",
       "         -2.5145e-02,  2.5051e-02, -3.2018e-02, -4.4606e-02, -3.0460e-02,\n",
       "         -1.4777e-01, -6.2704e-05,  6.1838e-02,  1.0283e-01,  5.5587e-02,\n",
       "         -5.3007e-02,  3.5040e-02,  1.2295e-01, -4.5435e-02,  1.2571e-01,\n",
       "         -2.4100e-02, -6.8989e-02,  7.2361e-05,  3.3255e-02,  1.1738e-01]), 'layers.1.weight': tensor([[ 0.0521,  0.1229, -0.1397, -0.0810,  0.0583, -0.1092, -0.0686, -0.0282,\n",
       "           0.1530, -0.0329,  0.0432, -0.0766,  0.0636,  0.0053, -0.0767,  0.0593,\n",
       "          -0.0973, -0.0134,  0.0241,  0.0687, -0.1102,  0.0434, -0.0736, -0.0670,\n",
       "          -0.0604,  0.1228,  0.0720,  0.1023,  0.1118, -0.0253, -0.1210,  0.1362,\n",
       "           0.0142,  0.0554, -0.0903,  0.1261,  0.1077, -0.0850,  0.1782, -0.0480,\n",
       "          -0.1281,  0.0562,  0.1415, -0.0812,  0.0749,  0.1099, -0.0945, -0.0701,\n",
       "          -0.0788, -0.1037]]), 'layers.1.bias': tensor([-0.0624]), 'skip.weight': tensor([[ 0.0088, -0.0086,  0.0092,  0.0086,  0.0098,  0.0067, -0.0093, -0.0091,\n",
       "           0.0064,  0.0079, -0.0109, -0.0076, -0.0089,  0.0078,  0.0076, -0.0082,\n",
       "           0.0087,  0.0087,  0.0091,  0.0089,  0.0068,  0.0086,  0.0117,  0.0083,\n",
       "          -0.0091,  0.0084, -0.0082,  0.0082, -0.0093,  0.0088,  0.0110, -0.0098,\n",
       "           0.0108, -0.0099,  0.0090, -0.0104, -0.0108, -0.0081, -0.0082, -0.0092,\n",
       "          -0.0068, -0.0073,  0.0116, -0.0079,  0.0100,  0.0091, -0.0118, -0.0085,\n",
       "          -0.0107, -0.0080,  0.0084, -0.0078, -0.0090,  0.0076,  0.0102,  0.0086,\n",
       "          -0.0083, -0.0105, -0.0094,  0.0082,  0.0073,  0.0087, -0.0125,  0.0140,\n",
       "           0.0195, -0.0196,  0.0078]])}, objective=13.443186337732163, loss=0.7353633642196655, val_objective=13.464198167108384, val_loss=0.7563751935958862, regularization=0.6245997548103333, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=20.752456806389237, state_dict={'layers.0.weight': tensor([[-0.0663,  0.0240,  0.0834,  ..., -0.0064,  0.0572,  0.0369],\n",
       "         [-0.0869,  0.0226, -0.0134,  ...,  0.0344, -0.1055, -0.0672],\n",
       "         [-0.0459, -0.0554, -0.0230,  ..., -0.1940, -0.1277, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0856, -0.0280,  ..., -0.1659, -0.0576,  0.0380],\n",
       "         [ 0.0869, -0.0226, -0.0912,  ..., -0.0279,  0.0003,  0.0775],\n",
       "         [-0.0451, -0.0247,  0.0912,  ...,  0.0445, -0.0832,  0.0775]]), 'layers.0.bias': tensor([-6.3269e-02,  1.3785e-01,  4.2547e-02,  5.9461e-02,  9.3907e-02,\n",
       "          8.9885e-02,  4.8663e-03, -1.5072e-01,  3.7703e-03, -8.3317e-02,\n",
       "          6.9735e-02,  9.5549e-02,  1.2709e-01,  3.7107e-02, -1.5152e-01,\n",
       "         -1.1983e-01, -7.1853e-02, -1.0103e-01,  1.4810e-01, -6.1629e-04,\n",
       "          5.8001e-02,  1.5038e-01, -9.8442e-02,  5.0912e-02, -8.0274e-02,\n",
       "          1.7806e-01, -9.1246e-02, -5.1113e-02, -5.4728e-02,  1.0738e-01,\n",
       "         -2.5138e-02,  2.5055e-02, -3.2023e-02, -4.4592e-02, -3.0443e-02,\n",
       "         -1.4776e-01, -8.3965e-05,  6.1844e-02,  1.0283e-01,  5.5567e-02,\n",
       "         -5.3080e-02,  3.5040e-02,  1.2300e-01, -4.5436e-02,  1.2570e-01,\n",
       "         -2.4134e-02, -6.8967e-02,  9.1694e-05,  3.3281e-02,  1.1738e-01]), 'layers.1.weight': tensor([[ 0.0522,  0.1230, -0.1399, -0.0810,  0.0583, -0.1094, -0.0687, -0.0282,\n",
       "           0.1531, -0.0329,  0.0433, -0.0767,  0.0638,  0.0052, -0.0768,  0.0594,\n",
       "          -0.0975, -0.0133,  0.0242,  0.0687, -0.1103,  0.0433, -0.0736, -0.0671,\n",
       "          -0.0604,  0.1228,  0.0721,  0.1024,  0.1119, -0.0254, -0.1211,  0.1363,\n",
       "           0.0143,  0.0555, -0.0903,  0.1264,  0.1076, -0.0852,  0.1785, -0.0480,\n",
       "          -0.1281,  0.0562,  0.1417, -0.0813,  0.0750,  0.1099, -0.0945, -0.0703,\n",
       "          -0.0789, -0.1039]]), 'layers.1.bias': tensor([-0.0624]), 'skip.weight': tensor([[ 0.0087, -0.0086,  0.0091,  0.0085,  0.0097,  0.0067, -0.0092, -0.0091,\n",
       "           0.0063,  0.0079, -0.0108, -0.0076, -0.0088,  0.0078,  0.0075, -0.0082,\n",
       "           0.0086,  0.0087,  0.0091,  0.0088,  0.0067,  0.0085,  0.0116,  0.0082,\n",
       "          -0.0091,  0.0084, -0.0081,  0.0081, -0.0092,  0.0087,  0.0109, -0.0097,\n",
       "           0.0106, -0.0099,  0.0089, -0.0103, -0.0108, -0.0080, -0.0082, -0.0091,\n",
       "          -0.0067, -0.0072,  0.0115, -0.0078,  0.0099,  0.0090, -0.0117, -0.0084,\n",
       "          -0.0106, -0.0080,  0.0084, -0.0078, -0.0089,  0.0075,  0.0102,  0.0085,\n",
       "          -0.0083, -0.0104, -0.0094,  0.0081,  0.0072,  0.0086, -0.0124,  0.0139,\n",
       "           0.0194, -0.0195,  0.0078]])}, objective=13.596249076131446, loss=0.7354404330253601, val_objective=13.617086025479896, val_loss=0.7562773823738098, regularization=0.6197246313095093, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=21.16750594251702, state_dict={'layers.0.weight': tensor([[-0.0663,  0.0240,  0.0834,  ..., -0.0064,  0.0572,  0.0369],\n",
       "         [-0.0862,  0.0226, -0.0133,  ...,  0.0344, -0.1055, -0.0671],\n",
       "         [-0.0460, -0.0554, -0.0231,  ..., -0.1932, -0.1277, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0849, -0.0280,  ..., -0.1659, -0.0576,  0.0380],\n",
       "         [ 0.0862, -0.0226, -0.0905,  ..., -0.0279,  0.0003,  0.0769],\n",
       "         [-0.0452, -0.0247,  0.0905,  ...,  0.0444, -0.0831,  0.0769]]), 'layers.0.bias': tensor([-6.3261e-02,  1.3781e-01,  4.2560e-02,  5.9453e-02,  9.3904e-02,\n",
       "          8.9874e-02,  4.8584e-03, -1.5072e-01,  3.7533e-03, -8.3323e-02,\n",
       "          6.9747e-02,  9.5555e-02,  1.2710e-01,  3.7108e-02, -1.5155e-01,\n",
       "         -1.1983e-01, -7.1849e-02, -1.0103e-01,  1.4810e-01, -6.5604e-04,\n",
       "          5.7989e-02,  1.5036e-01, -9.8458e-02,  5.0894e-02, -8.0294e-02,\n",
       "          1.7803e-01, -9.1296e-02, -5.1139e-02, -5.4686e-02,  1.0737e-01,\n",
       "         -2.5129e-02,  2.5061e-02, -3.2028e-02, -4.4578e-02, -3.0426e-02,\n",
       "         -1.4775e-01, -1.0636e-04,  6.1851e-02,  1.0282e-01,  5.5547e-02,\n",
       "         -5.3153e-02,  3.5040e-02,  1.2306e-01, -4.5438e-02,  1.2568e-01,\n",
       "         -2.4170e-02, -6.8945e-02,  1.0989e-04,  3.3308e-02,  1.1738e-01]), 'layers.1.weight': tensor([[ 0.0522,  0.1232, -0.1401, -0.0810,  0.0584, -0.1095, -0.0688, -0.0283,\n",
       "           0.1533, -0.0330,  0.0433, -0.0768,  0.0639,  0.0051, -0.0768,  0.0595,\n",
       "          -0.0977, -0.0132,  0.0243,  0.0687, -0.1104,  0.0433, -0.0736, -0.0671,\n",
       "          -0.0605,  0.1228,  0.0721,  0.1025,  0.1119, -0.0255, -0.1212,  0.1364,\n",
       "           0.0144,  0.0556, -0.0903,  0.1267,  0.1075, -0.0854,  0.1788, -0.0480,\n",
       "          -0.1281,  0.0563,  0.1419, -0.0814,  0.0750,  0.1099, -0.0946, -0.0705,\n",
       "          -0.0790, -0.1042]]), 'layers.1.bias': tensor([-0.0624]), 'skip.weight': tensor([[ 0.0086, -0.0085,  0.0090,  0.0085,  0.0096,  0.0066, -0.0091, -0.0090,\n",
       "           0.0063,  0.0078, -0.0107, -0.0075, -0.0088,  0.0077,  0.0074, -0.0081,\n",
       "           0.0085,  0.0086,  0.0090,  0.0087,  0.0067,  0.0084,  0.0115,  0.0082,\n",
       "          -0.0090,  0.0083, -0.0080,  0.0081, -0.0091,  0.0086,  0.0109, -0.0097,\n",
       "           0.0105, -0.0098,  0.0088, -0.0102, -0.0107, -0.0079, -0.0081, -0.0090,\n",
       "          -0.0067, -0.0071,  0.0114, -0.0077,  0.0098,  0.0089, -0.0116, -0.0084,\n",
       "          -0.0105, -0.0079,  0.0083, -0.0077, -0.0089,  0.0075,  0.0101,  0.0085,\n",
       "          -0.0082, -0.0103, -0.0093,  0.0080,  0.0072,  0.0086, -0.0122,  0.0138,\n",
       "           0.0193, -0.0194,  0.0077]])}, objective=13.749447370651938, loss=0.7355201244354248, val_objective=13.770107890251852, val_loss=0.7561806440353394, regularization=0.6148068308830261, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=21.59085606136736, state_dict={'layers.0.weight': tensor([[-0.0663,  0.0240,  0.0834,  ..., -0.0063,  0.0572,  0.0369],\n",
       "         [-0.0855,  0.0226, -0.0133,  ...,  0.0344, -0.1055, -0.0670],\n",
       "         [-0.0460, -0.0554, -0.0231,  ..., -0.1923, -0.1276, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0842, -0.0280,  ..., -0.1659, -0.0576,  0.0380],\n",
       "         [ 0.0855, -0.0226, -0.0897,  ..., -0.0279,  0.0003,  0.0763],\n",
       "         [-0.0452, -0.0247,  0.0897,  ...,  0.0444, -0.0830,  0.0763]]), 'layers.0.bias': tensor([-6.3253e-02,  1.3778e-01,  4.2575e-02,  5.9446e-02,  9.3900e-02,\n",
       "          8.9863e-02,  4.8512e-03, -1.5073e-01,  3.7364e-03, -8.3330e-02,\n",
       "          6.9759e-02,  9.5562e-02,  1.2711e-01,  3.7108e-02, -1.5157e-01,\n",
       "         -1.1984e-01, -7.1845e-02, -1.0103e-01,  1.4810e-01, -6.9506e-04,\n",
       "          5.7977e-02,  1.5035e-01, -9.8475e-02,  5.0875e-02, -8.0313e-02,\n",
       "          1.7800e-01, -9.1346e-02, -5.1163e-02, -5.4643e-02,  1.0737e-01,\n",
       "         -2.5120e-02,  2.5069e-02, -3.2032e-02, -4.4565e-02, -3.0410e-02,\n",
       "         -1.4774e-01, -1.2800e-04,  6.1859e-02,  1.0282e-01,  5.5527e-02,\n",
       "         -5.3224e-02,  3.5040e-02,  1.2311e-01, -4.5440e-02,  1.2567e-01,\n",
       "         -2.4206e-02, -6.8924e-02,  1.2668e-04,  3.3335e-02,  1.1739e-01]), 'layers.1.weight': tensor([[ 0.0522,  0.1233, -0.1402, -0.0810,  0.0584, -0.1096, -0.0689, -0.0283,\n",
       "           0.1534, -0.0330,  0.0433, -0.0769,  0.0641,  0.0050, -0.0769,  0.0596,\n",
       "          -0.0979, -0.0131,  0.0244,  0.0687, -0.1105,  0.0433, -0.0736, -0.0672,\n",
       "          -0.0606,  0.1228,  0.0722,  0.1025,  0.1119, -0.0256, -0.1213,  0.1365,\n",
       "           0.0145,  0.0557, -0.0903,  0.1270,  0.1074, -0.0856,  0.1790, -0.0480,\n",
       "          -0.1281,  0.0563,  0.1421, -0.0815,  0.0751,  0.1100, -0.0947, -0.0706,\n",
       "          -0.0791, -0.1044]]), 'layers.1.bias': tensor([-0.0624]), 'skip.weight': tensor([[ 0.0086, -0.0084,  0.0090,  0.0084,  0.0096,  0.0066, -0.0090, -0.0089,\n",
       "           0.0062,  0.0078, -0.0106, -0.0075, -0.0087,  0.0076,  0.0073, -0.0081,\n",
       "           0.0085,  0.0085,  0.0089,  0.0086,  0.0066,  0.0083,  0.0114,  0.0081,\n",
       "          -0.0089,  0.0082, -0.0080,  0.0080, -0.0090,  0.0085,  0.0108, -0.0096,\n",
       "           0.0104, -0.0097,  0.0087, -0.0101, -0.0106, -0.0078, -0.0081, -0.0089,\n",
       "          -0.0066, -0.0071,  0.0113, -0.0077,  0.0098,  0.0089, -0.0115, -0.0083,\n",
       "          -0.0104, -0.0078,  0.0082, -0.0077, -0.0088,  0.0074,  0.0100,  0.0084,\n",
       "          -0.0081, -0.0102, -0.0092,  0.0080,  0.0071,  0.0085, -0.0121,  0.0137,\n",
       "           0.0192, -0.0192,  0.0076]])}, objective=13.90312477408585, loss=0.7356029748916626, val_objective=13.92360189019379, val_loss=0.7560800909996033, regularization=0.609865665435791, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=22.02267318259471, state_dict={'layers.0.weight': tensor([[-0.0662,  0.0240,  0.0834,  ..., -0.0063,  0.0572,  0.0369],\n",
       "         [-0.0848,  0.0226, -0.0133,  ...,  0.0345, -0.1056, -0.0670],\n",
       "         [-0.0460, -0.0554, -0.0231,  ..., -0.1914, -0.1276, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0834, -0.0280,  ..., -0.1660, -0.0576,  0.0380],\n",
       "         [ 0.0848, -0.0226, -0.0890,  ..., -0.0279,  0.0003,  0.0757],\n",
       "         [-0.0452, -0.0246,  0.0890,  ...,  0.0443, -0.0830,  0.0757]]), 'layers.0.bias': tensor([-6.3243e-02,  1.3774e-01,  4.2590e-02,  5.9439e-02,  9.3896e-02,\n",
       "          8.9852e-02,  4.8447e-03, -1.5073e-01,  3.7200e-03, -8.3337e-02,\n",
       "          6.9771e-02,  9.5568e-02,  1.2711e-01,  3.7109e-02, -1.5160e-01,\n",
       "         -1.1985e-01, -7.1841e-02, -1.0103e-01,  1.4810e-01, -7.3364e-04,\n",
       "          5.7966e-02,  1.5033e-01, -9.8492e-02,  5.0856e-02, -8.0332e-02,\n",
       "          1.7797e-01, -9.1395e-02, -5.1186e-02, -5.4602e-02,  1.0736e-01,\n",
       "         -2.5111e-02,  2.5079e-02, -3.2037e-02, -4.4551e-02, -3.0394e-02,\n",
       "         -1.4772e-01, -1.4694e-04,  6.1868e-02,  1.0282e-01,  5.5507e-02,\n",
       "         -5.3296e-02,  3.5040e-02,  1.2317e-01, -4.5444e-02,  1.2565e-01,\n",
       "         -2.4242e-02, -6.8903e-02,  1.4302e-04,  3.3362e-02,  1.1739e-01]), 'layers.1.weight': tensor([[ 0.0522,  0.1234, -0.1404, -0.0810,  0.0585, -0.1098, -0.0690, -0.0284,\n",
       "           0.1536, -0.0331,  0.0433, -0.0769,  0.0642,  0.0049, -0.0770,  0.0597,\n",
       "          -0.0981, -0.0130,  0.0244,  0.0687, -0.1106,  0.0433, -0.0735, -0.0673,\n",
       "          -0.0606,  0.1228,  0.0722,  0.1026,  0.1119, -0.0258, -0.1214,  0.1366,\n",
       "           0.0146,  0.0559, -0.0903,  0.1273,  0.1074, -0.0859,  0.1793, -0.0481,\n",
       "          -0.1281,  0.0564,  0.1423, -0.0816,  0.0751,  0.1100, -0.0948, -0.0708,\n",
       "          -0.0793, -0.1046]]), 'layers.1.bias': tensor([-0.0623]), 'skip.weight': tensor([[ 0.0085, -0.0083,  0.0089,  0.0084,  0.0095,  0.0065, -0.0089, -0.0089,\n",
       "           0.0062,  0.0077, -0.0106, -0.0074, -0.0086,  0.0075,  0.0073, -0.0080,\n",
       "           0.0084,  0.0085,  0.0088,  0.0085,  0.0066,  0.0083,  0.0113,  0.0080,\n",
       "          -0.0088,  0.0081, -0.0079,  0.0079, -0.0090,  0.0085,  0.0107, -0.0096,\n",
       "           0.0103, -0.0097,  0.0086, -0.0100, -0.0105, -0.0078, -0.0080, -0.0088,\n",
       "          -0.0066, -0.0070,  0.0113, -0.0076,  0.0097,  0.0088, -0.0115, -0.0083,\n",
       "          -0.0103, -0.0078,  0.0081, -0.0076, -0.0087,  0.0074,  0.0099,  0.0084,\n",
       "          -0.0081, -0.0101, -0.0092,  0.0079,  0.0071,  0.0084, -0.0120,  0.0137,\n",
       "           0.0191, -0.0191,  0.0076]])}, objective=14.057090026453116, loss=0.7356878519058228, val_objective=14.077377540186026, val_loss=0.7559753656387329, regularization=0.6048948764801025, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=22.463126646246604, state_dict={'layers.0.weight': tensor([[-0.0662,  0.0240,  0.0834,  ..., -0.0063,  0.0571,  0.0369],\n",
       "         [-0.0841,  0.0226, -0.0133,  ...,  0.0345, -0.1056, -0.0669],\n",
       "         [-0.0461, -0.0553, -0.0231,  ..., -0.1905, -0.1276, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0826, -0.0281,  ..., -0.1660, -0.0576,  0.0380],\n",
       "         [ 0.0841, -0.0226, -0.0883,  ..., -0.0280,  0.0003,  0.0752],\n",
       "         [-0.0453, -0.0246,  0.0883,  ...,  0.0443, -0.0829,  0.0752]]), 'layers.0.bias': tensor([-6.3234e-02,  1.3770e-01,  4.2606e-02,  5.9431e-02,  9.3893e-02,\n",
       "          8.9841e-02,  4.8386e-03, -1.5074e-01,  3.7039e-03, -8.3343e-02,\n",
       "          6.9783e-02,  9.5574e-02,  1.2712e-01,  3.7109e-02, -1.5163e-01,\n",
       "         -1.1986e-01, -7.1836e-02, -1.0103e-01,  1.4810e-01, -7.7172e-04,\n",
       "          5.7953e-02,  1.5032e-01, -9.8509e-02,  5.0837e-02, -8.0352e-02,\n",
       "          1.7793e-01, -9.1444e-02, -5.1206e-02, -5.4560e-02,  1.0735e-01,\n",
       "         -2.5104e-02,  2.5088e-02, -3.2042e-02, -4.4537e-02, -3.0379e-02,\n",
       "         -1.4771e-01, -1.6498e-04,  6.1878e-02,  1.0282e-01,  5.5488e-02,\n",
       "         -5.3367e-02,  3.5040e-02,  1.2322e-01, -4.5448e-02,  1.2564e-01,\n",
       "         -2.4278e-02, -6.8883e-02,  1.5936e-04,  3.3389e-02,  1.1739e-01]), 'layers.1.weight': tensor([[ 0.0523,  0.1235, -0.1406, -0.0810,  0.0585, -0.1099, -0.0691, -0.0284,\n",
       "           0.1537, -0.0331,  0.0433, -0.0770,  0.0644,  0.0048, -0.0771,  0.0599,\n",
       "          -0.0983, -0.0129,  0.0245,  0.0687, -0.1107,  0.0432, -0.0735, -0.0674,\n",
       "          -0.0607,  0.1229,  0.0723,  0.1027,  0.1120, -0.0259, -0.1215,  0.1366,\n",
       "           0.0147,  0.0560, -0.0903,  0.1276,  0.1073, -0.0861,  0.1796, -0.0481,\n",
       "          -0.1281,  0.0564,  0.1425, -0.0817,  0.0752,  0.1100, -0.0949, -0.0710,\n",
       "          -0.0794, -0.1048]]), 'layers.1.bias': tensor([-0.0623]), 'skip.weight': tensor([[ 0.0084, -0.0083,  0.0088,  0.0083,  0.0094,  0.0065, -0.0088, -0.0088,\n",
       "           0.0061,  0.0076, -0.0105, -0.0074, -0.0085,  0.0075,  0.0072, -0.0079,\n",
       "           0.0083,  0.0084,  0.0087,  0.0085,  0.0065,  0.0082,  0.0113,  0.0080,\n",
       "          -0.0088,  0.0080, -0.0078,  0.0078, -0.0089,  0.0084,  0.0106, -0.0095,\n",
       "           0.0102, -0.0096,  0.0085, -0.0099, -0.0104, -0.0077, -0.0080, -0.0088,\n",
       "          -0.0065, -0.0070,  0.0112, -0.0075,  0.0096,  0.0087, -0.0114, -0.0082,\n",
       "          -0.0102, -0.0077,  0.0080, -0.0075, -0.0087,  0.0073,  0.0099,  0.0083,\n",
       "          -0.0080, -0.0100, -0.0091,  0.0078,  0.0070,  0.0084, -0.0119,  0.0136,\n",
       "           0.0191, -0.0190,  0.0075]])}, objective=14.211956076112436, loss=0.7357759475708008, val_objective=14.232049576726602, val_loss=0.755869448184967, regularization=0.5999245047569275, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=22.912389179171537, state_dict={'layers.0.weight': tensor([[-0.0662,  0.0239,  0.0834,  ..., -0.0063,  0.0571,  0.0369],\n",
       "         [-0.0833,  0.0227, -0.0133,  ...,  0.0345, -0.1057, -0.0669],\n",
       "         [-0.0461, -0.0553, -0.0231,  ..., -0.1896, -0.1275, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0818, -0.0281,  ..., -0.1660, -0.0575,  0.0380],\n",
       "         [ 0.0833, -0.0226, -0.0876,  ..., -0.0280,  0.0003,  0.0746],\n",
       "         [-0.0453, -0.0246,  0.0876,  ...,  0.0442, -0.0829,  0.0746]]), 'layers.0.bias': tensor([-6.3224e-02,  1.3767e-01,  4.2622e-02,  5.9424e-02,  9.3890e-02,\n",
       "          8.9831e-02,  4.8329e-03, -1.5074e-01,  3.6878e-03, -8.3350e-02,\n",
       "          6.9796e-02,  9.5579e-02,  1.2713e-01,  3.7110e-02, -1.5165e-01,\n",
       "         -1.1986e-01, -7.1831e-02, -1.0104e-01,  1.4810e-01, -8.0910e-04,\n",
       "          5.7940e-02,  1.5030e-01, -9.8527e-02,  5.0817e-02, -8.0371e-02,\n",
       "          1.7790e-01, -9.1492e-02, -5.1225e-02, -5.4519e-02,  1.0734e-01,\n",
       "         -2.5098e-02,  2.5098e-02, -3.2046e-02, -4.4523e-02, -3.0365e-02,\n",
       "         -1.4769e-01, -1.8283e-04,  6.1888e-02,  1.0281e-01,  5.5470e-02,\n",
       "         -5.3439e-02,  3.5040e-02,  1.2328e-01, -4.5453e-02,  1.2562e-01,\n",
       "         -2.4312e-02, -6.8864e-02,  1.7604e-04,  3.3417e-02,  1.1739e-01]), 'layers.1.weight': tensor([[ 0.0523,  0.1237, -0.1408, -0.0810,  0.0585, -0.1100, -0.0692, -0.0285,\n",
       "           0.1539, -0.0332,  0.0433, -0.0771,  0.0645,  0.0047, -0.0772,  0.0600,\n",
       "          -0.0985, -0.0128,  0.0246,  0.0687, -0.1108,  0.0432, -0.0735, -0.0675,\n",
       "          -0.0608,  0.1229,  0.0724,  0.1028,  0.1120, -0.0260, -0.1216,  0.1367,\n",
       "           0.0148,  0.0561, -0.0903,  0.1280,  0.1072, -0.0863,  0.1799, -0.0481,\n",
       "          -0.1281,  0.0565,  0.1427, -0.0818,  0.0752,  0.1101, -0.0949, -0.0712,\n",
       "          -0.0795, -0.1051]]), 'layers.1.bias': tensor([-0.0622]), 'skip.weight': tensor([[ 0.0083, -0.0082,  0.0088,  0.0083,  0.0094,  0.0064, -0.0087, -0.0087,\n",
       "           0.0061,  0.0076, -0.0104, -0.0073, -0.0084,  0.0074,  0.0071, -0.0079,\n",
       "           0.0083,  0.0083,  0.0087,  0.0084,  0.0065,  0.0081,  0.0112,  0.0079,\n",
       "          -0.0087,  0.0080, -0.0078,  0.0078, -0.0088,  0.0083,  0.0106, -0.0094,\n",
       "           0.0101, -0.0095,  0.0085, -0.0098, -0.0103, -0.0076, -0.0079, -0.0087,\n",
       "          -0.0065, -0.0069,  0.0111, -0.0074,  0.0095,  0.0086, -0.0113, -0.0081,\n",
       "          -0.0101, -0.0076,  0.0080, -0.0075, -0.0086,  0.0073,  0.0098,  0.0082,\n",
       "          -0.0079, -0.0099, -0.0090,  0.0077,  0.0070,  0.0083, -0.0118,  0.0135,\n",
       "           0.0190, -0.0188,  0.0075]])}, objective=14.36691592694049, loss=0.7358655333518982, val_objective=14.386817560203124, val_loss=0.7557671666145325, regularization=0.5949205160140991, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=23.37063696275497, state_dict={'layers.0.weight': tensor([[-0.0662,  0.0239,  0.0834,  ..., -0.0063,  0.0571,  0.0369],\n",
       "         [-0.0826,  0.0227, -0.0132,  ...,  0.0345, -0.1057, -0.0668],\n",
       "         [-0.0461, -0.0553, -0.0232,  ..., -0.1887, -0.1275, -0.0237],\n",
       "         ...,\n",
       "         [-0.0072, -0.0810, -0.0281,  ..., -0.1660, -0.0575,  0.0380],\n",
       "         [ 0.0826, -0.0225, -0.0869,  ..., -0.0280,  0.0003,  0.0739],\n",
       "         [-0.0454, -0.0246,  0.0869,  ...,  0.0442, -0.0828,  0.0739]]), 'layers.0.bias': tensor([-0.0632,  0.1376,  0.0426,  0.0594,  0.0939,  0.0898,  0.0048, -0.1507,\n",
       "          0.0037, -0.0834,  0.0698,  0.0956,  0.1271,  0.0371, -0.1517, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0008,  0.0579,  0.1503, -0.0985,  0.0508,\n",
       "         -0.0804,  0.1779, -0.0915, -0.0512, -0.0545,  0.1073, -0.0251,  0.0251,\n",
       "         -0.0321, -0.0445, -0.0304, -0.1477, -0.0002,  0.0619,  0.1028,  0.0555,\n",
       "         -0.0535,  0.0350,  0.1233, -0.0455,  0.1256, -0.0243, -0.0688,  0.0002,\n",
       "          0.0334,  0.1174]), 'layers.1.weight': tensor([[ 0.0523,  0.1238, -0.1409, -0.0810,  0.0586, -0.1101, -0.0693, -0.0285,\n",
       "           0.1541, -0.0332,  0.0433, -0.0772,  0.0647,  0.0046, -0.0773,  0.0601,\n",
       "          -0.0987, -0.0128,  0.0247,  0.0687, -0.1109,  0.0432, -0.0735, -0.0676,\n",
       "          -0.0608,  0.1229,  0.0724,  0.1029,  0.1120, -0.0262, -0.1217,  0.1368,\n",
       "           0.0149,  0.0563, -0.0903,  0.1283,  0.1071, -0.0865,  0.1802, -0.0481,\n",
       "          -0.1281,  0.0566,  0.1429, -0.0819,  0.0753,  0.1101, -0.0950, -0.0713,\n",
       "          -0.0796, -0.1053]]), 'layers.1.bias': tensor([-0.0622]), 'skip.weight': tensor([[ 0.0083, -0.0081,  0.0087,  0.0082,  0.0093,  0.0064, -0.0086, -0.0087,\n",
       "           0.0060,  0.0075, -0.0103, -0.0073, -0.0083,  0.0073,  0.0070, -0.0078,\n",
       "           0.0082,  0.0083,  0.0086,  0.0083,  0.0064,  0.0080,  0.0111,  0.0078,\n",
       "          -0.0086,  0.0079, -0.0077,  0.0077, -0.0088,  0.0082,  0.0105, -0.0094,\n",
       "           0.0100, -0.0095,  0.0084, -0.0096, -0.0101, -0.0075, -0.0078, -0.0086,\n",
       "          -0.0064, -0.0069,  0.0110, -0.0073,  0.0095,  0.0086, -0.0112, -0.0081,\n",
       "          -0.0100, -0.0076,  0.0079, -0.0074, -0.0085,  0.0073,  0.0097,  0.0082,\n",
       "          -0.0078, -0.0099, -0.0090,  0.0077,  0.0069,  0.0083, -0.0117,  0.0134,\n",
       "           0.0189, -0.0187,  0.0074]])}, objective=14.5219299015875, loss=0.7359585165977478, val_objective=14.541639488684668, val_loss=0.7556681036949158, regularization=0.5898842811584473, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=23.838049702010068, state_dict={'layers.0.weight': tensor([[-0.0661,  0.0239,  0.0834,  ..., -0.0063,  0.0571,  0.0369],\n",
       "         [-0.0819,  0.0227, -0.0132,  ...,  0.0345, -0.1058, -0.0667],\n",
       "         [-0.0462, -0.0553, -0.0232,  ..., -0.1879, -0.1274, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0802, -0.0281,  ..., -0.1660, -0.0575,  0.0380],\n",
       "         [ 0.0819, -0.0225, -0.0862,  ..., -0.0280,  0.0004,  0.0733],\n",
       "         [-0.0454, -0.0246,  0.0862,  ...,  0.0441, -0.0828,  0.0733]]), 'layers.0.bias': tensor([-0.0632,  0.1376,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0037, -0.0834,  0.0698,  0.0956,  0.1272,  0.0371, -0.1517, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0009,  0.0579,  0.1503, -0.0986,  0.0508,\n",
       "         -0.0804,  0.1778, -0.0916, -0.0513, -0.0544,  0.1073, -0.0251,  0.0251,\n",
       "         -0.0321, -0.0445, -0.0303, -0.1477, -0.0002,  0.0619,  0.1028,  0.0554,\n",
       "         -0.0536,  0.0350,  0.1234, -0.0455,  0.1256, -0.0244, -0.0688,  0.0002,\n",
       "          0.0335,  0.1174]), 'layers.1.weight': tensor([[ 0.0523,  0.1239, -0.1411, -0.0810,  0.0586, -0.1103, -0.0694, -0.0285,\n",
       "           0.1542, -0.0333,  0.0433, -0.0772,  0.0649,  0.0045, -0.0773,  0.0602,\n",
       "          -0.0989, -0.0127,  0.0248,  0.0687, -0.1110,  0.0432, -0.0735, -0.0677,\n",
       "          -0.0609,  0.1229,  0.0725,  0.1029,  0.1121, -0.0263, -0.1218,  0.1369,\n",
       "           0.0150,  0.0564, -0.0903,  0.1286,  0.1070, -0.0867,  0.1805, -0.0481,\n",
       "          -0.1282,  0.0566,  0.1431, -0.0820,  0.0753,  0.1101, -0.0951, -0.0715,\n",
       "          -0.0798, -0.1055]]), 'layers.1.bias': tensor([-0.0621]), 'skip.weight': tensor([[ 0.0082, -0.0080,  0.0086,  0.0082,  0.0092,  0.0063, -0.0085, -0.0086,\n",
       "           0.0060,  0.0075, -0.0103, -0.0072, -0.0083,  0.0072,  0.0069, -0.0077,\n",
       "           0.0081,  0.0082,  0.0085,  0.0082,  0.0064,  0.0079,  0.0110,  0.0078,\n",
       "          -0.0085,  0.0078, -0.0077,  0.0076, -0.0087,  0.0082,  0.0104, -0.0093,\n",
       "           0.0099, -0.0094,  0.0083, -0.0095, -0.0100, -0.0074, -0.0078, -0.0085,\n",
       "          -0.0064, -0.0068,  0.0109, -0.0072,  0.0094,  0.0085, -0.0111, -0.0080,\n",
       "          -0.0099, -0.0075,  0.0078, -0.0074, -0.0084,  0.0072,  0.0097,  0.0081,\n",
       "          -0.0078, -0.0098, -0.0089,  0.0076,  0.0069,  0.0082, -0.0116,  0.0133,\n",
       "           0.0188, -0.0185,  0.0073]])}, objective=14.676852085042748, loss=0.7360550165176392, val_objective=14.696368553090844, val_loss=0.7555714845657349, regularization=0.5848128199577332, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=24.31481069605027, state_dict={'layers.0.weight': tensor([[-0.0661,  0.0239,  0.0835,  ..., -0.0062,  0.0570,  0.0369],\n",
       "         [-0.0813,  0.0227, -0.0132,  ...,  0.0346, -0.1058, -0.0667],\n",
       "         [-0.0462, -0.0553, -0.0232,  ..., -0.1871, -0.1274, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0793, -0.0281,  ..., -0.1660, -0.0575,  0.0380],\n",
       "         [ 0.0813, -0.0225, -0.0855,  ..., -0.0280,  0.0004,  0.0727],\n",
       "         [-0.0455, -0.0246,  0.0855,  ...,  0.0441, -0.0827,  0.0727]]), 'layers.0.bias': tensor([-0.0632,  0.1376,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0037, -0.0834,  0.0698,  0.0956,  0.1272,  0.0371, -0.1517, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0009,  0.0579,  0.1503, -0.0986,  0.0508,\n",
       "         -0.0804,  0.1778, -0.0916, -0.0513, -0.0544,  0.1073, -0.0251,  0.0251,\n",
       "         -0.0321, -0.0445, -0.0303, -0.1476, -0.0002,  0.0619,  0.1028,  0.0554,\n",
       "         -0.0537,  0.0350,  0.1235, -0.0455,  0.1256, -0.0244, -0.0688,  0.0002,\n",
       "          0.0335,  0.1174]), 'layers.1.weight': tensor([[ 0.0523,  0.1240, -0.1413, -0.0809,  0.0587, -0.1104, -0.0695, -0.0286,\n",
       "           0.1544, -0.0333,  0.0433, -0.0773,  0.0650,  0.0045, -0.0774,  0.0603,\n",
       "          -0.0991, -0.0126,  0.0249,  0.0687, -0.1111,  0.0431, -0.0735, -0.0678,\n",
       "          -0.0610,  0.1229,  0.0725,  0.1030,  0.1121, -0.0264, -0.1219,  0.1370,\n",
       "           0.0151,  0.0565, -0.0903,  0.1289,  0.1069, -0.0869,  0.1808, -0.0482,\n",
       "          -0.1282,  0.0567,  0.1433, -0.0821,  0.0754,  0.1102, -0.0952, -0.0717,\n",
       "          -0.0799, -0.1057]]), 'layers.1.bias': tensor([-0.0621]), 'skip.weight': tensor([[ 0.0081, -0.0079,  0.0085,  0.0081,  0.0091,  0.0063, -0.0084, -0.0085,\n",
       "           0.0059,  0.0074, -0.0102, -0.0071, -0.0082,  0.0072,  0.0069, -0.0077,\n",
       "           0.0081,  0.0081,  0.0084,  0.0081,  0.0063,  0.0079,  0.0109,  0.0077,\n",
       "          -0.0084,  0.0078, -0.0076,  0.0075, -0.0086,  0.0081,  0.0103, -0.0092,\n",
       "           0.0097, -0.0093,  0.0082, -0.0095, -0.0099, -0.0074, -0.0077, -0.0084,\n",
       "          -0.0063, -0.0067,  0.0109, -0.0072,  0.0093,  0.0084, -0.0110, -0.0079,\n",
       "          -0.0098, -0.0074,  0.0077, -0.0073, -0.0084,  0.0072,  0.0096,  0.0080,\n",
       "          -0.0077, -0.0097, -0.0088,  0.0075,  0.0068,  0.0082, -0.0115,  0.0132,\n",
       "           0.0187, -0.0184,  0.0073]])}, objective=14.832435258794803, loss=0.736152708530426, val_objective=14.851760693956393, val_loss=0.7554781436920166, regularization=0.579740583896637, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=24.801106909971274, state_dict={'layers.0.weight': tensor([[-0.0661,  0.0239,  0.0835,  ..., -0.0062,  0.0570,  0.0369],\n",
       "         [-0.0806,  0.0227, -0.0132,  ...,  0.0346, -0.1059, -0.0666],\n",
       "         [-0.0462, -0.0553, -0.0232,  ..., -0.1862, -0.1274, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0784, -0.0281,  ..., -0.1661, -0.0575,  0.0380],\n",
       "         [ 0.0806, -0.0225, -0.0847,  ..., -0.0281,  0.0004,  0.0721],\n",
       "         [-0.0455, -0.0246,  0.0847,  ...,  0.0440, -0.0827,  0.0721]]), 'layers.0.bias': tensor([-0.0632,  0.1375,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0698,  0.0956,  0.1272,  0.0371, -0.1518, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0009,  0.0579,  0.1502, -0.0986,  0.0507,\n",
       "         -0.0804,  0.1777, -0.0917, -0.0513, -0.0544,  0.1073, -0.0251,  0.0251,\n",
       "         -0.0321, -0.0445, -0.0303, -0.1476, -0.0002,  0.0619,  0.1028,  0.0554,\n",
       "         -0.0537,  0.0350,  0.1235, -0.0455,  0.1256, -0.0244, -0.0688,  0.0002,\n",
       "          0.0335,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1241, -0.1415, -0.0809,  0.0587, -0.1106, -0.0696, -0.0286,\n",
       "           0.1545, -0.0334,  0.0433, -0.0773,  0.0652,  0.0044, -0.0775,  0.0604,\n",
       "          -0.0993, -0.0125,  0.0250,  0.0687, -0.1112,  0.0431, -0.0734, -0.0679,\n",
       "          -0.0611,  0.1230,  0.0726,  0.1031,  0.1121, -0.0266, -0.1220,  0.1371,\n",
       "           0.0152,  0.0567, -0.0903,  0.1293,  0.1068, -0.0871,  0.1811, -0.0482,\n",
       "          -0.1282,  0.0567,  0.1435, -0.0822,  0.0754,  0.1102, -0.0953, -0.0719,\n",
       "          -0.0800, -0.1060]]), 'layers.1.bias': tensor([-0.0620]), 'skip.weight': tensor([[ 0.0081, -0.0078,  0.0085,  0.0080,  0.0090,  0.0062, -0.0083, -0.0084,\n",
       "           0.0058,  0.0074, -0.0101, -0.0071, -0.0081,  0.0071,  0.0068, -0.0076,\n",
       "           0.0080,  0.0080,  0.0084,  0.0080,  0.0063,  0.0078,  0.0108,  0.0076,\n",
       "          -0.0084,  0.0077, -0.0075,  0.0074, -0.0085,  0.0080,  0.0103, -0.0092,\n",
       "           0.0096, -0.0092,  0.0082, -0.0094, -0.0098, -0.0073, -0.0077, -0.0083,\n",
       "          -0.0062, -0.0067,  0.0108, -0.0071,  0.0092,  0.0083, -0.0110, -0.0079,\n",
       "          -0.0097, -0.0074,  0.0076, -0.0072, -0.0083,  0.0071,  0.0095,  0.0079,\n",
       "          -0.0076, -0.0096, -0.0088,  0.0075,  0.0067,  0.0081, -0.0114,  0.0131,\n",
       "           0.0186, -0.0182,  0.0072]])}, objective=14.98859068380732, loss=0.7362490296363831, val_objective=15.007732894290871, val_loss=0.7553912401199341, regularization=0.5746655464172363, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=25.2971290481707, state_dict={'layers.0.weight': tensor([[-0.0661,  0.0239,  0.0835,  ..., -0.0062,  0.0570,  0.0369],\n",
       "         [-0.0799,  0.0227, -0.0132,  ...,  0.0346, -0.1059, -0.0666],\n",
       "         [-0.0462, -0.0553, -0.0233,  ..., -0.1853, -0.1273, -0.0238],\n",
       "         ...,\n",
       "         [-0.0072, -0.0776, -0.0281,  ..., -0.1661, -0.0575,  0.0380],\n",
       "         [ 0.0799, -0.0225, -0.0840,  ..., -0.0281,  0.0004,  0.0715],\n",
       "         [-0.0455, -0.0245,  0.0840,  ...,  0.0440, -0.0826,  0.0715]]), 'layers.0.bias': tensor([-0.0632,  0.1375,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1272,  0.0371, -0.1518, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0010,  0.0579,  0.1502, -0.0986,  0.0507,\n",
       "         -0.0805,  0.1777, -0.0917, -0.0513, -0.0543,  0.1073, -0.0251,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0303, -0.1476, -0.0003,  0.0619,  0.1028,  0.0554,\n",
       "         -0.0538,  0.0350,  0.1236, -0.0455,  0.1255, -0.0245, -0.0688,  0.0003,\n",
       "          0.0335,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1243, -0.1417, -0.0809,  0.0588, -0.1107, -0.0697, -0.0287,\n",
       "           0.1547, -0.0334,  0.0433, -0.0774,  0.0654,  0.0043, -0.0776,  0.0606,\n",
       "          -0.0995, -0.0125,  0.0251,  0.0687, -0.1113,  0.0431, -0.0734, -0.0680,\n",
       "          -0.0611,  0.1230,  0.0727,  0.1032,  0.1121, -0.0267, -0.1221,  0.1372,\n",
       "           0.0152,  0.0568, -0.0903,  0.1296,  0.1067, -0.0873,  0.1814, -0.0482,\n",
       "          -0.1282,  0.0568,  0.1438, -0.0823,  0.0754,  0.1103, -0.0954, -0.0720,\n",
       "          -0.0801, -0.1062]]), 'layers.1.bias': tensor([-0.0620]), 'skip.weight': tensor([[ 0.0080, -0.0078,  0.0084,  0.0080,  0.0090,  0.0062, -0.0082, -0.0084,\n",
       "           0.0058,  0.0073, -0.0101, -0.0070, -0.0080,  0.0070,  0.0067, -0.0075,\n",
       "           0.0079,  0.0080,  0.0083,  0.0080,  0.0062,  0.0077,  0.0107,  0.0076,\n",
       "          -0.0083,  0.0076, -0.0074,  0.0073, -0.0085,  0.0079,  0.0102, -0.0091,\n",
       "           0.0095, -0.0092,  0.0081, -0.0093, -0.0097, -0.0072, -0.0076, -0.0083,\n",
       "          -0.0062, -0.0066,  0.0107, -0.0070,  0.0091,  0.0083, -0.0109, -0.0078,\n",
       "          -0.0096, -0.0073,  0.0076, -0.0072, -0.0082,  0.0071,  0.0095,  0.0079,\n",
       "          -0.0076, -0.0095, -0.0087,  0.0074,  0.0067,  0.0080, -0.0113,  0.0130,\n",
       "           0.0185, -0.0181,  0.0071]])}, objective=15.145331704935645, loss=0.7363436818122864, val_objective=15.164290094694708, val_loss=0.7553020715713501, regularization=0.5695898532867432, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=25.803071629134113, state_dict={'layers.0.weight': tensor([[-0.0660,  0.0239,  0.0833,  ..., -0.0062,  0.0570,  0.0369],\n",
       "         [-0.0793,  0.0227, -0.0132,  ...,  0.0346, -0.1060, -0.0665],\n",
       "         [-0.0463, -0.0553, -0.0233,  ..., -0.1844, -0.1273, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0768, -0.0281,  ..., -0.1661, -0.0575,  0.0380],\n",
       "         [ 0.0793, -0.0225, -0.0833,  ..., -0.0281,  0.0004,  0.0708],\n",
       "         [-0.0456, -0.0245,  0.0833,  ...,  0.0439, -0.0825,  0.0708]]), 'layers.0.bias': tensor([-0.0632,  0.1375,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1272,  0.0371, -0.1518, -0.1199,\n",
       "         -0.0718, -0.1010,  0.1481, -0.0010,  0.0578,  0.1502, -0.0987,  0.0507,\n",
       "         -0.0805,  0.1776, -0.0918, -0.0513, -0.0543,  0.1073, -0.0251,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0303, -0.1476, -0.0003,  0.0620,  0.1028,  0.0554,\n",
       "         -0.0539,  0.0350,  0.1236, -0.0455,  0.1255, -0.0245, -0.0687,  0.0003,\n",
       "          0.0336,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1244, -0.1419, -0.0809,  0.0589, -0.1109, -0.0698, -0.0287,\n",
       "           0.1548, -0.0335,  0.0433, -0.0774,  0.0656,  0.0042, -0.0777,  0.0607,\n",
       "          -0.0997, -0.0124,  0.0252,  0.0688, -0.1114,  0.0430, -0.0734, -0.0681,\n",
       "          -0.0612,  0.1230,  0.0728,  0.1033,  0.1121, -0.0268, -0.1222,  0.1373,\n",
       "           0.0153,  0.0570, -0.0903,  0.1299,  0.1066, -0.0875,  0.1817, -0.0482,\n",
       "          -0.1282,  0.0568,  0.1440, -0.0824,  0.0755,  0.1103, -0.0954, -0.0722,\n",
       "          -0.0803, -0.1064]]), 'layers.1.bias': tensor([-0.0619]), 'skip.weight': tensor([[ 0.0079, -0.0077,  0.0083,  0.0079,  0.0089,  0.0061, -0.0081, -0.0083,\n",
       "           0.0057,  0.0072, -0.0100, -0.0070, -0.0079,  0.0069,  0.0066, -0.0074,\n",
       "           0.0079,  0.0079,  0.0082,  0.0079,  0.0062,  0.0076,  0.0107,  0.0075,\n",
       "          -0.0082,  0.0075, -0.0074,  0.0073, -0.0084,  0.0079,  0.0101, -0.0090,\n",
       "           0.0094, -0.0091,  0.0080, -0.0092, -0.0096, -0.0071, -0.0076, -0.0082,\n",
       "          -0.0061, -0.0066,  0.0106, -0.0069,  0.0091,  0.0082, -0.0108, -0.0077,\n",
       "          -0.0095, -0.0072,  0.0075, -0.0071, -0.0082,  0.0070,  0.0094,  0.0078,\n",
       "          -0.0075, -0.0094, -0.0086,  0.0073,  0.0066,  0.0080, -0.0112,  0.0129,\n",
       "           0.0184, -0.0179,  0.0071]])}, objective=15.302272677109382, loss=0.7364394068717957, val_objective=15.32104438512101, val_loss=0.7552111148834229, regularization=0.5644999742507935, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=26.319133061716794, state_dict={'layers.0.weight': tensor([[-0.0660,  0.0239,  0.0826,  ..., -0.0062,  0.0569,  0.0369],\n",
       "         [-0.0786,  0.0227, -0.0131,  ...,  0.0347, -0.1061, -0.0664],\n",
       "         [-0.0463, -0.0553, -0.0233,  ..., -0.1835, -0.1272, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0761, -0.0282,  ..., -0.1661, -0.0574,  0.0380],\n",
       "         [ 0.0786, -0.0225, -0.0826,  ..., -0.0281,  0.0004,  0.0702],\n",
       "         [-0.0456, -0.0245,  0.0826,  ...,  0.0439, -0.0825,  0.0702]]), 'layers.0.bias': tensor([-0.0632,  0.1374,  0.0427,  0.0594,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1272,  0.0371, -0.1518, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0010,  0.0578,  0.1502, -0.0987,  0.0507,\n",
       "         -0.0805,  0.1776, -0.0918, -0.0513, -0.0543,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0303, -0.1476, -0.0003,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0539,  0.0350,  0.1237, -0.0455,  0.1255, -0.0245, -0.0687,  0.0003,\n",
       "          0.0336,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1245, -0.1420, -0.0809,  0.0589, -0.1110, -0.0699, -0.0288,\n",
       "           0.1550, -0.0335,  0.0433, -0.0775,  0.0657,  0.0041, -0.0777,  0.0608,\n",
       "          -0.0999, -0.0123,  0.0253,  0.0688, -0.1115,  0.0430, -0.0734, -0.0682,\n",
       "          -0.0613,  0.1230,  0.0728,  0.1034,  0.1122, -0.0270, -0.1224,  0.1374,\n",
       "           0.0154,  0.0571, -0.0902,  0.1302,  0.1065, -0.0877,  0.1820, -0.0482,\n",
       "          -0.1282,  0.0569,  0.1442, -0.0825,  0.0755,  0.1104, -0.0955, -0.0724,\n",
       "          -0.0804, -0.1067]]), 'layers.1.bias': tensor([-0.0618]), 'skip.weight': tensor([[ 0.0079, -0.0076,  0.0083,  0.0079,  0.0088,  0.0061, -0.0080, -0.0082,\n",
       "           0.0057,  0.0072, -0.0099, -0.0069, -0.0078,  0.0068,  0.0065, -0.0074,\n",
       "           0.0078,  0.0078,  0.0081,  0.0078,  0.0061,  0.0076,  0.0106,  0.0074,\n",
       "          -0.0081,  0.0075, -0.0073,  0.0072, -0.0083,  0.0078,  0.0100, -0.0090,\n",
       "           0.0093, -0.0090,  0.0079, -0.0091, -0.0095, -0.0070, -0.0075, -0.0081,\n",
       "          -0.0061, -0.0065,  0.0105, -0.0068,  0.0090,  0.0081, -0.0107, -0.0077,\n",
       "          -0.0094, -0.0072,  0.0074, -0.0071, -0.0081,  0.0070,  0.0093,  0.0077,\n",
       "          -0.0074, -0.0093, -0.0085,  0.0072,  0.0066,  0.0079, -0.0111,  0.0128,\n",
       "           0.0184, -0.0178,  0.0070]])}, objective=15.459137175795682, loss=0.736538290977478, val_objective=15.477717314479001, val_loss=0.7551184296607971, regularization=0.5593876838684082, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=26.84551572295113, state_dict={'layers.0.weight': tensor([[-0.0660,  0.0239,  0.0818,  ..., -0.0061,  0.0569,  0.0369],\n",
       "         [-0.0779,  0.0227, -0.0131,  ...,  0.0347, -0.1061, -0.0664],\n",
       "         [-0.0463, -0.0553, -0.0233,  ..., -0.1826, -0.1272, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0753, -0.0282,  ..., -0.1661, -0.0574,  0.0380],\n",
       "         [ 0.0779, -0.0224, -0.0818,  ..., -0.0281,  0.0004,  0.0695],\n",
       "         [-0.0456, -0.0245,  0.0818,  ...,  0.0439, -0.0824,  0.0695]]), 'layers.0.bias': tensor([-0.0632,  0.1374,  0.0427,  0.0593,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1272,  0.0371, -0.1519, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0011,  0.0578,  0.1502, -0.0987,  0.0506,\n",
       "         -0.0805,  0.1775, -0.0919, -0.0513, -0.0542,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0303, -0.1475, -0.0003,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0540,  0.0350,  0.1238, -0.0455,  0.1255, -0.0246, -0.0687,  0.0003,\n",
       "          0.0336,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1246, -0.1422, -0.0809,  0.0590, -0.1112, -0.0700, -0.0288,\n",
       "           0.1551, -0.0336,  0.0432, -0.0775,  0.0659,  0.0040, -0.0778,  0.0609,\n",
       "          -0.1001, -0.0123,  0.0254,  0.0689, -0.1116,  0.0429, -0.0734, -0.0682,\n",
       "          -0.0613,  0.1230,  0.0729,  0.1035,  0.1122, -0.0271, -0.1225,  0.1374,\n",
       "           0.0155,  0.0573, -0.0902,  0.1306,  0.1064, -0.0879,  0.1824, -0.0482,\n",
       "          -0.1282,  0.0570,  0.1444, -0.0826,  0.0755,  0.1105, -0.0956, -0.0726,\n",
       "          -0.0805, -0.1069]]), 'layers.1.bias': tensor([-0.0618]), 'skip.weight': tensor([[ 0.0078, -0.0075,  0.0082,  0.0078,  0.0087,  0.0060, -0.0079, -0.0081,\n",
       "           0.0056,  0.0071, -0.0098, -0.0068, -0.0077,  0.0067,  0.0065, -0.0073,\n",
       "           0.0077,  0.0078,  0.0081,  0.0077,  0.0061,  0.0075,  0.0105,  0.0074,\n",
       "          -0.0080,  0.0074, -0.0072,  0.0071, -0.0082,  0.0077,  0.0100, -0.0089,\n",
       "           0.0092, -0.0089,  0.0079, -0.0090, -0.0094, -0.0069, -0.0074, -0.0080,\n",
       "          -0.0060, -0.0065,  0.0104, -0.0067,  0.0089,  0.0081, -0.0106, -0.0076,\n",
       "          -0.0093, -0.0071,  0.0073, -0.0070, -0.0080,  0.0069,  0.0092,  0.0076,\n",
       "          -0.0074, -0.0093, -0.0085,  0.0071,  0.0065,  0.0079, -0.0110,  0.0127,\n",
       "           0.0183, -0.0176,  0.0070]])}, objective=15.616144089212915, loss=0.7366393208503723, val_objective=15.63452359866192, val_loss=0.7550188302993774, regularization=0.5542640686035156, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=27.382426037410156, state_dict={'layers.0.weight': tensor([[-0.0660,  0.0239,  0.0811,  ..., -0.0061,  0.0569,  0.0369],\n",
       "         [-0.0773,  0.0227, -0.0131,  ...,  0.0347, -0.1062, -0.0663],\n",
       "         [-0.0463, -0.0553, -0.0233,  ..., -0.1818, -0.1272, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0746, -0.0282,  ..., -0.1661, -0.0574,  0.0380],\n",
       "         [ 0.0773, -0.0224, -0.0811,  ..., -0.0281,  0.0005,  0.0688],\n",
       "         [-0.0457, -0.0245,  0.0811,  ...,  0.0438, -0.0824,  0.0688]]), 'layers.0.bias': tensor([-0.0632,  0.1374,  0.0427,  0.0593,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1272,  0.0371, -0.1519, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0011,  0.0578,  0.1502, -0.0987,  0.0506,\n",
       "         -0.0805,  0.1775, -0.0919, -0.0513, -0.0542,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0302, -0.1475, -0.0003,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0541,  0.0350,  0.1238, -0.0455,  0.1255, -0.0246, -0.0687,  0.0003,\n",
       "          0.0336,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1247, -0.1424, -0.0809,  0.0590, -0.1113, -0.0701, -0.0289,\n",
       "           0.1553, -0.0336,  0.0432, -0.0776,  0.0661,  0.0039, -0.0779,  0.0610,\n",
       "          -0.1003, -0.0122,  0.0255,  0.0689, -0.1117,  0.0429, -0.0734, -0.0683,\n",
       "          -0.0614,  0.1230,  0.0730,  0.1035,  0.1122, -0.0272, -0.1226,  0.1375,\n",
       "           0.0156,  0.0574, -0.0902,  0.1309,  0.1063, -0.0880,  0.1827, -0.0482,\n",
       "          -0.1282,  0.0570,  0.1446, -0.0827,  0.0756,  0.1105, -0.0957, -0.0727,\n",
       "          -0.0807, -0.1072]]), 'layers.1.bias': tensor([-0.0617]), 'skip.weight': tensor([[ 0.0077, -0.0075,  0.0081,  0.0077,  0.0086,  0.0060, -0.0078, -0.0081,\n",
       "           0.0055,  0.0071, -0.0098, -0.0068, -0.0077,  0.0067,  0.0064, -0.0072,\n",
       "           0.0077,  0.0077,  0.0080,  0.0076,  0.0060,  0.0074,  0.0104,  0.0073,\n",
       "          -0.0080,  0.0073, -0.0072,  0.0070, -0.0082,  0.0076,  0.0099, -0.0088,\n",
       "           0.0090, -0.0089,  0.0078, -0.0089, -0.0093, -0.0069, -0.0074, -0.0079,\n",
       "          -0.0060, -0.0064,  0.0104, -0.0067,  0.0088,  0.0080, -0.0105, -0.0075,\n",
       "          -0.0092, -0.0070,  0.0073, -0.0069, -0.0080,  0.0069,  0.0092,  0.0076,\n",
       "          -0.0073, -0.0092, -0.0084,  0.0071,  0.0064,  0.0078, -0.0109,  0.0126,\n",
       "           0.0182, -0.0175,  0.0069]])}, objective=15.77246617095333, loss=0.7367422580718994, val_objective=15.790654111074026, val_loss=0.7549301981925964, regularization=0.5491012334823608, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=27.93007455815836, state_dict={'layers.0.weight': tensor([[-0.0660,  0.0239,  0.0803,  ..., -0.0061,  0.0569,  0.0369],\n",
       "         [-0.0766,  0.0228, -0.0131,  ...,  0.0347, -0.1062, -0.0662],\n",
       "         [-0.0463, -0.0553, -0.0234,  ..., -0.1808, -0.1271, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0740, -0.0282,  ..., -0.1662, -0.0574,  0.0380],\n",
       "         [ 0.0766, -0.0224, -0.0803,  ..., -0.0282,  0.0005,  0.0681],\n",
       "         [-0.0457, -0.0244,  0.0803,  ...,  0.0438, -0.0823,  0.0681]]), 'layers.0.bias': tensor([-0.0631,  0.1374,  0.0427,  0.0593,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1273,  0.0371, -0.1519, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0011,  0.0577,  0.1501, -0.0987,  0.0506,\n",
       "         -0.0806,  0.1774, -0.0920, -0.0513, -0.0542,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0302, -0.1475, -0.0004,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0542,  0.0350,  0.1239, -0.0455,  0.1254, -0.0246, -0.0686,  0.0003,\n",
       "          0.0337,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1249, -0.1426, -0.0809,  0.0591, -0.1115, -0.0703, -0.0289,\n",
       "           0.1554, -0.0337,  0.0432, -0.0776,  0.0663,  0.0038, -0.0780,  0.0611,\n",
       "          -0.1005, -0.0122,  0.0256,  0.0690, -0.1118,  0.0429, -0.0734, -0.0684,\n",
       "          -0.0615,  0.1230,  0.0731,  0.1036,  0.1122, -0.0274, -0.1227,  0.1376,\n",
       "           0.0157,  0.0576, -0.0902,  0.1312,  0.1062, -0.0882,  0.1830, -0.0482,\n",
       "          -0.1282,  0.0571,  0.1448, -0.0828,  0.0756,  0.1106, -0.0958, -0.0729,\n",
       "          -0.0808, -0.1074]]), 'layers.1.bias': tensor([-0.0617]), 'skip.weight': tensor([[ 0.0077, -0.0074,  0.0080,  0.0077,  0.0086,  0.0059, -0.0077, -0.0080,\n",
       "           0.0055,  0.0070, -0.0097, -0.0067, -0.0076,  0.0066,  0.0063, -0.0072,\n",
       "           0.0076,  0.0076,  0.0079,  0.0075,  0.0059,  0.0073,  0.0103,  0.0072,\n",
       "          -0.0079,  0.0072, -0.0071,  0.0069, -0.0081,  0.0076,  0.0098, -0.0088,\n",
       "           0.0089, -0.0088,  0.0077, -0.0088, -0.0092, -0.0068, -0.0073, -0.0079,\n",
       "          -0.0059, -0.0063,  0.0103, -0.0066,  0.0087,  0.0079, -0.0104, -0.0074,\n",
       "          -0.0092, -0.0069,  0.0072, -0.0069, -0.0079,  0.0068,  0.0091,  0.0075,\n",
       "          -0.0072, -0.0091, -0.0083,  0.0070,  0.0064,  0.0077, -0.0108,  0.0125,\n",
       "           0.0181, -0.0173,  0.0068]])}, objective=15.92776090451068, loss=0.7368476986885071, val_objective=15.945754891117279, val_loss=0.754841685295105, regularization=0.5438908934593201, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=28.488676049321526, state_dict={'layers.0.weight': tensor([[-0.0659,  0.0239,  0.0795,  ..., -0.0061,  0.0569,  0.0369],\n",
       "         [-0.0759,  0.0228, -0.0131,  ...,  0.0348, -0.1063, -0.0662],\n",
       "         [-0.0464, -0.0553, -0.0234,  ..., -0.1799, -0.1271, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0733, -0.0282,  ..., -0.1662, -0.0574,  0.0380],\n",
       "         [ 0.0759, -0.0224, -0.0795,  ..., -0.0282,  0.0005,  0.0674],\n",
       "         [-0.0458, -0.0244,  0.0795,  ...,  0.0437, -0.0823,  0.0674]]), 'layers.0.bias': tensor([-0.0631,  0.1373,  0.0427,  0.0593,  0.0939,  0.0898,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1273,  0.0371, -0.1519, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0012,  0.0577,  0.1501, -0.0988,  0.0505,\n",
       "         -0.0806,  0.1774, -0.0920, -0.0514, -0.0541,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0444, -0.0302, -0.1475, -0.0004,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0542,  0.0350,  0.1239, -0.0455,  0.1254, -0.0246, -0.0686,  0.0003,\n",
       "          0.0337,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1250, -0.1428, -0.0809,  0.0592, -0.1116, -0.0704, -0.0290,\n",
       "           0.1556, -0.0337,  0.0432, -0.0777,  0.0665,  0.0036, -0.0780,  0.0612,\n",
       "          -0.1007, -0.0121,  0.0257,  0.0691, -0.1118,  0.0428, -0.0734, -0.0685,\n",
       "          -0.0616,  0.1230,  0.0731,  0.1037,  0.1122, -0.0275, -0.1229,  0.1377,\n",
       "           0.0158,  0.0577, -0.0902,  0.1315,  0.1061, -0.0884,  0.1834, -0.0482,\n",
       "          -0.1282,  0.0571,  0.1450, -0.0829,  0.0757,  0.1107, -0.0959, -0.0731,\n",
       "          -0.0809, -0.1077]]), 'layers.1.bias': tensor([-0.0616]), 'skip.weight': tensor([[ 0.0076, -0.0073,  0.0080,  0.0076,  0.0085,  0.0059, -0.0076, -0.0079,\n",
       "           0.0054,  0.0069, -0.0096, -0.0066, -0.0075,  0.0065,  0.0062, -0.0071,\n",
       "           0.0075,  0.0075,  0.0078,  0.0075,  0.0059,  0.0072,  0.0102,  0.0071,\n",
       "          -0.0078,  0.0072, -0.0070,  0.0069, -0.0080,  0.0075,  0.0097, -0.0087,\n",
       "           0.0088, -0.0087,  0.0077, -0.0088, -0.0091, -0.0067, -0.0073, -0.0078,\n",
       "          -0.0058, -0.0063,  0.0102, -0.0065,  0.0087,  0.0078, -0.0103, -0.0074,\n",
       "          -0.0091, -0.0069,  0.0071, -0.0068, -0.0078,  0.0067,  0.0090,  0.0074,\n",
       "          -0.0072, -0.0090, -0.0082,  0.0069,  0.0063,  0.0077, -0.0107,  0.0124,\n",
       "           0.0180, -0.0172,  0.0067]])}, objective=16.082424680295112, loss=0.7369609475135803, val_objective=16.10021446138871, val_loss=0.754750728607176, regularization=0.5386513471603394, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=29.058449570307957, state_dict={'layers.0.weight': tensor([[-0.0659,  0.0239,  0.0787,  ..., -0.0061,  0.0568,  0.0369],\n",
       "         [-0.0752,  0.0228, -0.0130,  ...,  0.0348, -0.1063, -0.0661],\n",
       "         [-0.0464, -0.0553, -0.0234,  ..., -0.1790, -0.1270, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0725, -0.0282,  ..., -0.1662, -0.0574,  0.0380],\n",
       "         [ 0.0752, -0.0223, -0.0787,  ..., -0.0282,  0.0005,  0.0667],\n",
       "         [-0.0458, -0.0244,  0.0787,  ...,  0.0437, -0.0822,  0.0667]]), 'layers.0.bias': tensor([-0.0631,  0.1373,  0.0427,  0.0593,  0.0939,  0.0897,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0699,  0.0956,  0.1273,  0.0371, -0.1519, -0.1199,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0012,  0.0577,  0.1501, -0.0988,  0.0505,\n",
       "         -0.0806,  0.1773, -0.0920, -0.0514, -0.0541,  0.1073, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0443, -0.0302, -0.1474, -0.0004,  0.0620,  0.1028,  0.0553,\n",
       "         -0.0543,  0.0350,  0.1240, -0.0455,  0.1254, -0.0247, -0.0686,  0.0004,\n",
       "          0.0337,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1251, -0.1430, -0.0809,  0.0592, -0.1118, -0.0705, -0.0290,\n",
       "           0.1557, -0.0338,  0.0433, -0.0777,  0.0667,  0.0035, -0.0781,  0.0613,\n",
       "          -0.1009, -0.0121,  0.0258,  0.0691, -0.1119,  0.0428, -0.0734, -0.0686,\n",
       "          -0.0616,  0.1230,  0.0732,  0.1038,  0.1122, -0.0276, -0.1230,  0.1377,\n",
       "           0.0159,  0.0578, -0.0902,  0.1318,  0.1060, -0.0886,  0.1837, -0.0482,\n",
       "          -0.1282,  0.0572,  0.1452, -0.0830,  0.0757,  0.1108, -0.0959, -0.0732,\n",
       "          -0.0810, -0.1079]]), 'layers.1.bias': tensor([-0.0615]), 'skip.weight': tensor([[ 0.0075, -0.0073,  0.0079,  0.0075,  0.0084,  0.0058, -0.0075, -0.0078,\n",
       "           0.0053,  0.0069, -0.0095, -0.0066, -0.0074,  0.0064,  0.0061, -0.0070,\n",
       "           0.0074,  0.0075,  0.0078,  0.0074,  0.0058,  0.0072,  0.0101,  0.0071,\n",
       "          -0.0077,  0.0071, -0.0069,  0.0068, -0.0079,  0.0074,  0.0097, -0.0086,\n",
       "           0.0087, -0.0086,  0.0076, -0.0087, -0.0090, -0.0066, -0.0072, -0.0077,\n",
       "          -0.0058, -0.0062,  0.0101, -0.0064,  0.0086,  0.0078, -0.0102, -0.0073,\n",
       "          -0.0090, -0.0068,  0.0070, -0.0067, -0.0077,  0.0067,  0.0089,  0.0073,\n",
       "          -0.0071, -0.0089, -0.0082,  0.0068,  0.0063,  0.0076, -0.0106,  0.0123,\n",
       "           0.0179, -0.0170,  0.0067]])}, objective=16.23565200885527, loss=0.7370787858963013, val_objective=16.253235855901167, val_loss=0.7546626329422015, regularization=0.5333585739135742, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=29.639618561714116, state_dict={'layers.0.weight': tensor([[-0.0659,  0.0238,  0.0779,  ..., -0.0061,  0.0568,  0.0369],\n",
       "         [-0.0745,  0.0228, -0.0130,  ...,  0.0348, -0.1064, -0.0660],\n",
       "         [-0.0464, -0.0553, -0.0234,  ..., -0.1781, -0.1270, -0.0238],\n",
       "         ...,\n",
       "         [-0.0073, -0.0719, -0.0282,  ..., -0.1662, -0.0574,  0.0380],\n",
       "         [ 0.0745, -0.0223, -0.0779,  ..., -0.0282,  0.0005,  0.0660],\n",
       "         [-0.0458, -0.0244,  0.0779,  ...,  0.0436, -0.0822,  0.0660]]), 'layers.0.bias': tensor([-0.0631,  0.1373,  0.0428,  0.0593,  0.0939,  0.0897,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0700,  0.0956,  0.1273,  0.0371, -0.1520, -0.1200,\n",
       "         -0.0718, -0.1011,  0.1481, -0.0012,  0.0576,  0.1501, -0.0988,  0.0505,\n",
       "         -0.0806,  0.1773, -0.0921, -0.0514, -0.0541,  0.1072, -0.0250,  0.0252,\n",
       "         -0.0321, -0.0443, -0.0302, -0.1474, -0.0004,  0.0620,  0.1029,  0.0552,\n",
       "         -0.0544,  0.0350,  0.1241, -0.0455,  0.1254, -0.0247, -0.0686,  0.0004,\n",
       "          0.0337,  0.1174]), 'layers.1.weight': tensor([[ 0.0524,  0.1252, -0.1431, -0.0809,  0.0593, -0.1120, -0.0706, -0.0291,\n",
       "           0.1559, -0.0338,  0.0433, -0.0778,  0.0668,  0.0034, -0.0782,  0.0614,\n",
       "          -0.1011, -0.0120,  0.0259,  0.0692, -0.1120,  0.0427, -0.0734, -0.0687,\n",
       "          -0.0617,  0.1231,  0.0733,  0.1039,  0.1122, -0.0277, -0.1231,  0.1378,\n",
       "           0.0160,  0.0580, -0.0902,  0.1321,  0.1059, -0.0888,  0.1840, -0.0482,\n",
       "          -0.1282,  0.0572,  0.1454, -0.0831,  0.0757,  0.1108, -0.0960, -0.0734,\n",
       "          -0.0812, -0.1082]]), 'layers.1.bias': tensor([-0.0615]), 'skip.weight': tensor([[ 0.0074, -0.0072,  0.0078,  0.0075,  0.0083,  0.0058, -0.0074, -0.0078,\n",
       "           0.0053,  0.0068, -0.0094, -0.0065, -0.0073,  0.0063,  0.0060, -0.0069,\n",
       "           0.0074,  0.0074,  0.0077,  0.0073,  0.0058,  0.0071,  0.0100,  0.0070,\n",
       "          -0.0076,  0.0070, -0.0069,  0.0067, -0.0079,  0.0073,  0.0096, -0.0086,\n",
       "           0.0086, -0.0086,  0.0075, -0.0086, -0.0089, -0.0065, -0.0071, -0.0076,\n",
       "          -0.0057, -0.0062,  0.0100, -0.0063,  0.0085,  0.0077, -0.0102, -0.0072,\n",
       "          -0.0089, -0.0067,  0.0069, -0.0067, -0.0077,  0.0066,  0.0089,  0.0072,\n",
       "          -0.0070, -0.0088, -0.0081,  0.0067,  0.0062,  0.0075, -0.0105,  0.0122,\n",
       "           0.0178, -0.0168,  0.0066]])}, objective=16.387966800448723, loss=0.7371988892555237, val_objective=16.405349243399925, val_loss=0.7545813322067261, regularization=0.5280354022979736, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=30.232410932948397, state_dict={'layers.0.weight': tensor([[-0.0659,  0.0238,  0.0771,  ..., -0.0060,  0.0568,  0.0369],\n",
       "         [-0.0738,  0.0228, -0.0130,  ...,  0.0349, -0.1065, -0.0654],\n",
       "         [-0.0464, -0.0553, -0.0235,  ..., -0.1772, -0.1270, -0.0238],\n",
       "         ...,\n",
       "         [-0.0074, -0.0712, -0.0283,  ..., -0.1662, -0.0573,  0.0380],\n",
       "         [ 0.0738, -0.0223, -0.0771,  ..., -0.0283,  0.0005,  0.0654],\n",
       "         [-0.0459, -0.0244,  0.0771,  ...,  0.0436, -0.0821,  0.0654]]), 'layers.0.bias': tensor([-0.0631,  0.1372,  0.0428,  0.0593,  0.0939,  0.0897,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0700,  0.0956,  0.1273,  0.0371, -0.1520, -0.1200,\n",
       "         -0.0717, -0.1011,  0.1481, -0.0013,  0.0576,  0.1501, -0.0988,  0.0505,\n",
       "         -0.0806,  0.1772, -0.0921, -0.0514, -0.0540,  0.1072, -0.0250,  0.0253,\n",
       "         -0.0321, -0.0443, -0.0302, -0.1474, -0.0004,  0.0620,  0.1029,  0.0552,\n",
       "         -0.0544,  0.0350,  0.1241, -0.0455,  0.1253, -0.0247, -0.0685,  0.0004,\n",
       "          0.0337,  0.1175]), 'layers.1.weight': tensor([[ 0.0524,  0.1253, -0.1433, -0.0809,  0.0594, -0.1121, -0.0707, -0.0292,\n",
       "           0.1560, -0.0339,  0.0433, -0.0778,  0.0670,  0.0033, -0.0783,  0.0615,\n",
       "          -0.1013, -0.0120,  0.0260,  0.0693, -0.1120,  0.0427, -0.0734, -0.0688,\n",
       "          -0.0618,  0.1231,  0.0734,  0.1040,  0.1123, -0.0279, -0.1233,  0.1379,\n",
       "           0.0161,  0.0581, -0.0902,  0.1325,  0.1058, -0.0889,  0.1844, -0.0482,\n",
       "          -0.1282,  0.0573,  0.1456, -0.0832,  0.0758,  0.1109, -0.0961, -0.0736,\n",
       "          -0.0813, -0.1085]]), 'layers.1.bias': tensor([-0.0614]), 'skip.weight': tensor([[ 0.0074, -0.0071,  0.0077,  0.0074,  0.0082,  0.0057, -0.0073, -0.0077,\n",
       "           0.0052,  0.0068, -0.0094, -0.0064, -0.0072,  0.0063,  0.0060, -0.0069,\n",
       "           0.0073,  0.0073,  0.0076,  0.0072,  0.0057,  0.0070,  0.0099,  0.0069,\n",
       "          -0.0075,  0.0070, -0.0068,  0.0066, -0.0078,  0.0072,  0.0095, -0.0085,\n",
       "           0.0085, -0.0085,  0.0074, -0.0085, -0.0088, -0.0064, -0.0071, -0.0075,\n",
       "          -0.0057, -0.0061,  0.0100, -0.0062,  0.0084,  0.0076, -0.0101, -0.0072,\n",
       "          -0.0088, -0.0066,  0.0069, -0.0066, -0.0076,  0.0066,  0.0088,  0.0072,\n",
       "          -0.0070, -0.0087, -0.0080,  0.0067,  0.0061,  0.0075, -0.0104,  0.0121,\n",
       "           0.0177, -0.0167,  0.0065]])}, objective=16.538909124143217, loss=0.7373231649398804, val_objective=16.55609338165054, val_loss=0.7545074224472028, regularization=0.5226703882217407, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=30.837059151607367, state_dict={'layers.0.weight': tensor([[-0.0658,  0.0238,  0.0762,  ..., -0.0060,  0.0568,  0.0370],\n",
       "         [-0.0731,  0.0228, -0.0130,  ...,  0.0349, -0.1065, -0.0647],\n",
       "         [-0.0465, -0.0553, -0.0235,  ..., -0.1763, -0.1269, -0.0238],\n",
       "         ...,\n",
       "         [-0.0074, -0.0704, -0.0283,  ..., -0.1663, -0.0573,  0.0380],\n",
       "         [ 0.0731, -0.0223, -0.0762,  ..., -0.0283,  0.0006,  0.0647],\n",
       "         [-0.0459, -0.0244,  0.0762,  ...,  0.0435, -0.0820,  0.0647]]), 'layers.0.bias': tensor([-0.0631,  0.1372,  0.0428,  0.0592,  0.0939,  0.0897,  0.0048, -0.1508,\n",
       "          0.0036, -0.0834,  0.0700,  0.0956,  0.1273,  0.0371, -0.1520, -0.1200,\n",
       "         -0.0717, -0.1011,  0.1481, -0.0013,  0.0576,  0.1501, -0.0989,  0.0504,\n",
       "         -0.0807,  0.1772, -0.0922, -0.0514, -0.0540,  0.1072, -0.0249,  0.0253,\n",
       "         -0.0321, -0.0443, -0.0302, -0.1474, -0.0005,  0.0620,  0.1029,  0.0552,\n",
       "         -0.0545,  0.0350,  0.1242, -0.0455,  0.1253, -0.0247, -0.0685,  0.0004,\n",
       "          0.0338,  0.1175]), 'layers.1.weight': tensor([[ 0.0524,  0.1255, -0.1435, -0.0809,  0.0594, -0.1123, -0.0709, -0.0292,\n",
       "           0.1562, -0.0340,  0.0433, -0.0778,  0.0672,  0.0032, -0.0783,  0.0616,\n",
       "          -0.1015, -0.0120,  0.0260,  0.0694, -0.1121,  0.0426, -0.0734, -0.0689,\n",
       "          -0.0619,  0.1231,  0.0735,  0.1041,  0.1123, -0.0280, -0.1234,  0.1379,\n",
       "           0.0162,  0.0583, -0.0903,  0.1328,  0.1057, -0.0891,  0.1847, -0.0482,\n",
       "          -0.1282,  0.0574,  0.1458, -0.0832,  0.0758,  0.1110, -0.0962, -0.0738,\n",
       "          -0.0814, -0.1087]]), 'layers.1.bias': tensor([-0.0614]), 'skip.weight': tensor([[ 0.0073, -0.0070,  0.0076,  0.0073,  0.0081,  0.0056, -0.0072, -0.0076,\n",
       "           0.0051,  0.0067, -0.0093, -0.0064, -0.0072,  0.0062,  0.0059, -0.0068,\n",
       "           0.0072,  0.0072,  0.0075,  0.0071,  0.0057,  0.0069,  0.0098,  0.0069,\n",
       "          -0.0074,  0.0069, -0.0067,  0.0065, -0.0077,  0.0072,  0.0094, -0.0084,\n",
       "           0.0084, -0.0084,  0.0074, -0.0084, -0.0087, -0.0064, -0.0070, -0.0074,\n",
       "          -0.0056, -0.0060,  0.0099, -0.0061,  0.0083,  0.0075, -0.0100, -0.0071,\n",
       "          -0.0087, -0.0065,  0.0068, -0.0066, -0.0075,  0.0065,  0.0087,  0.0071,\n",
       "          -0.0069, -0.0086, -0.0079,  0.0066,  0.0061,  0.0074, -0.0103,  0.0119,\n",
       "           0.0176, -0.0165,  0.0065]])}, objective=16.688805888480317, loss=0.7374492287635803, val_objective=16.705795477217805, val_loss=0.7544388175010663, regularization=0.517278790473938, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=31.453800334639514, state_dict={'layers.0.weight': tensor([[-0.0658,  0.0238,  0.0754,  ..., -0.0060,  0.0568,  0.0370],\n",
       "         [-0.0724,  0.0228, -0.0130,  ...,  0.0349, -0.1066, -0.0640],\n",
       "         [-0.0465, -0.0553, -0.0235,  ..., -0.1754, -0.1269, -0.0239],\n",
       "         ...,\n",
       "         [-0.0074, -0.0697, -0.0283,  ..., -0.1663, -0.0573,  0.0380],\n",
       "         [ 0.0724, -0.0222, -0.0754,  ..., -0.0283,  0.0006,  0.0640],\n",
       "         [-0.0460, -0.0244,  0.0754,  ...,  0.0435, -0.0820,  0.0640]]), 'layers.0.bias': tensor([-0.0631,  0.1372,  0.0428,  0.0592,  0.0939,  0.0897,  0.0049, -0.1508,\n",
       "          0.0035, -0.0834,  0.0700,  0.0956,  0.1273,  0.0371, -0.1520, -0.1200,\n",
       "         -0.0717, -0.1011,  0.1481, -0.0013,  0.0575,  0.1501, -0.0989,  0.0504,\n",
       "         -0.0807,  0.1771, -0.0922, -0.0514, -0.0540,  0.1072, -0.0249,  0.0253,\n",
       "         -0.0321, -0.0443, -0.0302, -0.1473, -0.0005,  0.0621,  0.1030,  0.0552,\n",
       "         -0.0546,  0.0350,  0.1242, -0.0455,  0.1253, -0.0247, -0.0685,  0.0004,\n",
       "          0.0338,  0.1175]), 'layers.1.weight': tensor([[ 0.0524,  0.1256, -0.1437, -0.0809,  0.0595, -0.1125, -0.0710, -0.0293,\n",
       "           0.1563, -0.0340,  0.0433, -0.0779,  0.0674,  0.0031, -0.0784,  0.0617,\n",
       "          -0.1017, -0.0119,  0.0261,  0.0694, -0.1122,  0.0425, -0.0734, -0.0690,\n",
       "          -0.0619,  0.1231,  0.0736,  0.1042,  0.1123, -0.0281, -0.1236,  0.1380,\n",
       "           0.0163,  0.0585, -0.0903,  0.1331,  0.1056, -0.0893,  0.1851, -0.0482,\n",
       "          -0.1282,  0.0574,  0.1459, -0.0833,  0.0758,  0.1111, -0.0963, -0.0739,\n",
       "          -0.0816, -0.1090]]), 'layers.1.bias': tensor([-0.0613]), 'skip.weight': tensor([[ 0.0072, -0.0070,  0.0075,  0.0073,  0.0080,  0.0056, -0.0071, -0.0075,\n",
       "           0.0051,  0.0066, -0.0092, -0.0063, -0.0071,  0.0061,  0.0058, -0.0067,\n",
       "           0.0071,  0.0071,  0.0075,  0.0070,  0.0056,  0.0068,  0.0097,  0.0068,\n",
       "          -0.0074,  0.0068, -0.0066,  0.0064, -0.0076,  0.0071,  0.0094, -0.0084,\n",
       "           0.0083, -0.0084,  0.0073, -0.0083, -0.0086, -0.0063, -0.0070, -0.0073,\n",
       "          -0.0055, -0.0060,  0.0098, -0.0060,  0.0083,  0.0075, -0.0099, -0.0070,\n",
       "          -0.0086, -0.0065,  0.0067, -0.0065, -0.0074,  0.0065,  0.0086,  0.0070,\n",
       "          -0.0068, -0.0086, -0.0078,  0.0065,  0.0060,  0.0073, -0.0102,  0.0118,\n",
       "           0.0175, -0.0163,  0.0064]])}, objective=16.837905194140326, loss=0.7375782132148743, val_objective=16.854698683596503, val_loss=0.754371702671051, regularization=0.5118722319602966, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=5),\n",
       " HistoryItem(lambda_=32.0828763413323, state_dict={'layers.0.weight': tensor([[-0.0657,  0.0237,  0.0712,  ..., -0.0059,  0.0566,  0.0370],\n",
       "         [-0.0691,  0.0228, -0.0129,  ...,  0.0351, -0.1069, -0.0607],\n",
       "         [-0.0467, -0.0553, -0.0237,  ..., -0.1709, -0.1267, -0.0239],\n",
       "         ...,\n",
       "         [-0.0075, -0.0662, -0.0284,  ..., -0.1664, -0.0572,  0.0380],\n",
       "         [ 0.0691, -0.0221, -0.0712,  ..., -0.0284,  0.0007,  0.0607],\n",
       "         [-0.0461, -0.0243,  0.0712,  ...,  0.0433, -0.0817,  0.0607]]), 'layers.0.bias': tensor([-0.0631,  0.1370,  0.0429,  0.0591,  0.0939,  0.0897,  0.0049, -0.1509,\n",
       "          0.0035, -0.0834,  0.0700,  0.0956,  0.1274,  0.0371, -0.1521, -0.1200,\n",
       "         -0.0717, -0.1011,  0.1482, -0.0015,  0.0573,  0.1500, -0.0990,  0.0503,\n",
       "         -0.0808,  0.1769, -0.0924, -0.0515, -0.0538,  0.1072, -0.0248,  0.0252,\n",
       "         -0.0321, -0.0442, -0.0301, -0.1472, -0.0006,  0.0621,  0.1032,  0.0551,\n",
       "         -0.0549,  0.0350,  0.1245, -0.0456,  0.1252, -0.0248, -0.0684,  0.0004,\n",
       "          0.0338,  0.1175]), 'layers.1.weight': tensor([[ 0.0523,  0.1262, -0.1446, -0.0809,  0.0599, -0.1134, -0.0716, -0.0296,\n",
       "           0.1571, -0.0344,  0.0432, -0.0780,  0.0684,  0.0027, -0.0787,  0.0621,\n",
       "          -0.1028, -0.0119,  0.0265,  0.0698, -0.1125,  0.0422, -0.0734, -0.0695,\n",
       "          -0.0623,  0.1231,  0.0740,  0.1046,  0.1123, -0.0288, -0.1242,  0.1383,\n",
       "           0.0168,  0.0592, -0.0903,  0.1346,  0.1050, -0.0902,  0.1869, -0.0482,\n",
       "          -0.1282,  0.0579,  0.1468, -0.0838,  0.0759,  0.1116, -0.0967, -0.0748,\n",
       "          -0.0823, -0.1103]]), 'layers.1.bias': tensor([-0.0610]), 'skip.weight': tensor([[ 0.0069, -0.0066,  0.0071,  0.0069,  0.0076,  0.0053, -0.0066, -0.0071,\n",
       "           0.0048,  0.0063, -0.0088, -0.0060, -0.0067,  0.0058,  0.0054, -0.0064,\n",
       "           0.0067,  0.0067,  0.0070,  0.0066,  0.0054,  0.0064,  0.0092,  0.0065,\n",
       "          -0.0069,  0.0065, -0.0063,  0.0060, -0.0072,  0.0067,  0.0089, -0.0080,\n",
       "           0.0078, -0.0080,  0.0069, -0.0078, -0.0080, -0.0059, -0.0066, -0.0069,\n",
       "          -0.0053, -0.0057,  0.0094, -0.0056,  0.0079,  0.0071, -0.0094, -0.0067,\n",
       "          -0.0081, -0.0061,  0.0063, -0.0062, -0.0070,  0.0062,  0.0082,  0.0066,\n",
       "          -0.0065, -0.0081, -0.0074,  0.0061,  0.0057,  0.0070, -0.0097,  0.0113,\n",
       "           0.0171, -0.0155,  0.0061]])}, objective=16.31162891454635, loss=0.7382128238677979, val_objective=16.32740233011184, val_loss=0.7539862394332886, regularization=0.4854120910167694, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=25),\n",
       " HistoryItem(lambda_=32.72453386815895, state_dict={'layers.0.weight': tensor([[-0.0632,  0.0236,  0.0636,  ..., -0.0058,  0.0564,  0.0370],\n",
       "         [-0.0632,  0.0227, -0.0129,  ...,  0.0354, -0.1076, -0.0551],\n",
       "         [-0.0469, -0.0552, -0.0239,  ..., -0.1633, -0.1262, -0.0240],\n",
       "         ...,\n",
       "         [-0.0076, -0.0602, -0.0285,  ..., -0.1633, -0.0571,  0.0379],\n",
       "         [ 0.0632, -0.0218, -0.0636,  ..., -0.0286,  0.0009,  0.0551],\n",
       "         [-0.0464, -0.0241,  0.0636,  ...,  0.0428, -0.0811,  0.0551]]), 'layers.0.bias': tensor([-0.0630,  0.1368,  0.0429,  0.0589,  0.0940,  0.0897,  0.0050, -0.1509,\n",
       "          0.0034, -0.0835,  0.0702,  0.0956,  0.1275,  0.0371, -0.1523, -0.1201,\n",
       "         -0.0716, -0.1011,  0.1482, -0.0018,  0.0569,  0.1498, -0.0992,  0.0501,\n",
       "         -0.0810,  0.1765, -0.0928, -0.0516, -0.0536,  0.1071, -0.0247,  0.0250,\n",
       "         -0.0321, -0.0440, -0.0301, -0.1469, -0.0009,  0.0622,  0.1038,  0.0549,\n",
       "         -0.0555,  0.0350,  0.1250, -0.0456,  0.1250, -0.0250, -0.0683,  0.0004,\n",
       "          0.0340,  0.1176]), 'layers.1.weight': tensor([[ 0.0521,  0.1273, -0.1462, -0.0810,  0.0610, -0.1155, -0.0728, -0.0302,\n",
       "           0.1585, -0.0351,  0.0428, -0.0779,  0.0700,  0.0021, -0.0794,  0.0629,\n",
       "          -0.1046, -0.0121,  0.0273,  0.0702, -0.1132,  0.0413, -0.0733, -0.0706,\n",
       "          -0.0631,  0.1230,  0.0748,  0.1055,  0.1123, -0.0299, -0.1253,  0.1386,\n",
       "           0.0176,  0.0607, -0.0905,  0.1374,  0.1038, -0.0919,  0.1904, -0.0484,\n",
       "          -0.1281,  0.0588,  0.1484, -0.0849,  0.0757,  0.1127, -0.0974, -0.0765,\n",
       "          -0.0837, -0.1125]]), 'layers.1.bias': tensor([-0.0600]), 'skip.weight': tensor([[ 0.0063, -0.0060,  0.0064,  0.0063,  0.0069,  0.0049, -0.0057, -0.0065,\n",
       "           0.0042,  0.0058, -0.0081, -0.0053, -0.0061,  0.0052,  0.0048, -0.0058,\n",
       "           0.0061,  0.0061,  0.0063,  0.0059,  0.0049,  0.0057,  0.0084,  0.0059,\n",
       "          -0.0063,  0.0059, -0.0057,  0.0052, -0.0066,  0.0061,  0.0083, -0.0075,\n",
       "           0.0070, -0.0074,  0.0063, -0.0071, -0.0071, -0.0052, -0.0061, -0.0062,\n",
       "          -0.0048, -0.0051,  0.0087, -0.0048,  0.0071,  0.0065, -0.0086, -0.0061,\n",
       "          -0.0072, -0.0055,  0.0057, -0.0057, -0.0063,  0.0057,  0.0075,  0.0059,\n",
       "          -0.0059, -0.0073, -0.0067,  0.0055,  0.0051,  0.0065, -0.0090,  0.0104,\n",
       "           0.0163, -0.0142,  0.0055]])}, objective=15.18102528269121, loss=0.7393089532852173, val_objective=15.195195452521533, val_loss=0.7534791231155396, regularization=0.4413115978240967, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=45),\n",
       " HistoryItem(lambda_=33.37902454552213, state_dict={'layers.0.weight': tensor([[-0.0516,  0.0235,  0.0504,  ..., -0.0056,  0.0559,  0.0372],\n",
       "         [-0.0516,  0.0226, -0.0128,  ...,  0.0362, -0.1094, -0.0425],\n",
       "         [-0.0472, -0.0484, -0.0244,  ..., -0.1483, -0.1180, -0.0241],\n",
       "         ...,\n",
       "         [-0.0080, -0.0484, -0.0288,  ..., -0.1483, -0.0568,  0.0377],\n",
       "         [ 0.0516, -0.0213, -0.0504,  ..., -0.0289,  0.0014,  0.0425],\n",
       "         [-0.0469, -0.0236,  0.0504,  ...,  0.0419, -0.0797,  0.0425]]), 'layers.0.bias': tensor([-0.0629,  0.1365,  0.0429,  0.0584,  0.0941,  0.0896,  0.0051, -0.1510,\n",
       "          0.0032, -0.0835,  0.0705,  0.0954,  0.1276,  0.0371, -0.1526, -0.1201,\n",
       "         -0.0715, -0.1011,  0.1483, -0.0023,  0.0558,  0.1495, -0.0997,  0.0495,\n",
       "         -0.0815,  0.1759, -0.0935, -0.0516, -0.0529,  0.1070, -0.0245,  0.0249,\n",
       "         -0.0321, -0.0434, -0.0300, -0.1461, -0.0016,  0.0625,  0.1052,  0.0544,\n",
       "         -0.0569,  0.0350,  0.1257, -0.0457,  0.1245, -0.0251, -0.0679,  0.0004,\n",
       "          0.0343,  0.1174]), 'layers.1.weight': tensor([[ 0.0512,  0.1297, -0.1500, -0.0815,  0.0635, -0.1210, -0.0756, -0.0320,\n",
       "           0.1615, -0.0373,  0.0415, -0.0775,  0.0729,  0.0007, -0.0817,  0.0641,\n",
       "          -0.1083, -0.0138,  0.0279,  0.0701, -0.1150,  0.0386, -0.0734, -0.0738,\n",
       "          -0.0655,  0.1228,  0.0764,  0.1078,  0.1121, -0.0322, -0.1281,  0.1386,\n",
       "           0.0190,  0.0635, -0.0909,  0.1430,  0.1010, -0.0964,  0.1983, -0.0502,\n",
       "          -0.1276,  0.0607,  0.1504, -0.0874,  0.0747,  0.1157, -0.0986, -0.0805,\n",
       "          -0.0870, -0.1173]]), 'layers.1.bias': tensor([-0.0570]), 'skip.weight': tensor([[ 0.0052, -0.0048,  0.0050,  0.0052,  0.0056,  0.0039, -0.0042, -0.0053,\n",
       "           0.0030,  0.0047, -0.0068, -0.0041, -0.0049,  0.0041,  0.0038, -0.0046,\n",
       "           0.0048,  0.0049,  0.0050,  0.0048,  0.0040,  0.0044,  0.0068,  0.0047,\n",
       "          -0.0050,  0.0046, -0.0044,  0.0040, -0.0052,  0.0047,  0.0070, -0.0063,\n",
       "           0.0056, -0.0062,  0.0051, -0.0059, -0.0055, -0.0039, -0.0050, -0.0050,\n",
       "          -0.0039, -0.0041,  0.0072, -0.0035,  0.0057,  0.0052, -0.0071, -0.0050,\n",
       "          -0.0058, -0.0043,  0.0044, -0.0047, -0.0050,  0.0048,  0.0062,  0.0047,\n",
       "          -0.0047, -0.0058, -0.0055,  0.0044,  0.0039,  0.0054, -0.0076,  0.0086,\n",
       "           0.0148, -0.0118,  0.0043]])}, objective=12.626334623026473, loss=0.741535484790802, val_objective=12.637622312235457, val_loss=0.7528231739997864, regularization=0.3560559153556824, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=100),\n",
       " HistoryItem(lambda_=34.046605036432574, state_dict={'layers.0.weight': tensor([[-0.0420,  0.0235,  0.0394,  ..., -0.0055,  0.0554,  0.0319],\n",
       "         [-0.0420,  0.0230, -0.0125,  ...,  0.0370, -0.0991, -0.0319],\n",
       "         [-0.0420, -0.0385, -0.0247,  ..., -0.1345, -0.0991, -0.0246],\n",
       "         ...,\n",
       "         [-0.0085, -0.0385, -0.0294,  ..., -0.1345, -0.0566,  0.0319],\n",
       "         [ 0.0420, -0.0210, -0.0394,  ..., -0.0292,  0.0020,  0.0319],\n",
       "         [-0.0420, -0.0236,  0.0394,  ...,  0.0410, -0.0781,  0.0319]]), 'layers.0.bias': tensor([-0.0628,  0.1363,  0.0434,  0.0579,  0.0940,  0.0894,  0.0051, -0.1512,\n",
       "          0.0033, -0.0835,  0.0708,  0.0949,  0.1278,  0.0371, -0.1526, -0.1198,\n",
       "         -0.0715, -0.1011,  0.1483, -0.0028,  0.0544,  0.1491, -0.1002,  0.0491,\n",
       "         -0.0819,  0.1752, -0.0941, -0.0514, -0.0523,  0.1069, -0.0241,  0.0248,\n",
       "         -0.0321, -0.0427, -0.0300, -0.1452, -0.0021,  0.0629,  0.1066,  0.0538,\n",
       "         -0.0582,  0.0349,  0.1263, -0.0457,  0.1240, -0.0248, -0.0677,  0.0004,\n",
       "          0.0344,  0.1175]), 'layers.1.weight': tensor([[ 0.0503,  0.1317, -0.1546, -0.0824,  0.0658, -0.1266, -0.0783, -0.0342,\n",
       "           0.1647, -0.0395,  0.0400, -0.0773,  0.0746, -0.0005, -0.0842,  0.0651,\n",
       "          -0.1118, -0.0161,  0.0273,  0.0696, -0.1166,  0.0353, -0.0739, -0.0774,\n",
       "          -0.0680,  0.1227,  0.0777,  0.1099,  0.1118, -0.0337, -0.1312,  0.1384,\n",
       "           0.0206,  0.0659, -0.0917,  0.1478,  0.0986, -0.1008,  0.2051, -0.0527,\n",
       "          -0.1273,  0.0622,  0.1510, -0.0903,  0.0741,  0.1191, -0.0997, -0.0844,\n",
       "          -0.0903, -0.1225]]), 'layers.1.bias': tensor([-0.0536]), 'skip.weight': tensor([[ 0.0042, -0.0038,  0.0039,  0.0043,  0.0045,  0.0030, -0.0029, -0.0043,\n",
       "           0.0019,  0.0036, -0.0057, -0.0031, -0.0040,  0.0031,  0.0029, -0.0036,\n",
       "           0.0037,  0.0040,  0.0038,  0.0037,  0.0031,  0.0032,  0.0054,  0.0036,\n",
       "          -0.0038,  0.0035, -0.0033,  0.0029, -0.0041,  0.0037,  0.0059, -0.0051,\n",
       "           0.0045, -0.0050,  0.0041, -0.0047, -0.0042, -0.0028, -0.0040, -0.0039,\n",
       "          -0.0030, -0.0032,  0.0058, -0.0023,  0.0045,  0.0040, -0.0059, -0.0040,\n",
       "          -0.0045, -0.0032,  0.0033, -0.0037, -0.0039,  0.0038,  0.0050,  0.0037,\n",
       "          -0.0037, -0.0045, -0.0044,  0.0034,  0.0029,  0.0045, -0.0063,  0.0070,\n",
       "           0.0135, -0.0099,  0.0032]])}, objective=10.346239206221204, loss=0.7436870336532593, val_objective=10.354937431242567, val_loss=0.7523852586746216, regularization=0.28204140067100525, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=100),\n",
       " HistoryItem(lambda_=34.72753713716123, state_dict={'layers.0.weight': tensor([[-0.0332,  0.0236,  0.0294,  ..., -0.0054,  0.0551,  0.0228],\n",
       "         [-0.0332,  0.0235, -0.0123,  ...,  0.0377, -0.0832, -0.0228],\n",
       "         [-0.0332, -0.0296, -0.0250,  ..., -0.1218, -0.0832, -0.0228],\n",
       "         ...,\n",
       "         [-0.0090, -0.0296, -0.0294,  ..., -0.1218, -0.0565,  0.0228],\n",
       "         [ 0.0332, -0.0209, -0.0294,  ..., -0.0296,  0.0027,  0.0228],\n",
       "         [-0.0332, -0.0240,  0.0294,  ...,  0.0403, -0.0761,  0.0228]]), 'layers.0.bias': tensor([-0.0629,  0.1359,  0.0442,  0.0574,  0.0939,  0.0889,  0.0051, -0.1512,\n",
       "          0.0032, -0.0834,  0.0711,  0.0944,  0.1279,  0.0371, -0.1525, -0.1194,\n",
       "         -0.0711, -0.1010,  0.1484, -0.0031,  0.0529,  0.1489, -0.1007,  0.0489,\n",
       "         -0.0821,  0.1742, -0.0944, -0.0513, -0.0521,  0.1068, -0.0235,  0.0248,\n",
       "         -0.0321, -0.0421, -0.0298, -0.1442, -0.0026,  0.0634,  0.1076,  0.0533,\n",
       "         -0.0592,  0.0348,  0.1265, -0.0452,  0.1233, -0.0242, -0.0674,  0.0006,\n",
       "          0.0346,  0.1176]), 'layers.1.weight': tensor([[ 0.0492,  0.1340, -0.1597, -0.0834,  0.0679, -0.1315, -0.0808, -0.0366,\n",
       "           0.1682, -0.0413,  0.0393, -0.0776,  0.0758, -0.0017, -0.0864,  0.0664,\n",
       "          -0.1150, -0.0182,  0.0258,  0.0691, -0.1172,  0.0321, -0.0746, -0.0807,\n",
       "          -0.0706,  0.1226,  0.0789,  0.1116,  0.1120, -0.0345, -0.1340,  0.1387,\n",
       "           0.0223,  0.0681, -0.0930,  0.1519,  0.0965, -0.1048,  0.2108, -0.0552,\n",
       "          -0.1271,  0.0633,  0.1511, -0.0930,  0.0739,  0.1226, -0.1009, -0.0878,\n",
       "          -0.0929, -0.1275]]), 'layers.1.bias': tensor([-0.0518]), 'skip.weight': tensor([[ 0.0033, -0.0030,  0.0029,  0.0034,  0.0035,  0.0021, -0.0019, -0.0034,\n",
       "           0.0011,  0.0027, -0.0047, -0.0021, -0.0031,  0.0021,  0.0020, -0.0026,\n",
       "           0.0027,  0.0031,  0.0028,  0.0027,  0.0023,  0.0023,  0.0042,  0.0026,\n",
       "          -0.0028,  0.0025, -0.0023,  0.0020, -0.0031,  0.0028,  0.0049, -0.0041,\n",
       "           0.0035, -0.0040,  0.0032, -0.0037, -0.0032, -0.0019, -0.0031, -0.0029,\n",
       "          -0.0021, -0.0023,  0.0046, -0.0013,  0.0036,  0.0031, -0.0049, -0.0030,\n",
       "          -0.0035, -0.0023,  0.0024, -0.0028, -0.0030,  0.0029,  0.0040,  0.0028,\n",
       "          -0.0028, -0.0036, -0.0034,  0.0024,  0.0020,  0.0036, -0.0051,  0.0058,\n",
       "           0.0122, -0.0083,  0.0023]])}, objective=8.253393622977125, loss=0.7458974719047546, val_objective=8.259540709597456, val_loss=0.7520445585250846, regularization=0.21618279814720154, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=100),\n",
       " HistoryItem(lambda_=35.42208787990445, state_dict={'layers.0.weight': tensor([[-0.0245,  0.0213,  0.0205,  ..., -0.0055,  0.0548,  0.0142],\n",
       "         [-0.0245,  0.0213, -0.0123,  ...,  0.0384, -0.0712, -0.0142],\n",
       "         [-0.0245, -0.0213, -0.0205,  ..., -0.1096, -0.0712, -0.0142],\n",
       "         ...,\n",
       "         [-0.0095, -0.0213, -0.0205,  ..., -0.1096, -0.0565,  0.0142],\n",
       "         [ 0.0245, -0.0209, -0.0205,  ..., -0.0301,  0.0034,  0.0142],\n",
       "         [-0.0245, -0.0213,  0.0205,  ...,  0.0397, -0.0712,  0.0142]]), 'layers.0.bias': tensor([-0.0631,  0.1356,  0.0445,  0.0572,  0.0938,  0.0885,  0.0049, -0.1512,\n",
       "          0.0032, -0.0833,  0.0713,  0.0940,  0.1280,  0.0371, -0.1523, -0.1186,\n",
       "         -0.0702, -0.1009,  0.1484, -0.0032,  0.0517,  0.1486, -0.1009,  0.0487,\n",
       "         -0.0821,  0.1735, -0.0945, -0.0510, -0.0516,  0.1065, -0.0227,  0.0250,\n",
       "         -0.0321, -0.0419, -0.0294, -0.1429, -0.0031,  0.0639,  0.1087,  0.0527,\n",
       "         -0.0601,  0.0347,  0.1262, -0.0444,  0.1223, -0.0233, -0.0673,  0.0012,\n",
       "          0.0348,  0.1178]), 'layers.1.weight': tensor([[ 0.0479,  0.1361, -0.1642, -0.0843,  0.0698, -0.1354, -0.0827, -0.0391,\n",
       "           0.1724, -0.0425,  0.0390, -0.0779,  0.0775, -0.0026, -0.0884,  0.0675,\n",
       "          -0.1178, -0.0199,  0.0241,  0.0688, -0.1175,  0.0292, -0.0760, -0.0835,\n",
       "          -0.0729,  0.1226,  0.0800,  0.1130,  0.1124, -0.0351, -0.1365,  0.1397,\n",
       "           0.0240,  0.0701, -0.0947,  0.1554,  0.0951, -0.1078,  0.2161, -0.0570,\n",
       "          -0.1272,  0.0640,  0.1511, -0.0954,  0.0732,  0.1260, -0.1018, -0.0909,\n",
       "          -0.0949, -0.1324]]), 'layers.1.bias': tensor([-0.0511]), 'skip.weight': tensor([[ 0.0024, -0.0021,  0.0020,  0.0026,  0.0025,  0.0013, -0.0010, -0.0024,\n",
       "           0.0002,  0.0018, -0.0037, -0.0013, -0.0022,  0.0013,  0.0012, -0.0018,\n",
       "           0.0018,  0.0023,  0.0019,  0.0018,  0.0015,  0.0014,  0.0032,  0.0017,\n",
       "          -0.0018,  0.0016, -0.0015,  0.0012, -0.0022,  0.0019,  0.0040, -0.0030,\n",
       "           0.0026, -0.0031,  0.0023, -0.0027, -0.0022, -0.0011, -0.0023, -0.0020,\n",
       "          -0.0013, -0.0015,  0.0036, -0.0004,  0.0028,  0.0022, -0.0038, -0.0021,\n",
       "          -0.0027, -0.0013,  0.0016, -0.0020, -0.0021,  0.0020,  0.0030,  0.0019,\n",
       "          -0.0019, -0.0027, -0.0025,  0.0015,  0.0011,  0.0028, -0.0041,  0.0048,\n",
       "           0.0110, -0.0071,  0.0014]])}, objective=6.2817708114310955, loss=0.7485116124153137, val_objective=6.2857181886359905, val_loss=0.7524589896202087, regularization=0.1562092900276184, selected=tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True]), n_iters=100),\n",
       " HistoryItem(lambda_=36.13052963750254, state_dict={'layers.0.weight': tensor([[-0.0159,  0.0135,  0.0120,  ..., -0.0056,  0.0546,  0.0061],\n",
       "         [-0.0159,  0.0135, -0.0118,  ...,  0.0391, -0.0608, -0.0061],\n",
       "         [-0.0159, -0.0135, -0.0120,  ..., -0.0977, -0.0608, -0.0061],\n",
       "         ...,\n",
       "         [-0.0102, -0.0135, -0.0120,  ..., -0.0977, -0.0566,  0.0061],\n",
       "         [ 0.0159, -0.0135, -0.0120,  ..., -0.0305,  0.0042,  0.0061],\n",
       "         [-0.0159, -0.0135,  0.0120,  ...,  0.0391, -0.0608,  0.0061]]), 'layers.0.bias': tensor([-0.0634,  0.1353,  0.0445,  0.0572,  0.0936,  0.0880,  0.0043, -0.1510,\n",
       "          0.0033, -0.0832,  0.0714,  0.0935,  0.1280,  0.0371, -0.1516, -0.1178,\n",
       "         -0.0690, -0.1007,  0.1483, -0.0030,  0.0506,  0.1483, -0.1008,  0.0488,\n",
       "         -0.0817,  0.1728, -0.0946, -0.0506, -0.0509,  0.1064, -0.0212,  0.0259,\n",
       "         -0.0320, -0.0420, -0.0291, -0.1410, -0.0039,  0.0642,  0.1098,  0.0522,\n",
       "         -0.0605,  0.0346,  0.1258, -0.0433,  0.1212, -0.0221, -0.0669,  0.0021,\n",
       "          0.0354,  0.1184]), 'layers.1.weight': tensor([[ 0.0466,  0.1376, -0.1678, -0.0851,  0.0710, -0.1387, -0.0842, -0.0412,\n",
       "           0.1768, -0.0432,  0.0391, -0.0784,  0.0795, -0.0030, -0.0900,  0.0680,\n",
       "          -0.1202, -0.0215,  0.0219,  0.0687, -0.1175,  0.0261, -0.0773, -0.0856,\n",
       "          -0.0746,  0.1227,  0.0807,  0.1140,  0.1130, -0.0355, -0.1390,  0.1410,\n",
       "           0.0256,  0.0715, -0.0962,  0.1579,  0.0940, -0.1100,  0.2212, -0.0580,\n",
       "          -0.1274,  0.0639,  0.1506, -0.0973,  0.0720,  0.1292, -0.1024, -0.0939,\n",
       "          -0.0970, -0.1371]]), 'layers.1.bias': tensor([-0.0514]), 'skip.weight': tensor([[ 0.0016, -0.0014,  0.0012,  0.0018,  0.0017,  0.0005, -0.0002, -0.0015,\n",
       "           0.0000,  0.0010, -0.0027, -0.0005, -0.0014,  0.0005,  0.0004, -0.0010,\n",
       "           0.0010,  0.0015,  0.0010,  0.0009,  0.0007,  0.0006,  0.0023,  0.0009,\n",
       "          -0.0010,  0.0008, -0.0007,  0.0005, -0.0014,  0.0011,  0.0031, -0.0020,\n",
       "           0.0017, -0.0023,  0.0015, -0.0018, -0.0012, -0.0004, -0.0015, -0.0012,\n",
       "          -0.0005, -0.0008,  0.0026,  0.0000,  0.0019,  0.0013, -0.0028, -0.0012,\n",
       "          -0.0018, -0.0005,  0.0008, -0.0012, -0.0013,  0.0012,  0.0022,  0.0011,\n",
       "          -0.0010, -0.0018, -0.0017,  0.0007,  0.0003,  0.0020, -0.0032,  0.0038,\n",
       "           0.0098, -0.0061,  0.0006]])}, objective=4.397944262473828, loss=0.7515567541122437, val_objective=4.400077691524274, val_loss=0.7536901831626888, regularization=0.1009226143360138, selected=tensor([ True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True]), n_iters=100),\n",
       " HistoryItem(lambda_=36.85314023025259, state_dict={'layers.0.weight': tensor([[-0.0082,  0.0060,  0.0044,  ..., -0.0058,  0.0514,  0.0000],\n",
       "         [-0.0082,  0.0060, -0.0044,  ...,  0.0399, -0.0514,  0.0000],\n",
       "         [-0.0082, -0.0060, -0.0044,  ..., -0.0864, -0.0514, -0.0000],\n",
       "         ...,\n",
       "         [-0.0082, -0.0060, -0.0044,  ..., -0.0864, -0.0514,  0.0000],\n",
       "         [ 0.0082, -0.0060, -0.0044,  ..., -0.0309,  0.0050, -0.0000],\n",
       "         [-0.0082, -0.0060,  0.0044,  ...,  0.0384, -0.0514, -0.0000]]), 'layers.0.bias': tensor([-0.0638,  0.1349,  0.0441,  0.0573,  0.0934,  0.0878,  0.0038, -0.1506,\n",
       "          0.0043, -0.0832,  0.0714,  0.0933,  0.1279,  0.0371, -0.1509, -0.1172,\n",
       "         -0.0672, -0.1004,  0.1483, -0.0025,  0.0494,  0.1480, -0.1007,  0.0487,\n",
       "         -0.0809,  0.1723, -0.0944, -0.0501, -0.0498,  0.1064, -0.0193,  0.0275,\n",
       "         -0.0319, -0.0419, -0.0287, -0.1388, -0.0048,  0.0641,  0.1107,  0.0518,\n",
       "         -0.0606,  0.0345,  0.1254, -0.0422,  0.1198, -0.0207, -0.0666,  0.0031,\n",
       "          0.0364,  0.1190]), 'layers.1.weight': tensor([[ 0.0458,  0.1388, -0.1700, -0.0856,  0.0709, -0.1410, -0.0853, -0.0423,\n",
       "           0.1807, -0.0434,  0.0394, -0.0796,  0.0821, -0.0032, -0.0906,  0.0683,\n",
       "          -0.1218, -0.0225,  0.0200,  0.0691, -0.1172,  0.0229, -0.0782, -0.0861,\n",
       "          -0.0758,  0.1229,  0.0810,  0.1143,  0.1136, -0.0359, -0.1409,  0.1426,\n",
       "           0.0270,  0.0726, -0.0973,  0.1592,  0.0931, -0.1114,  0.2263, -0.0579,\n",
       "          -0.1274,  0.0635,  0.1502, -0.0987,  0.0702,  0.1322, -0.1027, -0.0964,\n",
       "          -0.0989, -0.1408]]), 'layers.1.bias': tensor([-0.0527]), 'skip.weight': tensor([[ 8.1641e-04, -6.0281e-04,  4.4262e-04,  1.0611e-03,  8.9236e-04,\n",
       "          -0.0000e+00, -0.0000e+00, -7.1814e-04,  0.0000e+00, -2.6760e-04,\n",
       "          -1.8515e-03,  0.0000e+00, -6.1689e-04, -0.0000e+00, -0.0000e+00,\n",
       "          -2.0911e-04,  2.8074e-04,  7.3824e-04,  2.3904e-04,  1.2516e-04,\n",
       "          -0.0000e+00, -0.0000e+00,  1.4762e-03, -1.0044e-04, -1.7592e-04,\n",
       "           2.0325e-06,  0.0000e+00,  0.0000e+00, -5.6928e-04,  3.7520e-04,\n",
       "           2.2275e-03, -1.1810e-03,  9.6411e-04, -1.4683e-03,  7.4278e-04,\n",
       "          -9.8330e-04, -4.1016e-04, -0.0000e+00, -7.4694e-04, -4.6733e-04,\n",
       "          -0.0000e+00, -1.7700e-05,  1.7638e-03,  0.0000e+00,  1.1639e-03,\n",
       "           5.2000e-04, -1.9053e-03, -4.1817e-04, -1.0323e-03,  0.0000e+00,\n",
       "           2.7255e-05, -3.8924e-04, -5.0128e-04,  4.2893e-04,  1.4203e-03,\n",
       "           3.5498e-04, -2.9675e-04, -1.0069e-03, -8.5440e-04, -0.0000e+00,\n",
       "          -0.0000e+00,  1.1861e-03, -2.3346e-03,  2.8434e-03,  8.6356e-03,\n",
       "          -5.1415e-03,  0.0000e+00]])}, objective=2.7078619258939396, loss=0.7548506259918213, val_objective=2.7082307594358097, val_loss=0.7552194595336916, regularization=0.05299443379044533, selected=tensor([ True,  True,  True,  True,  True, False, False,  True, False,  True,\n",
       "          True, False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         False, False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         False,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False,  True,  True,  True,  True,  True, False]), n_iters=100),\n",
       " HistoryItem(lambda_=37.590203034857645, state_dict={'layers.0.weight': tensor([[-0.0007,  0.0000,  0.0000,  ..., -0.0058,  0.0425,  0.0000],\n",
       "         [-0.0007,  0.0000,  0.0000,  ...,  0.0411, -0.0425,  0.0000],\n",
       "         [-0.0007, -0.0000, -0.0000,  ..., -0.0759, -0.0425, -0.0000],\n",
       "         ...,\n",
       "         [-0.0007, -0.0000, -0.0000,  ..., -0.0759, -0.0425, -0.0000],\n",
       "         [ 0.0007, -0.0000, -0.0000,  ..., -0.0311,  0.0060, -0.0000],\n",
       "         [-0.0007, -0.0000, -0.0000,  ...,  0.0370, -0.0425, -0.0000]]), 'layers.0.bias': tensor([-0.0641,  0.1345,  0.0430,  0.0574,  0.0933,  0.0869,  0.0036, -0.1503,\n",
       "          0.0057, -0.0832,  0.0718,  0.0933,  0.1278,  0.0371, -0.1508, -0.1168,\n",
       "         -0.0657, -0.1002,  0.1482, -0.0025,  0.0483,  0.1478, -0.1009,  0.0484,\n",
       "         -0.0800,  0.1721, -0.0940, -0.0500, -0.0484,  0.1066, -0.0176,  0.0303,\n",
       "         -0.0318, -0.0415, -0.0280, -0.1375, -0.0059,  0.0644,  0.1117,  0.0512,\n",
       "         -0.0611,  0.0345,  0.1253, -0.0412,  0.1190, -0.0189, -0.0671,  0.0041,\n",
       "          0.0373,  0.1194]), 'layers.1.weight': tensor([[ 0.0454,  0.1403, -0.1712, -0.0855,  0.0703, -0.1417, -0.0861, -0.0426,\n",
       "           0.1835, -0.0435,  0.0401, -0.0807,  0.0847, -0.0034, -0.0907,  0.0684,\n",
       "          -0.1225, -0.0227,  0.0191,  0.0697, -0.1167,  0.0199, -0.0784, -0.0855,\n",
       "          -0.0765,  0.1239,  0.0812,  0.1143,  0.1141, -0.0367, -0.1419,  0.1447,\n",
       "           0.0279,  0.0734, -0.0982,  0.1595,  0.0924, -0.1123,  0.2308, -0.0577,\n",
       "          -0.1272,  0.0635,  0.1501, -0.0994,  0.0680,  0.1347, -0.1027, -0.0982,\n",
       "          -0.1004, -0.1429]]), 'layers.1.bias': tensor([-0.0538]), 'skip.weight': tensor([[ 7.4025e-05,  0.0000e+00,  0.0000e+00,  3.1848e-04,  1.0788e-04,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -1.0169e-03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -3.1223e-06, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  6.9263e-04, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           1.3812e-03, -3.7273e-04,  2.1615e-04, -7.4488e-04,  0.0000e+00,\n",
       "          -2.0176e-04, -0.0000e+00, -0.0000e+00,  1.4676e-05, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  9.4705e-04,  0.0000e+00, -4.3636e-04,\n",
       "           0.0000e+00, -1.0423e-03, -0.0000e+00, -2.8075e-04,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  6.4932e-04,\n",
       "           0.0000e+00,  0.0000e+00, -2.5072e-04, -9.1055e-05, -0.0000e+00,\n",
       "          -0.0000e+00,  4.1819e-04, -1.5507e-03,  1.9687e-03,  7.5877e-03,\n",
       "          -4.2516e-03,  0.0000e+00]])}, objective=1.6827409158610864, loss=0.7573109269142151, val_objective=1.6825649629497095, val_loss=0.7571349740028381, regularization=0.02461891435086727, selected=tensor([ True, False, False,  True,  True, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False,  True, False, False,\n",
       "         False, False,  True, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True, False,  True, False, False,  True, False,\n",
       "         False, False,  True, False,  True, False,  True, False,  True, False,\n",
       "         False, False, False, False,  True, False, False,  True,  True, False,\n",
       "         False,  True,  True,  True,  True,  True, False]), n_iters=100),\n",
       " HistoryItem(lambda_=38.3420070955548, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0340,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0429, -0.0340,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0661, -0.0340, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0661, -0.0340, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0315,  0.0072, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0351, -0.0340, -0.0000]]), 'layers.0.bias': tensor([-0.0642,  0.1346,  0.0425,  0.0576,  0.0937,  0.0857,  0.0029, -0.1503,\n",
       "          0.0071, -0.0830,  0.0722,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0646, -0.1002,  0.1482, -0.0032,  0.0473,  0.1478, -0.1011,  0.0478,\n",
       "         -0.0791,  0.1721, -0.0937, -0.0500, -0.0470,  0.1066, -0.0163,  0.0333,\n",
       "         -0.0319, -0.0407, -0.0280, -0.1373, -0.0073,  0.0658,  0.1123,  0.0505,\n",
       "         -0.0625,  0.0346,  0.1253, -0.0402,  0.1189, -0.0165, -0.0678,  0.0053,\n",
       "          0.0381,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1424, -0.1721, -0.0850,  0.0704, -0.1412, -0.0865, -0.0426,\n",
       "           0.1848, -0.0437,  0.0409, -0.0814,  0.0873, -0.0033, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0191,  0.0700, -0.1166,  0.0178, -0.0784, -0.0848,\n",
       "          -0.0768,  0.1255,  0.0813,  0.1142,  0.1147, -0.0374, -0.1426,  0.1466,\n",
       "           0.0285,  0.0741, -0.0990,  0.1594,  0.0920, -0.1135,  0.2342, -0.0577,\n",
       "          -0.1270,  0.0644,  0.1506, -0.0998,  0.0658,  0.1364, -0.1026, -0.0991,\n",
       "          -0.1014, -0.1432]]), 'layers.1.bias': tensor([-0.0535]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -2.0785e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           5.6180e-04, -0.0000e+00,  0.0000e+00,  9.7457e-05,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  1.4160e-04,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -2.5549e-04, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -8.1429e-04,  1.1201e-03,  6.6136e-03,\n",
       "          -3.4039e-03,  0.0000e+00]])}, objective=1.2655354673439425, loss=0.7588045001029968, val_objective=1.2656466300064486, val_loss=0.7589156627655029, regularization=0.013216078281402588, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False,  True, False, False, False, False, False, False,\n",
       "         False, False,  True, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=100),\n",
       " HistoryItem(lambda_=39.108847237465895, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0324,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0433, -0.0324,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0642, -0.0324, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0642, -0.0324, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0316,  0.0075, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0347, -0.0324, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0425,  0.0576,  0.0937,  0.0856,  0.0027, -0.1503,\n",
       "          0.0073, -0.0830,  0.0723,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0643, -0.1002,  0.1482, -0.0033,  0.0470,  0.1478, -0.1011,  0.0476,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0499, -0.0466,  0.1066, -0.0161,  0.0336,\n",
       "         -0.0319, -0.0405, -0.0281, -0.1373, -0.0076,  0.0662,  0.1123,  0.0503,\n",
       "         -0.0626,  0.0346,  0.1254, -0.0399,  0.1189, -0.0159, -0.0679,  0.0055,\n",
       "          0.0382,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1427, -0.1723, -0.0849,  0.0706, -0.1410, -0.0865, -0.0426,\n",
       "           0.1849, -0.0437,  0.0410, -0.0814,  0.0878, -0.0032, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1166,  0.0174, -0.0784, -0.0846,\n",
       "          -0.0768,  0.1259,  0.0813,  0.1142,  0.1148, -0.0375, -0.1427,  0.1468,\n",
       "           0.0286,  0.0742, -0.0991,  0.1594,  0.0919, -0.1138,  0.2347, -0.0578,\n",
       "          -0.1270,  0.0647,  0.1507, -0.0998,  0.0654,  0.1367, -0.1026, -0.0992,\n",
       "          -0.1015, -0.1431]]), 'layers.1.bias': tensor([-0.0534]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -5.2489e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           3.9960e-04, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -1.0681e-04, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -6.7644e-04,  9.5539e-04,  6.4191e-03,\n",
       "          -3.2353e-03,  0.0000e+00]])}, objective=1.2223096021442685, loss=0.7590588927268982, val_objective=1.2224083670406614, val_loss=0.759157657623291, regularization=0.011845164000988007, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=20),\n",
       " HistoryItem(lambda_=39.89102418221521, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0319,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0434, -0.0319,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0637, -0.0319, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0637, -0.0319, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0317,  0.0076, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0346, -0.0319, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0425,  0.0576,  0.0937,  0.0855,  0.0027, -0.1503,\n",
       "          0.0074, -0.0830,  0.0723,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0643, -0.1002,  0.1482, -0.0034,  0.0469,  0.1478, -0.1012,  0.0476,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0498, -0.0465,  0.1066, -0.0160,  0.0337,\n",
       "         -0.0319, -0.0405, -0.0281, -0.1373, -0.0077,  0.0664,  0.1123,  0.0503,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0399,  0.1189, -0.0157, -0.0679,  0.0056,\n",
       "          0.0383,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1428, -0.1724, -0.0849,  0.0706, -0.1410, -0.0865, -0.0426,\n",
       "           0.1849, -0.0437,  0.0410, -0.0814,  0.0879, -0.0032, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1166,  0.0173, -0.0784, -0.0846,\n",
       "          -0.0768,  0.1259,  0.0813,  0.1142,  0.1148, -0.0375, -0.1427,  0.1469,\n",
       "           0.0286,  0.0742, -0.0992,  0.1594,  0.0919, -0.1139,  0.2348, -0.0578,\n",
       "          -0.1270,  0.0648,  0.1508, -0.0999,  0.0653,  0.1368, -0.1026, -0.0993,\n",
       "          -0.1016, -0.1430]]), 'layers.1.bias': tensor([-0.0533]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -1.2903e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           3.5865e-04, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -7.0223e-05, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -6.4177e-04,  9.1377e-04,  6.3695e-03,\n",
       "          -3.1924e-03,  0.0000e+00]])}, objective=1.2202111816489678, loss=0.7591027617454529, val_objective=1.2203097677314263, val_loss=0.7592013478279113, regularization=0.011559202335774899, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=40.68884466585952, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0315,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0435, -0.0315,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0632, -0.0315, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0632, -0.0315, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0317,  0.0077, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0345, -0.0315, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0576,  0.0937,  0.0855,  0.0026, -0.1503,\n",
       "          0.0075, -0.0830,  0.0723,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0642, -0.1002,  0.1482, -0.0034,  0.0468,  0.1478, -0.1012,  0.0475,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0498, -0.0464,  0.1066, -0.0160,  0.0338,\n",
       "         -0.0319, -0.0404, -0.0282, -0.1373, -0.0077,  0.0665,  0.1124,  0.0502,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0398,  0.1189, -0.0156, -0.0679,  0.0056,\n",
       "          0.0383,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1429, -0.1724, -0.0849,  0.0706, -0.1409, -0.0865, -0.0426,\n",
       "           0.1850, -0.0437,  0.0410, -0.0815,  0.0880, -0.0032, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1166,  0.0172, -0.0784, -0.0845,\n",
       "          -0.0768,  0.1260,  0.0813,  0.1142,  0.1149, -0.0376, -0.1428,  0.1470,\n",
       "           0.0287,  0.0743, -0.0992,  0.1594,  0.0919, -0.1140,  0.2349, -0.0578,\n",
       "          -0.1270,  0.0649,  0.1508, -0.0999,  0.0652,  0.1369, -0.1026, -0.0993,\n",
       "          -0.1016, -0.1430]]), 'layers.1.bias': tensor([-0.0533]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "           3.1693e-04, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -3.2877e-05, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -6.0630e-04,  8.7130e-04,  6.3201e-03,\n",
       "          -3.1496e-03,  0.0000e+00]])}, objective=1.218815278622994, loss=0.7591478824615479, val_objective=1.2189151760076375, val_loss=0.7592477798461914, regularization=0.0112971356138587, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=41.50262155917671, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0311, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0436, -0.0311,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0627, -0.0311, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0627, -0.0311, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0318,  0.0078, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0344, -0.0311, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0575,  0.0937,  0.0855,  0.0026, -0.1503,\n",
       "          0.0075, -0.0830,  0.0723,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0642, -0.1002,  0.1482, -0.0035,  0.0467,  0.1478, -0.1012,  0.0475,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0498, -0.0463,  0.1066, -0.0159,  0.0339,\n",
       "         -0.0319, -0.0404, -0.0282, -0.1373, -0.0078,  0.0666,  0.1124,  0.0501,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0397,  0.1189, -0.0154, -0.0680,  0.0057,\n",
       "          0.0383,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1430, -0.1725, -0.0849,  0.0706, -0.1409, -0.0865, -0.0426,\n",
       "           0.1850, -0.0437,  0.0410, -0.0815,  0.0881, -0.0032, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1166,  0.0172, -0.0784, -0.0845,\n",
       "          -0.0768,  0.1261,  0.0813,  0.1142,  0.1149, -0.0376, -0.1428,  0.1470,\n",
       "           0.0287,  0.0743, -0.0992,  0.1594,  0.0919, -0.1140,  0.2351, -0.0578,\n",
       "          -0.1270,  0.0650,  0.1509, -0.0999,  0.0651,  0.1369, -0.1026, -0.0993,\n",
       "          -0.1017, -0.1429]]), 'layers.1.bias': tensor([-0.0532]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0003, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0006,  0.0008,\n",
       "           0.0063, -0.0031,  0.0000]])}, objective=1.2177422597291767, loss=0.7591939568519592, val_objective=1.217841680276662, val_loss=0.7592933773994446, regularization=0.01104865875095129, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=42.33267399036024, state_dict={'layers.0.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0057,  0.0306, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0437, -0.0306,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0622, -0.0306, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0622, -0.0306, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0318,  0.0079, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0343, -0.0306, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0575,  0.0937,  0.0855,  0.0026, -0.1503,\n",
       "          0.0076, -0.0830,  0.0723,  0.0933,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0641, -0.1002,  0.1482, -0.0035,  0.0466,  0.1478, -0.1012,  0.0474,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0497, -0.0462,  0.1066, -0.0159,  0.0339,\n",
       "         -0.0319, -0.0403, -0.0283, -0.1373, -0.0079,  0.0667,  0.1124,  0.0501,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0397,  0.1189, -0.0153, -0.0680,  0.0057,\n",
       "          0.0383,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1431, -0.1725, -0.0848,  0.0707, -0.1409, -0.0864, -0.0426,\n",
       "           0.1850, -0.0437,  0.0410, -0.0815,  0.0882, -0.0031, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1166,  0.0171, -0.0784, -0.0845,\n",
       "          -0.0768,  0.1262,  0.0813,  0.1142,  0.1149, -0.0376, -0.1428,  0.1471,\n",
       "           0.0287,  0.0743, -0.0993,  0.1594,  0.0918, -0.1141,  0.2352, -0.0578,\n",
       "          -0.1270,  0.0650,  0.1509, -0.0999,  0.0650,  0.1370, -0.1026, -0.0994,\n",
       "          -0.1017, -0.1429]]), 'layers.1.bias': tensor([-0.0532]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0002, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0005,  0.0008,\n",
       "           0.0062, -0.0031,  0.0000]])}, objective=1.2176744880209134, loss=0.7592150568962097, val_objective=1.2177669944296048, val_loss=0.7593075633049011, regularization=0.010829919017851353, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=43.17932747016745, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0302, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0438, -0.0302,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0617, -0.0302, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0617, -0.0302, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0319,  0.0080, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0342, -0.0302, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0575,  0.0937,  0.0855,  0.0025, -0.1503,\n",
       "          0.0076, -0.0830,  0.0723,  0.0932,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0641, -0.1002,  0.1482, -0.0036,  0.0465,  0.1478, -0.1012,  0.0474,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0497, -0.0461,  0.1066, -0.0159,  0.0340,\n",
       "         -0.0319, -0.0403, -0.0283, -0.1373, -0.0080,  0.0669,  0.1124,  0.0500,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0396,  0.1189, -0.0151, -0.0680,  0.0058,\n",
       "          0.0384,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1432, -0.1726, -0.0848,  0.0707, -0.1408, -0.0864, -0.0426,\n",
       "           0.1850, -0.0437,  0.0411, -0.0815,  0.0884, -0.0031, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1167,  0.0170, -0.0784, -0.0844,\n",
       "          -0.0768,  0.1263,  0.0813,  0.1142,  0.1150, -0.0376, -0.1428,  0.1471,\n",
       "           0.0287,  0.0743, -0.0993,  0.1594,  0.0918, -0.1142,  0.2353, -0.0578,\n",
       "          -0.1270,  0.0651,  0.1510, -0.0999,  0.0650,  0.1371, -0.1026, -0.0994,\n",
       "          -0.1018, -0.1429]]), 'layers.1.bias': tensor([-0.0531]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0002, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0005,  0.0007,\n",
       "           0.0062, -0.0030,  0.0000]])}, objective=1.2172702417694314, loss=0.7592516541481018, val_objective=1.2173554168068155, val_loss=0.7593368291854858, regularization=0.010607358068227768, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=44.0429140195708, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0297, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0440, -0.0297,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0611, -0.0297, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0611, -0.0297, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0320,  0.0081, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0340, -0.0297, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0575,  0.0937,  0.0855,  0.0025, -0.1503,\n",
       "          0.0077, -0.0830,  0.0724,  0.0932,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0640, -0.1002,  0.1483, -0.0036,  0.0464,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0496, -0.0460,  0.1066, -0.0158,  0.0340,\n",
       "         -0.0319, -0.0402, -0.0284, -0.1373, -0.0081,  0.0671,  0.1124,  0.0500,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0395,  0.1189, -0.0150, -0.0680,  0.0058,\n",
       "          0.0384,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1433, -0.1726, -0.0848,  0.0707, -0.1408, -0.0864, -0.0426,\n",
       "           0.1850, -0.0437,  0.0411, -0.0815,  0.0885, -0.0031, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1167,  0.0169, -0.0784, -0.0844,\n",
       "          -0.0768,  0.1264,  0.0813,  0.1142,  0.1150, -0.0377, -0.1429,  0.1472,\n",
       "           0.0287,  0.0744, -0.0993,  0.1594,  0.0918, -0.1143,  0.2354, -0.0578,\n",
       "          -0.1270,  0.0652,  0.1511, -0.0999,  0.0649,  0.1371, -0.1026, -0.0994,\n",
       "          -0.1018, -0.1428]]), 'layers.1.bias': tensor([-0.0530]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0001, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0005,  0.0007,\n",
       "           0.0061, -0.0030,  0.0000]])}, objective=1.2164735744559299, loss=0.7592899203300476, val_objective=1.2165498087965976, val_loss=0.7593661546707153, regularization=0.010380413383245468, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=44.923772299962216, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0292, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0441, -0.0292,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0606, -0.0292, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0606, -0.0292, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0320,  0.0082, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0339, -0.0292, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0426,  0.0575,  0.0937,  0.0854,  0.0024, -0.1503,\n",
       "          0.0077, -0.0830,  0.0724,  0.0932,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0640, -0.1002,  0.1483, -0.0037,  0.0463,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0496, -0.0459,  0.1066, -0.0158,  0.0340,\n",
       "         -0.0319, -0.0402, -0.0285, -0.1373, -0.0081,  0.0672,  0.1124,  0.0499,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0394,  0.1189, -0.0148, -0.0680,  0.0059,\n",
       "          0.0384,  0.1194]), 'layers.1.weight': tensor([[ 0.0453,  0.1434, -0.1727, -0.0848,  0.0708, -0.1407, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0815,  0.0886, -0.0031, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1167,  0.0168, -0.0784, -0.0843,\n",
       "          -0.0768,  0.1265,  0.0813,  0.1142,  0.1151, -0.0377, -0.1429,  0.1472,\n",
       "           0.0287,  0.0744, -0.0993,  0.1594,  0.0918, -0.1144,  0.2355, -0.0578,\n",
       "          -0.1270,  0.0653,  0.1511, -0.0999,  0.0648,  0.1372, -0.1026, -0.0995,\n",
       "          -0.1019, -0.1428]]), 'layers.1.bias': tensor([-0.0530]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -9.8314e-05, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -4.1855e-04,  6.5234e-04,  6.0577e-03,\n",
       "          -2.9219e-03,  0.0000e+00]])}, objective=1.2152522754662176, loss=0.7593302726745605, val_objective=1.215319569110169, val_loss=0.759397566318512, regularization=0.01014879159629345, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=45.82224774596146, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0287, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0442, -0.0287,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0600, -0.0287, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0600, -0.0287, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0321,  0.0083, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0338, -0.0287, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0425,  0.0575,  0.0937,  0.0854,  0.0024, -0.1503,\n",
       "          0.0078, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0640, -0.1002,  0.1483, -0.0038,  0.0461,  0.1478, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0495, -0.0458,  0.1066, -0.0158,  0.0341,\n",
       "         -0.0319, -0.0401, -0.0285, -0.1373, -0.0082,  0.0674,  0.1124,  0.0498,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0394,  0.1189, -0.0147, -0.0680,  0.0059,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1435, -0.1727, -0.0848,  0.0708, -0.1407, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0815,  0.0887, -0.0031, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1167,  0.0167, -0.0784, -0.0843,\n",
       "          -0.0768,  0.1266,  0.0813,  0.1142,  0.1151, -0.0377, -0.1429,  0.1473,\n",
       "           0.0288,  0.0744, -0.0994,  0.1594,  0.0918, -0.1145,  0.2357, -0.0578,\n",
       "          -0.1270,  0.0654,  0.1512, -0.0999,  0.0647,  0.1373, -0.1026, -0.0995,\n",
       "          -0.1019, -0.1427]]), 'layers.1.bias': tensor([-0.0529]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -5.2223e-05, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -3.7851e-04,  6.0634e-04,  6.0030e-03,\n",
       "          -2.8734e-03,  0.0000e+00]])}, objective=1.213628450944734, loss=0.759372353553772, val_objective=1.2136869231012586, val_loss=0.7594308257102966, regularization=0.009913439862430096, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=46.73869270088069, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0282, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0443, -0.0282,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0595, -0.0282, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0595, -0.0282, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0322,  0.0084, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0337, -0.0282, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0425,  0.0575,  0.0937,  0.0854,  0.0024, -0.1503,\n",
       "          0.0078, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0639, -0.1002,  0.1483, -0.0038,  0.0460,  0.1478, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0495, -0.0457,  0.1066, -0.0157,  0.0341,\n",
       "         -0.0319, -0.0401, -0.0286, -0.1373, -0.0083,  0.0676,  0.1125,  0.0498,\n",
       "         -0.0627,  0.0346,  0.1254, -0.0393,  0.1189, -0.0145, -0.0681,  0.0059,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1436, -0.1728, -0.0847,  0.0708, -0.1407, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0816,  0.0888, -0.0030, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0192,  0.0701, -0.1167,  0.0166, -0.0784, -0.0842,\n",
       "          -0.0768,  0.1267,  0.0813,  0.1142,  0.1151, -0.0377, -0.1429,  0.1473,\n",
       "           0.0288,  0.0744, -0.0994,  0.1594,  0.0918, -0.1146,  0.2358, -0.0579,\n",
       "          -0.1270,  0.0655,  0.1513, -0.0999,  0.0646,  0.1373, -0.1026, -0.0995,\n",
       "          -0.1020, -0.1427]]), 'layers.1.bias': tensor([-0.0529]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -5.2765e-06, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -3.3760e-04,  5.5941e-04,  5.9475e-03,\n",
       "          -2.8239e-03,  0.0000e+00]])}, objective=1.2115494732091232, loss=0.7594173550605774, val_objective=1.2115984682271286, val_loss=0.7594663500785827, regularization=0.009673614986240864, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=47.673466554898305, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0277, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0444, -0.0277,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0589, -0.0277, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0589, -0.0277, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0322,  0.0086, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0336, -0.0277, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0424,  0.0575,  0.0937,  0.0854,  0.0023, -0.1503,\n",
       "          0.0078, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0639, -0.1002,  0.1483, -0.0039,  0.0459,  0.1478, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0494, -0.0456,  0.1066, -0.0157,  0.0341,\n",
       "         -0.0319, -0.0400, -0.0287, -0.1373, -0.0084,  0.0678,  0.1125,  0.0497,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0392,  0.1189, -0.0144, -0.0681,  0.0060,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1437, -0.1728, -0.0847,  0.0709, -0.1407, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0816,  0.0889, -0.0030, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0193,  0.0701, -0.1167,  0.0165, -0.0784, -0.0842,\n",
       "          -0.0768,  0.1268,  0.0813,  0.1142,  0.1152, -0.0377, -0.1429,  0.1474,\n",
       "           0.0288,  0.0745, -0.0994,  0.1594,  0.0918, -0.1147,  0.2359, -0.0579,\n",
       "          -0.1270,  0.0656,  0.1513, -0.0999,  0.0645,  0.1374, -0.1026, -0.0995,\n",
       "          -0.1020, -0.1426]]), 'layers.1.bias': tensor([-0.0528]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0003,  0.0005,\n",
       "           0.0059, -0.0028,  0.0000]])}, objective=1.2110083808000944, loss=0.759465754032135, val_objective=1.2110456933077238, val_loss=0.7595030665397644, regularization=0.009471571072936058, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=48.62693588599627, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0272, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0446, -0.0272,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0583, -0.0272, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0583, -0.0272, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0323,  0.0087, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0334, -0.0272, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0423,  0.0575,  0.0937,  0.0854,  0.0023, -0.1503,\n",
       "          0.0079, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0639, -0.1002,  0.1483, -0.0039,  0.0457,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0494, -0.0455,  0.1066, -0.0157,  0.0341,\n",
       "         -0.0319, -0.0399, -0.0287, -0.1373, -0.0084,  0.0679,  0.1125,  0.0496,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0392,  0.1189, -0.0142, -0.0681,  0.0060,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1438, -0.1729, -0.0847,  0.0709, -0.1406, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0816,  0.0890, -0.0030, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0193,  0.0701, -0.1167,  0.0165, -0.0784, -0.0842,\n",
       "          -0.0768,  0.1269,  0.0813,  0.1142,  0.1152, -0.0378, -0.1430,  0.1474,\n",
       "           0.0288,  0.0745, -0.0994,  0.1594,  0.0918, -0.1147,  0.2360, -0.0579,\n",
       "          -0.1270,  0.0657,  0.1514, -0.1000,  0.0644,  0.1375, -0.1026, -0.0996,\n",
       "          -0.1021, -0.1426]]), 'layers.1.bias': tensor([-0.0527]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0003,  0.0005,\n",
       "           0.0058, -0.0027,  0.0000]])}, objective=1.2103740925153534, loss=0.759519100189209, val_objective=1.21039888804758, val_loss=0.7595438957214355, regularization=0.009271712973713875, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=49.599474603716196, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0267, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0447, -0.0267,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0577, -0.0267, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0577, -0.0267, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0324,  0.0088, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0333, -0.0267, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0422,  0.0575,  0.0937,  0.0854,  0.0023, -0.1503,\n",
       "          0.0079, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0639, -0.1002,  0.1483, -0.0040,  0.0456,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0493, -0.0453,  0.1066, -0.0156,  0.0341,\n",
       "         -0.0319, -0.0399, -0.0288, -0.1373, -0.0085,  0.0680,  0.1125,  0.0496,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0391,  0.1189, -0.0141, -0.0681,  0.0060,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1439, -0.1729, -0.0846,  0.0709, -0.1406, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0816,  0.0891, -0.0030, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0193,  0.0701, -0.1167,  0.0164, -0.0784, -0.0841,\n",
       "          -0.0768,  0.1270,  0.0813,  0.1142,  0.1152, -0.0378, -0.1430,  0.1475,\n",
       "           0.0288,  0.0745, -0.0994,  0.1594,  0.0918, -0.1148,  0.2361, -0.0579,\n",
       "          -0.1270,  0.0658,  0.1515, -0.1000,  0.0643,  0.1375, -0.1026, -0.0996,\n",
       "          -0.1021, -0.1425]]), 'layers.1.bias': tensor([-0.0526]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0002,  0.0004,\n",
       "           0.0058, -0.0027,  0.0000]])}, objective=1.2094995642964141, loss=0.7595834732055664, val_objective=1.2095057631794708, val_loss=0.759589672088623, regularization=0.009070985019207, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=50.59146409579052, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0262, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0448, -0.0262,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0571, -0.0262, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0571, -0.0262, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0325,  0.0089, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0332, -0.0262, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0420,  0.0575,  0.0937,  0.0854,  0.0023, -0.1503,\n",
       "          0.0080, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0041,  0.0455,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0492, -0.0452,  0.1066, -0.0156,  0.0342,\n",
       "         -0.0319, -0.0398, -0.0289, -0.1373, -0.0086,  0.0681,  0.1125,  0.0495,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0390,  0.1189, -0.0139, -0.0681,  0.0061,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1440, -0.1729, -0.0846,  0.0710, -0.1406, -0.0864, -0.0426,\n",
       "           0.1851, -0.0437,  0.0411, -0.0816,  0.0892, -0.0029, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0193,  0.0701, -0.1168,  0.0163, -0.0784, -0.0841,\n",
       "          -0.0768,  0.1271,  0.0813,  0.1142,  0.1152, -0.0378, -0.1430,  0.1475,\n",
       "           0.0288,  0.0746, -0.0995,  0.1594,  0.0918, -0.1149,  0.2362, -0.0579,\n",
       "          -0.1270,  0.0658,  0.1515, -0.1000,  0.0642,  0.1376, -0.1026, -0.0996,\n",
       "          -0.1021, -0.1424]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0002,  0.0004,\n",
       "           0.0057, -0.0026,  0.0000]])}, objective=1.2082941492252337, loss=0.7596496343612671, val_objective=1.2082828243427264, val_loss=0.7596383094787598, regularization=0.008867988362908363, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=51.60329337770633, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0257, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0449, -0.0257,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0565, -0.0257, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0565, -0.0257, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0326,  0.0091, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0331, -0.0257, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0418,  0.0575,  0.0938,  0.0854,  0.0022, -0.1503,\n",
       "          0.0080, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0042,  0.0453,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0492, -0.0451,  0.1066, -0.0156,  0.0342,\n",
       "         -0.0319, -0.0397, -0.0290, -0.1373, -0.0087,  0.0681,  0.1126,  0.0494,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0390,  0.1189, -0.0137, -0.0681,  0.0061,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1441, -0.1730, -0.0846,  0.0710, -0.1405, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0411, -0.0816,  0.0894, -0.0029, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0193,  0.0701, -0.1168,  0.0162, -0.0784, -0.0840,\n",
       "          -0.0768,  0.1272,  0.0813,  0.1142,  0.1153, -0.0378, -0.1430,  0.1476,\n",
       "           0.0288,  0.0746, -0.0995,  0.1594,  0.0918, -0.1150,  0.2363, -0.0579,\n",
       "          -0.1270,  0.0659,  0.1516, -0.1000,  0.0642,  0.1376, -0.1026, -0.0996,\n",
       "          -0.1022, -0.1424]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0001,  0.0003,\n",
       "           0.0057, -0.0026,  0.0000]])}, objective=1.2067349687350195, loss=0.7597249746322632, val_objective=1.2067020073664587, val_loss=0.7596920132637024, regularization=0.008662431500852108, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=52.63535924526046, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0251, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0451, -0.0251,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0559, -0.0251, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0559, -0.0251, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0327,  0.0092, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0329, -0.0251, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0417,  0.0575,  0.0938,  0.0854,  0.0022, -0.1503,\n",
       "          0.0081, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0042,  0.0452,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0491, -0.0450,  0.1066, -0.0155,  0.0342,\n",
       "         -0.0319, -0.0397, -0.0291, -0.1373, -0.0087,  0.0682,  0.1126,  0.0494,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0389,  0.1189, -0.0136, -0.0681,  0.0062,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1442, -0.1730, -0.0845,  0.0710, -0.1405, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0411, -0.0816,  0.0895, -0.0029, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0194,  0.0701, -0.1168,  0.0161, -0.0784, -0.0840,\n",
       "          -0.0768,  0.1273,  0.0813,  0.1142,  0.1153, -0.0378, -0.1430,  0.1476,\n",
       "           0.0289,  0.0746, -0.0995,  0.1594,  0.0918, -0.1151,  0.2364, -0.0580,\n",
       "          -0.1270,  0.0660,  0.1517, -0.1000,  0.0641,  0.1377, -0.1026, -0.0997,\n",
       "          -0.1022, -0.1423]]), 'layers.1.bias': tensor([-0.0524]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -9.1154e-05,  2.5752e-04,  5.5919e-03,\n",
       "          -2.5133e-03,  0.0000e+00]])}, objective=1.2047794523321533, loss=0.7598059773445129, val_objective=1.2047214570127869, val_loss=0.7597479820251465, regularization=0.008453888818621635, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=53.68806643016567, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0246, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0452, -0.0246,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0553, -0.0246, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0553, -0.0246, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0328,  0.0093, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0328, -0.0246, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0415,  0.0575,  0.0938,  0.0853,  0.0022, -0.1503,\n",
       "          0.0081, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0043,  0.0451,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0491, -0.0449,  0.1066, -0.0155,  0.0342,\n",
       "         -0.0319, -0.0396, -0.0293, -0.1373, -0.0088,  0.0682,  0.1126,  0.0493,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0389,  0.1189, -0.0134, -0.0681,  0.0062,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1443, -0.1731, -0.0845,  0.0711, -0.1405, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0411, -0.0817,  0.0896, -0.0029, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0194,  0.0701, -0.1168,  0.0161, -0.0784, -0.0840,\n",
       "          -0.0768,  0.1274,  0.0813,  0.1142,  0.1153, -0.0378, -0.1431,  0.1476,\n",
       "           0.0289,  0.0746, -0.0995,  0.1594,  0.0918, -0.1152,  0.2365, -0.0580,\n",
       "          -0.1270,  0.0661,  0.1518, -0.1000,  0.0640,  0.1378, -0.1026, -0.0997,\n",
       "          -0.1023, -0.1422]]), 'layers.1.bias': tensor([-0.0523]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -5.1007e-05,  2.0364e-04,  5.5285e-03,\n",
       "          -2.4587e-03,  0.0000e+00]])}, objective=1.2023842471637949, loss=0.759894609451294, val_objective=1.2022975820102915, val_loss=0.7598079442977905, regularization=0.008241862058639526, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=54.76182775876898, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0240, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0453, -0.0240,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0546, -0.0240, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0546, -0.0240, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0329,  0.0095, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0327, -0.0240, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0413,  0.0575,  0.0938,  0.0853,  0.0022, -0.1503,\n",
       "          0.0081, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0044,  0.0449,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0490, -0.0448,  0.1066, -0.0155,  0.0342,\n",
       "         -0.0319, -0.0395, -0.0294, -0.1373, -0.0088,  0.0682,  0.1126,  0.0492,\n",
       "         -0.0627,  0.0346,  0.1255, -0.0388,  0.1189, -0.0132, -0.0681,  0.0062,\n",
       "          0.0384,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1444, -0.1731, -0.0845,  0.0711, -0.1405, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0411, -0.0817,  0.0897, -0.0029, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0194,  0.0701, -0.1169,  0.0160, -0.0784, -0.0839,\n",
       "          -0.0768,  0.1275,  0.0813,  0.1142,  0.1154, -0.0379, -0.1431,  0.1477,\n",
       "           0.0289,  0.0747, -0.0995,  0.1594,  0.0918, -0.1153,  0.2366, -0.0580,\n",
       "          -0.1270,  0.0662,  0.1518, -0.1000,  0.0639,  0.1378, -0.1026, -0.0997,\n",
       "          -0.1023, -0.1422]]), 'layers.1.bias': tensor([-0.0522]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -1.0075e-05,  1.4867e-04,  5.4639e-03,\n",
       "          -2.4029e-03,  0.0000e+00]])}, objective=1.1994797021139931, loss=0.7599868178367615, val_objective=1.199364545940287, val_loss=0.7598716616630554, regularization=0.008025533519685268, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=55.85706431394436, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0235, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0455, -0.0235,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0540, -0.0235, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0540, -0.0235, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0330,  0.0096, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0325, -0.0235, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0411,  0.0575,  0.0938,  0.0853,  0.0022, -0.1503,\n",
       "          0.0082, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0045,  0.0448,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0490, -0.0446,  0.1066, -0.0154,  0.0342,\n",
       "         -0.0319, -0.0394, -0.0295, -0.1373, -0.0089,  0.0682,  0.1126,  0.0492,\n",
       "         -0.0627,  0.0346,  0.1256, -0.0388,  0.1190, -0.0130, -0.0681,  0.0063,\n",
       "          0.0384,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1445, -0.1731, -0.0844,  0.0711, -0.1405, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0411, -0.0817,  0.0898, -0.0028, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0194,  0.0701, -0.1169,  0.0159, -0.0784, -0.0839,\n",
       "          -0.0768,  0.1276,  0.0813,  0.1142,  0.1154, -0.0379, -0.1431,  0.1477,\n",
       "           0.0289,  0.0747, -0.0996,  0.1594,  0.0918, -0.1154,  0.2367, -0.0580,\n",
       "          -0.1270,  0.0663,  0.1519, -0.1000,  0.0638,  0.1379, -0.1026, -0.0997,\n",
       "          -0.1024, -0.1421]]), 'layers.1.bias': tensor([-0.0521]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00,  9.2593e-05,  5.3979e-03,\n",
       "          -2.3460e-03,  0.0000e+00]])}, objective=1.1977721778379768, loss=0.7600504159927368, val_objective=1.1976400939451546, val_loss=0.7599183320999146, regularization=0.007836461998522282, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=56.97420560022325, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0229, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0456, -0.0229,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0533, -0.0229, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0533, -0.0229, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0331,  0.0097, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0324, -0.0229, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0409,  0.0574,  0.0938,  0.0853,  0.0021, -0.1503,\n",
       "          0.0082, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0046,  0.0446,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0490, -0.0445,  0.1066, -0.0154,  0.0342,\n",
       "         -0.0319, -0.0394, -0.0296, -0.1373, -0.0090,  0.0682,  0.1127,  0.0491,\n",
       "         -0.0627,  0.0346,  0.1256, -0.0387,  0.1190, -0.0129, -0.0681,  0.0063,\n",
       "          0.0384,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1446, -0.1732, -0.0844,  0.0712, -0.1404, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0410, -0.0817,  0.0899, -0.0028, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0195,  0.0701, -0.1169,  0.0158, -0.0784, -0.0838,\n",
       "          -0.0768,  0.1277,  0.0813,  0.1142,  0.1154, -0.0379, -0.1431,  0.1477,\n",
       "           0.0289,  0.0747, -0.0996,  0.1594,  0.0918, -0.1154,  0.2368, -0.0581,\n",
       "          -0.1270,  0.0664,  0.1520, -0.1000,  0.0638,  0.1379, -0.1026, -0.0998,\n",
       "          -0.1024, -0.1420]]), 'layers.1.bias': tensor([-0.0520]), 'skip.weight': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          -0.0000e+00,  0.0000e+00, -0.0000e+00,  3.6408e-05,  5.3306e-03,\n",
       "          -2.2878e-03,  0.0000e+00]])}, objective=1.1962146459925544, loss=0.7600869536399841, val_objective=1.1960863767969978, val_loss=0.7599586844444275, regularization=0.0076548270881175995, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=58.11368971222772, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0223, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0458, -0.0223,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0526, -0.0223, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0526, -0.0223, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0332,  0.0099, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0323, -0.0223, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0407,  0.0574,  0.0938,  0.0853,  0.0021, -0.1503,\n",
       "          0.0083, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0047,  0.0445,  0.1478, -0.1012,  0.0471,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0489, -0.0444,  0.1066, -0.0154,  0.0343,\n",
       "         -0.0319, -0.0393, -0.0297, -0.1373, -0.0090,  0.0681,  0.1127,  0.0490,\n",
       "         -0.0627,  0.0346,  0.1256, -0.0387,  0.1190, -0.0127, -0.0681,  0.0063,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1447, -0.1732, -0.0843,  0.0712, -0.1404, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0410, -0.0817,  0.0900, -0.0028, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0195,  0.0701, -0.1169,  0.0158, -0.0784, -0.0838,\n",
       "          -0.0768,  0.1278,  0.0813,  0.1142,  0.1154, -0.0379, -0.1431,  0.1477,\n",
       "           0.0289,  0.0748, -0.0996,  0.1594,  0.0918, -0.1155,  0.2369, -0.0581,\n",
       "          -0.1270,  0.0665,  0.1521, -0.1000,  0.0637,  0.1380, -0.1026, -0.0998,\n",
       "          -0.1024, -0.1419]]), 'layers.1.bias': tensor([-0.0519]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0053, -0.0022,  0.0000]])}, objective=1.1954184433625357, loss=0.7601240277290344, val_objective=1.1952911874459402, val_loss=0.759996771812439, regularization=0.007490393705666065, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=59.27596350647227, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0217, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0459, -0.0217,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0519, -0.0217, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0519, -0.0217, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0333,  0.0100, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0321, -0.0217, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0404,  0.0574,  0.0938,  0.0853,  0.0021, -0.1503,\n",
       "          0.0083, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0048,  0.0444,  0.1478, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0489, -0.0443,  0.1066, -0.0153,  0.0343,\n",
       "         -0.0319, -0.0392, -0.0299, -0.1373, -0.0091,  0.0681,  0.1127,  0.0489,\n",
       "         -0.0627,  0.0346,  0.1256, -0.0387,  0.1190, -0.0125, -0.0681,  0.0063,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1447, -0.1732, -0.0843,  0.0712, -0.1404, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0410, -0.0818,  0.0901, -0.0028, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0195,  0.0701, -0.1170,  0.0157, -0.0784, -0.0838,\n",
       "          -0.0768,  0.1279,  0.0813,  0.1142,  0.1155, -0.0379, -0.1431,  0.1478,\n",
       "           0.0289,  0.0748, -0.0996,  0.1594,  0.0918, -0.1156,  0.2370, -0.0581,\n",
       "          -0.1270,  0.0666,  0.1521, -0.1000,  0.0636,  0.1380, -0.1026, -0.0998,\n",
       "          -0.1025, -0.1419]]), 'layers.1.bias': tensor([-0.0518]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0052, -0.0022,  0.0000]])}, objective=1.196414445321136, loss=0.760158360004425, val_objective=1.196286295334869, val_loss=0.760030210018158, regularization=0.007359746843576431, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=60.46148277660172, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0211, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0460, -0.0211,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0512, -0.0211, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0512, -0.0211, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0334,  0.0102, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0320, -0.0211, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0402,  0.0574,  0.0938,  0.0853,  0.0021, -0.1503,\n",
       "          0.0084, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0049,  0.0442,  0.1479, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0488, -0.0442,  0.1066, -0.0153,  0.0343,\n",
       "         -0.0319, -0.0391, -0.0300, -0.1373, -0.0091,  0.0681,  0.1127,  0.0489,\n",
       "         -0.0627,  0.0346,  0.1256, -0.0386,  0.1190, -0.0123, -0.0681,  0.0063,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1448, -0.1733, -0.0842,  0.0713, -0.1403, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0410, -0.0818,  0.0902, -0.0027, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0196,  0.0701, -0.1170,  0.0156, -0.0784, -0.0838,\n",
       "          -0.0768,  0.1280,  0.0813,  0.1142,  0.1155, -0.0379, -0.1432,  0.1478,\n",
       "           0.0289,  0.0748, -0.0996,  0.1594,  0.0918, -0.1157,  0.2371, -0.0581,\n",
       "          -0.1270,  0.0667,  0.1522, -0.1000,  0.0635,  0.1381, -0.1026, -0.0998,\n",
       "          -0.1025, -0.1418]]), 'layers.1.bias': tensor([-0.0518]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0051, -0.0021,  0.0000]])}, objective=1.1971156711752302, loss=0.7601943016052246, val_objective=1.1969874615843183, val_loss=0.7600660920143127, regularization=0.0072264415211975574, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=61.670712432133755, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0204, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0462, -0.0204,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0505, -0.0204, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0505, -0.0204, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0335,  0.0103, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0318, -0.0204, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0400,  0.0574,  0.0938,  0.0853,  0.0020, -0.1503,\n",
       "          0.0084, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0050,  0.0441,  0.1479, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0488, -0.0440,  0.1066, -0.0153,  0.0343,\n",
       "         -0.0319, -0.0390, -0.0301, -0.1373, -0.0092,  0.0681,  0.1127,  0.0488,\n",
       "         -0.0627,  0.0345,  0.1256, -0.0386,  0.1190, -0.0121, -0.0681,  0.0064,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1449, -0.1733, -0.0842,  0.0713, -0.1403, -0.0864, -0.0426,\n",
       "           0.1852, -0.0437,  0.0410, -0.0818,  0.0903, -0.0027, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0196,  0.0701, -0.1170,  0.0155, -0.0784, -0.0837,\n",
       "          -0.0768,  0.1281,  0.0813,  0.1142,  0.1155, -0.0379, -0.1432,  0.1478,\n",
       "           0.0289,  0.0748, -0.0996,  0.1594,  0.0917, -0.1158,  0.2372, -0.0581,\n",
       "          -0.1270,  0.0668,  0.1523, -0.1000,  0.0635,  0.1382, -0.1026, -0.0998,\n",
       "          -0.1026, -0.1417]]), 'layers.1.bias': tensor([-0.0517]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0050, -0.0020,  0.0000]])}, objective=1.1975057249757926, loss=0.7602320313453674, val_objective=1.1973785286638419, val_loss=0.7601048350334167, regularization=0.007090459577739239, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=62.90412668077643, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0198, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0463, -0.0198,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0497, -0.0198, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0497, -0.0198, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0336,  0.0105, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0317, -0.0198, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0398,  0.0574,  0.0938,  0.0853,  0.0020, -0.1503,\n",
       "          0.0085, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0051,  0.0439,  0.1479, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0488, -0.0439,  0.1066, -0.0152,  0.0343,\n",
       "         -0.0319, -0.0389, -0.0302, -0.1373, -0.0092,  0.0681,  0.1127,  0.0487,\n",
       "         -0.0627,  0.0345,  0.1256, -0.0385,  0.1190, -0.0119, -0.0681,  0.0064,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1450, -0.1734, -0.0841,  0.0713, -0.1403, -0.0864, -0.0426,\n",
       "           0.1853, -0.0437,  0.0410, -0.0818,  0.0903, -0.0027, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0196,  0.0701, -0.1170,  0.0155, -0.0784, -0.0837,\n",
       "          -0.0768,  0.1282,  0.0813,  0.1142,  0.1155, -0.0379, -0.1432,  0.1478,\n",
       "           0.0289,  0.0749, -0.0996,  0.1594,  0.0917, -0.1158,  0.2373, -0.0582,\n",
       "          -0.1270,  0.0669,  0.1523, -0.1000,  0.0634,  0.1382, -0.1026, -0.0999,\n",
       "          -0.1026, -0.1417]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0050, -0.0020,  0.0000]])}, objective=1.197666048230676, loss=0.7602723836898804, val_objective=1.197541593732385, val_loss=0.7601479291915894, regularization=0.006953338161110878, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=64.16220921439196, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0192, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0465, -0.0192,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0490, -0.0192, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0490, -0.0192, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0337,  0.0106, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0315, -0.0192, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0396,  0.0574,  0.0938,  0.0853,  0.0020, -0.1503,\n",
       "          0.0085, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0052,  0.0438,  0.1479, -0.1012,  0.0472,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0437,  0.1066, -0.0152,  0.0343,\n",
       "         -0.0319, -0.0389, -0.0304, -0.1373, -0.0093,  0.0681,  0.1128,  0.0487,\n",
       "         -0.0627,  0.0345,  0.1256, -0.0385,  0.1190, -0.0117, -0.0681,  0.0064,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1451, -0.1734, -0.0841,  0.0713, -0.1403, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0409, -0.0818,  0.0904, -0.0027, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0197,  0.0701, -0.1171,  0.0154, -0.0784, -0.0837,\n",
       "          -0.0768,  0.1283,  0.0813,  0.1142,  0.1155, -0.0380, -0.1432,  0.1479,\n",
       "           0.0289,  0.0749, -0.0997,  0.1594,  0.0917, -0.1159,  0.2374, -0.0582,\n",
       "          -0.1270,  0.0670,  0.1524, -0.1000,  0.0633,  0.1383, -0.1026, -0.0999,\n",
       "          -0.1027, -0.1416]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0049, -0.0019,  0.0000]])}, objective=1.19748260590578, loss=0.7603146433830261, val_objective=1.1973611912443725, val_loss=0.7601932287216187, regularization=0.006813480518758297, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=65.4454533986798, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0185, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0467, -0.0185,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0482, -0.0185, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0482, -0.0185, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0338,  0.0108, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0314, -0.0185, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0394,  0.0574,  0.0938,  0.0853,  0.0020, -0.1503,\n",
       "          0.0086, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0053,  0.0437,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0436,  0.1066, -0.0151,  0.0343,\n",
       "         -0.0319, -0.0388, -0.0305, -0.1373, -0.0094,  0.0681,  0.1128,  0.0486,\n",
       "         -0.0627,  0.0345,  0.1256, -0.0384,  0.1190, -0.0115, -0.0681,  0.0064,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1452, -0.1734, -0.0841,  0.0714, -0.1402, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0409, -0.0819,  0.0905, -0.0027, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0197,  0.0700, -0.1171,  0.0153, -0.0784, -0.0836,\n",
       "          -0.0768,  0.1284,  0.0813,  0.1142,  0.1155, -0.0380, -0.1432,  0.1479,\n",
       "           0.0289,  0.0749, -0.0997,  0.1594,  0.0917, -0.1160,  0.2375, -0.0582,\n",
       "          -0.1270,  0.0670,  0.1525, -0.1000,  0.0632,  0.1383, -0.1026, -0.0999,\n",
       "          -0.1027, -0.1415]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0048, -0.0019,  0.0000]])}, objective=1.1969280401453388, loss=0.7603577375411987, val_objective=1.1968103209719074, val_loss=0.7602400183677672, regularization=0.006670750677585602, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=66.7543624666534, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0178, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0468, -0.0178,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0474, -0.0178, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0474, -0.0178, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0339,  0.0109, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0312, -0.0178, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0392,  0.0574,  0.0938,  0.0853,  0.0019, -0.1503,\n",
       "          0.0087, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0054,  0.0435,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0434,  0.1066, -0.0151,  0.0343,\n",
       "         -0.0319, -0.0387, -0.0306, -0.1373, -0.0094,  0.0681,  0.1128,  0.0485,\n",
       "         -0.0627,  0.0345,  0.1256, -0.0384,  0.1190, -0.0114, -0.0681,  0.0065,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1453, -0.1735, -0.0840,  0.0714, -0.1402, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0409, -0.0819,  0.0906, -0.0026, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0197,  0.0700, -0.1171,  0.0152, -0.0784, -0.0836,\n",
       "          -0.0768,  0.1285,  0.0813,  0.1142,  0.1156, -0.0380, -0.1432,  0.1479,\n",
       "           0.0289,  0.0749, -0.0997,  0.1594,  0.0917, -0.1161,  0.2376, -0.0582,\n",
       "          -0.1270,  0.0671,  0.1525, -0.1000,  0.0631,  0.1384, -0.1026, -0.0999,\n",
       "          -0.1028, -0.1415]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0047, -0.0018,  0.0000]])}, objective=1.1959744779903492, loss=0.7604016661643982, val_objective=1.1958612887699207, val_loss=0.7602884769439697, regularization=0.0065250089392066, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=68.08944971598648, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0172, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0466, -0.0172,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0466, -0.0172, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0466, -0.0172, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0340,  0.0111, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0311, -0.0172, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0390,  0.0574,  0.0938,  0.0853,  0.0019, -0.1503,\n",
       "          0.0087, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0055,  0.0434,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0432,  0.1066, -0.0150,  0.0343,\n",
       "         -0.0319, -0.0386, -0.0307, -0.1373, -0.0095,  0.0681,  0.1128,  0.0485,\n",
       "         -0.0627,  0.0344,  0.1256, -0.0383,  0.1190, -0.0112, -0.0681,  0.0065,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1453, -0.1735, -0.0840,  0.0714, -0.1402, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0409, -0.0819,  0.0907, -0.0026, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0197,  0.0700, -0.1172,  0.0151, -0.0784, -0.0836,\n",
       "          -0.0768,  0.1286,  0.0813,  0.1142,  0.1156, -0.0380, -0.1432,  0.1479,\n",
       "           0.0289,  0.0749, -0.0997,  0.1594,  0.0917, -0.1162,  0.2376, -0.0583,\n",
       "          -0.1270,  0.0672,  0.1526, -0.1000,  0.0630,  0.1384, -0.1026, -0.0999,\n",
       "          -0.1028, -0.1414]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0047, -0.0017,  0.0000]])}, objective=1.194707954164914, loss=0.7604468464851379, val_objective=1.194601261850766, val_loss=0.76034015417099, regularization=0.006377803161740303, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=69.4512387103062, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0165, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0458, -0.0165,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0458, -0.0165, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0458, -0.0165, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0341,  0.0112, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0309, -0.0165, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0388,  0.0574,  0.0938,  0.0853,  0.0019, -0.1503,\n",
       "          0.0088, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0056,  0.0432,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0431,  0.1066, -0.0150,  0.0343,\n",
       "         -0.0319, -0.0385, -0.0309, -0.1373, -0.0096,  0.0681,  0.1127,  0.0485,\n",
       "         -0.0627,  0.0344,  0.1256, -0.0383,  0.1190, -0.0110, -0.0681,  0.0065,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1454, -0.1735, -0.0839,  0.0714, -0.1402, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0408, -0.0819,  0.0908, -0.0026, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0198,  0.0700, -0.1172,  0.0150, -0.0784, -0.0836,\n",
       "          -0.0768,  0.1287,  0.0813,  0.1142,  0.1156, -0.0381, -0.1433,  0.1479,\n",
       "           0.0289,  0.0750, -0.0997,  0.1594,  0.0917, -0.1163,  0.2377, -0.0583,\n",
       "          -0.1270,  0.0673,  0.1526, -0.1000,  0.0630,  0.1385, -0.1026, -0.1000,\n",
       "          -0.1029, -0.1413]]), 'layers.1.bias': tensor([-0.0516]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0046, -0.0016,  0.0000]])}, objective=1.19312009309544, loss=0.7604940533638, val_objective=1.1930207917572442, val_loss=0.7603947520256042, regularization=0.006229205522686243, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=70.84026348451232, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0158, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0450, -0.0158,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0450, -0.0158, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0450, -0.0158, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0343,  0.0114, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0307, -0.0158, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0386,  0.0574,  0.0938,  0.0853,  0.0019, -0.1503,\n",
       "          0.0088, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0057,  0.0431,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0429,  0.1066, -0.0149,  0.0343,\n",
       "         -0.0319, -0.0384, -0.0310, -0.1373, -0.0096,  0.0681,  0.1127,  0.0485,\n",
       "         -0.0627,  0.0344,  0.1256, -0.0383,  0.1190, -0.0108, -0.0681,  0.0066,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1455, -0.1736, -0.0839,  0.0715, -0.1401, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0408, -0.0820,  0.0908, -0.0025, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0198,  0.0700, -0.1172,  0.0150, -0.0784, -0.0835,\n",
       "          -0.0768,  0.1287,  0.0813,  0.1142,  0.1156, -0.0381, -0.1433,  0.1480,\n",
       "           0.0289,  0.0750, -0.0997,  0.1594,  0.0917, -0.1164,  0.2378, -0.0583,\n",
       "          -0.1270,  0.0674,  0.1527, -0.1000,  0.0629,  0.1385, -0.1026, -0.1000,\n",
       "          -0.1030, -0.1413]]), 'layers.1.bias': tensor([-0.0517]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0045, -0.0016,  0.0000]])}, objective=1.1910795574175483, loss=0.760543167591095, val_objective=1.190987825869239, val_loss=0.7604514360427858, regularization=0.006077566184103489, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=72.25706875420256, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0151, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0442, -0.0151,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0442, -0.0151, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0442, -0.0151, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0344,  0.0116, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0305, -0.0151, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0384,  0.0574,  0.0938,  0.0853,  0.0018, -0.1503,\n",
       "          0.0089, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0058,  0.0430,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0487, -0.0427,  0.1066, -0.0149,  0.0343,\n",
       "         -0.0319, -0.0383, -0.0311, -0.1373, -0.0097,  0.0681,  0.1127,  0.0485,\n",
       "         -0.0627,  0.0344,  0.1256, -0.0383,  0.1190, -0.0105, -0.0681,  0.0066,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1456, -0.1736, -0.0838,  0.0715, -0.1401, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0408, -0.0820,  0.0909, -0.0025, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0198,  0.0700, -0.1173,  0.0149, -0.0784, -0.0835,\n",
       "          -0.0768,  0.1288,  0.0813,  0.1142,  0.1156, -0.0381, -0.1433,  0.1480,\n",
       "           0.0289,  0.0750, -0.0998,  0.1594,  0.0917, -0.1164,  0.2379, -0.0584,\n",
       "          -0.1270,  0.0675,  0.1528, -0.1000,  0.0628,  0.1386, -0.1026, -0.1000,\n",
       "          -0.1030, -0.1412]]), 'layers.1.bias': tensor([-0.0517]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0044, -0.0015,  0.0000]])}, objective=1.1885633393900514, loss=0.76059490442276, val_objective=1.1884806081431032, val_loss=0.7605121731758118, regularization=0.005922859068959951, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=73.70221012928661, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057,  0.0143, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0433, -0.0143,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0433, -0.0143, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0433, -0.0143, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0345,  0.0117, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0304, -0.0143, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1348,  0.0382,  0.0574,  0.0938,  0.0853,  0.0018, -0.1503,\n",
       "          0.0090, -0.0830,  0.0724,  0.0931,  0.1281,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0059,  0.0428,  0.1479, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1724, -0.0936, -0.0488, -0.0426,  0.1066, -0.0148,  0.0343,\n",
       "         -0.0319, -0.0382, -0.0311, -0.1373, -0.0098,  0.0681,  0.1127,  0.0485,\n",
       "         -0.0627,  0.0344,  0.1256, -0.0383,  0.1190, -0.0103, -0.0681,  0.0066,\n",
       "          0.0383,  0.1192]), 'layers.1.weight': tensor([[ 0.0453,  0.1457, -0.1737, -0.0838,  0.0715, -0.1401, -0.0863, -0.0426,\n",
       "           0.1853, -0.0437,  0.0407, -0.0820,  0.0910, -0.0025, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0198,  0.0700, -0.1173,  0.0148, -0.0784, -0.0835,\n",
       "          -0.0768,  0.1289,  0.0813,  0.1142,  0.1156, -0.0382, -0.1433,  0.1480,\n",
       "           0.0290,  0.0750, -0.0998,  0.1594,  0.0917, -0.1165,  0.2380, -0.0584,\n",
       "          -0.1270,  0.0676,  0.1528, -0.1000,  0.0627,  0.1386, -0.1026, -0.1000,\n",
       "          -0.1031, -0.1411]]), 'layers.1.bias': tensor([-0.0517]), 'skip.weight': tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "           0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "          -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "           0.0043, -0.0014,  0.0000]])}, objective=1.1855500694321033, loss=0.7606498003005981, val_objective=1.185477947811925, val_loss=0.76057767868042, regularization=0.005765095353126526, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False]), n_iters=5),\n",
       " HistoryItem(lambda_=75.17625433187234, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0270, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0270,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0270,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0270,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0257,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0008, -0.1503,\n",
       "          0.0122, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0081,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0118,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0119,  0.0682,  0.1126,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0060, -0.0681,  0.0085,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1471, -0.1746, -0.0827,  0.0723, -0.1392, -0.0858, -0.0426,\n",
       "           0.1859, -0.0437,  0.0398, -0.0823,  0.0924, -0.0016, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0206,  0.0698, -0.1182,  0.0132, -0.0784, -0.0826,\n",
       "          -0.0768,  0.1303,  0.0813,  0.1142,  0.1156, -0.0391, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1181,  0.2394, -0.0593,\n",
       "          -0.1270,  0.0690,  0.1540, -0.1000,  0.0611,  0.1394, -0.1026, -0.1006,\n",
       "          -0.1045, -0.1400]]), 'layers.1.bias': tensor([-0.0524]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0027, -0.0000, 0.0000]])}, objective=0.9647914082115628, loss=0.7618154287338257, val_objective=0.9649269491737821, val_loss=0.7619509696960449, regularization=0.002700001234188676, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=100),\n",
       " HistoryItem(lambda_=76.6797794185098, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0262, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0262,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0262,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0262,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0254,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0007, -0.1503,\n",
       "          0.0125, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0082,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0116,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0120,  0.0682,  0.1126,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0058, -0.0681,  0.0086,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1471, -0.1747, -0.0826,  0.0724, -0.1392, -0.0858, -0.0426,\n",
       "           0.1860, -0.0437,  0.0397, -0.0823,  0.0925, -0.0016, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0207,  0.0698, -0.1183,  0.0131, -0.0784, -0.0826,\n",
       "          -0.0768,  0.1303,  0.0813,  0.1142,  0.1156, -0.0392, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1181,  0.2394, -0.0594,\n",
       "          -0.1270,  0.0691,  0.1541, -0.1000,  0.0611,  0.1394, -0.1026, -0.1006,\n",
       "          -0.1046, -0.1399]]), 'layers.1.bias': tensor([-0.0524]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0026, -0.0000, 0.0000]])}, objective=0.9629828978208935, loss=0.7618512511253357, val_objective=0.9631238032011425, val_loss=0.7619921565055847, regularization=0.002623007632791996, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=78.21337500688, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0254, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0254,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0254,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0254,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0251,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0006, -0.1503,\n",
       "          0.0127, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0083,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0114,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0121,  0.0682,  0.1126,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0055, -0.0681,  0.0088,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1472, -0.1747, -0.0826,  0.0725, -0.1391, -0.0858, -0.0426,\n",
       "           0.1860, -0.0437,  0.0397, -0.0823,  0.0925, -0.0015, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0207,  0.0698, -0.1184,  0.0131, -0.0784, -0.0825,\n",
       "          -0.0768,  0.1304,  0.0813,  0.1142,  0.1156, -0.0393, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1182,  0.2395, -0.0594,\n",
       "          -0.1270,  0.0692,  0.1542, -0.1000,  0.0610,  0.1394, -0.1026, -0.1007,\n",
       "          -0.1046, -0.1399]]), 'layers.1.bias': tensor([-0.0524]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0025, -0.0000, 0.0000]])}, objective=0.96089989202992, loss=0.7618886232376099, val_objective=0.9610461618281988, val_loss=0.7620348930358887, regularization=0.0025444659404456615, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=79.7776425070176, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0246, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0246,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0246,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0246,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0246,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0005, -0.1503,\n",
       "          0.0129, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0084,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0112,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0123,  0.0682,  0.1126,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0053, -0.0681,  0.0090,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1472, -0.1748, -0.0825,  0.0725, -0.1391, -0.0857, -0.0426,\n",
       "           0.1861, -0.0437,  0.0396, -0.0823,  0.0926, -0.0015, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0208,  0.0698, -0.1184,  0.0130, -0.0784, -0.0825,\n",
       "          -0.0768,  0.1304,  0.0813,  0.1142,  0.1156, -0.0393, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1182,  0.2395, -0.0595,\n",
       "          -0.1270,  0.0692,  0.1542, -0.1000,  0.0609,  0.1394, -0.1026, -0.1007,\n",
       "          -0.1047, -0.1398]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0025, -0.0000, 0.0000]])}, objective=0.9585591991406465, loss=0.7619289755821228, val_objective=0.9587112505894685, val_loss=0.7620810270309448, regularization=0.002464728429913521, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=81.37319535715795, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0238, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0238,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0238,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0238,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0238,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0004, -0.1503,\n",
       "          0.0131, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0085,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0110,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0124,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0051, -0.0681,  0.0091,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1473, -0.1748, -0.0824,  0.0726, -0.1390, -0.0857, -0.0426,\n",
       "           0.1861, -0.0437,  0.0396, -0.0823,  0.0926, -0.0014, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0209,  0.0697, -0.1185,  0.0129, -0.0784, -0.0824,\n",
       "          -0.0768,  0.1305,  0.0813,  0.1142,  0.1156, -0.0394, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1183,  0.2396, -0.0596,\n",
       "          -0.1270,  0.0693,  0.1543, -0.1000,  0.0609,  0.1395, -0.1026, -0.1007,\n",
       "          -0.1047, -0.1398]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0024, -0.0000, 0.0000]])}, objective=0.9559788039999593, loss=0.7619688510894775, val_objective=0.9561371139364827, val_loss=0.762127161026001, regularization=0.0023841997608542442, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=83.00065926430112, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0230, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0230,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0230,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0230,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0230,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0364,  0.0575,  0.0938,  0.0854,  0.0003, -0.1503,\n",
       "          0.0133, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0086,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0107,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0125,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0048, -0.0681,  0.0093,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1473, -0.1749, -0.0824,  0.0726, -0.1390, -0.0857, -0.0426,\n",
       "           0.1862, -0.0437,  0.0395, -0.0823,  0.0927, -0.0013, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0209,  0.0697, -0.1185,  0.0129, -0.0784, -0.0824,\n",
       "          -0.0768,  0.1305,  0.0813,  0.1142,  0.1156, -0.0394, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1184,  0.2397, -0.0596,\n",
       "          -0.1270,  0.0693,  0.1543, -0.1000,  0.0608,  0.1395, -0.1026, -0.1008,\n",
       "          -0.1048, -0.1397]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0023, -0.0000, 0.0000]])}, objective=0.9530885169532667, loss=0.7620106935501099, val_objective=0.9532532045867811, val_loss=0.7621753811836243, regularization=0.0023021241649985313, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=84.66067244958714, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0222, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0222,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0222,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0222,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0222,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-6.4260e-02,  1.3471e-01,  3.6450e-02,  5.7486e-02,  9.3751e-02,\n",
       "          8.5378e-02,  1.3811e-04, -1.5034e-01,  1.3404e-02, -8.2985e-02,\n",
       "          7.2413e-02,  9.3198e-02,  1.2799e-01,  3.6971e-02, -1.5084e-01,\n",
       "         -1.1669e-01, -6.3810e-02, -1.0019e-01,  1.4826e-01, -8.6979e-03,\n",
       "          4.2518e-02,  1.4784e-01, -1.0115e-01,  4.7317e-02, -7.8861e-02,\n",
       "          1.7227e-01, -9.3646e-02, -4.8758e-02, -4.1717e-02,  1.0660e-01,\n",
       "         -1.0528e-02,  3.4173e-02, -3.1774e-02, -3.7264e-02, -2.9208e-02,\n",
       "         -1.3732e-01, -1.2564e-02,  6.8220e-02,  1.1254e-01,  4.8495e-02,\n",
       "         -6.2697e-02,  3.4161e-02,  1.2550e-01, -3.8359e-02,  1.1893e-01,\n",
       "         -4.6009e-03, -6.8070e-02,  9.4839e-03,  3.8410e-02,  1.1928e-01]), 'layers.1.weight': tensor([[ 0.0453,  0.1474, -0.1750, -0.0823,  0.0727, -0.1389, -0.0856, -0.0426,\n",
       "           0.1862, -0.0437,  0.0395, -0.0823,  0.0927, -0.0013, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0210,  0.0697, -0.1186,  0.0128, -0.0784, -0.0823,\n",
       "          -0.0768,  0.1306,  0.0813,  0.1142,  0.1156, -0.0395, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1184,  0.2397, -0.0597,\n",
       "          -0.1270,  0.0694,  0.1544, -0.1000,  0.0608,  0.1395, -0.1026, -0.1008,\n",
       "          -0.1048, -0.1397]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0022, -0.0000, 0.0000]])}, objective=0.9498692577732242, loss=0.762054443359375, val_objective=0.9500406211269534, val_loss=0.7622258067131042, regularization=0.0022184422705322504, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=86.35388589857888, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0213, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0213,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0213,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0213,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0213,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-6.4260e-02,  1.3471e-01,  3.6453e-02,  5.7487e-02,  9.3750e-02,\n",
       "          8.5380e-02,  9.5056e-06, -1.5034e-01,  1.3527e-02, -8.2985e-02,\n",
       "          7.2412e-02,  9.3200e-02,  1.2799e-01,  3.6971e-02, -1.5084e-01,\n",
       "         -1.1669e-01, -6.3810e-02, -1.0019e-01,  1.4826e-01, -8.8042e-03,\n",
       "          4.2520e-02,  1.4784e-01, -1.0115e-01,  4.7319e-02, -7.8861e-02,\n",
       "          1.7227e-01, -9.3646e-02, -4.8758e-02, -4.1717e-02,  1.0660e-01,\n",
       "         -1.0310e-02,  3.4170e-02, -3.1774e-02, -3.7264e-02, -2.9207e-02,\n",
       "         -1.3732e-01, -1.2632e-02,  6.8222e-02,  1.1254e-01,  4.8496e-02,\n",
       "         -6.2697e-02,  3.4160e-02,  1.2549e-01, -3.8359e-02,  1.1893e-01,\n",
       "         -4.3559e-03, -6.8070e-02,  9.6624e-03,  3.8412e-02,  1.1928e-01]), 'layers.1.weight': tensor([[ 0.0453,  0.1474, -0.1750, -0.0823,  0.0727, -0.1389, -0.0856, -0.0426,\n",
       "           0.1863, -0.0437,  0.0394, -0.0823,  0.0928, -0.0012, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0210,  0.0697, -0.1186,  0.0128, -0.0784, -0.0822,\n",
       "          -0.0768,  0.1306,  0.0813,  0.1142,  0.1156, -0.0395, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1185,  0.2398, -0.0597,\n",
       "          -0.1270,  0.0694,  0.1544, -0.1000,  0.0607,  0.1395, -0.1026, -0.1009,\n",
       "          -0.1049, -0.1396]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0021, -0.0000, 0.0000]])}, objective=0.9463019423909939, loss=0.7621000409126282, val_objective=0.9464801602788723, val_loss=0.7622782588005066, regularization=0.0021331049501895905, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=88.08096361655046, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0205, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0205,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0205,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0205,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0205,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-6.4260e-02,  1.3470e-01,  3.6456e-02,  5.7489e-02,  9.3749e-02,\n",
       "          8.5382e-02, -1.2553e-04, -1.5034e-01,  1.3647e-02, -8.2985e-02,\n",
       "          7.2412e-02,  9.3201e-02,  1.2799e-01,  3.6971e-02, -1.5084e-01,\n",
       "         -1.1669e-01, -6.3810e-02, -1.0019e-01,  1.4826e-01, -8.9124e-03,\n",
       "          4.2522e-02,  1.4784e-01, -1.0115e-01,  4.7320e-02, -7.8861e-02,\n",
       "          1.7227e-01, -9.3646e-02, -4.8758e-02, -4.1717e-02,  1.0660e-01,\n",
       "         -1.0087e-02,  3.4168e-02, -3.1774e-02, -3.7264e-02, -2.9207e-02,\n",
       "         -1.3732e-01, -1.2696e-02,  6.8224e-02,  1.1253e-01,  4.8497e-02,\n",
       "         -6.2697e-02,  3.4159e-02,  1.2549e-01, -3.8359e-02,  1.1893e-01,\n",
       "         -4.1070e-03, -6.8070e-02,  9.8439e-03,  3.8414e-02,  1.1929e-01]), 'layers.1.weight': tensor([[ 0.0453,  0.1475, -0.1751, -0.0822,  0.0728, -0.1388, -0.0856, -0.0426,\n",
       "           0.1863, -0.0437,  0.0393, -0.0823,  0.0928, -0.0012, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0211,  0.0697, -0.1187,  0.0127, -0.0784, -0.0822,\n",
       "          -0.0768,  0.1307,  0.0813,  0.1142,  0.1156, -0.0396, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1185,  0.2398, -0.0598,\n",
       "          -0.1270,  0.0695,  0.1545, -0.1000,  0.0607,  0.1396, -0.1026, -0.1009,\n",
       "          -0.1050, -0.1396]]), 'layers.1.bias': tensor([-0.0525]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0020, -0.0000, 0.0000]])}, objective=0.9423674895978225, loss=0.7621476054191589, val_objective=0.9425528600430739, val_loss=0.7623329758644104, regularization=0.002046070760115981, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=89.84258288888148, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0196, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0196,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0196,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0196,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0196,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0365,  0.0575,  0.0937,  0.0854, -0.0003, -0.1503,\n",
       "          0.0138, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0090,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0099,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0128,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0039, -0.0681,  0.0100,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1475, -0.1751, -0.0822,  0.0728, -0.1388, -0.0855, -0.0426,\n",
       "           0.1864, -0.0437,  0.0393, -0.0823,  0.0929, -0.0011, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0211,  0.0697, -0.1187,  0.0127, -0.0784, -0.0821,\n",
       "          -0.0768,  0.1307,  0.0813,  0.1142,  0.1156, -0.0396, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1186,  0.2399, -0.0598,\n",
       "          -0.1270,  0.0695,  0.1545, -0.1000,  0.0606,  0.1396, -0.1026, -0.1009,\n",
       "          -0.1050, -0.1395]]), 'layers.1.bias': tensor([-0.0526]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0020, -0.0000, 0.0000]])}, objective=0.9380456052365953, loss=0.762196958065033, val_objective=0.9382383666577989, val_loss=0.7623897194862366, regularization=0.0019572973251342773, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=91.63943454665912, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0187, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0187,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0187,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0187,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0187,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0365,  0.0575,  0.0937,  0.0854, -0.0004, -0.1503,\n",
       "          0.0139, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0091,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0097,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0128,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0036, -0.0681,  0.0102,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1476, -0.1752, -0.0821,  0.0729, -0.1387, -0.0855, -0.0426,\n",
       "           0.1864, -0.0437,  0.0392, -0.0823,  0.0929, -0.0011, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0212,  0.0697, -0.1188,  0.0126, -0.0784, -0.0821,\n",
       "          -0.0768,  0.1308,  0.0813,  0.1142,  0.1156, -0.0397, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1186,  0.2399, -0.0599,\n",
       "          -0.1270,  0.0696,  0.1546, -0.1000,  0.0605,  0.1396, -0.1026, -0.1010,\n",
       "          -0.1051, -0.1395]]), 'layers.1.bias': tensor([-0.0526]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0019, -0.0000, 0.0000]])}, objective=0.9333119764344769, loss=0.7622480988502502, val_objective=0.9335126056687909, val_loss=0.7624487280845642, regularization=0.0018667059484869242, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=93.4722232375923, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0177, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0177,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0177,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0177,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0177,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0365,  0.0575,  0.0937,  0.0854, -0.0006, -0.1503,\n",
       "          0.0140, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0092,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0095,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0129,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0033, -0.0681,  0.0104,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1476, -0.1752, -0.0821,  0.0729, -0.1387, -0.0855, -0.0426,\n",
       "           0.1865, -0.0437,  0.0392, -0.0824,  0.0930, -0.0010, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0212,  0.0697, -0.1188,  0.0126, -0.0784, -0.0820,\n",
       "          -0.0768,  0.1308,  0.0813,  0.1142,  0.1156, -0.0398, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1187,  0.2400, -0.0599,\n",
       "          -0.1270,  0.0696,  0.1546, -0.1000,  0.0605,  0.1396, -0.1026, -0.1010,\n",
       "          -0.1051, -0.1394]]), 'layers.1.bias': tensor([-0.0526]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0018, -0.0000, 0.0000]])}, objective=0.9281472827945096, loss=0.762302041053772, val_objective=0.9283561374698026, val_loss=0.7625108957290649, regularization=0.0017742729978635907, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=95.34166770234415, state_dict={'layers.0.weight': tensor([[ 0.0000, -0.0000,  0.0000,  ..., -0.0057, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0168, -0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0168,  0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0168,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.0168,  0.0000, -0.0000],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.0168,  0.0000, -0.0000]]), 'layers.0.bias': tensor([-0.0643,  0.1347,  0.0365,  0.0575,  0.0937,  0.0854, -0.0007, -0.1503,\n",
       "          0.0141, -0.0830,  0.0724,  0.0932,  0.1280,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0093,  0.0425,  0.1478, -0.1012,  0.0473,\n",
       "         -0.0789,  0.1723, -0.0936, -0.0488, -0.0417,  0.1066, -0.0094,  0.0342,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0129,  0.0682,  0.1125,  0.0485,\n",
       "         -0.0627,  0.0342,  0.1255, -0.0384,  0.1189, -0.0031, -0.0681,  0.0106,\n",
       "          0.0384,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1477, -0.1753, -0.0820,  0.0730, -0.1386, -0.0855, -0.0426,\n",
       "           0.1865, -0.0437,  0.0391, -0.0824,  0.0930, -0.0010, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0213,  0.0697, -0.1189,  0.0125, -0.0784, -0.0820,\n",
       "          -0.0768,  0.1309,  0.0813,  0.1142,  0.1156, -0.0398, -0.1436,  0.1481,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1187,  0.2400, -0.0600,\n",
       "          -0.1270,  0.0697,  0.1547, -0.1000,  0.0604,  0.1397, -0.1026, -0.1011,\n",
       "          -0.1052, -0.1394]]), 'layers.1.bias': tensor([-0.0526]), 'skip.weight': tensor([[0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000,\n",
       "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000,\n",
       "          0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000, 0.0000, -0.0000, -0.0000,\n",
       "          -0.0000, 0.0000, 0.0000, 0.0000, -0.0000, -0.0000, -0.0000, 0.0000, -0.0000,\n",
       "          0.0000, 0.0017, -0.0000, 0.0000]])}, objective=0.9225323551562529, loss=0.7623586654663086, val_objective=0.9227496140864592, val_loss=0.7625759243965149, regularization=0.0016799967270344496, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False]), n_iters=5),\n",
       " HistoryItem(lambda_=97.24850105639104, state_dict={'layers.0.weight': tensor([[0., -0., 0.,  ..., 0., -0., -0.],\n",
       "         [0., 0., 0.,  ..., 0., -0., 0.],\n",
       "         [-0., -0., -0.,  ..., -0., 0., -0.],\n",
       "         ...,\n",
       "         [-0., -0., -0.,  ..., -0., 0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., 0., -0.],\n",
       "         [-0., -0., -0.,  ..., -0., 0., -0.]]), 'layers.0.bias': tensor([-0.0643,  0.1346,  0.0365,  0.0575,  0.0937,  0.0854, -0.0036, -0.1503,\n",
       "          0.0143, -0.0830,  0.0724,  0.0932,  0.1279,  0.0370, -0.1508, -0.1167,\n",
       "         -0.0638, -0.1002,  0.1483, -0.0098,  0.0426,  0.1478, -0.1012,  0.0474,\n",
       "         -0.0789,  0.1722, -0.0936, -0.0488, -0.0417,  0.1066, -0.0083,  0.0341,\n",
       "         -0.0318, -0.0373, -0.0292, -0.1373, -0.0131,  0.0683,  0.1124,  0.0485,\n",
       "         -0.0627,  0.0341,  0.1254, -0.0384,  0.1189,  0.0021, -0.0681,  0.0116,\n",
       "          0.0385,  0.1193]), 'layers.1.weight': tensor([[ 0.0453,  0.1482, -0.1758, -0.0815,  0.0735, -0.1381, -0.0852, -0.0426,\n",
       "           0.1871, -0.0437,  0.0386, -0.0826,  0.0935, -0.0005, -0.0907,  0.0684,\n",
       "          -0.1228, -0.0228,  0.0217,  0.0697, -0.1195,  0.0119, -0.0784, -0.0815,\n",
       "          -0.0768,  0.1314,  0.0813,  0.1142,  0.1156, -0.0404, -0.1436,  0.1483,\n",
       "           0.0290,  0.0751, -0.0999,  0.1594,  0.0916, -0.1193,  0.2405, -0.0605,\n",
       "          -0.1270,  0.0702,  0.1552, -0.1000,  0.0599,  0.1399, -0.1026, -0.1016,\n",
       "          -0.1057, -0.1389]]), 'layers.1.bias': tensor([-0.0530]), 'skip.weight': tensor([[0., 0., 0., 0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0.,\n",
       "          -0., 0., 0., 0., -0., 0., -0., -0., 0., 0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., -0., 0., -0., -0.,\n",
       "          -0., 0., -0., 0., -0., -0., -0., 0., 0., 0., -0., -0., -0., 0., -0., 0., 0., -0., 0.]])}, objective=0.763928234577179, loss=0.763928234577179, val_objective=0.7643004655838013, val_loss=0.7643004655838013, regularization=0.0, selected=tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False]), n_iters=95)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f153419-e36e-4562-a1a3-f1320193a651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3168x1944 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = data.iloc[:,:-1].columns\n",
    "plot_feature_importance(X_train, model, feature_names, run_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "993c189b-62f5-47a2-8e76-81521a240ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f54123d-a017-498a-88ab-91e7f38a4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_epochs = []\n",
    "feat_selection = {\"epoch\" : [],\n",
    "                 \"features\" : []}\n",
    "feature_names = data.iloc[:,:-1].columns\n",
    "i = 0\n",
    "for epoch in path:\n",
    "    num_feats = int(sum(epoch.selected))\n",
    "    sel_epochs.append(num_feats)\n",
    "    if num_feats < 67:\n",
    "        feat_selection[\"epoch\"].append(i)\n",
    "        feat_selection[\"features\"].append(list(feature_names[epoch.selected]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36c541b-f6b1-4331-95c3-4634c176c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract loss-history\n",
    "history_val = []\n",
    "history = []\n",
    "for epoch in path:\n",
    "    loss = epoch.loss\n",
    "    val_loss = epoch.val_loss\n",
    "    history_val.append(val_loss)\n",
    "    history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ace39e2-f1c5-4a8a-9e4e-d16421924be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29059f87a60>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAArt0lEQVR4nO3deXxU5dn/8c+VlbCHJIQlK2sCCggBRIIWBYuoxbrUaKulG611af1pK62Pa2sft1afx9r6aOtaBZTWioooFEVBFAICQjAhJEASAgZMZM9kuX9/3JMw2WAgMznJyfV+vc5rZs6cmbkOE75zn/vc5xwxxqCUUsq9QpwuQCmlVHBp0CullMtp0CullMtp0CullMtp0CullMuFOV1AY7GxsSYlJcXpMpRSqkNZt27dPmNMXHPPtbugT0lJITs72+kylFKqQxGRnS09p103Sinlchr0Sinlchr0Sinlchr0Sinlchr0Sinlchr0Sinlchr0Sinlcq4M+q1lW1mUu8jpMpRSql1wZdDf9M5NzJo/i3e2veN0KUop5Ti/gl5EZohIrojki8jcZp5/TEQ2eKc8Eanwee5hEdkiIltF5H9FRAJYf7Oiu0QD8L3Xv8e2/duC/XFKKdWunTToRSQUeBK4CBgBXCMiI3yXMcbcaowZY4wZAzwB/Mv72nOAycAo4AxgPHBeIFegOaEhoYSHhBMiIXzzH99k98Hdwf5IpZRqt/xp0U8A8o0xBcYYDzAfmHWC5a8B5nnvG6ALEAFEAuHA3tMv1z+eGg/pceksvnYxZUfKmPLcFArLC4P9sUop1S75E/QDgSKfx8XeeU2ISDKQCiwHMMasBt4HSr3Tu8aYrc28bo6IZItIdllZ2amtQTM8NR4iQiMYP3A8y65bRvnRcqY8N4WtZU0+WimlXC/QO2OzgIXGmBoAERkCpAMJ2B+H80VkSuMXGWOeNsZkGGMy4uKaPcvmKakLeoCJCRNZMXsFNaaGc58/l/Wl61v9/kop1ZH4E/QlQKLP4wTvvOZkcbzbBuDbwCfGmEPGmEPAO8Ck0yn0VFTVVNUHPcCZ8Wfy0Q8+olt4N6a+MFV30CqlOhV/gn4tMFREUkUkAhvmTQapi0gaEA2s9pm9CzhPRMJEJBy7Izbo/Se+Lfo6Q/oMYcXsFYSFhHH1wquprK4MdhlKKdUunDTojTHVwE3Au9iQftUYs0VE7heRb/ksmgXMN8YYn3kLge3A58BGYKMx5s2AVd+C5oIeILl3Ms/Pep7P9nzGr5b+KthlKKVUu+DXFaaMMYuBxY3m3d3o8b3NvK4G+Gkr6jstnhoP4SHhzT536fBL+eXEX/L4p49zXvJ5XDHiijauTiml2pYrj4xtqUVf56HpDzFx4ESue/061pasbcPKlFKq7XXKoI8IjeCNrDeI7x7PjJdnsKZkTRtWp5RSbatTBj1AfPd4/nP9f+gV2YsLXryA5YXL26g6pZRqW64M+qraqpMGPcCg6EGs/OFKknslM/PlmXy086M2qE4ppdqWK4PenxZ9nQE9BrBi9gqSeiXxnYXfofRgaZCrU0qptuXaoG9p1E1zYrrG8K+r/8WBygNc9dpVeGo8QaxOKaXalmuD3t8WfZ0z+p7Bs996llVFq7j9vduDVJlSSrU91wV9ramlurb6lIMe4OozrubWs2/liTVP8PKml4NQnVJKtT3XBX1VTRXAaQU9wEPTHuLc5HP5yZs/YdPeTYEsTSmlHOG6oK/rXz/doA8PDWfBlQuIjorm8gWX8/WxrwNZnlJKtTkN+mb0696PV698lcKKQn77n98GqjSllHKE64K+qrZ1XTd1JidN5uYJN/PX7L+yumj1yV+glFLtlOuCvq5FHx7q//DKlvxu6u/o36M/v3z3lzQ8KadSSnUcrg361rboAXpE9uCB8x9gTckaFmxZ0Or3U0opJ2jQn8R1o65jdPxo5i6by7HqYwF5T6WUaksa9CcRGhLKoxc+ys6vd/LnNX8OyHsqpVRb0qD3w7RB05g5dCa/+/B37D20N2Dvq5RSbUGD3k9/uvBPHK06yq+X/Tqg76uUUsHmuqCvOzL2VE5q5o/hscP51Tm/4sWNL+rpjJVSHYrrgj5YLXqA3075LUm9kvj54p/X/6AopVR7p0F/CrpFdON/ZvwPm7/crDtmlVIdhgb9KZo1fBYXDbmIez64h90HdwflM5RSKpA06E+RiPDERU/gqfHoeeuVUh2CBv1pGNxnMHdMvoN5m+fxfuH7QfscpZQKBA360zQ3cy6pvVP52ds/47DncFA/SymlWsO1QR+Ik5qdSFR4FH//1t/Ztn8bN71zU1A/SymlWsOvoBeRGSKSKyL5IjK3mecfE5EN3ilPRCq886f6zN8gIsdE5LLArkJDgTpNsT+mpk7lv879L57f8DwvbXwp6J+nlFKnI+xkC4hIKPAkMB0oBtaKyCJjTE7dMsaYW32Wvxk4yzv/fWCMd34fIB94L4D1N9FWXTd17j7vblbsXMENb99AxoAM0uPS2+RzlVLKX/606CcA+caYAmOMB5gPzDrB8tcA85qZfyXwjjHmyKmX6b+2DvqwkDBeufwVukV04+JXLqbscFmbfK5SSvnLn6AfCBT5PC72zmtCRJKBVGB5M09n0fwPACIyR0SyRSS7rKx1Qemp8SAIoRLaqvc5FQN7DmRR1iJKD5Vy2YLL9HTGSql2JdA7Y7OAhcaYGt+ZItIfOBN4t7kXGWOeNsZkGGMy4uLiWlWAp8ZDRGgEItKq9zlVExMm8tK3X+Ljoo+5/vXrqamtOfmLlFKqDfgT9CVAos/jBO+85rTUav8O8LoxJugniPHUeII+4qYlV464kkenP8prOa/xo0U/otbUOlKHUkr5OunOWGAtMFREUrEBnwVc23ghEUkDooHmrqR9DfCbVtTpt7oWvVNuO+c2Dlcd5p4P7iEiNIKnLnmKEHHdKFalVAdy0qA3xlSLyE3YbpdQ4FljzBYRuR/INsYs8i6aBcw3ja6iLSIp2C2CFQGtvAVVNVWOBj3AXefeRWV1JX9Y+Qc8NR7+9q2/ERbiz2+qUkoFnl/pY4xZDCxuNO/uRo/vbeG1O2hh520weGqdbdGDPR/O78//PZFhkdzzwT3sP7qfBVcuoGt4V0frUkp1Tq7rU3C666aOiHD3eXfzl5l/4e28t7ngxQvYc2iP02UppTohDfogu2H8DSz8zkI27d3E+GfGs273OqdLUkp1Mhr0beDy9MtZ9cNVhEgImc9l8vS6p2m0K0MppYLGlUEf6OvFBsKYfmNY+5O1ZCZl8tO3fsoVr17B/iP7nS5LKdUJuDLo21uLvk7fbn1593vv8uj0R3kr7y1GPzWa5YXNHUSslFKB47qgbw/DK08kREK47Zzb+OTHn9AtohsXvHgBP170Y23dK6WCxnVB355b9L7G9h/L+jnr+fU5v+b5Dc+T9mQaL2x4QfvulVIBp0HvoG4R3Xho+kN89tPPGNpnKLPfmM3kZyezYkebHFumlOokNOjbgTPjz2TlD1fyzKXPsPPrnXzjhW8w4x8zWF+63unSlFIu4LqgP1p9lMiwSKfLOGUhEsKPx/6Y/JvzeWT6I6zdvZZxT4/j0nmXsnLXSqfLU0p1YK4L+opjFUR3iXa6jNMWFR7F7efcTsEtBdz/jftZXbSaKc9NYfKzk3njizf09MdKqVPmqqCvNbVUHKugd5feTpfSar269OKu8+5i1627eOKiJyg5UMJlCy5jyBNDeHjVwzpKRynlN1cF/SHPIWpNbYdu0TfWNbwrN024ifxb8nn1yldJ7pXMHcvuYOCfBnLd69exrGCZtvKVcoHSg6VBuzqdq4K+/Gg5gCta9I2FhYRx1cir+GD2B3x+w+f8YMwPeDP3Taa/NJ3kx5O5Y+kdrC9dr8MzleqgfvLmT5j4t4lBeW93Bf0xG/TRUe5p0TfnjL5n8NdL/sqe2/fw6pWvMrb/WP70yZ8Y9/Q4kh9P5pZ3bmF54XKqaoJ+QS+lVAAYY1ibu5yz8g8H5f1ddTWMimMVAK7qujmRLmFduGrkVVw18ir2HdnHW3lv8e8v/s0z65/hiTVPEN0lmumDpzMtdRrTB08npXeK0yUrpZpRdKCIL0OOMv5A96C8v6uC3s1dNycT2zWW2WNmM3vMbA57DrO0YClv5L7Be9vf49UtrwIwpM8QpqVO47yU88hMyiShZ4LDVSulANZueQ+A8UPOC8r7uyro61v0Lu+6OZluEd24LO0yLku7DGMMW/dtZen2pSwrXMY/Pv8HT617CoCkXklkJmUyOXEymUmZjIwbSWhIqMPVK9X5rN3wNuE1MHry5UF5f1cFfV0ffWds0bdERBgRN4IRcSP4xdm/oLq2mo17NrJy10pWFa3i/cL3eeXzVwDoFt6Nsf3HkjEgg4wBGYwfMJ7BfQbrxc2VCrLs0vWMKhMiM84Oyvu7KugrjlUgCD0jezpdSrsVFhLGuAHjGDdgHL84+xcYY9hRsYNVRatYU7KG7N3Z/DX7r/XDvHpF9mJU/CiGxwxnWMwwhscOZ3jMcAZFDyI8tP2d91+p9qzscBlb921la9lWe7t3Mzl7N1MctpcbquMhMjhH9bsq6MuPltO7S29tgZ4CESE1OpXU6FS+N+p7gD3Vc05ZDtm7s1m7ey2bv9zMG7lvUHakrP51oRJKanQqg6MHMyh60PHbPva2e0Rwdiop1Z5VVley6+tdFFYUUlheyI7yQgr3fkHhvny2H9rF/pqD9ct2rRLSygzn7YMz98L1518TtLrcFfTHyrXbJgDCQ8MZ3W80o/uN5kdjf1Q/v/xoOXn788jdn0ve/jy2fbWN7V9tZ03Jmvpuszp9u/Vt8Uegf/f+iEhbr5ZSQfWD/7uIF0qXYHz+tMNqIPlrSC2HK8ohbR+kV/UivfcQEhNGEjJkKJw/FIYMgTFjglabq4K+4lhFp98RG0zRUdFMTJjIxISmB3WUHy2noLyA7eXb7e1X2ymoKGDlrpXM2zyPWlNbv2xUWFT91kDjH4HU3qkd8qR0qnM7UnmIV0qWMG2ncO3uGFK7DiA1ehAD+w0ldFgyJCbaafBg6Nn2XcuuCnpt0TsnOiqacVG2778xT42HnRU7m/wIbP9qO8sLl3O46vhBIoIwsOfABlsDdT8Cg6MH0yeqj24NqHZn1X+ewxMKt55zGxf99BGny2nCVUFfcayC9Nh0p8tQjUSERjA0ZihDY4Y2ec4Yw5eHv2y4NeC9XZK/hNJDpQ2W7xnZs0mXUGp0Kqm9U0nqlaRbA8oRyz+ZTxgwZdbNTpfSLL+CXkRmAP8DhAJ/M8Y82Oj5x4Cp3oddgb7GmN7e55KAvwGJgAFmGmN2BKL4xsqPlneao2LdQkSI7x5PfPd4JiVOavL8kaojFJYXNtka2PzlZt7MexNPjef4eyEM6DGAlN4ppEanktIr5fj93ikk9kzUkUIqcGproaSE6rwvWFqxjolhPeneL8npqpp10qAXkVDgSWA6UAysFZFFxpicumWMMbf6LH8zcJbPW7wIPGCMWSoi3YFagsQtpyhWx3UN78rIviMZ2Xdkk+dqTS0lB0rYUbGDworCBrcf7fyIVw680mDfQIiEkNAzwYZ/79QGt0P6DGFAjwHaLaSOO3YMiovtVFTEgaJ8duz5gq1f57P16C5yQr5ia59a8mLAEwP3dJvmdMUt8qdFPwHIN8YUAIjIfGAWkNPC8tcA93iXHQGEGWOWAhhjDrW64hZUVldytPqo7oztREIkhMReiST2SmRK8pQmz1fVVFF8oLjJD0FheSHLCpax++BuDMfP9tkzsidpsWmMiBtBemy6neLSSe2dqkcMu1FtLeTmwvr1eHYWUFKax67929l1aDdFnjJ2hR9hVy8o6gm7esGBLkCMncTAINOb9KhEZsaNYETqBK7InOP0GrXIn6AfCBT5PC4Gmj2XpogkA6nAcu+sYUCFiPzLO38ZMNcYE/ATqNed/kBb9KpOeGh4/TECU+t7Fo/zHfOctz+v/iCWJflLeH7D8/XLRYZGMixmGOlx6Q1+AIbFDKNLWJc2XCPVGtVle9m1egn5G98nrzCbvPJ88rpXkhcDO3tBbSwQe3z5WLqSGBHL4O4JfCNmEEn900iKG0JabBrDYoYRFR7l2LqcqkDvjM0CFvoEeRgwBduVswtYAMwG/u77IhGZA8wBSEo6vT6uPlF9yPl5DnHd4k7r9arziQyLrN9JfOHgCxs8V360nC/2fdHgKMbs3dm8tuW1+q2AEAlhUPSg+vAf2XckY/uPJS02jbAQV41zaPdqamsoO1LGnoOl7CnaSumuLezZk0/pV7so+HoH28w+CrtXU1W3YZYM3RPDGRaZzMT4EXwvYRQpfYeR1CuJxJ52K7FreFdH1ymQ/PlrLMHuSK2T4J3XnCzgRp/HxcAGn26ffwNn0yjojTFPA08DZGRknNaVM8JDw0mP0xE3KjCio6KZlDipyQ7io1VHyd2fe/wQdu8PwZL8JVTV2vP/R4VFMbrfaMb1H2enAeNIj03XHcGtUHGsgo+LPqbky3xKdudSsq+QkgPFlB4rY0/NAb4MOUJtM7tXelRCanUEZ4bG8+3IoQxNGceQUd9geGoG8d3iO80+GTnZFYlEJAzIAy7ABvxa4FpjzJZGy6UBS4BU431T747c9cA0Y0yZiDwHZBtjnmzp8zIyMkx2dnYrVkmptlddW03e/jzWl65n3e51rN+znvWl6znksbuluoR1YVT8KCYOnEhmUiaZSZkM6DHA4ao7hvc+f53rXruWL0Pt+ZfEQN/DMPAA9D8E/au60D+sN/26xdMvOpF+/YbQL3kk/YaMoeuQdOjWzeE1aBsiss4Yk9Hsc/5cek5EZgKPY4dXPmuMeUBE7seG9iLvMvcCXYwxcxu9djrwR0CAdcAcY4yHFmjQK7eoNbVs27/Nhn/pOtaVrmNNyRqOVB0BILV3KlOSp5CZaIM/LTat07Qw/WWMof+dkUQfqOIJM4NhyWPpn5hOeEIyJCTAgAFBOxFYR9PqoG9LGvTKzapqqtiwZwMrd61kZdFKPtr5Uf3J4mKiYupb+1OSpnBW/7OICI1wuGJnFRduJPHFMTwhF3PT3W85XU67dqKg1z1GSrWh8NBwxg8cz/iB47l10q0YY9j21TZW7lrJR7s+YuWulbyR+wZg+/rPTji7PvwnJUyiR2QPh9egbX324QIAzhp3scOVdGwa9Eo5SEQYFjOMYTHD+OFZPwSg9GApq4pW1Yf/Ax89QK2pJURCGNNvDFOSptSHf7/u/Rxeg+Ba/8X7SCSMPvc7TpfSoWnXjVLt3MHKg6wuXl0f/J8Wf8rR6qOAvQ5wXVdPZlImQ/sMdVU//2U3RPNFj0q+ePiI06W0e9p1o1QH1iOyBxcOvrB+rL+nxsNnpZ/Vd/W8mftm/QFefbv1bRD8Y/qN6bhj+g8d4rMuFUyOanr6C3VqOuhfgFKdV0RoRP11AW4/53ZqTS25+3Lrg/+jXR/xr63/Aux1gCclTiIzMZMpyVOYOHAi3SI6xnDD/Zs+YVdvuKnfWKdL6fA06JXq4EIkxJ6eIS6dOePs+VaKDxTbkT3e6b4V92EwhIWEMbb/WDITMzkv5TymJE1pt+eH+izHnknlrCFNz2OkTo320SvVCVQcq2B10er6Vv+akjVU1lQiCKP7jWZqylSmDZrGucnntpvr/T5834XcwVL23VxETJ8Ep8tp93QcvVKqgWPVx/i0+FNW7FzBBzs+4OOij6msqSQ8JJxJiZOYPmg60wdNJ2NAhmNn7rzm9hQ+lmJ2PlLtyOd3NBr0SqkTOlp1lFVFq1i6fSlLC5by2Z7PAHs22KkpU23wD57O4OjBbTaqJ+1XUaQf687rT5S1yed1dDrqRil1QlHhUUwbNI1pg6bxEA9RdriM5YXLWVpgg//1L14HIKV3Sn1r//zU84npGhOUeg55DpHX7RjXmjOC8v6djQa9UqqJuG5xXH3G1Vx9xtX1R+8u3b6UZYXLWLBlAc+sfwZBGNt/bH1rf3Li5IBds3dj3kcYgbPizgzI+3V2GvRKqRPyPXr3xgk3Ul1bzdqStSwtWMqygmU8uvpRHlz1IFFhUUxJnsL0QdO5IPUCRsWPOu3+/U83LwFgnI64CQjto1dKtcrByoOs2LmivsWfU2avMtojokf9GP7MpEwmDJzg9xj+Kx6dwGfFaymYswVGjAhm+a6hffRKqaDpEdmDS4ZdwiXDLgGg5EAJK3auqB/Df88H92AwCHbLYGLCRB684EH69+jf7PsZY1h5eCvf3AWc5hXnVEMa9EqpgBrYcyDXnnkt1555LWAvy/hx0cdk785mw94NLMxZyPrS9Xw4+8NmD9baXr6dLzlEZlkUdG8fY/o7Og16pVRQRUdFc/Gwi7l4mD3V8H8K/sPMV2Zy/b+vZ1HWoibDNVfuWglAZq0eJBUoIU4XoJTqXC4YdAEPTXuIt/Le4pn1zzR5fsXOFfTxhJLWe4gD1bmTBr1Sqs3dMvEWpqZMZe6yuZQfLa+fX2tqWZK/hAt3hBKSqP3zgaJBr5RqcyESwmPffIyKYxU8uPLB+vmflX7GnkN7mLnZA4mJDlboLhr0SilHjO43mutGX8djnzzGx0UfA7B422IE4Zvb0aAPIA16pZRjHv/m4yT3TubyBZezae8mXv78Zcb3GE7fw0CC7owNFA16pZRjoqOieSPrDaprqxnz1Bi2fbWN+7p6LwSuLfqA0aBXSjlqRNwIVsxewaj4UTx18VPM2O8dW68t+oDRcfRKKceN7DuSDT/bYB888zOIjYWoKEdrchNt0Sul2peiIu22CTANeqVU+6JBH3B+Bb2IzBCRXBHJF5G5zTz/mIhs8E55IlLh81yNz3OLAli7UsqNioq0fz7ATtpHLyKhwJPAdKAYWCsii4wxOXXLGGNu9Vn+ZuAsn7c4aowZE7CKlVLudegQVFRoiz7A/GnRTwDyjTEFxhgPMB+YdYLlrwHmBaI4pVQnU1xsbzXoA8qfoB8IFPk8LvbOa0JEkoFUYLnP7C4iki0in4jIZS28bo53meyyMr0QsFKdVpE3ajToAyrQO2OzgIXGmBqfecneq55cCzwuIoMbv8gY87QxJsMYkxEXFxfgkpRSHYYGfVD4E/QlgO+/eoJ3XnOyaNRtY4wp8d4WAB/QsP9eKaWOqwv6AQOcrcNl/An6tcBQEUkVkQhsmDcZPSMiaUA0sNpnXrSIRHrvxwKTgZzGr1VKKcD20cfHQ2Sk05W4yklH3RhjqkXkJuBdIBR41hizRUTuB7KNMXWhnwXMNw2vNp4O/J+I1GJ/VB70Ha2jlFIN6Bj6oPDrFAjGmMXA4kbz7m70+N5mXvcxcGYr6lNKdSa7dkFamtNVuI4eGauUah9qa6GgAAY3Ga+hWkmDXinVPuzeDZWVMGiQ05W4jga9Uqp92L7d3mqLPuA06JVS7YMGfdBo0Cul2oft2yE0FJKSnK7EdTTolVLtQ0EBJCdDeLjTlbiOBr1Sqn3Yvl27bYJEg14p1T5o0AeNBr1Synnl5fDVVxr0QaJBr5Ry3tat9jY93dk6XEqDXinlvBzvKbA06INCg14p5bytWyEqyo66UQGnQa+Ucl5ODgwfbsfRq4DToFdKOW/rVhgxwukqXEuDXinlrEOHYOdO7Z8PIg16pZSzcnPtrbbog0aDXinlrLoRNxr0QePXFaY6nD//Gf7wB3ulmpgY8Hjs5uGxY9C1K0ydCjNmwJgxEKK/dUo5autWCAvTg6WCyJ0pl50NFRU22Ddvtv1/lZV2+FZZGdx5J4wbB/37w/XXw9/+BkuW2GWUUm0rJweGDdOTmQWRO1v0VVWQkAAff9z883v3wnvv2XBfvBheesnO79sXbrgBbrwR4uLarl6lOrOcHBg1yukqXM2dLXqPByIiWn4+Ph6uuw5eftmG/vbt8PbbMH483Hef7St85522q1epzqqy0v7/0/75oHJv0Pu7GRgaaq9ROXMmvPUWfP45DBgAF19s+/qVUsGTl2cvCq5DK4PKnUFfVXXiFv2JnHEGrF4Nl14KN98Mv/0tGBPY+pRSVt3JzLRFH1TuDPqTdd2cTNeu8M9/wpw58N//DT//uYa9UsGQk2NHvg0b5nQlrubOnbGn0nXTkrAweOop6N0bHn7YdvE88QSIBKREpRS2RZ+aakfEqaBxZ9BXVdlWeWuJwIMPQk0N/PGPtuXx+OM69l6pQMnJ0W6bNuBXYonIDBHJFZF8EZnbzPOPicgG75QnIhWNnu8pIsUi0jZ7NwPRoq8jAo88Av/v/9kW/XXXQXV1YN5bqc6sutrujNUdsUF30ha9iIQCTwLTgWJgrYgsMsbk1C1jjLnVZ/mbgbMavc3vgA8DUrE/WttH35gIPPqoHVv/m99Az57wl79oN45SrVFQYP+vaos+6Pxp0U8A8o0xBcYYDzAfmHWC5a8B5tU9EJFxQDzwXmsKPSWtGXXTEhGYO9dOTz0Fjz0W2PdXqrPRETdtxp+gHwgU+Twu9s5rQkSSgVRgufdxCPBH4PYTfYCIzBGRbBHJLisr86fuEwtk101jDzwAV10Ft98OCxcG5zOU6gzqTmaWluZsHZ1AoPcqZgELjTE13sc/BxYbY4pP9CJjzNPGmAxjTEZcIE49EOiuG18hIfDCCzBpElxzjYa9UqcrJwcSE6FHD6crcT1/gr4ESPR5nOCd15wsfLptgEnATSKyA3gUuF5EHjyNOk9NMLpufEVF2VMkTJwIWVkwb97JX6OUOs4YWLMGzjzT6Uo6BX+Cfi0wVERSRSQCG+aLGi8kImlANLC6bp4x5rvGmCRjTAq2++ZFY0yTUTsBF8yumzo9e9qTomVmwne/a8fa60FVSvlnyxY74ubSS52upFM4adAbY6qBm4B3ga3Aq8aYLSJyv4h8y2fRLGC+Me0g7YLZdeOre3d79surroI77rCnPD52LPifq1RH989/2gEOl13mdCWdgl8HTBljFgOLG827u9Hje0/yHs8Dz59SdaerrYIe7IFZ8+fbTdC77oJNm+Af/9BNUqVaYozdt5WZCf36OV1Np+C+QzyNsQditOVFDETgv/7Lnv1yzx7IyLBH0uqBVUo19fbb9oJA3/2u05V0Gu4L+qoqe9tWLXpfF19sT3N80UV2+GVGBqxa1fZ1KNVelZXZ/xvDhsEPf+h0NZ2G+4Le47G3TgQ92KtUvf46vPYa7N9vN0+zsuCLL5ypRymnHThghyTPmGEv35mba7d49dKBbcZ9QV/Xonfyj0gErrzSHvl35522S2fkSHuenG3bnKtLqbZy6JBt7FxxhW38zJ5tA/5Xv7L7sS65xOkKOxX3Bb3TLXpf3bvD738PhYVw2212pEFaGlx+Obz/vg7HVO5hjO22fOQRuOAC6NMHvvMde93mn/7UXsynoMBe30EHKrQ5952muD0FfZ24ODvO/rbb7GmOn3nGdu+MHGkvapKVZf9jKNWRVFTAsmX2eJIlS6DEexzlqFFw6612X9WUKfZaDspR7mvRt4eum5bEx9sWTVERPPccREbCjTfaIWbf/rZt8es4fNVe1dbCunV2KzUzE2Jj7TEkCxfCOefA3/8OxcWwcSM89BB84xsa8u2EtuidEBVl+yy//337n+Kll+CVV+Df/4Zu3eDCC+0RgxdfbPs3lXJCba09gvWDD2xX44oV8NVX9rmMDHvK7hkz7KlAwtwXJW7ivm+nLujbY4u+MREYM8ZODz8My5fbLp0337S3IjBhgv3PdP759j9UZKTTVSu38nhgwwb49FP48EMb8Pv22edSUmDWLPt3eOGF2gDpYNwX9E6Oo2+N0FCYPt1OTz5pW/pvvmmn+++H++6zWwKTJ8PUqXbTedw4uwWg1Kkyxg4S+PTT49P69ccbSgkJto996lQ7paQ4Wq5qHfcFfUfoujkZ35b+XXdBebltYb3/vm3133mnXS40FM44w7b0J06EsWPtqJ4uXZysXrU3Ho8d6rtxo502bbIt97rWelSU7Yq55Zbjf0sJCXoFNRdxb9B3hK4bf0VH283mWd4Le+3bB598crwltmABPP20fS40FIYOtUPY6qb0dEhN7dg/furkampg5047Xn3zZhvoGzfakK87HUdkpG0cfOtbMH68DfUzznDX/xfVhPuCvqN23ZyK2Fh7wEndQSe1tfaUr5s22bHMn39uN8MXLjw+Vj8kBJKS7I/AkCHHp8GD7cUfevZ0bn2U/yor7aitnTthxw57AF5urv3+8/OPN3QABg6E0aPt38moUfb+0KG647QTct837oaum1MVEmK7bNLS7EEqdQ4ftqMmcnNtCGzbZm/nzbNjoH11726DISHB3g4caHe4xcU1nXSHcHAcPQqlpfbEeKWldiopsaFeF+ylpQ0PtAsPtz/Yw4fbQB82zN5PT4eYGMdWRbUv7g163RS1O2onTLBTY/v329Dfvt2GSd1UXGz3BZSWtnz2zR49GgZ/nz52iok5ft93io62r+lMLcnqartv5auvGk779ze8v2fP8WD/+uum7xMWZre4UlLsaJeUFDslJ9spMbFz/buq0+K+v5DO0HUTCDExdpo4sfnna2ttq7+s7MRTcbHtKtq/357f5ESiomwXUd3Uo8eJH/fsac/3HxHRcIqMbPg4xM/j/upOYV1V1XTyeFqe7/HYraNDh5pOjecfPGgDvrnQriMCvXvbH8F+/Wwf+bRp9oRfdVO/fvY2NlYPOlKt5r6g74xdN8EQEnK8RT58uH+v8Xiab8WWl9sAPHDATr73d+5s+Ni3j7m9ioqyXV3du9utprr78fH2trmtGt+tnV69NLxVm3Jv0GvXTduLiLBhFx9/+u9RWdkw+I8etfPqWtbN3T+Vk8OFhdm/jcZTRETz8+ue8w12DWnVwbgv6LXrpmOLjLRTbKzTlSjlGu47qZl23SilVAPuDXrtulFKKcCNQa9dN0op1YD7gl67bpRSqgF3Br2IjoxQSikv9wV9VZW25pVSyof7gt7j0R2xSinlw6+gF5EZIpIrIvkiMreZ5x8TkQ3eKU9EKrzzk0VkvXf+FhH5WYDrb8rj0Ra9Ukr5OOkBUyISCjwJTAeKgbUissgYk1O3jDHmVp/lbwbO8j4sBSYZYypFpDuw2fva3YFciQa060YppRrwp0U/Acg3xhQYYzzAfGDWCZa/BpgHYIzxGGMqvfMj/fy81tGuG6WUasCf4B0IFPk8LvbOa0JEkoFUYLnPvEQR2eR9j4eaa82LyBwRyRaR7LKyslOpvyntulFKqQYC3cLOAhYaY2rqZhhjiowxo4AhwPdFpMkZr4wxTxtjMowxGXFxca2rQLtulFKqAX+CvgRI9Hmc4J3XnCy83TaNeVvym4Epp1LgKdOuG6WUasCfoF8LDBWRVBGJwIb5osYLiUgaEA2s9pmXICJR3vvRQCaQG4jCW6RdN0op1cBJR90YY6pF5CbgXSAUeNYYs0VE7geyjTF1oZ8FzDemwcnB04E/iogBBHjUGPN5YFehEe26UUqpBvw6H70xZjGwuNG8uxs9vreZ1y0FRrWivlOnXTdKKdWAO4+M1Ra9UkrVc1/Qa9eNUko14L6g164bpZRqwH1BX1mpLXqllPLhrqA3BkpLoV8/pytRSql2w11BX1EBBw9CcrLTlSilVLvhrqDfudPeatArpVQ9dwX9jh32VoNeKaXquSvotUWvlFJNuC/ou3aF2FinK1FKqXbDfUGfnAwiTleilFLthjuDXimlVD0NeqWUcjn3BP3hw7Bvnwa9Uko14p6gP3IEsrIgI8PpSpRSql3x63z0HUJcHMxr9iqGSinVqbmnRa+UUqpZGvRKKeVyGvRKKeVyGvRKKeVyGvRKKeVyGvRKKeVyGvRKKeVyGvRKKeVyYoxxuoYGRKQM2NmKt4gF9gWonI6kM653Z1xn0PXubPxd72RjTFxzT7S7oG8tEck2xnS68yB0xvXujOsMut5O19HWArHe2nWjlFIup0GvlFIu58agf9rpAhzSGde7M64z6Hp3Nq1eb9f10SullGrIjS16pZRSPjTolVLK5VwT9CIyQ0RyRSRfROY6XU8wicgOEflcRDaISLZ3Xh8RWSoi27y30U7X2Voi8qyIfCkim33mNbueYv2v9/vfJCJjnau8dVpY73tFpMT7nW8QkZk+z/3Gu965IvJNZ6puHRFJFJH3RSRHRLaIyC+88139fZ9gvQP7fRtjOvwEhALbgUFABLARGOF0XUFc3x1AbKN5DwNzvffnAg85XWcA1vNcYCyw+WTrCcwE3gEEOBv41On6A7ze9wK3N7PsCO/feySQ6v1/EOr0OpzGOvcHxnrv9wDyvOvm6u/7BOsd0O/bLS36CUC+MabAGOMB5gOzHK6prc0CXvDefwG4zLlSAsMY8yHwVaPZLa3nLOBFY30C9BaR/m1SaIC1sN4tmQXMN8ZUGmMKgXzs/4cOxRhTaoxZ771/ENgKDMTl3/cJ1rslp/V9uyXoBwJFPo+LOfE/VkdngPdEZJ2IzPHOizfGlHrv7wHinSkt6Fpaz87wN3CTt5viWZ+uOdett4ikAGcBn9KJvu9G6w0B/L7dEvSdTaYxZixwEXCjiJzr+6Sx23iuHzfbWdbT66/AYGAMUAr80dFqgkREugP/BH5pjDng+5ybv+9m1jug37dbgr4ESPR5nOCd50rGmBLv7ZfA69hNt711m67e2y+dqzCoWlpPV/8NGGP2GmNqjDG1wDMc31x3zXqLSDg27F42xvzLO9v133dz6x3o79stQb8WGCoiqSISAWQBixyuKShEpJuI9Ki7D1wIbMau7/e9i30feMOZCoOupfVcBFzvHY1xNvC1zyZ/h9eo//nb2O8c7HpniUikiKQCQ4E1bV1fa4mIAH8Hthpj/uTzlKu/75bWO+Dft9N7nQO493omdo/1duBOp+sJ4noOwu513whsqVtXIAb4D7ANWAb0cbrWAKzrPOxmaxW2L/JHLa0ndvTFk97v/3Mgw+n6A7zeL3nXa5P3P3t/n+Xv9K53LnCR0/Wf5jpnYrtlNgEbvNNMt3/fJ1jvgH7fegoEpZRyObd03SillGqBBr1SSrmcBr1SSrmcBr1SSrmcBr1SSrmcBr1SSrmcBr1SSrnc/wctU+tVY2SuygAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history, c=\"r\")\n",
    "plt.plot(history_val, c=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26f22d-0c89-4a7f-9e92-44bffe82a915",
   "metadata": {},
   "source": [
    "## Experiment 2: without month features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ea4ea62",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dense model in 121 epochs, val loss 7.89e-01, regularization 1.55e+00\n",
      "Lambda = 7.89e-01, selected 67 features in 5 epochs\n",
      "val_objective 2.64e+00, val_loss 8.03e-01, regularization 2.33e+00\n",
      "Lambda = 8.05e-01, selected 67 features in 48 epochs\n",
      "val_objective 2.11e+00, val_loss 7.96e-01, regularization 1.63e+00\n",
      "Lambda = 8.21e-01, selected 67 features in 18 epochs\n",
      "val_objective 2.05e+00, val_loss 8.04e-01, regularization 1.51e+00\n",
      "Lambda = 8.38e-01, selected 67 features in 23 epochs\n",
      "val_objective 1.96e+00, val_loss 7.90e-01, regularization 1.40e+00\n",
      "Lambda = 8.54e-01, selected 67 features in 7 epochs\n",
      "val_objective 1.96e+00, val_loss 7.90e-01, regularization 1.37e+00\n",
      "Lambda = 8.72e-01, selected 67 features in 9 epochs\n",
      "val_objective 1.95e+00, val_loss 7.90e-01, regularization 1.33e+00\n",
      "Lambda = 8.89e-01, selected 67 features in 9 epochs\n",
      "val_objective 1.96e+00, val_loss 8.02e-01, regularization 1.30e+00\n",
      "Lambda = 9.07e-01, selected 67 features in 8 epochs\n",
      "val_objective 1.95e+00, val_loss 7.95e-01, regularization 1.27e+00\n",
      "Lambda = 9.25e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 8.02e-01, regularization 1.25e+00\n",
      "Lambda = 9.43e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 7.95e-01, regularization 1.24e+00\n",
      "Lambda = 9.62e-01, selected 67 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 7.90e-01, regularization 1.22e+00\n",
      "Lambda = 9.82e-01, selected 67 features in 10 epochs\n",
      "val_objective 1.98e+00, val_loss 8.12e-01, regularization 1.19e+00\n",
      "Lambda = 1.00e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.96e+00, val_loss 7.95e-01, regularization 1.16e+00\n",
      "Lambda = 1.02e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.97e+00, val_loss 8.04e-01, regularization 1.14e+00\n",
      "Lambda = 1.04e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.97e+00, val_loss 7.98e-01, regularization 1.12e+00\n",
      "Lambda = 1.06e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.97e+00, val_loss 7.95e-01, regularization 1.11e+00\n",
      "Lambda = 1.08e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 7.98e-01, regularization 1.09e+00\n",
      "Lambda = 1.11e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.00e+00, val_loss 8.07e-01, regularization 1.08e+00\n",
      "Lambda = 1.13e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.99e+00, val_loss 7.89e-01, regularization 1.06e+00\n",
      "Lambda = 1.15e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.98e+00, val_loss 8.00e-01, regularization 1.02e+00\n",
      "Lambda = 1.17e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.98e+00, val_loss 8.02e-01, regularization 1.01e+00\n",
      "Lambda = 1.20e+00, selected 67 features in 14 epochs\n",
      "val_objective 1.97e+00, val_loss 8.03e-01, regularization 9.72e-01\n",
      "Lambda = 1.22e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 8.09e-01, regularization 9.60e-01\n",
      "Lambda = 1.24e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 7.97e-01, regularization 9.47e-01\n",
      "Lambda = 1.27e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.99e+00, val_loss 7.99e-01, regularization 9.35e-01\n",
      "Lambda = 1.30e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.00e+00, val_loss 8.07e-01, regularization 9.23e-01\n",
      "Lambda = 1.32e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.01e+00, val_loss 8.03e-01, regularization 9.10e-01\n",
      "Lambda = 1.35e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.02e+00, val_loss 8.05e-01, regularization 8.98e-01\n",
      "Lambda = 1.37e+00, selected 67 features in 9 epochs\n",
      "val_objective 2.00e+00, val_loss 7.94e-01, regularization 8.77e-01\n",
      "Lambda = 1.40e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.99e+00, val_loss 7.92e-01, regularization 8.58e-01\n",
      "Lambda = 1.43e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.03e+00, val_loss 8.21e-01, regularization 8.46e-01\n",
      "Lambda = 1.46e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.03e+00, val_loss 8.11e-01, regularization 8.34e-01\n",
      "Lambda = 1.49e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.02e+00, val_loss 7.98e-01, regularization 8.22e-01\n",
      "Lambda = 1.52e+00, selected 67 features in 9 epochs\n",
      "val_objective 2.01e+00, val_loss 7.95e-01, regularization 8.01e-01\n",
      "Lambda = 1.55e+00, selected 67 features in 11 epochs\n",
      "val_objective 2.00e+00, val_loss 7.97e-01, regularization 7.76e-01\n",
      "Lambda = 1.58e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.01e+00, val_loss 8.04e-01, regularization 7.65e-01\n",
      "Lambda = 1.61e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.02e+00, val_loss 8.03e-01, regularization 7.55e-01\n",
      "Lambda = 1.64e+00, selected 67 features in 8 epochs\n",
      "val_objective 2.01e+00, val_loss 7.95e-01, regularization 7.37e-01\n",
      "Lambda = 1.68e+00, selected 67 features in 10 epochs\n",
      "val_objective 2.00e+00, val_loss 7.98e-01, regularization 7.16e-01\n",
      "Lambda = 1.71e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.98e+00, val_loss 7.96e-01, regularization 6.95e-01\n",
      "Lambda = 1.74e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.98e+00, val_loss 8.02e-01, regularization 6.75e-01\n",
      "Lambda = 1.78e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 7.99e-01, regularization 6.66e-01\n",
      "Lambda = 1.81e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.97e+00, val_loss 7.93e-01, regularization 6.51e-01\n",
      "Lambda = 1.85e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.98e+00, val_loss 7.97e-01, regularization 6.39e-01\n",
      "Lambda = 1.89e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.98e+00, val_loss 7.95e-01, regularization 6.30e-01\n",
      "Lambda = 1.92e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.00e+00, val_loss 8.03e-01, regularization 6.20e-01\n",
      "Lambda = 1.96e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.00e+00, val_loss 7.98e-01, regularization 6.10e-01\n",
      "Lambda = 2.00e+00, selected 67 features in 5 epochs\n",
      "val_objective 2.00e+00, val_loss 7.98e-01, regularization 6.00e-01\n",
      "Lambda = 2.04e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.99e+00, val_loss 8.06e-01, regularization 5.82e-01\n",
      "Lambda = 2.08e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.98e+00, val_loss 8.03e-01, regularization 5.65e-01\n",
      "Lambda = 2.12e+00, selected 67 features in 12 epochs\n",
      "val_objective 1.95e+00, val_loss 7.95e-01, regularization 5.43e-01\n",
      "Lambda = 2.17e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.95e+00, val_loss 7.93e-01, regularization 5.35e-01\n",
      "Lambda = 2.21e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.94e+00, val_loss 7.95e-01, regularization 5.17e-01\n",
      "Lambda = 2.25e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.93e+00, val_loss 7.99e-01, regularization 5.02e-01\n",
      "Lambda = 2.30e+00, selected 67 features in 12 epochs\n",
      "val_objective 1.90e+00, val_loss 7.91e-01, regularization 4.82e-01\n",
      "Lambda = 2.35e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.88e+00, val_loss 7.83e-01, regularization 4.69e-01\n",
      "Lambda = 2.39e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.89e+00, val_loss 7.92e-01, regularization 4.58e-01\n",
      "Lambda = 2.44e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.89e+00, val_loss 7.87e-01, regularization 4.51e-01\n",
      "Lambda = 2.49e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.86e+00, val_loss 7.82e-01, regularization 4.34e-01\n",
      "Lambda = 2.54e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.88e+00, val_loss 7.96e-01, regularization 4.26e-01\n",
      "Lambda = 2.59e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.86e+00, val_loss 7.85e-01, regularization 4.14e-01\n",
      "Lambda = 2.64e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.87e+00, val_loss 7.94e-01, regularization 4.07e-01\n",
      "Lambda = 2.69e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.84e+00, val_loss 7.85e-01, regularization 3.92e-01\n",
      "Lambda = 2.75e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.83e+00, val_loss 7.80e-01, regularization 3.81e-01\n",
      "Lambda = 2.80e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.82e+00, val_loss 7.83e-01, regularization 3.70e-01\n",
      "Lambda = 2.86e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.80e+00, val_loss 7.74e-01, regularization 3.58e-01\n",
      "Lambda = 2.92e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.81e+00, val_loss 7.80e-01, regularization 3.51e-01\n",
      "Lambda = 2.98e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.77e+00, val_loss 7.79e-01, regularization 3.32e-01\n",
      "Lambda = 3.03e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.74e+00, val_loss 7.89e-01, regularization 3.14e-01\n",
      "Lambda = 3.10e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.73e+00, val_loss 7.76e-01, regularization 3.07e-01\n",
      "Lambda = 3.16e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.73e+00, val_loss 7.82e-01, regularization 3.01e-01\n",
      "Lambda = 3.22e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.71e+00, val_loss 7.77e-01, regularization 2.90e-01\n",
      "Lambda = 3.28e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.71e+00, val_loss 7.82e-01, regularization 2.82e-01\n",
      "Lambda = 3.35e+00, selected 67 features in 19 epochs\n",
      "val_objective 1.66e+00, val_loss 7.83e-01, regularization 2.63e-01\n",
      "Lambda = 3.42e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.63e+00, val_loss 7.71e-01, regularization 2.52e-01\n",
      "Lambda = 3.49e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.63e+00, val_loss 7.73e-01, regularization 2.46e-01\n",
      "Lambda = 3.56e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.61e+00, val_loss 7.68e-01, regularization 2.38e-01\n",
      "Lambda = 3.63e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.63e+00, val_loss 7.81e-01, regularization 2.33e-01\n",
      "Lambda = 3.70e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.62e+00, val_loss 7.73e-01, regularization 2.28e-01\n",
      "Lambda = 3.77e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.62e+00, val_loss 7.71e-01, regularization 2.24e-01\n",
      "Lambda = 3.85e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.61e+00, val_loss 7.79e-01, regularization 2.16e-01\n",
      "Lambda = 3.93e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.58e+00, val_loss 7.81e-01, regularization 2.04e-01\n",
      "Lambda = 4.00e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.55e+00, val_loss 7.62e-01, regularization 1.96e-01\n",
      "Lambda = 4.08e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.55e+00, val_loss 7.72e-01, regularization 1.91e-01\n",
      "Lambda = 4.17e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.55e+00, val_loss 7.68e-01, regularization 1.87e-01\n",
      "Lambda = 4.25e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.54e+00, val_loss 7.65e-01, regularization 1.83e-01\n",
      "Lambda = 4.33e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.55e+00, val_loss 7.77e-01, regularization 1.79e-01\n",
      "Lambda = 4.42e+00, selected 67 features in 11 epochs\n",
      "val_objective 1.53e+00, val_loss 7.69e-01, regularization 1.72e-01\n",
      "Lambda = 4.51e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.51e+00, val_loss 7.61e-01, regularization 1.66e-01\n",
      "Lambda = 4.60e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.50e+00, val_loss 7.63e-01, regularization 1.59e-01\n",
      "Lambda = 4.69e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.48e+00, val_loss 7.64e-01, regularization 1.53e-01\n",
      "Lambda = 4.79e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.48e+00, val_loss 7.59e-01, regularization 1.50e-01\n",
      "Lambda = 4.88e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.47e+00, val_loss 7.58e-01, regularization 1.46e-01\n",
      "Lambda = 4.98e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.47e+00, val_loss 7.67e-01, regularization 1.41e-01\n",
      "Lambda = 5.08e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.46e+00, val_loss 7.65e-01, regularization 1.37e-01\n",
      "Lambda = 5.18e+00, selected 67 features in 12 epochs\n",
      "val_objective 1.43e+00, val_loss 7.62e-01, regularization 1.30e-01\n",
      "Lambda = 5.28e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.43e+00, val_loss 7.68e-01, regularization 1.25e-01\n",
      "Lambda = 5.39e+00, selected 67 features in 12 epochs\n",
      "val_objective 1.40e+00, val_loss 7.58e-01, regularization 1.19e-01\n",
      "Lambda = 5.50e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.40e+00, val_loss 7.57e-01, regularization 1.17e-01\n",
      "Lambda = 5.61e+00, selected 67 features in 8 epochs\n",
      "val_objective 1.39e+00, val_loss 7.54e-01, regularization 1.14e-01\n",
      "Lambda = 5.72e+00, selected 67 features in 17 epochs\n",
      "val_objective 1.36e+00, val_loss 7.61e-01, regularization 1.06e-01\n",
      "Lambda = 5.83e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.35e+00, val_loss 7.55e-01, regularization 1.02e-01\n",
      "Lambda = 5.95e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.35e+00, val_loss 7.57e-01, regularization 9.95e-02\n",
      "Lambda = 6.07e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.34e+00, val_loss 7.56e-01, regularization 9.67e-02\n",
      "Lambda = 6.19e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.34e+00, val_loss 7.58e-01, regularization 9.44e-02\n",
      "Lambda = 6.31e+00, selected 67 features in 13 epochs\n",
      "val_objective 1.32e+00, val_loss 7.55e-01, regularization 8.87e-02\n",
      "Lambda = 6.44e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.33e+00, val_loss 7.69e-01, regularization 8.65e-02\n",
      "Lambda = 6.57e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.31e+00, val_loss 7.63e-01, regularization 8.34e-02\n",
      "Lambda = 6.70e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.29e+00, val_loss 7.63e-01, regularization 7.82e-02\n",
      "Lambda = 6.83e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.27e+00, val_loss 7.62e-01, regularization 7.45e-02\n",
      "Lambda = 6.97e+00, selected 67 features in 13 epochs\n",
      "val_objective 1.25e+00, val_loss 7.57e-01, regularization 7.02e-02\n",
      "Lambda = 7.11e+00, selected 67 features in 10 epochs\n",
      "val_objective 1.22e+00, val_loss 7.51e-01, regularization 6.64e-02\n",
      "Lambda = 7.25e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.23e+00, val_loss 7.60e-01, regularization 6.42e-02\n",
      "Lambda = 7.40e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.22e+00, val_loss 7.57e-01, regularization 6.26e-02\n",
      "Lambda = 7.55e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.21e+00, val_loss 7.61e-01, regularization 5.97e-02\n",
      "Lambda = 7.70e+00, selected 67 features in 14 epochs\n",
      "val_objective 1.18e+00, val_loss 7.51e-01, regularization 5.59e-02\n",
      "Lambda = 7.85e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 7.69e-01, regularization 5.45e-02\n",
      "Lambda = 8.01e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.18e+00, val_loss 7.61e-01, regularization 5.26e-02\n",
      "Lambda = 8.17e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.17e+00, val_loss 7.59e-01, regularization 5.03e-02\n",
      "Lambda = 8.33e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.17e+00, val_loss 7.62e-01, regularization 4.94e-02\n",
      "Lambda = 8.50e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.16e+00, val_loss 7.57e-01, regularization 4.74e-02\n",
      "Lambda = 8.67e+00, selected 67 features in 15 epochs\n",
      "val_objective 1.14e+00, val_loss 7.58e-01, regularization 4.39e-02\n",
      "Lambda = 8.84e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.14e+00, val_loss 7.59e-01, regularization 4.32e-02\n",
      "Lambda = 9.02e+00, selected 67 features in 5 epochs\n",
      "val_objective 1.14e+00, val_loss 7.65e-01, regularization 4.20e-02\n",
      "Lambda = 9.20e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.13e+00, val_loss 7.55e-01, regularization 4.12e-02\n",
      "Lambda = 9.38e+00, selected 67 features in 9 epochs\n",
      "val_objective 1.13e+00, val_loss 7.56e-01, regularization 3.93e-02\n",
      "Lambda = 9.57e+00, selected 67 features in 7 epochs\n",
      "val_objective 1.12e+00, val_loss 7.61e-01, regularization 3.72e-02\n",
      "Lambda = 9.76e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.12e+00, val_loss 7.58e-01, regularization 3.75e-02\n",
      "Lambda = 9.96e+00, selected 67 features in 6 epochs\n",
      "val_objective 1.11e+00, val_loss 7.60e-01, regularization 3.56e-02\n",
      "Lambda = 1.02e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.11e+00, val_loss 7.66e-01, regularization 3.39e-02\n",
      "Lambda = 1.04e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.11e+00, val_loss 7.55e-01, regularization 3.42e-02\n",
      "Lambda = 1.06e+01, selected 67 features in 8 epochs\n",
      "val_objective 1.10e+00, val_loss 7.64e-01, regularization 3.22e-02\n",
      "Lambda = 1.08e+01, selected 67 features in 9 epochs\n",
      "val_objective 1.09e+00, val_loss 7.53e-01, regularization 3.11e-02\n",
      "Lambda = 1.10e+01, selected 67 features in 8 epochs\n",
      "val_objective 1.08e+00, val_loss 7.63e-01, regularization 2.92e-02\n",
      "Lambda = 1.12e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.08e+00, val_loss 7.53e-01, regularization 2.91e-02\n",
      "Lambda = 1.14e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.10e+00, val_loss 7.67e-01, regularization 2.87e-02\n",
      "Lambda = 1.17e+01, selected 67 features in 6 epochs\n",
      "val_objective 1.08e+00, val_loss 7.58e-01, regularization 2.80e-02\n",
      "Lambda = 1.19e+01, selected 67 features in 5 epochs\n",
      "val_objective 1.09e+00, val_loss 7.59e-01, regularization 2.76e-02\n",
      "Lambda = 1.21e+01, selected 67 features in 6 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.24e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.26e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.29e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.31e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.34e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.37e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.39e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.42e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.45e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.48e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.51e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.54e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.57e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.60e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.63e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.67e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.70e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.73e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.77e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.80e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.84e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.88e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.91e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.95e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.99e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.03e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.07e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.11e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.16e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.20e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.24e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.29e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.33e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.38e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.43e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.48e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.53e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.58e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.63e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.68e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.73e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.79e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.84e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.90e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.96e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.02e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.08e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.14e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.20e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.27e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.33e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.40e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.47e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.54e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.61e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.68e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.75e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.83e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.90e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.98e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.06e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.14e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.23e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.31e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.40e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.48e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.57e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.67e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.76e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.85e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.95e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.05e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.15e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.25e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.36e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.47e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.58e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.69e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.80e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.92e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.04e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.16e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.28e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.41e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.53e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.66e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.80e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.93e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.07e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.21e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.36e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.50e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.66e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.81e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.96e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.12e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.29e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.45e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.62e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.79e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.97e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.15e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.33e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.52e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.71e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.90e+01, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.01e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.03e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.05e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.07e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.09e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.12e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.14e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.16e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.18e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.21e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.23e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.26e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.28e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.31e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.33e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.36e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.39e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.41e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.44e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.47e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.50e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.53e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.56e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.59e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.62e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.66e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.69e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.72e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.76e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.79e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.83e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.87e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.90e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.94e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.98e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.02e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.06e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.10e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.14e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.19e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.23e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.27e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.32e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.37e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.41e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.46e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.51e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.56e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.61e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.67e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.72e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.77e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.83e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.89e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.94e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.00e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.06e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.12e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.19e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.25e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.31e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.38e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.45e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.52e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.59e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.66e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.73e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.81e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.88e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.96e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.04e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.12e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.20e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.29e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.37e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.46e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.55e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.64e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.73e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.83e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.92e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.02e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.12e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.23e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.33e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.44e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.55e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.66e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.77e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.89e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.00e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.12e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.25e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.37e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.50e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.63e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.76e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.90e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.03e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.17e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.32e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.46e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.61e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.77e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.92e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.08e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.24e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.41e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.57e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.75e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.92e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.10e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.28e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.47e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.66e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.85e+02, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.00e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.02e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.05e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.07e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.09e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.11e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.13e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.15e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.18e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.20e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.22e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.25e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.27e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.30e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.33e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.35e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.38e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.41e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.43e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.46e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.49e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.52e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.55e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.58e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.62e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.65e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.68e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.71e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.75e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.78e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.82e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.86e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.89e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.93e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.97e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.01e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.05e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.09e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.13e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.17e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.22e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.26e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.31e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.35e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.40e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.45e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.50e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.55e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.60e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.65e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.70e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.76e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.81e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.87e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.93e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.99e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.04e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.11e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.17e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.23e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.30e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.36e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.43e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.50e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.57e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.64e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.71e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.79e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.86e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.94e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.02e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.10e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.18e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.26e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.35e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.44e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.52e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.62e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.71e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.80e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.90e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.00e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.10e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.20e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.30e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.41e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.52e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.63e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.74e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.85e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.97e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.09e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.21e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.34e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.46e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.59e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.72e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.86e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.00e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.13e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.28e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.42e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.57e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.72e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.88e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.04e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.20e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.36e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.53e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.70e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.87e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.05e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.23e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.41e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.60e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.79e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.99e+03, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.02e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.04e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.06e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.08e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.10e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.13e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.15e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.17e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.19e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.22e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.24e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.27e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.29e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.32e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.34e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.37e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.40e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.43e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.46e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.48e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.51e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.54e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.58e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.61e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.64e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.67e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.71e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.74e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.77e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.81e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.85e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.88e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.92e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.96e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.00e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.04e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.08e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.12e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.16e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.21e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.25e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.30e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.34e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.39e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.44e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.48e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.53e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.58e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.64e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.69e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.74e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.80e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.85e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.91e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.97e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.03e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.09e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.15e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.21e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.28e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.34e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.41e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.48e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.55e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.62e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.69e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.77e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.84e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.92e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.00e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.08e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.16e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.24e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.33e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.41e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.50e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.59e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.68e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.78e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.87e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.97e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.07e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.17e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.27e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.38e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.49e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.60e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.71e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.82e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.94e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.06e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.18e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.30e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.43e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.56e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.69e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.82e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.96e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.10e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.24e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.38e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.53e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.68e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.83e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.99e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.15e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.31e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.48e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.65e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.82e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.00e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.18e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.36e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.55e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.74e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.94e+04, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.01e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.03e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.05e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.08e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.10e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.12e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.14e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.16e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.19e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.21e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.24e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.26e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.29e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.31e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.34e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.36e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.39e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.42e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.45e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.48e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.51e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.54e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.57e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.60e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.63e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.66e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.70e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.73e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.76e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.80e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.84e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.87e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.91e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.95e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.99e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.03e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.07e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.11e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.15e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.19e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.24e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.28e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.33e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.37e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.42e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.47e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.52e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.57e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.62e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.67e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.73e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.78e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.84e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.89e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.95e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.01e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.07e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.13e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.20e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.26e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.33e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.39e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.46e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.53e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.60e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.67e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.74e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.82e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.90e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.97e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.05e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.13e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.22e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.30e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.39e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.48e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.56e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.66e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.75e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.84e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.94e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.04e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.14e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.24e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.35e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.46e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.56e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.68e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.79e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.91e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.02e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.14e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.27e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.39e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.52e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.65e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.78e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.92e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.06e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.20e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.34e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.49e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.64e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.79e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.95e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.11e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.27e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.43e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.60e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.77e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.95e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.13e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.31e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.50e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.69e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.88e+05, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.01e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.03e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.05e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.07e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.09e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.11e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.14e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.16e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.18e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.20e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.23e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.25e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.28e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.30e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.33e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.36e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.38e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.41e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.44e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.47e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.50e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.53e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.56e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.59e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.62e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.65e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.69e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.72e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.75e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.79e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.83e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.86e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.90e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.94e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.98e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.02e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.06e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.10e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.14e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.18e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.23e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.27e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.32e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.36e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.41e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.46e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.51e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.56e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.61e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.66e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.71e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.77e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.82e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.88e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.94e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.00e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.06e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.12e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.18e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.24e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.31e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.37e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.44e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.51e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.58e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.65e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.72e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.80e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.87e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.95e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.03e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.11e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.19e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.28e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.36e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.45e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.54e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.63e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.72e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.82e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.91e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.01e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.11e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.21e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.32e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.43e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.53e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.64e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.76e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.87e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.99e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.11e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.23e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.36e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.48e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.61e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.75e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.88e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.02e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.16e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.30e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.45e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.60e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.75e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.90e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.06e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.22e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.39e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.56e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.73e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.90e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.08e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.26e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.45e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.63e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.83e+06, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.00e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.02e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.04e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.06e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.09e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.11e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.13e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.15e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.17e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.20e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.22e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.25e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.27e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.30e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.32e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.35e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.38e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.40e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.43e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.46e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.49e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.52e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.55e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.58e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.61e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.64e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.68e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.71e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.75e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.78e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.82e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.85e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.89e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.93e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.97e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.00e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.04e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.09e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.13e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.17e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.21e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.26e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.30e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.35e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.40e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.44e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.49e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.54e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.59e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.65e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.70e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.75e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.81e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.86e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.92e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.98e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.04e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.10e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.16e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.22e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.29e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.35e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.42e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.49e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.56e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.63e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.70e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.78e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.85e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 3.93e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.01e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.09e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.17e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.25e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.34e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.43e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.52e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.61e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.70e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.79e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.89e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 4.98e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.08e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.19e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.29e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.40e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.50e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.61e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.73e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.84e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 5.96e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.08e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.20e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.32e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.45e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.58e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.71e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.84e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 6.98e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.12e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.26e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.41e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.56e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.71e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 7.86e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.02e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.18e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.34e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.51e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.68e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 8.85e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.03e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.21e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.39e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.58e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.77e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 9.97e+07, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.02e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.04e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.06e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.08e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.10e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.12e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.15e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.17e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.19e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.22e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.24e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.26e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.29e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.32e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.34e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.37e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.40e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.42e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.45e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.48e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.51e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.54e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.57e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.60e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.64e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.67e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.70e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.74e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.77e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.81e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.84e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.88e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.92e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.95e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 1.99e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.03e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.07e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.12e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.16e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.20e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.25e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.29e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.34e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.38e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.43e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.48e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.53e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.58e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.63e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.68e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.74e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.79e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n",
      "Lambda = 2.85e+08, selected 67 features in 5 epochs\n",
      "val_objective nan, val_loss nan, regularization nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\Documents\\ml-seminar\\2-LassoNet.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000075?line=11'>12</a>\u001b[0m \u001b[39m## trial run#\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000075?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m LassoNetRegressor(hidden_dims\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m,), verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, patience\u001b[39m=\u001b[39m(\u001b[39m100\u001b[39m, \u001b[39m5\u001b[39m), batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000075?line=13'>14</a>\u001b[0m path \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpath(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ml-seminar\\lib\\site-packages\\lassonet\\interfaces.py:359\u001b[0m, in \u001b[0;36mBaseLassoNet.path\u001b[1;34m(self, X, y, X_val, y_val, lambda_)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mselected_count() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    357\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    358\u001b[0m hist\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m    360\u001b[0m         X_train,\n\u001b[0;32m    361\u001b[0m         y_train,\n\u001b[0;32m    362\u001b[0m         X_val,\n\u001b[0;32m    363\u001b[0m         y_val,\n\u001b[0;32m    364\u001b[0m         batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m    365\u001b[0m         lambda_\u001b[39m=\u001b[39;49mcurrent_lambda,\n\u001b[0;32m    366\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iters_path,\n\u001b[0;32m    367\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m    368\u001b[0m         patience\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatience_path,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m )\n\u001b[0;32m    371\u001b[0m last \u001b[39m=\u001b[39m hist[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ml-seminar\\lib\\site-packages\\lassonet\\interfaces.py:242\u001b[0m, in \u001b[0;36mBaseLassoNet._train\u001b[1;34m(self, X_train, y_train, X_val, y_val, batch_size, epochs, lambda_, optimizer, patience)\u001b[0m\n\u001b[0;32m    240\u001b[0m     optimizer\u001b[39m.\u001b[39mstep(closure)\n\u001b[0;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m lambda_:\n\u001b[1;32m--> 242\u001b[0m         model\u001b[39m.\u001b[39;49mprox(\n\u001b[0;32m    243\u001b[0m             lambda_\u001b[39m=\u001b[39;49mlambda_ \u001b[39m*\u001b[39;49m optimizer\u001b[39m.\u001b[39;49mparam_groups[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m], M\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mM\n\u001b[0;32m    244\u001b[0m         )\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    247\u001b[0m     \u001b[39m# fallback to running loss of first epoch\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     real_loss \u001b[39m=\u001b[39m loss\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ml-seminar\\lib\\site-packages\\lassonet\\model.py:36\u001b[0m, in \u001b[0;36mLassoNet.prox\u001b[1;34m(self, lambda_, lambda_bar, M)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprox\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, lambda_, lambda_bar\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, M\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 36\u001b[0m         inplace_prox(\n\u001b[0;32m     37\u001b[0m             beta\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mskip,\n\u001b[0;32m     38\u001b[0m             theta\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m     39\u001b[0m             lambda_\u001b[39m=\u001b[39;49mlambda_,\n\u001b[0;32m     40\u001b[0m             lambda_bar\u001b[39m=\u001b[39;49mlambda_bar,\n\u001b[0;32m     41\u001b[0m             M\u001b[39m=\u001b[39;49mM,\n\u001b[0;32m     42\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ml-seminar\\lib\\site-packages\\lassonet\\prox.py:61\u001b[0m, in \u001b[0;36minplace_prox\u001b[1;34m(beta, theta, lambda_, lambda_bar, M)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minplace_prox\u001b[39m(beta, theta, lambda_, lambda_bar, M):\n\u001b[1;32m---> 61\u001b[0m     beta\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata, theta\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m prox(\n\u001b[0;32m     62\u001b[0m         beta\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata, theta\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata, lambda_\u001b[39m=\u001b[39;49mlambda_, lambda_bar\u001b[39m=\u001b[39;49mlambda_bar, M\u001b[39m=\u001b[39;49mM\n\u001b[0;32m     63\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ml-seminar\\lib\\site-packages\\lassonet\\prox.py:39\u001b[0m, in \u001b[0;36mprox\u001b[1;34m(v, u, lambda_, lambda_bar, M)\u001b[0m\n\u001b[0;32m     33\u001b[0m a_s \u001b[39m=\u001b[39m lambda_ \u001b[39m-\u001b[39m M \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[0;32m     34\u001b[0m     [zeros, torch\u001b[39m.\u001b[39mcumsum(u_abs_sorted \u001b[39m-\u001b[39m lambda_bar, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)]\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m norm_v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(v, p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m a_s \u001b[39m/\u001b[39m norm_v) \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m s \u001b[39m*\u001b[39;49m M \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     41\u001b[0m w \u001b[39m=\u001b[39m M \u001b[39m*\u001b[39m x \u001b[39m*\u001b[39m norm_v\n\u001b[0;32m     42\u001b[0m intervals \u001b[39m=\u001b[39m soft_threshold(lambda_bar, u_abs_sorted)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run pipeline using all but month features\n",
    "results_dir = './results/'\n",
    "run_id = '02'\n",
    "\n",
    "# load an split data sets\n",
    "data = data_loader(subsample_path, pickle=False, parse_dates=True)\n",
    "data = normalize_target(data)\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = data_splitter(data)\n",
    "\n",
    "# bring data to array\n",
    "X_train, X_test, y_train, y_test = df_to_array(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "## trial run#\n",
    "start_time = datetime.now()\n",
    "model = LassoNetRegressor(hidden_dims=(100,), verbose=True, patience=(100, 5), batch_size=256, dropout=0.4, random_state=0)\n",
    "path = model.path(X_train, y_train)\n",
    "execution_time = round((datetime.now() - start_time).total_seconds())\n",
    "print(f\"Finished training in {execution_time} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ee315f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_path(model, path, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7cd1149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model scored -0.0014814291294054094\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LassoNetRegressor' object has no attribute 'best_lambda_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\Documents\\ml-seminar\\2-LassoNet.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest model scored\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39mscore(X_test, y_test))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Documents/ml-seminar/2-LassoNet.ipynb#ch0000033?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLambda =\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39;49mbest_lambda_)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LassoNetRegressor' object has no attribute 'best_lambda_'"
     ]
    }
   ],
   "source": [
    "print(\"Best model scored\", model.score(X_test, y_test))\n",
    "print(\"Lambda =\", model.best_lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ede1b-00d0-4e6e-8610-a64890c6c3ad",
   "metadata": {},
   "source": [
    "## Use all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecfac7-7e42-472a-b543-f6f9b1219c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an split data sets\n",
    "all_data = data_loader(fullsample_path, pickle=False, parse_dates=True)\n",
    "all_data = normalize_target(data)\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = data_splitter(all_data)\n",
    "# bring data to array\n",
    "X_train, X_test, y_train, y_test = df_to_array(X_train, X_valid, y_train, y_valid)\n",
    "\n",
    "## trial run#\n",
    "model = LassoNetRegressor(hidden_dims=(50,), verbose=True, patience=(100, 5))\n",
    "path = model.path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c535b01-338f-4c3b-8f6b-a7b405b60c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04467ed8-b70f-4ff1-a76a-de1a6461465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsample_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664636e-4554-4316-884a-1e92e192c119",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Some more modelling on various data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3058b793-6731-4841-a3e8-6bde5ee7b67e",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1656662704366,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "3058b793-6731-4841-a3e8-6bde5ee7b67e"
   },
   "outputs": [],
   "source": [
    "### Helper method to visualize prediction vs true values\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "permnos_total = subsample.index.droplevel(['date'])\n",
    "\n",
    "def visualize_sample_prediction(y_test, y_pred):\n",
    "    # Picks a random stock, to visualize its real returns \n",
    "    # against the predicted returns\n",
    "    sample_permno = random.choice(permnos_total)\n",
    "    ## delete:\n",
    "    #sample_permno = 51625\n",
    "    sample_test_y = y_test.xs(sample_permno, level='permno')\n",
    "    \n",
    "    sample_test_idx = sample_test_y.index.get_level_values('date')\n",
    "    \n",
    "    y_pred = pd.Series(y_pred, index=y_test.index)\n",
    "    sample_pred = y_pred.xs(sample_permno, level='permno')\n",
    "    \n",
    "    \n",
    "    fig,ax=plt.subplots(figsize=(18,6))\n",
    "\n",
    "    ax.scatter(x=sample_test_idx, y= sample_test_y, color='r')\n",
    "    ax.scatter(x=sample_test_idx, y= sample_pred, color='b')\n",
    "    plt.title(f'Stock nr {sample_permno} predicted returns (blue) vs actual returns (red)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2945f2b-00c5-4acf-84ce-14a83a4a2d8f",
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1656663258882,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "c2945f2b-00c5-4acf-84ce-14a83a4a2d8f"
   },
   "outputs": [],
   "source": [
    "## best features found by random forrest reg\n",
    "features_rf = ['d_shrout', 'roe', 'oa', 'free_cf', 'nop', 'dpi2a', 'rna', 'ato', 'd_dgm_dsales', 'roc', 'ipm', 'spread_mean', 'dto', 'suv', 'TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "_-LPHkgDPudc",
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1656664723490,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "_-LPHkgDPudc"
   },
   "outputs": [],
   "source": [
    "## best features used by freyberger et al:\n",
    "features_freyberger = ['d_shrout', 'd_so', 'investment', 'lme', 'lturnover', 'pm_adj', 'cum_return_1_0', 'cum_return_12_2', 'cum_return_12_7', 'rel_to_high_price', 'roc','suv', 'total_vol','TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ab596ce-f080-4225-8d5f-7f44d9dce200",
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1656667432382,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "0ab596ce-f080-4225-8d5f-7f44d9dce200"
   },
   "outputs": [],
   "source": [
    "features_ae = ['e2p', 'beme', 'cum_return_12_2', 'cum_return_12_7', 'mm_sin', 'mm_cos', 'yy', 'dpi2a', 'ret', 'total_vol', 'noa', 'std_volume', 'cto', 'TARGET']\n",
    "#pipe_run_4 = list(pipeline(subsample_path, feature_selection=features_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "Fi6FyYjvszff",
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1656667118302,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "Fi6FyYjvszff"
   },
   "outputs": [],
   "source": [
    "features_adhoc = ['yy', 'cum_return_12_7', 'ret', 'd_so', 'mm_sin', 'suv', 'd_shrout', 'mm_cos', 'rna', 'stock', 'TARGET']\n",
    "features_few = ['yy',  'ret', 'mm_sin', 'd_shrout', 'mm_cos', 'stock', 'TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3KWDt3sgwzR",
   "metadata": {
    "id": "g3KWDt3sgwzR",
    "tags": []
   },
   "source": [
    "### Use Union of features from three selection methods (RF, freyberger, AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67DauSDg7jg",
   "metadata": {
    "id": "b67DauSDg7jg"
   },
   "outputs": [],
   "source": [
    "# Without repetition \n",
    "def union(lst1, lst2, lst3):\n",
    "    final_list = list(set(lst1) | set(lst2) | set(lst3))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G4XtreJVhClq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1656627768459,
     "user": {
      "displayName": "Micha Ianniello",
      "userId": "13712894490193878768"
     },
     "user_tz": -120
    },
    "id": "G4XtreJVhClq",
    "outputId": "ebff30a9-5c82-43a0-d803-b6f66df60018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ato', 'yy', 'spread_mean', 'cum_return_12_7', 'ret', 'd_so', 'd_dgm_dsales', 'lturnover', 'roe', 'mm_sin', 'ipm', 'dpi2a', 'beme', 'nop', 'lme', 'suv', 'dto', 'noa', 'd_shrout', 'total_vol', 'free_cf', 'cum_return_1_0', 'mm_cos', 'roc', 'e2p', 'oa', 'cto', 'rna', 'pm_adj', 'std_volume', 'rel_to_high_price', 'cum_return_12_2', 'investment']\n"
     ]
    }
   ],
   "source": [
    "a = features_ae\n",
    "b = features_freyberger\n",
    "c = features_rf\n",
    "features_comb = union(a,b,c)\n",
    "features_comb.remove(\"TARGET\")\n",
    "print(features_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cr5sddl9uqkH",
   "metadata": {
    "id": "cr5sddl9uqkH"
   },
   "outputs": [],
   "source": [
    "features_combined = ['ato', 'yy', 'spread_mean', 'cum_return_12_7', 'ret', 'd_so', 'd_dgm_dsales', 'lturnover', 'roe', 'mm_sin', 'ipm', 'dpi2a', 'beme', 'nop', 'lme', 'suv', 'dto', 'noa', 'd_shrout', 'total_vol', 'free_cf', 'cum_return_1_0', 'mm_cos', 'roc', 'e2p', 'oa', 'cto', 'rna', 'pm_adj', 'std_volume', 'rel_to_high_price', 'cum_return_12_2', 'investment', 'TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5359aebd-5bfc-46a3-9252-4da8dcd5243f",
   "metadata": {
    "id": "0056f84b-b63f-42d4-bbd5-65365d59aa70"
   },
   "source": [
    "## California Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccf9a13b-5a4a-4e10-9890-9543c0244e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)  //  (20640,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, \" // \", y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d913772-c4cc-4592-86fc-9495aa3d3ee0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dense model in 1000 epochs, val loss 3.14e-01, regularization 9.81e-01\n",
      "Lambda = 3.14e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.61e-01, val_loss 3.11e-01, regularization 1.12e+00\n",
      "Lambda = 3.21e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.64e-01, val_loss 3.10e-01, regularization 1.10e+00\n",
      "Lambda = 3.27e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.66e-01, val_loss 3.10e-01, regularization 1.09e+00\n",
      "Lambda = 3.34e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.69e-01, val_loss 3.10e-01, regularization 1.08e+00\n",
      "Lambda = 3.40e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.72e-01, val_loss 3.10e-01, regularization 1.06e+00\n",
      "Lambda = 3.47e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.75e-01, val_loss 3.10e-01, regularization 1.05e+00\n",
      "Lambda = 3.54e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.79e-01, val_loss 3.10e-01, regularization 1.04e+00\n",
      "Lambda = 3.61e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.82e-01, val_loss 3.10e-01, regularization 1.03e+00\n",
      "Lambda = 3.68e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.86e-01, val_loss 3.10e-01, regularization 1.02e+00\n",
      "Lambda = 3.76e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.90e-01, val_loss 3.10e-01, regularization 1.01e+00\n",
      "Lambda = 3.83e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.93e-01, val_loss 3.10e-01, regularization 1.00e+00\n",
      "Lambda = 3.91e-01, selected 16 features in 5 epochs\n",
      "val_objective 6.97e-01, val_loss 3.10e-01, regularization 9.92e-01\n",
      "Lambda = 3.99e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.01e-01, val_loss 3.10e-01, regularization 9.82e-01\n",
      "Lambda = 4.07e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.05e-01, val_loss 3.10e-01, regularization 9.72e-01\n",
      "Lambda = 4.15e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.09e-01, val_loss 3.10e-01, regularization 9.62e-01\n",
      "Lambda = 4.23e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.13e-01, val_loss 3.10e-01, regularization 9.53e-01\n",
      "Lambda = 4.32e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.17e-01, val_loss 3.10e-01, regularization 9.44e-01\n",
      "Lambda = 4.40e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.22e-01, val_loss 3.10e-01, regularization 9.36e-01\n",
      "Lambda = 4.49e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.26e-01, val_loss 3.10e-01, regularization 9.28e-01\n",
      "Lambda = 4.58e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.31e-01, val_loss 3.10e-01, regularization 9.20e-01\n",
      "Lambda = 4.67e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.36e-01, val_loss 3.10e-01, regularization 9.11e-01\n",
      "Lambda = 4.77e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.40e-01, val_loss 3.10e-01, regularization 9.03e-01\n",
      "Lambda = 4.86e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.45e-01, val_loss 3.10e-01, regularization 8.95e-01\n",
      "Lambda = 4.96e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.49e-01, val_loss 3.10e-01, regularization 8.86e-01\n",
      "Lambda = 5.06e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.53e-01, val_loss 3.10e-01, regularization 8.77e-01\n",
      "Lambda = 5.16e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.58e-01, val_loss 3.10e-01, regularization 8.68e-01\n",
      "Lambda = 5.26e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.63e-01, val_loss 3.10e-01, regularization 8.60e-01\n",
      "Lambda = 5.37e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.68e-01, val_loss 3.10e-01, regularization 8.53e-01\n",
      "Lambda = 5.47e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.73e-01, val_loss 3.10e-01, regularization 8.47e-01\n",
      "Lambda = 5.58e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.79e-01, val_loss 3.10e-01, regularization 8.41e-01\n",
      "Lambda = 5.70e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.85e-01, val_loss 3.10e-01, regularization 8.34e-01\n",
      "Lambda = 5.81e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.91e-01, val_loss 3.10e-01, regularization 8.28e-01\n",
      "Lambda = 5.93e-01, selected 16 features in 5 epochs\n",
      "val_objective 7.96e-01, val_loss 3.10e-01, regularization 8.21e-01\n",
      "Lambda = 6.04e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.02e-01, val_loss 3.10e-01, regularization 8.15e-01\n",
      "Lambda = 6.17e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.10e-01, val_loss 3.10e-01, regularization 8.11e-01\n",
      "Lambda = 6.29e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.18e-01, val_loss 3.10e-01, regularization 8.08e-01\n",
      "Lambda = 6.41e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.25e-01, val_loss 3.10e-01, regularization 8.04e-01\n",
      "Lambda = 6.54e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.33e-01, val_loss 3.10e-01, regularization 8.00e-01\n",
      "Lambda = 6.67e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.41e-01, val_loss 3.10e-01, regularization 7.96e-01\n",
      "Lambda = 6.81e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.49e-01, val_loss 3.10e-01, regularization 7.92e-01\n",
      "Lambda = 6.94e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.57e-01, val_loss 3.10e-01, regularization 7.88e-01\n",
      "Lambda = 7.08e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.65e-01, val_loss 3.10e-01, regularization 7.84e-01\n",
      "Lambda = 7.22e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.73e-01, val_loss 3.10e-01, regularization 7.80e-01\n",
      "Lambda = 7.37e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.81e-01, val_loss 3.10e-01, regularization 7.75e-01\n",
      "Lambda = 7.52e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.89e-01, val_loss 3.10e-01, regularization 7.71e-01\n",
      "Lambda = 7.67e-01, selected 16 features in 5 epochs\n",
      "val_objective 8.97e-01, val_loss 3.10e-01, regularization 7.66e-01\n",
      "Lambda = 7.82e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.06e-01, val_loss 3.10e-01, regularization 7.62e-01\n",
      "Lambda = 7.98e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.14e-01, val_loss 3.10e-01, regularization 7.57e-01\n",
      "Lambda = 8.14e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.22e-01, val_loss 3.10e-01, regularization 7.53e-01\n",
      "Lambda = 8.30e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.30e-01, val_loss 3.10e-01, regularization 7.48e-01\n",
      "Lambda = 8.46e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.39e-01, val_loss 3.10e-01, regularization 7.43e-01\n",
      "Lambda = 8.63e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.47e-01, val_loss 3.10e-01, regularization 7.38e-01\n",
      "Lambda = 8.81e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.55e-01, val_loss 3.10e-01, regularization 7.33e-01\n",
      "Lambda = 8.98e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.64e-01, val_loss 3.10e-01, regularization 7.28e-01\n",
      "Lambda = 9.16e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.72e-01, val_loss 3.10e-01, regularization 7.23e-01\n",
      "Lambda = 9.34e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.80e-01, val_loss 3.10e-01, regularization 7.17e-01\n",
      "Lambda = 9.53e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.89e-01, val_loss 3.10e-01, regularization 7.12e-01\n",
      "Lambda = 9.72e-01, selected 16 features in 5 epochs\n",
      "val_objective 9.97e-01, val_loss 3.10e-01, regularization 7.06e-01\n",
      "Lambda = 9.92e-01, selected 16 features in 5 epochs\n",
      "val_objective 1.01e+00, val_loss 3.10e-01, regularization 7.01e-01\n",
      "Lambda = 1.01e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.02e+00, val_loss 3.10e-01, regularization 6.97e-01\n",
      "Lambda = 1.03e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.03e+00, val_loss 3.10e-01, regularization 6.94e-01\n",
      "Lambda = 1.05e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.04e+00, val_loss 3.10e-01, regularization 6.91e-01\n",
      "Lambda = 1.07e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.05e+00, val_loss 3.10e-01, regularization 6.87e-01\n",
      "Lambda = 1.09e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.06e+00, val_loss 3.11e-01, regularization 6.84e-01\n",
      "Lambda = 1.12e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.07e+00, val_loss 3.11e-01, regularization 6.80e-01\n",
      "Lambda = 1.14e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.08e+00, val_loss 3.11e-01, regularization 6.77e-01\n",
      "Lambda = 1.16e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.09e+00, val_loss 3.11e-01, regularization 6.73e-01\n",
      "Lambda = 1.19e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.11e+00, val_loss 3.10e-01, regularization 6.72e-01\n",
      "Lambda = 1.21e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.12e+00, val_loss 3.10e-01, regularization 6.71e-01\n",
      "Lambda = 1.23e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.14e+00, val_loss 3.10e-01, regularization 6.70e-01\n",
      "Lambda = 1.26e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.15e+00, val_loss 3.10e-01, regularization 6.69e-01\n",
      "Lambda = 1.28e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.17e+00, val_loss 3.10e-01, regularization 6.68e-01\n",
      "Lambda = 1.31e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.18e+00, val_loss 3.10e-01, regularization 6.67e-01\n",
      "Lambda = 1.33e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.20e+00, val_loss 3.09e-01, regularization 6.66e-01\n",
      "Lambda = 1.36e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.21e+00, val_loss 3.09e-01, regularization 6.65e-01\n",
      "Lambda = 1.39e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.23e+00, val_loss 3.09e-01, regularization 6.64e-01\n",
      "Lambda = 1.42e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.25e+00, val_loss 3.09e-01, regularization 6.63e-01\n",
      "Lambda = 1.44e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.27e+00, val_loss 3.09e-01, regularization 6.62e-01\n",
      "Lambda = 1.47e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.28e+00, val_loss 3.09e-01, regularization 6.61e-01\n",
      "Lambda = 1.50e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.30e+00, val_loss 3.09e-01, regularization 6.60e-01\n",
      "Lambda = 1.53e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.32e+00, val_loss 3.09e-01, regularization 6.58e-01\n",
      "Lambda = 1.56e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.34e+00, val_loss 3.09e-01, regularization 6.57e-01\n",
      "Lambda = 1.60e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.36e+00, val_loss 3.09e-01, regularization 6.56e-01\n",
      "Lambda = 1.63e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.37e+00, val_loss 3.09e-01, regularization 6.55e-01\n",
      "Lambda = 1.66e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.39e+00, val_loss 3.09e-01, regularization 6.54e-01\n",
      "Lambda = 1.69e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.41e+00, val_loss 3.09e-01, regularization 6.52e-01\n",
      "Lambda = 1.73e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.43e+00, val_loss 3.09e-01, regularization 6.51e-01\n",
      "Lambda = 1.76e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.45e+00, val_loss 3.09e-01, regularization 6.50e-01\n",
      "Lambda = 1.80e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.47e+00, val_loss 3.09e-01, regularization 6.49e-01\n",
      "Lambda = 1.83e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.49e+00, val_loss 3.08e-01, regularization 6.47e-01\n",
      "Lambda = 1.87e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.52e+00, val_loss 3.08e-01, regularization 6.46e-01\n",
      "Lambda = 1.91e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.54e+00, val_loss 3.08e-01, regularization 6.45e-01\n",
      "Lambda = 1.94e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.56e+00, val_loss 3.08e-01, regularization 6.43e-01\n",
      "Lambda = 1.98e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.58e+00, val_loss 3.08e-01, regularization 6.42e-01\n",
      "Lambda = 2.02e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.60e+00, val_loss 3.08e-01, regularization 6.40e-01\n",
      "Lambda = 2.06e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.63e+00, val_loss 3.08e-01, regularization 6.39e-01\n",
      "Lambda = 2.10e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.65e+00, val_loss 3.08e-01, regularization 6.38e-01\n",
      "Lambda = 2.15e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.67e+00, val_loss 3.08e-01, regularization 6.36e-01\n",
      "Lambda = 2.19e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.70e+00, val_loss 3.08e-01, regularization 6.34e-01\n",
      "Lambda = 2.23e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.72e+00, val_loss 3.08e-01, regularization 6.33e-01\n",
      "Lambda = 2.28e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.75e+00, val_loss 3.08e-01, regularization 6.31e-01\n",
      "Lambda = 2.32e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.77e+00, val_loss 3.08e-01, regularization 6.30e-01\n",
      "Lambda = 2.37e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.80e+00, val_loss 3.08e-01, regularization 6.28e-01\n",
      "Lambda = 2.42e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.82e+00, val_loss 3.08e-01, regularization 6.27e-01\n",
      "Lambda = 2.47e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.85e+00, val_loss 3.08e-01, regularization 6.25e-01\n",
      "Lambda = 2.52e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.88e+00, val_loss 3.08e-01, regularization 6.23e-01\n",
      "Lambda = 2.57e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.90e+00, val_loss 3.08e-01, regularization 6.22e-01\n",
      "Lambda = 2.62e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.93e+00, val_loss 3.08e-01, regularization 6.20e-01\n",
      "Lambda = 2.67e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 3.08e-01, regularization 6.18e-01\n",
      "Lambda = 2.72e+00, selected 16 features in 5 epochs\n",
      "val_objective 1.99e+00, val_loss 3.08e-01, regularization 6.17e-01\n",
      "Lambda = 2.78e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.02e+00, val_loss 3.08e-01, regularization 6.15e-01\n",
      "Lambda = 2.83e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.04e+00, val_loss 3.08e-01, regularization 6.13e-01\n",
      "Lambda = 2.89e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.07e+00, val_loss 3.08e-01, regularization 6.11e-01\n",
      "Lambda = 2.95e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.10e+00, val_loss 3.08e-01, regularization 6.09e-01\n",
      "Lambda = 3.01e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.13e+00, val_loss 3.08e-01, regularization 6.07e-01\n",
      "Lambda = 3.07e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.16e+00, val_loss 3.07e-01, regularization 6.06e-01\n",
      "Lambda = 3.13e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.19e+00, val_loss 3.07e-01, regularization 6.04e-01\n",
      "Lambda = 3.19e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.23e+00, val_loss 3.07e-01, regularization 6.02e-01\n",
      "Lambda = 3.25e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.26e+00, val_loss 3.07e-01, regularization 6.00e-01\n",
      "Lambda = 3.32e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.29e+00, val_loss 3.07e-01, regularization 5.98e-01\n",
      "Lambda = 3.39e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.32e+00, val_loss 3.07e-01, regularization 5.95e-01\n",
      "Lambda = 3.45e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.36e+00, val_loss 3.07e-01, regularization 5.93e-01\n",
      "Lambda = 3.52e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.39e+00, val_loss 3.07e-01, regularization 5.91e-01\n",
      "Lambda = 3.59e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.42e+00, val_loss 3.07e-01, regularization 5.89e-01\n",
      "Lambda = 3.66e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.46e+00, val_loss 3.07e-01, regularization 5.87e-01\n",
      "Lambda = 3.74e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.49e+00, val_loss 3.07e-01, regularization 5.85e-01\n",
      "Lambda = 3.81e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.53e+00, val_loss 3.07e-01, regularization 5.83e-01\n",
      "Lambda = 3.89e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.56e+00, val_loss 3.07e-01, regularization 5.80e-01\n",
      "Lambda = 3.97e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.60e+00, val_loss 3.07e-01, regularization 5.78e-01\n",
      "Lambda = 4.05e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.64e+00, val_loss 3.07e-01, regularization 5.76e-01\n",
      "Lambda = 4.13e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.67e+00, val_loss 3.07e-01, regularization 5.73e-01\n",
      "Lambda = 4.21e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.71e+00, val_loss 3.07e-01, regularization 5.71e-01\n",
      "Lambda = 4.29e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.75e+00, val_loss 3.07e-01, regularization 5.68e-01\n",
      "Lambda = 4.38e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.78e+00, val_loss 3.06e-01, regularization 5.66e-01\n",
      "Lambda = 4.47e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.82e+00, val_loss 3.06e-01, regularization 5.63e-01\n",
      "Lambda = 4.56e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.86e+00, val_loss 3.06e-01, regularization 5.61e-01\n",
      "Lambda = 4.65e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.90e+00, val_loss 3.06e-01, regularization 5.58e-01\n",
      "Lambda = 4.74e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.94e+00, val_loss 3.06e-01, regularization 5.56e-01\n",
      "Lambda = 4.83e+00, selected 16 features in 5 epochs\n",
      "val_objective 2.98e+00, val_loss 3.06e-01, regularization 5.53e-01\n",
      "Lambda = 4.93e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.02e+00, val_loss 3.06e-01, regularization 5.51e-01\n",
      "Lambda = 5.03e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.06e+00, val_loss 3.06e-01, regularization 5.48e-01\n",
      "Lambda = 5.13e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.11e+00, val_loss 3.06e-01, regularization 5.46e-01\n",
      "Lambda = 5.23e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.15e+00, val_loss 3.06e-01, regularization 5.43e-01\n",
      "Lambda = 5.34e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.19e+00, val_loss 3.06e-01, regularization 5.41e-01\n",
      "Lambda = 5.44e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.24e+00, val_loss 3.06e-01, regularization 5.38e-01\n",
      "Lambda = 5.55e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.28e+00, val_loss 3.06e-01, regularization 5.35e-01\n",
      "Lambda = 5.66e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.32e+00, val_loss 3.06e-01, regularization 5.33e-01\n",
      "Lambda = 5.78e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.37e+00, val_loss 3.06e-01, regularization 5.30e-01\n",
      "Lambda = 5.89e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.41e+00, val_loss 3.06e-01, regularization 5.27e-01\n",
      "Lambda = 6.01e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.46e+00, val_loss 3.06e-01, regularization 5.24e-01\n",
      "Lambda = 6.13e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.50e+00, val_loss 3.06e-01, regularization 5.21e-01\n",
      "Lambda = 6.25e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.55e+00, val_loss 3.06e-01, regularization 5.18e-01\n",
      "Lambda = 6.38e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.60e+00, val_loss 3.06e-01, regularization 5.16e-01\n",
      "Lambda = 6.51e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.64e+00, val_loss 3.06e-01, regularization 5.13e-01\n",
      "Lambda = 6.64e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.69e+00, val_loss 3.06e-01, regularization 5.10e-01\n",
      "Lambda = 6.77e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.74e+00, val_loss 3.06e-01, regularization 5.07e-01\n",
      "Lambda = 6.91e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.79e+00, val_loss 3.06e-01, regularization 5.04e-01\n",
      "Lambda = 7.04e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.84e+00, val_loss 3.06e-01, regularization 5.01e-01\n",
      "Lambda = 7.18e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.89e+00, val_loss 3.06e-01, regularization 4.98e-01\n",
      "Lambda = 7.33e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.94e+00, val_loss 3.06e-01, regularization 4.95e-01\n",
      "Lambda = 7.47e+00, selected 16 features in 5 epochs\n",
      "val_objective 3.99e+00, val_loss 3.06e-01, regularization 4.92e-01\n",
      "Lambda = 7.62e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.04e+00, val_loss 3.06e-01, regularization 4.89e-01\n",
      "Lambda = 7.78e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.09e+00, val_loss 3.06e-01, regularization 4.86e-01\n",
      "Lambda = 7.93e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.14e+00, val_loss 3.06e-01, regularization 4.83e-01\n",
      "Lambda = 8.09e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.19e+00, val_loss 3.06e-01, regularization 4.80e-01\n",
      "Lambda = 8.25e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.24e+00, val_loss 3.06e-01, regularization 4.77e-01\n",
      "Lambda = 8.42e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.29e+00, val_loss 3.06e-01, regularization 4.74e-01\n",
      "Lambda = 8.59e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.35e+00, val_loss 3.06e-01, regularization 4.70e-01\n",
      "Lambda = 8.76e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.40e+00, val_loss 3.06e-01, regularization 4.67e-01\n",
      "Lambda = 8.93e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.45e+00, val_loss 3.06e-01, regularization 4.64e-01\n",
      "Lambda = 9.11e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.51e+00, val_loss 3.06e-01, regularization 4.61e-01\n",
      "Lambda = 9.29e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.56e+00, val_loss 3.06e-01, regularization 4.58e-01\n",
      "Lambda = 9.48e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.62e+00, val_loss 3.06e-01, regularization 4.55e-01\n",
      "Lambda = 9.67e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.68e+00, val_loss 3.06e-01, regularization 4.52e-01\n",
      "Lambda = 9.86e+00, selected 16 features in 5 epochs\n",
      "val_objective 4.73e+00, val_loss 3.06e-01, regularization 4.49e-01\n",
      "Lambda = 1.01e+01, selected 16 features in 5 epochs\n",
      "val_objective 4.79e+00, val_loss 3.06e-01, regularization 4.46e-01\n",
      "Lambda = 1.03e+01, selected 16 features in 5 epochs\n",
      "val_objective 4.85e+00, val_loss 3.06e-01, regularization 4.43e-01\n",
      "Lambda = 1.05e+01, selected 16 features in 5 epochs\n",
      "val_objective 4.91e+00, val_loss 3.06e-01, regularization 4.40e-01\n",
      "Lambda = 1.07e+01, selected 16 features in 5 epochs\n",
      "val_objective 4.97e+00, val_loss 3.06e-01, regularization 4.37e-01\n",
      "Lambda = 1.09e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.03e+00, val_loss 3.06e-01, regularization 4.34e-01\n",
      "Lambda = 1.11e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.09e+00, val_loss 3.06e-01, regularization 4.31e-01\n",
      "Lambda = 1.13e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.15e+00, val_loss 3.06e-01, regularization 4.28e-01\n",
      "Lambda = 1.16e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.22e+00, val_loss 3.06e-01, regularization 4.25e-01\n",
      "Lambda = 1.18e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.28e+00, val_loss 3.06e-01, regularization 4.22e-01\n",
      "Lambda = 1.20e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.34e+00, val_loss 3.06e-01, regularization 4.19e-01\n",
      "Lambda = 1.23e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.40e+00, val_loss 3.06e-01, regularization 4.15e-01\n",
      "Lambda = 1.25e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.46e+00, val_loss 3.06e-01, regularization 4.12e-01\n",
      "Lambda = 1.28e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.52e+00, val_loss 3.06e-01, regularization 4.09e-01\n",
      "Lambda = 1.30e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.58e+00, val_loss 3.06e-01, regularization 4.06e-01\n",
      "Lambda = 1.33e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.65e+00, val_loss 3.06e-01, regularization 4.02e-01\n",
      "Lambda = 1.35e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.71e+00, val_loss 3.05e-01, regularization 3.99e-01\n",
      "Lambda = 1.38e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.77e+00, val_loss 3.05e-01, regularization 3.96e-01\n",
      "Lambda = 1.41e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.83e+00, val_loss 3.06e-01, regularization 3.92e-01\n",
      "Lambda = 1.44e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.89e+00, val_loss 3.05e-01, regularization 3.89e-01\n",
      "Lambda = 1.47e+01, selected 16 features in 5 epochs\n",
      "val_objective 5.96e+00, val_loss 3.05e-01, regularization 3.86e-01\n",
      "Lambda = 1.49e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.02e+00, val_loss 3.05e-01, regularization 3.82e-01\n",
      "Lambda = 1.52e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.09e+00, val_loss 3.05e-01, regularization 3.79e-01\n",
      "Lambda = 1.56e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.16e+00, val_loss 3.05e-01, regularization 3.76e-01\n",
      "Lambda = 1.59e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.22e+00, val_loss 3.05e-01, regularization 3.73e-01\n",
      "Lambda = 1.62e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.29e+00, val_loss 3.05e-01, regularization 3.70e-01\n",
      "Lambda = 1.65e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.36e+00, val_loss 3.06e-01, regularization 3.67e-01\n",
      "Lambda = 1.68e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.43e+00, val_loss 3.06e-01, regularization 3.64e-01\n",
      "Lambda = 1.72e+01, selected 15 features in 5 epochs\n",
      "val_objective 6.50e+00, val_loss 3.06e-01, regularization 3.61e-01\n",
      "Lambda = 1.75e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.57e+00, val_loss 3.06e-01, regularization 3.58e-01\n",
      "Lambda = 1.79e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.64e+00, val_loss 3.06e-01, regularization 3.55e-01\n",
      "Lambda = 1.82e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.71e+00, val_loss 3.06e-01, regularization 3.52e-01\n",
      "Lambda = 1.86e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.78e+00, val_loss 3.06e-01, regularization 3.48e-01\n",
      "Lambda = 1.90e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.85e+00, val_loss 3.06e-01, regularization 3.45e-01\n",
      "Lambda = 1.93e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.92e+00, val_loss 3.06e-01, regularization 3.42e-01\n",
      "Lambda = 1.97e+01, selected 14 features in 5 epochs\n",
      "val_objective 6.99e+00, val_loss 3.06e-01, regularization 3.39e-01\n",
      "Lambda = 2.01e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.06e+00, val_loss 3.07e-01, regularization 3.36e-01\n",
      "Lambda = 2.05e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.13e+00, val_loss 3.07e-01, regularization 3.33e-01\n",
      "Lambda = 2.09e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.21e+00, val_loss 3.07e-01, regularization 3.30e-01\n",
      "Lambda = 2.13e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.28e+00, val_loss 3.07e-01, regularization 3.27e-01\n",
      "Lambda = 2.18e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.36e+00, val_loss 3.07e-01, regularization 3.24e-01\n",
      "Lambda = 2.22e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.43e+00, val_loss 3.07e-01, regularization 3.21e-01\n",
      "Lambda = 2.27e+01, selected 13 features in 5 epochs\n",
      "val_objective 7.50e+00, val_loss 3.08e-01, regularization 3.17e-01\n",
      "Lambda = 2.31e+01, selected 12 features in 5 epochs\n",
      "val_objective 7.58e+00, val_loss 3.08e-01, regularization 3.14e-01\n",
      "Lambda = 2.36e+01, selected 12 features in 5 epochs\n",
      "val_objective 7.65e+00, val_loss 3.08e-01, regularization 3.11e-01\n",
      "Lambda = 2.40e+01, selected 11 features in 5 epochs\n",
      "val_objective 7.72e+00, val_loss 3.08e-01, regularization 3.08e-01\n",
      "Lambda = 2.45e+01, selected 11 features in 5 epochs\n",
      "val_objective 7.80e+00, val_loss 3.08e-01, regularization 3.05e-01\n",
      "Lambda = 2.50e+01, selected 11 features in 5 epochs\n",
      "val_objective 7.87e+00, val_loss 3.09e-01, regularization 3.02e-01\n",
      "Lambda = 2.55e+01, selected 11 features in 5 epochs\n",
      "val_objective 7.94e+00, val_loss 3.09e-01, regularization 2.99e-01\n",
      "Lambda = 2.60e+01, selected 11 features in 15 epochs\n",
      "val_objective 7.86e+00, val_loss 3.10e-01, regularization 2.90e-01\n",
      "Lambda = 2.65e+01, selected 10 features in 10 epochs\n",
      "val_objective 7.85e+00, val_loss 3.10e-01, regularization 2.84e-01\n",
      "Lambda = 2.71e+01, selected 10 features in 5 epochs\n",
      "val_objective 7.93e+00, val_loss 3.11e-01, regularization 2.81e-01\n",
      "Lambda = 2.76e+01, selected 10 features in 5 epochs\n",
      "val_objective 8.00e+00, val_loss 3.11e-01, regularization 2.79e-01\n",
      "Lambda = 2.82e+01, selected 10 features in 5 epochs\n",
      "val_objective 8.08e+00, val_loss 3.12e-01, regularization 2.76e-01\n",
      "Lambda = 2.87e+01, selected 10 features in 5 epochs\n",
      "val_objective 8.15e+00, val_loss 3.12e-01, regularization 2.73e-01\n",
      "Lambda = 2.93e+01, selected 9 features in 15 epochs\n",
      "val_objective 8.06e+00, val_loss 3.14e-01, regularization 2.64e-01\n",
      "Lambda = 2.99e+01, selected 9 features in 5 epochs\n",
      "val_objective 8.14e+00, val_loss 3.14e-01, regularization 2.62e-01\n",
      "Lambda = 3.05e+01, selected 9 features in 20 epochs\n",
      "val_objective 7.96e+00, val_loss 3.16e-01, regularization 2.51e-01\n",
      "Lambda = 3.11e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.04e+00, val_loss 3.17e-01, regularization 2.48e-01\n",
      "Lambda = 3.17e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.12e+00, val_loss 3.17e-01, regularization 2.46e-01\n",
      "Lambda = 3.24e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.21e+00, val_loss 3.18e-01, regularization 2.44e-01\n",
      "Lambda = 3.30e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.29e+00, val_loss 3.19e-01, regularization 2.42e-01\n",
      "Lambda = 3.37e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.38e+00, val_loss 3.19e-01, regularization 2.39e-01\n",
      "Lambda = 3.43e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.46e+00, val_loss 3.20e-01, regularization 2.37e-01\n",
      "Lambda = 3.50e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.54e+00, val_loss 3.21e-01, regularization 2.35e-01\n",
      "Lambda = 3.57e+01, selected 8 features in 5 epochs\n",
      "val_objective 8.62e+00, val_loss 3.22e-01, regularization 2.32e-01\n",
      "Lambda = 3.64e+01, selected 7 features in 45 epochs\n",
      "val_objective 8.02e+00, val_loss 3.29e-01, regularization 2.11e-01\n",
      "Lambda = 3.72e+01, selected 7 features in 5 epochs\n",
      "val_objective 8.10e+00, val_loss 3.29e-01, regularization 2.09e-01\n",
      "Lambda = 3.79e+01, selected 7 features in 5 epochs\n",
      "val_objective 8.17e+00, val_loss 3.30e-01, regularization 2.07e-01\n",
      "Lambda = 3.87e+01, selected 7 features in 70 epochs\n",
      "val_objective 7.21e+00, val_loss 3.40e-01, regularization 1.78e-01\n",
      "Lambda = 3.94e+01, selected 7 features in 75 epochs\n",
      "val_objective 6.30e+00, val_loss 3.51e-01, regularization 1.51e-01\n",
      "Lambda = 4.02e+01, selected 7 features in 60 epochs\n",
      "val_objective 5.67e+00, val_loss 3.59e-01, regularization 1.32e-01\n",
      "Lambda = 4.10e+01, selected 7 features in 35 epochs\n",
      "val_objective 5.37e+00, val_loss 3.64e-01, regularization 1.22e-01\n",
      "Lambda = 4.19e+01, selected 6 features in 70 epochs\n",
      "val_objective 4.72e+00, val_loss 3.76e-01, regularization 1.04e-01\n",
      "Lambda = 4.27e+01, selected 6 features in 100 epochs\n",
      "val_objective 3.89e+00, val_loss 3.90e-01, regularization 8.19e-02\n",
      "Lambda = 4.36e+01, selected 5 features in 75 epochs\n",
      "val_objective 3.34e+00, val_loss 4.01e-01, regularization 6.76e-02\n",
      "Lambda = 4.44e+01, selected 5 features in 5 epochs\n",
      "val_objective 3.37e+00, val_loss 4.02e-01, regularization 6.68e-02\n",
      "Lambda = 4.53e+01, selected 5 features in 5 epochs\n",
      "val_objective 3.40e+00, val_loss 4.02e-01, regularization 6.61e-02\n",
      "Lambda = 4.62e+01, selected 5 features in 5 epochs\n",
      "val_objective 3.42e+00, val_loss 4.03e-01, regularization 6.53e-02\n",
      "Lambda = 4.71e+01, selected 5 features in 60 epochs\n",
      "val_objective 3.09e+00, val_loss 4.13e-01, regularization 5.67e-02\n",
      "Lambda = 4.81e+01, selected 5 features in 5 epochs\n",
      "val_objective 3.11e+00, val_loss 4.14e-01, regularization 5.61e-02\n",
      "Lambda = 4.90e+01, selected 5 features in 30 epochs\n",
      "val_objective 2.98e+00, val_loss 4.15e-01, regularization 5.23e-02\n",
      "Lambda = 5.00e+01, selected 5 features in 100 epochs\n",
      "val_objective 2.44e+00, val_loss 4.21e-01, regularization 4.04e-02\n",
      "Lambda = 5.10e+01, selected 5 features in 100 epochs\n",
      "val_objective 2.01e+00, val_loss 4.29e-01, regularization 3.10e-02\n",
      "Lambda = 5.20e+01, selected 5 features in 100 epochs\n",
      "val_objective 1.62e+00, val_loss 4.39e-01, regularization 2.27e-02\n",
      "Lambda = 5.31e+01, selected 5 features in 14 epochs\n",
      "val_objective 1.59e+00, val_loss 4.40e-01, regularization 2.17e-02\n",
      "Lambda = 5.42e+01, selected 5 features in 5 epochs\n",
      "val_objective 1.60e+00, val_loss 4.39e-01, regularization 2.15e-02\n",
      "Lambda = 5.52e+01, selected 5 features in 10 epochs\n",
      "val_objective 1.59e+00, val_loss 4.39e-01, regularization 2.09e-02\n",
      "Lambda = 5.63e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.60e+00, val_loss 4.39e-01, regularization 2.06e-02\n",
      "Lambda = 5.75e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.62e+00, val_loss 4.40e-01, regularization 2.05e-02\n",
      "Lambda = 5.86e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.63e+00, val_loss 4.40e-01, regularization 2.03e-02\n",
      "Lambda = 5.98e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.65e+00, val_loss 4.41e-01, regularization 2.02e-02\n",
      "Lambda = 6.10e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.66e+00, val_loss 4.42e-01, regularization 2.00e-02\n",
      "Lambda = 6.22e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.68e+00, val_loss 4.43e-01, regularization 1.98e-02\n",
      "Lambda = 6.34e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.69e+00, val_loss 4.44e-01, regularization 1.96e-02\n",
      "Lambda = 6.47e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.70e+00, val_loss 4.44e-01, regularization 1.95e-02\n",
      "Lambda = 6.60e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.72e+00, val_loss 4.45e-01, regularization 1.93e-02\n",
      "Lambda = 6.73e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.73e+00, val_loss 4.46e-01, regularization 1.91e-02\n",
      "Lambda = 6.87e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.74e+00, val_loss 4.48e-01, regularization 1.88e-02\n",
      "Lambda = 7.00e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.75e+00, val_loss 4.49e-01, regularization 1.86e-02\n",
      "Lambda = 7.15e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.76e+00, val_loss 4.50e-01, regularization 1.84e-02\n",
      "Lambda = 7.29e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.78e+00, val_loss 4.51e-01, regularization 1.82e-02\n",
      "Lambda = 7.43e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.79e+00, val_loss 4.53e-01, regularization 1.79e-02\n",
      "Lambda = 7.58e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.79e+00, val_loss 4.54e-01, regularization 1.77e-02\n",
      "Lambda = 7.73e+01, selected 4 features in 10 epochs\n",
      "val_objective 1.79e+00, val_loss 4.57e-01, regularization 1.72e-02\n",
      "Lambda = 7.89e+01, selected 4 features in 5 epochs\n",
      "val_objective 1.79e+00, val_loss 4.58e-01, regularization 1.69e-02\n",
      "Lambda = 8.05e+01, selected 4 features in 10 epochs\n",
      "val_objective 1.78e+00, val_loss 4.61e-01, regularization 1.64e-02\n",
      "Lambda = 8.21e+01, selected 4 features in 10 epochs\n",
      "val_objective 1.77e+00, val_loss 4.64e-01, regularization 1.60e-02\n",
      "Lambda = 8.37e+01, selected 4 features in 15 epochs\n",
      "val_objective 1.75e+00, val_loss 4.68e-01, regularization 1.53e-02\n",
      "Lambda = 8.54e+01, selected 4 features in 10 epochs\n",
      "val_objective 1.74e+00, val_loss 4.71e-01, regularization 1.48e-02\n",
      "Lambda = 8.71e+01, selected 4 features in 20 epochs\n",
      "val_objective 1.69e+00, val_loss 4.76e-01, regularization 1.39e-02\n",
      "Lambda = 8.88e+01, selected 4 features in 15 epochs\n",
      "val_objective 1.66e+00, val_loss 4.81e-01, regularization 1.33e-02\n",
      "Lambda = 9.06e+01, selected 3 features in 15 epochs\n",
      "val_objective 1.63e+00, val_loss 4.85e-01, regularization 1.27e-02\n",
      "Lambda = 9.24e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.65e+00, val_loss 4.85e-01, regularization 1.26e-02\n",
      "Lambda = 9.43e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.66e+00, val_loss 4.86e-01, regularization 1.24e-02\n",
      "Lambda = 9.62e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.67e+00, val_loss 4.87e-01, regularization 1.23e-02\n",
      "Lambda = 9.81e+01, selected 3 features in 5 epochs\n",
      "val_objective 1.68e+00, val_loss 4.88e-01, regularization 1.22e-02\n",
      "Lambda = 1.00e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.70e+00, val_loss 4.89e-01, regularization 1.21e-02\n",
      "Lambda = 1.02e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.71e+00, val_loss 4.90e-01, regularization 1.20e-02\n",
      "Lambda = 1.04e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.73e+00, val_loss 4.91e-01, regularization 1.19e-02\n",
      "Lambda = 1.06e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.74e+00, val_loss 4.91e-01, regularization 1.18e-02\n",
      "Lambda = 1.08e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.76e+00, val_loss 4.92e-01, regularization 1.17e-02\n",
      "Lambda = 1.10e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.77e+00, val_loss 4.92e-01, regularization 1.16e-02\n",
      "Lambda = 1.13e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.79e+00, val_loss 4.93e-01, regularization 1.15e-02\n",
      "Lambda = 1.15e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.81e+00, val_loss 4.94e-01, regularization 1.14e-02\n",
      "Lambda = 1.17e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.82e+00, val_loss 4.95e-01, regularization 1.13e-02\n",
      "Lambda = 1.20e+02, selected 3 features in 5 epochs\n",
      "val_objective 1.84e+00, val_loss 4.96e-01, regularization 1.12e-02\n",
      "Lambda = 1.22e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.85e+00, val_loss 4.97e-01, regularization 1.11e-02\n",
      "Lambda = 1.24e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.87e+00, val_loss 4.98e-01, regularization 1.10e-02\n",
      "Lambda = 1.27e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.89e+00, val_loss 4.99e-01, regularization 1.09e-02\n",
      "Lambda = 1.29e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.90e+00, val_loss 5.00e-01, regularization 1.08e-02\n",
      "Lambda = 1.32e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.92e+00, val_loss 5.01e-01, regularization 1.08e-02\n",
      "Lambda = 1.35e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.94e+00, val_loss 5.02e-01, regularization 1.07e-02\n",
      "Lambda = 1.37e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.96e+00, val_loss 5.03e-01, regularization 1.06e-02\n",
      "Lambda = 1.40e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.97e+00, val_loss 5.04e-01, regularization 1.05e-02\n",
      "Lambda = 1.43e+02, selected 2 features in 5 epochs\n",
      "val_objective 1.99e+00, val_loss 5.05e-01, regularization 1.04e-02\n",
      "Lambda = 1.46e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.01e+00, val_loss 5.06e-01, regularization 1.03e-02\n",
      "Lambda = 1.49e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.02e+00, val_loss 5.07e-01, regularization 1.02e-02\n",
      "Lambda = 1.52e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.04e+00, val_loss 5.08e-01, regularization 1.01e-02\n",
      "Lambda = 1.55e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.06e+00, val_loss 5.09e-01, regularization 1.00e-02\n",
      "Lambda = 1.58e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.08e+00, val_loss 5.11e-01, regularization 9.92e-03\n",
      "Lambda = 1.61e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.09e+00, val_loss 5.12e-01, regularization 9.82e-03\n",
      "Lambda = 1.64e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.11e+00, val_loss 5.13e-01, regularization 9.73e-03\n",
      "Lambda = 1.67e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.13e+00, val_loss 5.15e-01, regularization 9.63e-03\n",
      "Lambda = 1.71e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.14e+00, val_loss 5.16e-01, regularization 9.52e-03\n",
      "Lambda = 1.74e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.16e+00, val_loss 5.18e-01, regularization 9.42e-03\n",
      "Lambda = 1.78e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.17e+00, val_loss 5.19e-01, regularization 9.32e-03\n",
      "Lambda = 1.81e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.19e+00, val_loss 5.21e-01, regularization 9.21e-03\n",
      "Lambda = 1.85e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.21e+00, val_loss 5.23e-01, regularization 9.10e-03\n",
      "Lambda = 1.89e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.22e+00, val_loss 5.24e-01, regularization 8.99e-03\n",
      "Lambda = 1.92e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.23e+00, val_loss 5.26e-01, regularization 8.88e-03\n",
      "Lambda = 1.96e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.25e+00, val_loss 5.28e-01, regularization 8.77e-03\n",
      "Lambda = 2.00e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.26e+00, val_loss 5.30e-01, regularization 8.66e-03\n",
      "Lambda = 2.04e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.28e+00, val_loss 5.32e-01, regularization 8.54e-03\n",
      "Lambda = 2.08e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.29e+00, val_loss 5.34e-01, regularization 8.43e-03\n",
      "Lambda = 2.12e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.30e+00, val_loss 5.36e-01, regularization 8.31e-03\n",
      "Lambda = 2.17e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.31e+00, val_loss 5.39e-01, regularization 8.19e-03\n",
      "Lambda = 2.21e+02, selected 2 features in 10 epochs\n",
      "val_objective 2.31e+00, val_loss 5.42e-01, regularization 8.00e-03\n",
      "Lambda = 2.25e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.33e+00, val_loss 5.44e-01, regularization 7.92e-03\n",
      "Lambda = 2.30e+02, selected 2 features in 5 epochs\n",
      "val_objective 2.34e+00, val_loss 5.46e-01, regularization 7.82e-03\n",
      "Lambda = 2.34e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.37e+00, val_loss 5.47e-01, regularization 7.76e-03\n",
      "Lambda = 2.39e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.39e+00, val_loss 5.48e-01, regularization 7.69e-03\n",
      "Lambda = 2.44e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.41e+00, val_loss 5.49e-01, regularization 7.62e-03\n",
      "Lambda = 2.49e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.43e+00, val_loss 5.51e-01, regularization 7.56e-03\n",
      "Lambda = 2.54e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.45e+00, val_loss 5.52e-01, regularization 7.49e-03\n",
      "Lambda = 2.59e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.47e+00, val_loss 5.54e-01, regularization 7.42e-03\n",
      "Lambda = 2.64e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.49e+00, val_loss 5.55e-01, regularization 7.35e-03\n",
      "Lambda = 2.69e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.52e+00, val_loss 5.57e-01, regularization 7.28e-03\n",
      "Lambda = 2.75e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.54e+00, val_loss 5.58e-01, regularization 7.21e-03\n",
      "Lambda = 2.80e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.56e+00, val_loss 5.60e-01, regularization 7.14e-03\n",
      "Lambda = 2.86e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.58e+00, val_loss 5.61e-01, regularization 7.07e-03\n",
      "Lambda = 2.91e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.60e+00, val_loss 5.63e-01, regularization 7.00e-03\n",
      "Lambda = 2.97e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.62e+00, val_loss 5.65e-01, regularization 6.92e-03\n",
      "Lambda = 3.03e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.64e+00, val_loss 5.67e-01, regularization 6.85e-03\n",
      "Lambda = 3.09e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.66e+00, val_loss 5.68e-01, regularization 6.78e-03\n",
      "Lambda = 3.16e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.69e+00, val_loss 5.70e-01, regularization 6.70e-03\n",
      "Lambda = 3.22e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.71e+00, val_loss 5.72e-01, regularization 6.63e-03\n",
      "Lambda = 3.28e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.73e+00, val_loss 5.74e-01, regularization 6.55e-03\n",
      "Lambda = 3.35e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.75e+00, val_loss 5.76e-01, regularization 6.48e-03\n",
      "Lambda = 3.42e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.77e+00, val_loss 5.79e-01, regularization 6.40e-03\n",
      "Lambda = 3.48e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.78e+00, val_loss 5.81e-01, regularization 6.33e-03\n",
      "Lambda = 3.55e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.80e+00, val_loss 5.83e-01, regularization 6.25e-03\n",
      "Lambda = 3.62e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.82e+00, val_loss 5.86e-01, regularization 6.17e-03\n",
      "Lambda = 3.70e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.84e+00, val_loss 5.88e-01, regularization 6.09e-03\n",
      "Lambda = 3.77e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.86e+00, val_loss 5.91e-01, regularization 6.01e-03\n",
      "Lambda = 3.85e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.87e+00, val_loss 5.94e-01, regularization 5.93e-03\n",
      "Lambda = 3.92e+02, selected 1 features in 10 epochs\n",
      "val_objective 2.87e+00, val_loss 5.98e-01, regularization 5.80e-03\n",
      "Lambda = 4.00e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.90e+00, val_loss 5.99e-01, regularization 5.75e-03\n",
      "Lambda = 4.08e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.92e+00, val_loss 6.01e-01, regularization 5.68e-03\n",
      "Lambda = 4.16e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.94e+00, val_loss 6.04e-01, regularization 5.61e-03\n",
      "Lambda = 4.25e+02, selected 1 features in 10 epochs\n",
      "val_objective 2.93e+00, val_loss 6.09e-01, regularization 5.47e-03\n",
      "Lambda = 4.33e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.96e+00, val_loss 6.11e-01, regularization 5.41e-03\n",
      "Lambda = 4.42e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.97e+00, val_loss 6.14e-01, regularization 5.34e-03\n",
      "Lambda = 4.51e+02, selected 1 features in 10 epochs\n",
      "val_objective 2.97e+00, val_loss 6.19e-01, regularization 5.21e-03\n",
      "Lambda = 4.60e+02, selected 1 features in 5 epochs\n",
      "val_objective 2.99e+00, val_loss 6.21e-01, regularization 5.15e-03\n",
      "Lambda = 4.69e+02, selected 1 features in 10 epochs\n",
      "val_objective 2.99e+00, val_loss 6.26e-01, regularization 5.03e-03\n",
      "Lambda = 4.78e+02, selected 1 features in 5 epochs\n",
      "val_objective 3.01e+00, val_loss 6.28e-01, regularization 4.97e-03\n",
      "Lambda = 4.88e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.00e+00, val_loss 6.33e-01, regularization 4.86e-03\n",
      "Lambda = 4.98e+02, selected 1 features in 5 epochs\n",
      "val_objective 3.02e+00, val_loss 6.36e-01, regularization 4.80e-03\n",
      "Lambda = 5.07e+02, selected 1 features in 9 epochs\n",
      "val_objective 3.02e+00, val_loss 6.41e-01, regularization 4.68e-03\n",
      "Lambda = 5.18e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.02e+00, val_loss 6.45e-01, regularization 4.58e-03\n",
      "Lambda = 5.28e+02, selected 1 features in 5 epochs\n",
      "val_objective 3.04e+00, val_loss 6.48e-01, regularization 4.52e-03\n",
      "Lambda = 5.39e+02, selected 1 features in 9 epochs\n",
      "val_objective 3.02e+00, val_loss 6.53e-01, regularization 4.40e-03\n",
      "Lambda = 5.49e+02, selected 1 features in 9 epochs\n",
      "val_objective 3.02e+00, val_loss 6.58e-01, regularization 4.30e-03\n",
      "Lambda = 5.60e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.02e+00, val_loss 6.63e-01, regularization 4.20e-03\n",
      "Lambda = 5.72e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.02e+00, val_loss 6.67e-01, regularization 4.12e-03\n",
      "Lambda = 5.83e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.02e+00, val_loss 6.72e-01, regularization 4.03e-03\n",
      "Lambda = 5.95e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.02e+00, val_loss 6.76e-01, regularization 3.93e-03\n",
      "Lambda = 6.06e+02, selected 1 features in 10 epochs\n",
      "val_objective 3.01e+00, val_loss 6.81e-01, regularization 3.84e-03\n",
      "Lambda = 6.19e+02, selected 1 features in 9 epochs\n",
      "val_objective 3.00e+00, val_loss 6.87e-01, regularization 3.74e-03\n",
      "Lambda = 6.31e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.99e+00, val_loss 6.93e-01, regularization 3.64e-03\n",
      "Lambda = 6.44e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.97e+00, val_loss 6.99e-01, regularization 3.53e-03\n",
      "Lambda = 6.56e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.95e+00, val_loss 7.05e-01, regularization 3.43e-03\n",
      "Lambda = 6.70e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.94e+00, val_loss 7.12e-01, regularization 3.32e-03\n",
      "Lambda = 6.83e+02, selected 1 features in 8 epochs\n",
      "val_objective 2.92e+00, val_loss 7.18e-01, regularization 3.23e-03\n",
      "Lambda = 6.97e+02, selected 1 features in 13 epochs\n",
      "val_objective 2.89e+00, val_loss 7.25e-01, regularization 3.11e-03\n",
      "Lambda = 7.11e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.89e+00, val_loss 7.30e-01, regularization 3.03e-03\n",
      "Lambda = 7.25e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.85e+00, val_loss 7.38e-01, regularization 2.92e-03\n",
      "Lambda = 7.39e+02, selected 1 features in 13 epochs\n",
      "val_objective 2.82e+00, val_loss 7.45e-01, regularization 2.81e-03\n",
      "Lambda = 7.54e+02, selected 1 features in 9 epochs\n",
      "val_objective 2.80e+00, val_loss 7.51e-01, regularization 2.72e-03\n",
      "Lambda = 7.69e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.75e+00, val_loss 7.61e-01, regularization 2.59e-03\n",
      "Lambda = 7.85e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.72e+00, val_loss 7.69e-01, regularization 2.48e-03\n",
      "Lambda = 8.00e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.68e+00, val_loss 7.77e-01, regularization 2.38e-03\n",
      "Lambda = 8.16e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.64e+00, val_loss 7.85e-01, regularization 2.27e-03\n",
      "Lambda = 8.33e+02, selected 1 features in 11 epochs\n",
      "val_objective 2.59e+00, val_loss 7.94e-01, regularization 2.16e-03\n",
      "Lambda = 8.49e+02, selected 1 features in 14 epochs\n",
      "val_objective 2.53e+00, val_loss 8.05e-01, regularization 2.03e-03\n",
      "Lambda = 8.66e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.48e+00, val_loss 8.13e-01, regularization 1.93e-03\n",
      "Lambda = 8.84e+02, selected 1 features in 14 epochs\n",
      "val_objective 2.42e+00, val_loss 8.24e-01, regularization 1.81e-03\n",
      "Lambda = 9.01e+02, selected 1 features in 14 epochs\n",
      "val_objective 2.36e+00, val_loss 8.34e-01, regularization 1.69e-03\n",
      "Lambda = 9.19e+02, selected 1 features in 14 epochs\n",
      "val_objective 2.29e+00, val_loss 8.45e-01, regularization 1.58e-03\n",
      "Lambda = 9.38e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.22e+00, val_loss 8.56e-01, regularization 1.45e-03\n",
      "Lambda = 9.56e+02, selected 1 features in 14 epochs\n",
      "val_objective 2.13e+00, val_loss 8.69e-01, regularization 1.32e-03\n",
      "Lambda = 9.75e+02, selected 1 features in 12 epochs\n",
      "val_objective 2.05e+00, val_loss 8.81e-01, regularization 1.20e-03\n",
      "Lambda = 9.95e+02, selected 1 features in 14 epochs\n",
      "val_objective 1.95e+00, val_loss 8.94e-01, regularization 1.06e-03\n",
      "Lambda = 1.01e+03, selected 1 features in 14 epochs\n",
      "val_objective 1.86e+00, val_loss 9.07e-01, regularization 9.35e-04\n",
      "Lambda = 1.04e+03, selected 1 features in 14 epochs\n",
      "val_objective 1.75e+00, val_loss 9.21e-01, regularization 8.01e-04\n",
      "Lambda = 1.06e+03, selected 1 features in 16 epochs\n",
      "val_objective 1.64e+00, val_loss 9.36e-01, regularization 6.63e-04\n",
      "Lambda = 1.08e+03, selected 1 features in 16 epochs\n",
      "val_objective 1.52e+00, val_loss 9.51e-01, regularization 5.29e-04\n",
      "Lambda = 1.10e+03, selected 1 features in 15 epochs\n",
      "val_objective 1.39e+00, val_loss 9.68e-01, regularization 3.81e-04\n",
      "Lambda = 1.12e+03, selected 1 features in 19 epochs\n",
      "val_objective 1.25e+00, val_loss 9.84e-01, regularization 2.35e-04\n",
      "Lambda = 1.14e+03, selected 1 features in 20 epochs\n",
      "val_objective 1.11e+00, val_loss 1.00e+00, regularization 9.33e-05\n",
      "Lambda = 1.17e+03, selected 0 features in 10 epochs\n",
      "val_objective 1.01e+00, val_loss 1.01e+00, regularization 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lassonet import LassoNetRegressor\n",
    "\n",
    "dataset = fetch_california_housing() \n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "_, true_features = X.shape\n",
    "\n",
    "# add dummy feature\n",
    "X = np.concatenate([X, np.random.randn(*X.shape)], axis=1)\n",
    "feature_names = list(dataset.feature_names) + [\"fake\"] * true_features\n",
    "\n",
    "# standardize\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = scale(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = LassoNetRegressor(hidden_dims=(10,), verbose=True, patience=(100, 5))\n",
    "path = model.path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48105b37-e8f2-42be-aa80-fc9fe7078985",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49d69907-6079-493f-9948-e1391f24b114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_path(model, path, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9c7e4ca-fb1b-4cab-88ae-21b9e8bf5b53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Feature Selection path\n",
    "n_selected = []\n",
    "mse = []\n",
    "lambda_ = []\n",
    "\n",
    "for save in path:\n",
    "    model.load(save.state_dict)\n",
    "    y_pred = model.predict(X_test)\n",
    "    n_selected.append(save.selected.sum().cpu().numpy())\n",
    "    mse.append(mean_squared_error(y_test, y_pred))\n",
    "    lambda_.append(save.lambda_)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.grid(True)\n",
    "plt.plot(n_selected, mse, \".-\")\n",
    "plt.xlabel(\"number of selected features\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.grid(True)\n",
    "plt.plot(lambda_, mse, \".-\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.grid(True)\n",
    "plt.plot(lambda_, n_selected, \".-\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"number of selected features\")\n",
    "\n",
    "plt.savefig(\"./results/lassonet/california-select-features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "309223e1-4423-4b68-bc75-d6f137c6939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importance(X, model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146a93a-92db-4bd8-9dff-9d66842c0e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "bfda6998-3dfe-48f6-ad47-b09aacc2feab",
    "c43c05fc-4ef5-4262-a5a9-1ceb96fe2568",
    "53124539-1002-4340-ac1d-37c9c5c8d7cc",
    "00cc1ace-632a-4f89-aa3d-bf1d67c8033f",
    "DOP-scgUpPHv",
    "6947d869-f264-401b-810c-c1ec61d00e6f",
    "87aedcd1-1560-4c30-9453-ed25c6380b27",
    "adcfa927-21ac-445b-b0fb-3173df85f9c4",
    "650194b7-0dfa-45d2-8145-711dfeed0c06",
    "3906832a-5e54-4889-af0e-e6ce3a73bcfb",
    "6316c7c1-5270-4f2a-8c5e-4d1bd636d2cb",
    "70e41696-220e-410e-a558-5b1a5efbc369"
   ],
   "name": "2-EBM.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "101ac7f09dba69cde75534be8081c80174d03be9832ab662aa46cf8ab6d34c8d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0744f9ce664e49c183d2708a1cc9916a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "086c119e987a46fbbd3c7db012f50dfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0eb84763937c4013801d536c22520d63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0163cbca9d042e6ad3c268f0849f805",
      "placeholder": "â",
      "style": "IPY_MODEL_1138717d01804531b2e594ef7c6e2440",
      "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "0fa57d8e4c7042c9bc2f89bf07308793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ffbdd8f828b4111a5aa5b6bd5618f1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2687648435c04721a10b2264b79238ed",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f77efffbce644ab905358fc79220b36",
      "value": 1
     }
    },
    "1138717d01804531b2e594ef7c6e2440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12a0cc8d47f34f6fb42984319d8fc87c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee3086784e3b434daa66b8ae3f4e769c",
      "placeholder": "â",
      "style": "IPY_MODEL_5a22e14491944c49940dc2a9845f0d0b",
      "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "16fa08fc9efd4aefb863a4fac98491aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18650cb2214942babc81da9650998890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a3bd2d57a234ae6897b0f7abddfa076": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f77efffbce644ab905358fc79220b36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "203e4005eb0f4c0cb1c41d6894ac9023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "251e18d448e84bf79325c42e8ddf336c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2687648435c04721a10b2264b79238ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38efd34173e84756a7cea31c29b13aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a631a021e5c64582be3ed75396653728",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0744f9ce664e49c183d2708a1cc9916a",
      "value": 1
     }
    },
    "425b30b73f564c64a2f6777549f2b763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_251e18d448e84bf79325c42e8ddf336c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6895d7d2c9fa44258a4e9e289e1deaa8",
      "value": 1
     }
    },
    "439da5bd0b9e4f45b7655a2505f3dc90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554f8eb070eb4a96bc193c3dcad4ce0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a22e14491944c49940dc2a9845f0d0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "670ba83a13824b1390bc3758e325e089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9630315efbea403eb6840751b40043ed",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fa57d8e4c7042c9bc2f89bf07308793",
      "value": 1
     }
    },
    "6895d7d2c9fa44258a4e9e289e1deaa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "703da1f8122948809ff0c61d4e19326e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c602a5bb34ea47289df10d5dcf4ab135",
       "IPY_MODEL_0ffbdd8f828b4111a5aa5b6bd5618f1e"
      ],
      "layout": "IPY_MODEL_d4e8bccf39304e47b8770ae86ff7784d"
     }
    },
    "7f56791935684275b4a90c16b6cc0f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9630315efbea403eb6840751b40043ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0163cbca9d042e6ad3c268f0849f805": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a631a021e5c64582be3ed75396653728": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a835a67380dc492eb5b31d2c4c9bd6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7445d6b764d4e9a9c85fd0082b4168d",
       "IPY_MODEL_a83866a9c1c54c0bb84f70fc48051a07"
      ],
      "layout": "IPY_MODEL_c21ed167418649a39b8986847aa4509c"
     }
    },
    "a83866a9c1c54c0bb84f70fc48051a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_439da5bd0b9e4f45b7655a2505f3dc90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18650cb2214942babc81da9650998890",
      "value": 1
     }
    },
    "b4440a2be1e142bc9e9ba82fb4a18e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd2d647f05a34355bed335ef7a026f14",
       "IPY_MODEL_425b30b73f564c64a2f6777549f2b763"
      ],
      "layout": "IPY_MODEL_554f8eb070eb4a96bc193c3dcad4ce0f"
     }
    },
    "c21ed167418649a39b8986847aa4509c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2898615576247f498f1e24532a94b9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c602a5bb34ea47289df10d5dcf4ab135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da60682d0cd14a9993da61469630117d",
      "placeholder": "â",
      "style": "IPY_MODEL_f9442fd14cac4e8fab04dd4f061a0543",
      "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "d4e8bccf39304e47b8770ae86ff7784d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7445d6b764d4e9a9c85fd0082b4168d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a3bd2d57a234ae6897b0f7abddfa076",
      "placeholder": "â",
      "style": "IPY_MODEL_16fa08fc9efd4aefb863a4fac98491aa",
      "value": "0.010 MB of 0.010 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "da60682d0cd14a9993da61469630117d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2d647f05a34355bed335ef7a026f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2898615576247f498f1e24532a94b9d",
      "placeholder": "â",
      "style": "IPY_MODEL_086c119e987a46fbbd3c7db012f50dfb",
      "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "ee3086784e3b434daa66b8ae3f4e769c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10d99b45f094b9fa4506c91ae795020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0eb84763937c4013801d536c22520d63",
       "IPY_MODEL_38efd34173e84756a7cea31c29b13aeb"
      ],
      "layout": "IPY_MODEL_7f56791935684275b4a90c16b6cc0f81"
     }
    },
    "f2a5974fe70a4ad7a7b818c1e99930bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12a0cc8d47f34f6fb42984319d8fc87c",
       "IPY_MODEL_670ba83a13824b1390bc3758e325e089"
      ],
      "layout": "IPY_MODEL_203e4005eb0f4c0cb1c41d6894ac9023"
     }
    },
    "f9442fd14cac4e8fab04dd4f061a0543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
